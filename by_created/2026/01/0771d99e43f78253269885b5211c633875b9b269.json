{
  "id": "0771d99e43f78253269885b5211c633875b9b269",
  "url": "https://www.r-bloggers.com/2026/01/from-scripts-to-pipelines-in-the-age-of-llms/",
  "created_at_utc": "2026-01-13T18:26:28Z",
  "crawled_at_utc": "2026-01-13T18:26:28Z",
  "html_title": "From scripts to pipelines in the age of LLMs | R-bloggers",
  "meta_description": "I was recently reading Davis Vaughan’s blog post Semi-automating 200 Pull Requests with Claude Code and it really resonated with me, as I’ve been using LLMs for tedious tasks like that for some time now. Davis’s key insight: structure = su...",
  "data": {
    "url": "https://www.r-bloggers.com/2026/01/from-scripts-to-pipelines-in-the-age-of-llms/",
    "canonical_url": "https://www.r-bloggers.com/2026/01/from-scripts-to-pipelines-in-the-age-of-llms/",
    "html_title": "From scripts to pipelines in the age of LLMs | R-bloggers",
    "h1_title": "R-bloggers",
    "meta_description": "I was recently reading Davis Vaughan’s blog post Semi-automating 200 Pull Requests with Claude Code and it really resonated with me, as I’ve been using LLMs for tedious tasks like that for some time now. Davis’s key insight: structure = su...",
    "meta_keywords": null,
    "og_title": "From scripts to pipelines in the age of LLMs | R-bloggers",
    "og_description": "I was recently reading Davis Vaughan’s blog post Semi-automating 200 Pull Requests with Claude Code and it really resonated with me, as I’ve been using LLMs for tedious tasks like that for some time now. Davis’s key insight: structure = su...",
    "og_image": "https://b-rodrigues.github.io/assets/img/chad_beach.png",
    "twitter_title": "From scripts to pipelines in the age of LLMs | R-bloggers",
    "twitter_description": "I was recently reading Davis Vaughan’s blog post Semi-automating 200 Pull Requests with Claude Code and it really resonated with me, as I’ve been using LLMs for tedious tasks like that for some time now. Davis’s key insight: structure = su...",
    "raw_jsonld_article": null,
    "article_headline": null,
    "article_section": null,
    "article_tags": null,
    "article_author": null,
    "article_published": null,
    "article_modified": null,
    "main_text": "From scripts to pipelines in the age of LLMs\nPosted on\nJanuary 12, 2026\nby\nEconometrics and Free Software\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nEconometrics and Free Software\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nI was recently reading Davis Vaughan’s blog post\nSemi-automating 200 Pull Requests with Claude Code\nand it really resonated with me, as I’ve been using LLMs for tedious tasks like that for some time now. Davis’s key insight:\nstructure = success\n. When you can scope a task tightly and provide clear context, LLMs become genuinely useful tools.\nIf you’ve been following my work, you know that reproducible pipelines have been my main focus for some time now. It’s the reason I wrote\n{rix}\nfor reproducible R environments,\n{rixpress}\nfor declarative pipelines, and even a Python port called\nryxpress\n. I genuinely believe these tools make data science better: more reproducible, more debuggable, more shareable.\nBut I also know that getting people to adopt new tools is hard. Learning a new way of structuring your code takes time and effort, and most people are busy enough already. Here’s where LLMs enter the picture: they can help translate your existing scripts into this more structured format. You provide your monolithic script, explain what you want, and the LLM does the grunt work of restructuring it.\nThe typical way we write analytics scripts (long chains of\n%>%\ncalls in R or method-chaining in Python) works fine for interactive exploration, but quickly turns into spaghetti that’s hard to modify, test, or debug. Take\nmy old Luxembourg Airport analysis\nas an example: it works, but turning that kind of script into a proper pipeline with caching, explicit dependencies, and testability is tedious work.\nBut we’re in 2026 where LLMs now make this trivial.\nFrom implicit to explicit: translating a script into a rixpress pipeline\nLet me show you what I mean by translating that old Luxembourg Airport data cleaning code into a\n{rixpress}\npipeline. The original script uses continuous\n%>%\nchaining, standard tidyverse style. The\n{rixpress}\nversion makes every intermediate step explicit.\nBut here’s the thing: LLMs don’t know about\n{rixpress}\nout of the box. It’s a relatively new package, and it’s not in their training data (or if it is, it’s outdated). So I wrote another tool called\npkgctx\nthat extracts structured, LLM-ready API specifications from R or Python packages (and guess what, I did not write a single line of code of that tool, LLMs did).\nThe idea is simple: run\npkgctx r rixpress > rixpress.ctx.yaml\nand you get a compact YAML file describing every function, its arguments, and its purpose. Feed that to an LLM, and suddenly it “knows” the package. All my packages now have such a file generated on each push thanks to GitHub Actions. Here’s how my conversation went:\nMe:\nI want to use a package called rixpress, but I am not familiar with it. You’ll help me, and here is a file with a detailed description of the API, for context.\n[uploaded rixpress.ctx.yaml]\nLLM:\nGot it. I’ll use this API specification as the authoritative reference for\nrixpress\nand help you write correct, idiomatic pipelines with it.\nA few orientation points to set the frame (no action required yet):\nrixpress is declarative\n: you describe\nderivations\n(\nrxp_r()\n,\nrxp_py()\n,\nrxp_qmd()\n, …), then materialize them with\nrxp_populate()\nand\nrxp_make()\n.\nData flows through the DAG\nvia serialized artifacts (RDS / pickle / Julia Serialization), not in-memory objects.\nLanguage boundaries are explicit\n(\nrxp_r2py()\n,\nrxp_py2r()\n).\nNix is the execution engine\n;\ndefault.nix\n(or equivalents) define the runtime environment.\nWhen you’re ready, tell me what you want to do […]\nThen I simply asked:\nMe:\nHelp me translate this R script into a rixpress pipeline:\n[pasted the old script]\nAnd that’s how I got a working\n{rixpress}\npipeline. The LLM did the tedious restructuring; I reviewed the output, made minor tweaks, and was done. The combination of\npkgctx\nfor context and a clear task (“translate this script”) made the LLM genuinely useful.\nNow let’s look at what the translated pipeline looks like. First, let’s assume:\nThe data file\navia_par_lu.tsv\nis in the project directory\nRequired R packages are available via\ndefault.nix\n(we’ll also use an LLM for this one)\nThe project has been initialized with\nrxp_init()\n(this sets up two skeleton files to get started quickly)\nClick to expand the full rixpress pipeline\nlibrary(rixpress)\n\n# Step 0: Load the data\navia <- rxp_r_file(\n  name = avia,\n  path = \"avia_par_lu.tsv\",\n  read_function = readr::read_tsv\n)\n\n# Step 1: Select and reshape (wide → long)\navia_long <- rxp_r(\n  name = avia_long,\n  expr =\n    avia %>%\n      select(\"unit,tra_meas,airp_pr\\\\time\", contains(\"20\")) %>%\n      gather(date, passengers, -`unit,tra_meas,airp_pr\\\\time`)\n)\n\n# Step 2: Split composite key column\navia_split <- rxp_r(\n  name = avia_split,\n  expr =\n    avia_long %>%\n      separate(\n        col = `unit,tra_meas,airp_pr\\\\time`,\n        into = c(\"unit\", \"tra_meas\", \"air_pr\\\\time\"),\n        sep = \",\"\n      )\n)\n\n# Step 3: Recode transport measure\navia_recode_tra_meas <- rxp_r(\n  name = avia_recode_tra_meas,\n  expr =\n    avia_split %>%\n      mutate(\n        tra_meas = fct_recode(\n          tra_meas,\n          `Passengers on board` = \"PAS_BRD\",\n          `Passengers on board (arrivals)` = \"PAS_BRD_ARR\",\n          `Passengers on board (departures)` = \"PAS_BRD_DEP\",\n          `Passengers carried` = \"PAS_CRD\",\n          `Passengers carried (arrival)` = \"PAS_CRD_ARR\",\n          `Passengers carried (departures)` = \"PAS_CRD_DEP\",\n          `Passengers seats available` = \"ST_PAS\",\n          `Passengers seats available (arrivals)` = \"ST_PAS_ARR\",\n          `Passengers seats available (departures)` = \"ST_PAS_DEP\",\n          `Commercial passenger air flights` = \"CAF_PAS\",\n          `Commercial passenger air flights (arrivals)` = \"CAF_PAS_ARR\",\n          `Commercial passenger air flights (departures)` = \"CAF_PAS_DEP\"\n        )\n      )\n)\n\n# Step 4: Recode unit\navia_recode_unit <- rxp_r(\n  name = avia_recode_unit,\n  expr =\n    avia_recode_tra_meas %>%\n      mutate(\n        unit = fct_recode(\n          unit,\n          Passenger = \"PAS\",\n          Flight = \"FLIGHT\",\n          `Seats and berths` = \"SEAT\"\n        )\n      )\n)\n\n# Step 5: Recode destination\navia_recode_destination <- rxp_r(\n  name = avia_recode_destination,\n  expr =\n    avia_recode_unit %>%\n      mutate(\n        destination = fct_recode(\n          `air_pr\\\\time`,\n          `WIEN-SCHWECHAT` = \"LU_ELLX_AT_LOWW\",\n          `BRUSSELS` = \"LU_ELLX_BE_EBBR\",\n          `GENEVA` = \"LU_ELLX_CH_LSGG\",\n          `ZURICH` = \"LU_ELLX_CH_LSZH\",\n          `FRANKFURT/MAIN` = \"LU_ELLX_DE_EDDF\",\n          `HAMBURG` = \"LU_ELLX_DE_EDDH\",\n          `BERLIN-TEMPELHOF` = \"LU_ELLX_DE_EDDI\",\n          `MUENCHEN` = \"LU_ELLX_DE_EDDM\",\n          `SAARBRUECKEN` = \"LU_ELLX_DE_EDDR\",\n          `BERLIN-TEGEL` = \"LU_ELLX_DE_EDDT\",\n          `KOBENHAVN/KASTRUP` = \"LU_ELLX_DK_EKCH\",\n          `HURGHADA / INTL` = \"LU_ELLX_EG_HEGN\",\n          `IRAKLION/NIKOS KAZANTZAKIS` = \"LU_ELLX_EL_LGIR\",\n          `FUERTEVENTURA` = \"LU_ELLX_ES_GCFV\",\n          `GRAN CANARIA` = \"LU_ELLX_ES_GCLP\",\n          `LANZAROTE` = \"LU_ELLX_ES_GCRR\",\n          `TENERIFE SUR/REINA SOFIA` = \"LU_ELLX_ES_GCTS\",\n          `BARCELONA/EL PRAT` = \"LU_ELLX_ES_LEBL\",\n          `ADOLFO SUAREZ MADRID-BARAJAS` = \"LU_ELLX_ES_LEMD\",\n          `MALAGA/COSTA DEL SOL` = \"LU_ELLX_ES_LEMG\",\n          `PALMA DE MALLORCA` = \"LU_ELLX_ES_LEPA\",\n          `SYSTEM - PARIS` = \"LU_ELLX_FR_LF90\",\n          `NICE-COTE D'AZUR` = \"LU_ELLX_FR_LFMN\",\n          `PARIS-CHARLES DE GAULLE` = \"LU_ELLX_FR_LFPG\",\n          `STRASBOURG-ENTZHEIM` = \"LU_ELLX_FR_LFST\",\n          `KEFLAVIK` = \"LU_ELLX_IS_BIKF\",\n          `MILANO/MALPENSA` = \"LU_ELLX_IT_LIMC\",\n          `BERGAMO/ORIO AL SERIO` = \"LU_ELLX_IT_LIME\",\n          `ROMA/FIUMICINO` = \"LU_ELLX_IT_LIRF\",\n          `AGADIR/AL MASSIRA` = \"LU_ELLX_MA_GMAD\",\n          `AMSTERDAM/SCHIPHOL` = \"LU_ELLX_NL_EHAM\",\n          `WARSZAWA/CHOPINA` = \"LU_ELLX_PL_EPWA\",\n          `PORTO` = \"LU_ELLX_PT_LPPR\",\n          `LISBOA` = \"LU_ELLX_PT_LPPT\",\n          `STOCKHOLM/ARLANDA` = \"LU_ELLX_SE_ESSA\",\n          `MONASTIR/HABIB BOURGUIBA` = \"LU_ELLX_TN_DTMB\",\n          `ENFIDHA-HAMMAMET INTERNATIONAL` = \"LU_ELLX_TN_DTNH\",\n          `ENFIDHA ZINE EL ABIDINE BEN ALI` = \"LU_ELLX_TN_DTNZ\",\n          `DJERBA/ZARZIS` = \"LU_ELLX_TN_DTTJ\",\n          `ANTALYA (MIL-CIV)` = \"LU_ELLX_TR_LTAI\",\n          `ISTANBUL/ATATURK` = \"LU_ELLX_TR_LTBA\",\n          `SYSTEM - LONDON` = \"LU_ELLX_UK_EG90\",\n          `MANCHESTER` = \"LU_ELLX_UK_EGCC\",\n          `LONDON GATWICK` = \"LU_ELLX_UK_EGKK\",\n          `LONDON/CITY` = \"LU_ELLX_UK_EGLC\",\n          `LONDON HEATHROW` = \"LU_ELLX_UK_EGLL\",\n          `LONDON STANSTED` = \"LU_ELLX_UK_EGSS\",\n          `NEWARK LIBERTY INTERNATIONAL, NJ.` = \"LU_ELLX_US_KEWR\",\n          `O.R TAMBO INTERNATIONAL` = \"LU_ELLX_ZA_FAJS\"\n        )\n      )\n)\n\n# Step 6: Final cleaned dataset\navia_clean <- rxp_r(\n  name = avia_clean,\n  expr =\n    avia_recode_destination %>%\n      mutate(passengers = as.numeric(passengers)) %>%\n      select(unit, tra_meas, destination, date, passengers)\n)\n\n# Step 7: Quarterly arrivals\navia_clean_quarterly <- rxp_r(\n  name = avia_clean_quarterly,\n  expr =\n    avia_clean %>%\n      filter(\n        tra_meas == \"Passengers on board (arrivals)\",\n        !is.na(passengers),\n        str_detect(date, \"Q\")\n      ) %>%\n      mutate(date = yq(date))\n)\n\n# Step 8: Monthly arrivals\navia_clean_monthly <- rxp_r(\n  name = avia_clean_monthly,\n  expr =\n    avia_clean %>%\n      filter(\n        tra_meas == \"Passengers on board (arrivals)\",\n        !is.na(passengers),\n        str_detect(date, \"M\")\n      ) %>%\n      mutate(date = ymd(paste0(date, \"01\"))) %>%\n      select(destination, date, passengers)\n)\n\n# Populate and build the pipeline\nrxp_populate(\n  list(\n    avia,\n    avia_long,\n    avia_split,\n    avia_recode_tra_meas,\n    avia_recode_unit,\n    avia_recode_destination,\n    avia_clean,\n    avia_clean_quarterly,\n    avia_clean_monthly\n  )\n)\n\nrxp_make()\nNow this is a faithful “translation” of the script into a\n{rixpress}\npipeline, however, the original data is now not available anymore, and recent data sets have changed slightly, which means that this script would need further adaptation to the current data source. Otherwise, this would be it! You can view the updated script\nhere\n(I have also removed all the recoding of factors, because there seems to be something wrong with how\n{rixpress}\nhandles  `, so writing this blog post actually help me find something to fix!)\nGenerating the environment\nI also used an LLM to generate the\n{rix}\nscript that sets up the reproducible environment for this pipeline. I gave it the\nrix.pkgctx.yaml\ncontext file (generated with\npkgctx r rix > rix.pkgctx.yaml\n, which is also available on the rix GitHub repo) and asked: “Using this knowledge, write me an R script that uses rix to set up the right default.nix for this pipeline.”\nThe LLM correctly identified the packages needed from the pipeline code:\nreadr\n(for\nread_tsv\n)\ndplyr\n(for\nselect\n,\nfilter\n,\nmutate\n,\n%>%\n)\ntidyr\n(for\ngather\n,\nseparate\n)\nforcats\n(for\nfct_recode\n)\nlubridate\n(for\nyq\n,\nymd\n)\nstringr\n(for\nstr_detect\n)\nrixpress\n(for the pipeline itself)\nAnd produced this script:\nlibrary(rix)\n\nrix(\n  date = \"2026-01-10\",\n  r_pkgs = c(\n    \"readr\",\n    \"dplyr\",\n    \"tidyr\",\n    \"forcats\",\n    \"lubridate\",\n    \"stringr\",\n    \"rixpress\"\n  ),\n  ide = \"none\",\n  project_path = \".\",\n  overwrite = TRUE\n)\nThere’s only one issue with that script: the selected date is not valid, it should instead be the 12th of January. But that’s actually my fault: the LLM had no way of knowing that. The only way it could have known is if I had told it to look at the csv file that lists all the valid dates on\n{rix}\n’s repository. But after changing the date, it becomes possible to run this script, then\nnix-build\nto build the environment and\nnix-shell\nto drop into it. From there, run your pipeline.\nWhat we’ve done here is use LLMs at every step:\nGave context about rixpress\n(via\npkgctx\n) and asked the LLM to translate my old script into a pipeline\nGave context about rix\n(via\npkgctx\n) and asked the LLM to generate the environment setup\nThe pattern is always the same: context + scoped task = useful output.\nStructure + context = outsourceable grunt work\nThe point I’m making here isn’t really about\n{rixpress}\npipelines specifically. It’s about a broader principle that both Davis Vaughan and I have observed: LLMs are genuinely useful when you give them enough structure and context.\nDavis\npre-cloned repositories, pre-generated\n.Rprofile\nfiles, and pre-created task lists\nso Claude could focus on the actual fixes rather than git management. I used\npkgctx\nto give the LLM a complete API specification and provided a clear starting point (my old script). In both cases, the formula is the same:\nStructure + Context → Scoped Task → LLM can actually help\nI’ve\nwritten before\nabout how you can outsource grunt work to an LLM, but not expertise. The same applies here. I still had to know what data transformations I needed. I still had to review the output and make adjustments. But the tedious restructuring (turning a monolithic script into a declarative pipeline) is exactly the kind of work LLMs can handle if you set them up properly.\nIf you want LLMs to help with your data science work:\nGive them context.\nUse tools like\npkgctx\nto feed them API specifications. Paste your existing code. Show them examples.\nScope the task tightly.\n“Translate this script into a rixpress pipeline” is a well-defined task. “Make my code better” is not.\nReview the output.\nLLMs do grunt work; you provide expertise.\nIf you’re not familiar with\n{rixpress}\n, check out\nmy announcement post\nor the\nCRAN release post\n. And if you want to give LLMs context about R or Python packages,\npkgctx\nis there to help. For those who want to dive deeper into Nix,\n{rix}\n, and\n{rixpress}\n, I’ve recently submitted a paper to the Journal of Statistical Software, which you can read\nhere\n. For more examples of\n{rixpress}\npipelines, check out the\nrixpress_demos\nrepository.\nLLMs aren’t going anywhere: the genie is out of the bottle. I still see plenty of people online claiming that LLMs aren’t useful, but I genuinely believe it comes down to one of two things:\nThey’re not providing enough context or scoping their tasks well enough.\nThey have a principled objection to LLMs, AI, and automation in general which, ok, whatever, but it’s not a technical argument about usefulness.\nSome people might even say that to feel good about themselves:\nwhat I program is much too complex and important for mere LLMs to be able to help me\n. Ok perhaps, but not all of us are working for NASA or whatever. I’ll keep on outsourcing the tedious grunt work to LLMs.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nEconometrics and Free Software\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "main_html": "<article class=\"post-398257 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">From scripts to pipelines in the age of LLMs</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">January 12, 2026</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/econometrics-and-free-software/\">Econometrics and Free Software</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://b-rodrigues.github.io/posts/2026-01-13-data_science_llm_age.html\"> Econometrics and Free Software</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"text-align: center;\">\n<p>\n<a> <img data-lazy-src=\"https://i1.wp.com/b-rodrigues.github.io/assets/img/chad_beach.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" style=\"width: 80%; height: auto;\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i1.wp.com/b-rodrigues.github.io/assets/img/chad_beach.png?w=578&amp;ssl=1\" style=\"width: 80%; height: auto;\"/></noscript> </a>\n</p>\n</div>\n<p>I was recently reading Davis Vaughan’s blog post <a href=\"https://blog.davisvaughan.com/posts/2026-01-09-claude-200-pull-requests/\" rel=\"nofollow\" target=\"_blank\">Semi-automating 200 Pull Requests with Claude Code</a> and it really resonated with me, as I’ve been using LLMs for tedious tasks like that for some time now. Davis’s key insight: <em>structure = success</em>. When you can scope a task tightly and provide clear context, LLMs become genuinely useful tools.</p>\n<p>If you’ve been following my work, you know that reproducible pipelines have been my main focus for some time now. It’s the reason I wrote <code>{rix}</code> for reproducible R environments, <code>{rixpress}</code> for declarative pipelines, and even a Python port called <code>ryxpress</code>. I genuinely believe these tools make data science better: more reproducible, more debuggable, more shareable.</p>\n<p>But I also know that getting people to adopt new tools is hard. Learning a new way of structuring your code takes time and effort, and most people are busy enough already. Here’s where LLMs enter the picture: they can help translate your existing scripts into this more structured format. You provide your monolithic script, explain what you want, and the LLM does the grunt work of restructuring it.</p>\n<p>The typical way we write analytics scripts (long chains of <code>%&gt;%</code> calls in R or method-chaining in Python) works fine for interactive exploration, but quickly turns into spaghetti that’s hard to modify, test, or debug. Take <a href=\"https://b-rodrigues.github.io/posts/2018-11-14-luxairport.html\" rel=\"nofollow\" target=\"_blank\">my old Luxembourg Airport analysis</a> as an example: it works, but turning that kind of script into a proper pipeline with caching, explicit dependencies, and testability is tedious work.</p>\n<p>But we’re in 2026 where LLMs now make this trivial.</p>\n<section class=\"level2\" id=\"from-implicit-to-explicit-translating-a-script-into-a-rixpress-pipeline\">\n<h2 class=\"anchored\" data-anchor-id=\"from-implicit-to-explicit-translating-a-script-into-a-rixpress-pipeline\">From implicit to explicit: translating a script into a rixpress pipeline</h2>\n<p>Let me show you what I mean by translating that old Luxembourg Airport data cleaning code into a <code>{rixpress}</code> pipeline. The original script uses continuous <code>%&gt;%</code> chaining, standard tidyverse style. The <code>{rixpress}</code> version makes every intermediate step explicit.</p>\n<p>But here’s the thing: LLMs don’t know about <code>{rixpress}</code> out of the box. It’s a relatively new package, and it’s not in their training data (or if it is, it’s outdated). So I wrote another tool called <a href=\"https://github.com/b-rodrigues/pkgctx\" rel=\"nofollow\" target=\"_blank\">pkgctx</a> that extracts structured, LLM-ready API specifications from R or Python packages (and guess what, I did not write a single line of code of that tool, LLMs did).</p>\n<p>The idea is simple: run <code>pkgctx r rixpress &gt; rixpress.ctx.yaml</code> and you get a compact YAML file describing every function, its arguments, and its purpose. Feed that to an LLM, and suddenly it “knows” the package. All my packages now have such a file generated on each push thanks to GitHub Actions. Here’s how my conversation went:</p>\n<blockquote class=\"blockquote\">\n<p><strong>Me:</strong> I want to use a package called rixpress, but I am not familiar with it. You’ll help me, and here is a file with a detailed description of the API, for context.</p>\n<p><em>[uploaded rixpress.ctx.yaml]</em></p>\n<p><strong>LLM:</strong> Got it. I’ll use this API specification as the authoritative reference for <strong>rixpress</strong> and help you write correct, idiomatic pipelines with it.</p>\n<p>A few orientation points to set the frame (no action required yet):</p>\n<ul>\n<li><strong>rixpress is declarative</strong>: you describe <em>derivations</em> (<code>rxp_r()</code>, <code>rxp_py()</code>, <code>rxp_qmd()</code>, …), then materialize them with <code>rxp_populate()</code> and <code>rxp_make()</code>.</li>\n<li><strong>Data flows through the DAG</strong> via serialized artifacts (RDS / pickle / Julia Serialization), not in-memory objects.</li>\n<li><strong>Language boundaries are explicit</strong> (<code>rxp_r2py()</code>, <code>rxp_py2r()</code>).</li>\n<li><strong>Nix is the execution engine</strong>; <code>default.nix</code> (or equivalents) define the runtime environment.</li>\n</ul>\n<p>When you’re ready, tell me what you want to do […]</p>\n</blockquote>\n<p>Then I simply asked:</p>\n<blockquote class=\"blockquote\">\n<p><strong>Me:</strong> Help me translate this R script into a rixpress pipeline: <em>[pasted the old script]</em></p>\n</blockquote>\n<p>And that’s how I got a working <code>{rixpress}</code> pipeline. The LLM did the tedious restructuring; I reviewed the output, made minor tweaks, and was done. The combination of <code>pkgctx</code> for context and a clear task (“translate this script”) made the LLM genuinely useful.</p>\n<p>Now let’s look at what the translated pipeline looks like. First, let’s assume:</p>\n<ul>\n<li>The data file <code>avia_par_lu.tsv</code> is in the project directory</li>\n<li>Required R packages are available via <code>default.nix</code> (we’ll also use an LLM for this one)</li>\n<li>The project has been initialized with <code>rxp_init()</code> (this sets up two skeleton files to get started quickly)</li>\n</ul>\n<details>\n<summary>\nClick to expand the full rixpress pipeline\n</summary>\n<pre>library(rixpress)\n\n# Step 0: Load the data\navia &lt;- rxp_r_file(\n  name = avia,\n  path = \"avia_par_lu.tsv\",\n  read_function = readr::read_tsv\n)\n\n# Step 1: Select and reshape (wide → long)\navia_long &lt;- rxp_r(\n  name = avia_long,\n  expr =\n    avia %&gt;%\n      select(\"unit,tra_meas,airp_pr\\\\time\", contains(\"20\")) %&gt;%\n      gather(date, passengers, -`unit,tra_meas,airp_pr\\\\time`)\n)\n\n# Step 2: Split composite key column\navia_split &lt;- rxp_r(\n  name = avia_split,\n  expr =\n    avia_long %&gt;%\n      separate(\n        col = `unit,tra_meas,airp_pr\\\\time`,\n        into = c(\"unit\", \"tra_meas\", \"air_pr\\\\time\"),\n        sep = \",\"\n      )\n)\n\n# Step 3: Recode transport measure\navia_recode_tra_meas &lt;- rxp_r(\n  name = avia_recode_tra_meas,\n  expr =\n    avia_split %&gt;%\n      mutate(\n        tra_meas = fct_recode(\n          tra_meas,\n          `Passengers on board` = \"PAS_BRD\",\n          `Passengers on board (arrivals)` = \"PAS_BRD_ARR\",\n          `Passengers on board (departures)` = \"PAS_BRD_DEP\",\n          `Passengers carried` = \"PAS_CRD\",\n          `Passengers carried (arrival)` = \"PAS_CRD_ARR\",\n          `Passengers carried (departures)` = \"PAS_CRD_DEP\",\n          `Passengers seats available` = \"ST_PAS\",\n          `Passengers seats available (arrivals)` = \"ST_PAS_ARR\",\n          `Passengers seats available (departures)` = \"ST_PAS_DEP\",\n          `Commercial passenger air flights` = \"CAF_PAS\",\n          `Commercial passenger air flights (arrivals)` = \"CAF_PAS_ARR\",\n          `Commercial passenger air flights (departures)` = \"CAF_PAS_DEP\"\n        )\n      )\n)\n\n# Step 4: Recode unit\navia_recode_unit &lt;- rxp_r(\n  name = avia_recode_unit,\n  expr =\n    avia_recode_tra_meas %&gt;%\n      mutate(\n        unit = fct_recode(\n          unit,\n          Passenger = \"PAS\",\n          Flight = \"FLIGHT\",\n          `Seats and berths` = \"SEAT\"\n        )\n      )\n)\n\n# Step 5: Recode destination\navia_recode_destination &lt;- rxp_r(\n  name = avia_recode_destination,\n  expr =\n    avia_recode_unit %&gt;%\n      mutate(\n        destination = fct_recode(\n          `air_pr\\\\time`,\n          `WIEN-SCHWECHAT` = \"LU_ELLX_AT_LOWW\",\n          `BRUSSELS` = \"LU_ELLX_BE_EBBR\",\n          `GENEVA` = \"LU_ELLX_CH_LSGG\",\n          `ZURICH` = \"LU_ELLX_CH_LSZH\",\n          `FRANKFURT/MAIN` = \"LU_ELLX_DE_EDDF\",\n          `HAMBURG` = \"LU_ELLX_DE_EDDH\",\n          `BERLIN-TEMPELHOF` = \"LU_ELLX_DE_EDDI\",\n          `MUENCHEN` = \"LU_ELLX_DE_EDDM\",\n          `SAARBRUECKEN` = \"LU_ELLX_DE_EDDR\",\n          `BERLIN-TEGEL` = \"LU_ELLX_DE_EDDT\",\n          `KOBENHAVN/KASTRUP` = \"LU_ELLX_DK_EKCH\",\n          `HURGHADA / INTL` = \"LU_ELLX_EG_HEGN\",\n          `IRAKLION/NIKOS KAZANTZAKIS` = \"LU_ELLX_EL_LGIR\",\n          `FUERTEVENTURA` = \"LU_ELLX_ES_GCFV\",\n          `GRAN CANARIA` = \"LU_ELLX_ES_GCLP\",\n          `LANZAROTE` = \"LU_ELLX_ES_GCRR\",\n          `TENERIFE SUR/REINA SOFIA` = \"LU_ELLX_ES_GCTS\",\n          `BARCELONA/EL PRAT` = \"LU_ELLX_ES_LEBL\",\n          `ADOLFO SUAREZ MADRID-BARAJAS` = \"LU_ELLX_ES_LEMD\",\n          `MALAGA/COSTA DEL SOL` = \"LU_ELLX_ES_LEMG\",\n          `PALMA DE MALLORCA` = \"LU_ELLX_ES_LEPA\",\n          `SYSTEM - PARIS` = \"LU_ELLX_FR_LF90\",\n          `NICE-COTE D'AZUR` = \"LU_ELLX_FR_LFMN\",\n          `PARIS-CHARLES DE GAULLE` = \"LU_ELLX_FR_LFPG\",\n          `STRASBOURG-ENTZHEIM` = \"LU_ELLX_FR_LFST\",\n          `KEFLAVIK` = \"LU_ELLX_IS_BIKF\",\n          `MILANO/MALPENSA` = \"LU_ELLX_IT_LIMC\",\n          `BERGAMO/ORIO AL SERIO` = \"LU_ELLX_IT_LIME\",\n          `ROMA/FIUMICINO` = \"LU_ELLX_IT_LIRF\",\n          `AGADIR/AL MASSIRA` = \"LU_ELLX_MA_GMAD\",\n          `AMSTERDAM/SCHIPHOL` = \"LU_ELLX_NL_EHAM\",\n          `WARSZAWA/CHOPINA` = \"LU_ELLX_PL_EPWA\",\n          `PORTO` = \"LU_ELLX_PT_LPPR\",\n          `LISBOA` = \"LU_ELLX_PT_LPPT\",\n          `STOCKHOLM/ARLANDA` = \"LU_ELLX_SE_ESSA\",\n          `MONASTIR/HABIB BOURGUIBA` = \"LU_ELLX_TN_DTMB\",\n          `ENFIDHA-HAMMAMET INTERNATIONAL` = \"LU_ELLX_TN_DTNH\",\n          `ENFIDHA ZINE EL ABIDINE BEN ALI` = \"LU_ELLX_TN_DTNZ\",\n          `DJERBA/ZARZIS` = \"LU_ELLX_TN_DTTJ\",\n          `ANTALYA (MIL-CIV)` = \"LU_ELLX_TR_LTAI\",\n          `ISTANBUL/ATATURK` = \"LU_ELLX_TR_LTBA\",\n          `SYSTEM - LONDON` = \"LU_ELLX_UK_EG90\",\n          `MANCHESTER` = \"LU_ELLX_UK_EGCC\",\n          `LONDON GATWICK` = \"LU_ELLX_UK_EGKK\",\n          `LONDON/CITY` = \"LU_ELLX_UK_EGLC\",\n          `LONDON HEATHROW` = \"LU_ELLX_UK_EGLL\",\n          `LONDON STANSTED` = \"LU_ELLX_UK_EGSS\",\n          `NEWARK LIBERTY INTERNATIONAL, NJ.` = \"LU_ELLX_US_KEWR\",\n          `O.R TAMBO INTERNATIONAL` = \"LU_ELLX_ZA_FAJS\"\n        )\n      )\n)\n\n# Step 6: Final cleaned dataset\navia_clean &lt;- rxp_r(\n  name = avia_clean,\n  expr =\n    avia_recode_destination %&gt;%\n      mutate(passengers = as.numeric(passengers)) %&gt;%\n      select(unit, tra_meas, destination, date, passengers)\n)\n\n# Step 7: Quarterly arrivals\navia_clean_quarterly &lt;- rxp_r(\n  name = avia_clean_quarterly,\n  expr =\n    avia_clean %&gt;%\n      filter(\n        tra_meas == \"Passengers on board (arrivals)\",\n        !is.na(passengers),\n        str_detect(date, \"Q\")\n      ) %&gt;%\n      mutate(date = yq(date))\n)\n\n# Step 8: Monthly arrivals\navia_clean_monthly &lt;- rxp_r(\n  name = avia_clean_monthly,\n  expr =\n    avia_clean %&gt;%\n      filter(\n        tra_meas == \"Passengers on board (arrivals)\",\n        !is.na(passengers),\n        str_detect(date, \"M\")\n      ) %&gt;%\n      mutate(date = ymd(paste0(date, \"01\"))) %&gt;%\n      select(destination, date, passengers)\n)\n\n# Populate and build the pipeline\nrxp_populate(\n  list(\n    avia,\n    avia_long,\n    avia_split,\n    avia_recode_tra_meas,\n    avia_recode_unit,\n    avia_recode_destination,\n    avia_clean,\n    avia_clean_quarterly,\n    avia_clean_monthly\n  )\n)\n\nrxp_make()</pre>\n</details>\n<p>Now this is a faithful “translation” of the script into a <code>{rixpress}</code> pipeline, however, the original data is now not available anymore, and recent data sets have changed slightly, which means that this script would need further adaptation to the current data source. Otherwise, this would be it! You can view the updated script <a href=\"https://github.com/b-rodrigues/rixpress_demos/tree/master/avia\" rel=\"nofollow\" target=\"_blank\">here</a> (I have also removed all the recoding of factors, because there seems to be something wrong with how <code>{rixpress}</code> handles  `, so writing this blog post actually help me find something to fix!)</p>\n</section>\n<section class=\"level2\" id=\"generating-the-environment\">\n<h2 class=\"anchored\" data-anchor-id=\"generating-the-environment\">Generating the environment</h2>\n<p>I also used an LLM to generate the <code>{rix}</code> script that sets up the reproducible environment for this pipeline. I gave it the <code>rix.pkgctx.yaml</code> context file (generated with <code>pkgctx r rix &gt; rix.pkgctx.yaml</code>, which is also available on the rix GitHub repo) and asked: “Using this knowledge, write me an R script that uses rix to set up the right default.nix for this pipeline.”</p>\n<p>The LLM correctly identified the packages needed from the pipeline code:</p>\n<ul>\n<li><code>readr</code> (for <code>read_tsv</code>)</li>\n<li><code>dplyr</code> (for <code>select</code>, <code>filter</code>, <code>mutate</code>, <code>%&gt;%</code>)</li>\n<li><code>tidyr</code> (for <code>gather</code>, <code>separate</code>)</li>\n<li><code>forcats</code> (for <code>fct_recode</code>)</li>\n<li><code>lubridate</code> (for <code>yq</code>, <code>ymd</code>)</li>\n<li><code>stringr</code> (for <code>str_detect</code>)</li>\n<li><code>rixpress</code> (for the pipeline itself)</li>\n</ul>\n<p>And produced this script:</p>\n<pre>library(rix)\n\nrix(\n  date = \"2026-01-10\",\n  r_pkgs = c(\n    \"readr\",\n    \"dplyr\",\n    \"tidyr\",\n    \"forcats\",\n    \"lubridate\",\n    \"stringr\",\n    \"rixpress\"\n  ),\n  ide = \"none\",\n  project_path = \".\",\n  overwrite = TRUE\n)</pre>\n<p>There’s only one issue with that script: the selected date is not valid, it should instead be the 12th of January. But that’s actually my fault: the LLM had no way of knowing that. The only way it could have known is if I had told it to look at the csv file that lists all the valid dates on <code>{rix}</code>’s repository. But after changing the date, it becomes possible to run this script, then <code>nix-build</code> to build the environment and <code>nix-shell</code> to drop into it. From there, run your pipeline.</p>\n<p>What we’ve done here is use LLMs at every step:</p>\n<ol type=\"1\">\n<li><strong>Gave context about rixpress</strong> (via <code>pkgctx</code>) and asked the LLM to translate my old script into a pipeline</li>\n<li><strong>Gave context about rix</strong> (via <code>pkgctx</code>) and asked the LLM to generate the environment setup</li>\n</ol>\n<p>The pattern is always the same: context + scoped task = useful output.</p>\n</section>\n<section class=\"level2\" id=\"structure-context-outsourceable-grunt-work\">\n<h2 class=\"anchored\" data-anchor-id=\"structure-context-outsourceable-grunt-work\">Structure + context = outsourceable grunt work</h2>\n<p>The point I’m making here isn’t really about <code>{rixpress}</code> pipelines specifically. It’s about a broader principle that both Davis Vaughan and I have observed: LLMs are genuinely useful when you give them enough structure and context.</p>\n<p>Davis <a href=\"https://blog.davisvaughan.com/posts/2026-01-09-claude-200-pull-requests/\" rel=\"nofollow\" target=\"_blank\">pre-cloned repositories, pre-generated <code>.Rprofile</code> files, and pre-created task lists</a> so Claude could focus on the actual fixes rather than git management. I used <code>pkgctx</code> to give the LLM a complete API specification and provided a clear starting point (my old script). In both cases, the formula is the same:</p>\n<blockquote class=\"blockquote\">\n<p><strong>Structure + Context → Scoped Task → LLM can actually help</strong></p>\n</blockquote>\n<p>I’ve <a href=\"https://b-rodrigues.github.io/posts/2025-07-03-llm_time.html\" rel=\"nofollow\" target=\"_blank\">written before</a> about how you can outsource grunt work to an LLM, but not expertise. The same applies here. I still had to know what data transformations I needed. I still had to review the output and make adjustments. But the tedious restructuring (turning a monolithic script into a declarative pipeline) is exactly the kind of work LLMs can handle if you set them up properly.</p>\n<p>If you want LLMs to help with your data science work:</p>\n<ol type=\"1\">\n<li><strong>Give them context.</strong> Use tools like <code>pkgctx</code> to feed them API specifications. Paste your existing code. Show them examples.</li>\n<li><strong>Scope the task tightly.</strong> “Translate this script into a rixpress pipeline” is a well-defined task. “Make my code better” is not.</li>\n<li><strong>Review the output.</strong> LLMs do grunt work; you provide expertise.</li>\n</ol>\n<p>If you’re not familiar with <code>{rixpress}</code>, check out <a href=\"https://b-rodrigues.github.io/posts/2025-03-20-announcing_rixpress.html\" rel=\"nofollow\" target=\"_blank\">my announcement post</a> or the <a href=\"https://b-rodrigues.github.io/posts/2025-10-23-rixpress_cran.html\" rel=\"nofollow\" target=\"_blank\">CRAN release post</a>. And if you want to give LLMs context about R or Python packages, <a href=\"https://github.com/b-rodrigues/pkgctx\" rel=\"nofollow\" target=\"_blank\">pkgctx</a> is there to help. For those who want to dive deeper into Nix, <code>{rix}</code>, and <code>{rixpress}</code>, I’ve recently submitted a paper to the Journal of Statistical Software, which you can read <a href=\"https://b-rodrigues.github.io/rix_paper/\" rel=\"nofollow\" target=\"_blank\">here</a>. For more examples of <code>{rixpress}</code> pipelines, check out the <a href=\"https://github.com/b-rodrigues/rixpress_demos\" rel=\"nofollow\" target=\"_blank\">rixpress_demos</a> repository.</p>\n<p>LLMs aren’t going anywhere: the genie is out of the bottle. I still see plenty of people online claiming that LLMs aren’t useful, but I genuinely believe it comes down to one of two things:</p>\n<ul>\n<li>They’re not providing enough context or scoping their tasks well enough.</li>\n<li>They have a principled objection to LLMs, AI, and automation in general which, ok, whatever, but it’s not a technical argument about usefulness.</li>\n</ul>\n<p>Some people might even say that to feel good about themselves: <em>what I program is much too complex and important for mere LLMs to be able to help me</em>. Ok perhaps, but not all of us are working for NASA or whatever. I’ll keep on outsourcing the tedious grunt work to LLMs.</p>\n</section>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://b-rodrigues.github.io/posts/2026-01-13-data_science_llm_age.html\"> Econometrics and Free Software</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div> </div>\n</article>",
    "word_count": 2102,
    "reading_time_min": 10.5,
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/econometrics-and-free-software/",
        "text": "Econometrics and Free Software"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "external_links": [
      {
        "href": "https://b-rodrigues.github.io/posts/2026-01-13-data_science_llm_age.html",
        "text": "Econometrics and Free Software"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://blog.davisvaughan.com/posts/2026-01-09-claude-200-pull-requests/",
        "text": "Semi-automating 200 Pull Requests with Claude Code"
      },
      {
        "href": "https://b-rodrigues.github.io/posts/2018-11-14-luxairport.html",
        "text": "my old Luxembourg Airport analysis"
      },
      {
        "href": "https://github.com/b-rodrigues/pkgctx",
        "text": "pkgctx"
      },
      {
        "href": "https://github.com/b-rodrigues/rixpress_demos/tree/master/avia",
        "text": "here"
      },
      {
        "href": "https://blog.davisvaughan.com/posts/2026-01-09-claude-200-pull-requests/",
        "text": "pre-cloned repositories, pre-generated.Rprofilefiles, and pre-created task lists"
      },
      {
        "href": "https://b-rodrigues.github.io/posts/2025-07-03-llm_time.html",
        "text": "written before"
      },
      {
        "href": "https://b-rodrigues.github.io/posts/2025-03-20-announcing_rixpress.html",
        "text": "my announcement post"
      },
      {
        "href": "https://b-rodrigues.github.io/posts/2025-10-23-rixpress_cran.html",
        "text": "CRAN release post"
      },
      {
        "href": "https://github.com/b-rodrigues/pkgctx",
        "text": "pkgctx"
      },
      {
        "href": "https://b-rodrigues.github.io/rix_paper/",
        "text": "here"
      },
      {
        "href": "https://github.com/b-rodrigues/rixpress_demos",
        "text": "rixpress_demos"
      },
      {
        "href": "https://b-rodrigues.github.io/posts/2026-01-13-data_science_llm_age.html",
        "text": "Econometrics and Free Software"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "images": [
      {
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif",
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"
      },
      {
        "src": "https://i1.wp.com/b-rodrigues.github.io/assets/img/chad_beach.png?w=578&ssl=1",
        "alt": null,
        "base64": null
      }
    ],
    "lang": "en-US",
    "crawled_at_utc": "2026-01-13T18:26:28Z"
  }
}