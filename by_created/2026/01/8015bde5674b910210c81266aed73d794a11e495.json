{
  "id": "8015bde5674b910210c81266aed73d794a11e495",
  "url": "https://www.r-bloggers.com/2025/10/200-r-programming-prompts-code-snippets-for-data-analysis-and-modeling/",
  "created_at_utc": "2026-01-04T05:35:43Z",
  "crawled_at_utc": "2026-01-04T05:36:55Z",
  "html_title": "200 R Programming Prompts & Code Snippets for Data Analysis and Modeling | R-bloggers",
  "meta_description": "R is a versatile programming language designed for statistical computing and graphics. It can act as a calculator, provide numerical and graphical summaries of data and handle a variety of specific analyses:contentReference[oaicite:0]{index=0}. Whether you’re exploring data, running statistical tests or building predictive models, R offers built-in functions and packages to streamline the workflow. The summary() […] The post 200 R Programming Prompts & Code Snippets for Data Analysis and Modeling appeared first on R Programming Books.",
  "data": {
    "url": "https://www.r-bloggers.com/2025/10/200-r-programming-prompts-code-snippets-for-data-analysis-and-modeling/",
    "canonical_url": "https://www.r-bloggers.com/2025/10/200-r-programming-prompts-code-snippets-for-data-analysis-and-modeling/",
    "html_title": "200 R Programming Prompts & Code Snippets for Data Analysis and Modeling | R-bloggers",
    "h1_title": "R-bloggers",
    "meta_description": "R is a versatile programming language designed for statistical computing and graphics. It can act as a calculator, provide numerical and graphical summaries of data and handle a variety of specific analyses:contentReference[oaicite:0]{index=0}. Whether you’re exploring data, running statistical tests or building predictive models, R offers built-in functions and packages to streamline the workflow. The summary() […] The post 200 R Programming Prompts & Code Snippets for Data Analysis and Modeling appeared first on R Programming Books.",
    "meta_keywords": null,
    "og_title": "200 R Programming Prompts & Code Snippets for Data Analysis and Modeling | R-bloggers",
    "og_description": "R is a versatile programming language designed for statistical computing and graphics. It can act as a calculator, provide numerical and graphical summaries of data and handle a variety of specific analyses:contentReference[oaicite:0]{index=0}. Whether you’re exploring data, running statistical tests or building predictive models, R offers built-in functions and packages to streamline the workflow. The summary() […] The post 200 R Programming Prompts & Code Snippets for Data Analysis and Modeling appeared first on R Programming Books.",
    "og_image": "https://www.r-bloggers.com/wp-content/uploads/2016/04/R_02_2016-05-01.png",
    "twitter_title": "200 R Programming Prompts & Code Snippets for Data Analysis and Modeling | R-bloggers",
    "twitter_description": "R is a versatile programming language designed for statistical computing and graphics. It can act as a calculator, provide numerical and graphical summaries of data and handle a variety of specific analyses:contentReference[oaicite:0]{index=0}. Whether you’re exploring data, running statistical tests or building predictive models, R offers built-in functions and packages to streamline the workflow. The summary() […] The post 200 R Programming Prompts & Code Snippets for Data Analysis and Modeling appeared first on R Programming Books.",
    "raw_jsonld_article": null,
    "article_headline": null,
    "article_section": null,
    "article_tags": null,
    "article_author": null,
    "article_published": null,
    "article_modified": null,
    "main_text": "200 R Programming Prompts & Code Snippets for Data Analysis and Modeling\nPosted on\nOctober 8, 2025\nby\nrprogrammingbooks\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nBlog - R Programming Books\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nR is a versatile programming language designed for statistical computing and graphics. It can act as a calculator, provide numerical and graphical summaries of data and handle a variety of specific analyses:contentReference[oaicite:0]{index=0}. Whether you’re exploring data, running statistical tests or building predictive models, R offers built-in functions and packages to streamline the workflow. The\nsummary()\nfunction, for example, gives a quick overview of each variable’s distribution:contentReference[oaicite:1]{index=1}, and the\nlm()\nfunction fits linear models and returns coefficients and diagnostics:contentReference[oaicite:2]{index=2}. The following sections present 200 practical prompts and code snippets organized by topic, from basic data operations to advanced modeling and visualization.\nData Input and Output\nPrompt 1: Read a CSV file\nUse `read.csv()` to import a comma‑separated values file and store it in a data frame.\ndata <- read.csv('path/to/file.csv', header = TRUE, stringsAsFactors = FALSE)\nPrompt 2: Read an Excel file\nLoad spreadsheet data from Excel files with the **readxl** package.\nlibrary(readxl)\ndata <- read_excel('path/to/file.xlsx', sheet = 1)\nPrompt 3: Import data from a remote CSV\nRead a CSV file from a web URL directly without downloading it first.\nurl <- 'https://example.com/data.csv'\ndata <- read.csv(url, header = TRUE)\nPrompt 4: Read a JSON file\nParse JSON data into an R list or data frame using **jsonlite**.\nlibrary(jsonlite)\njson_data <- fromJSON('data.json')\ndata <- as.data.frame(json_data)\nPrompt 5: Read data from a SQL database\nConnect to an SQLite database and query data via **DBI** and **RSQLite**.\nlibrary(DBI)\ncon <- dbConnect(RSQLite::SQLite(), 'database.sqlite')\nquery <- 'SELECT * FROM my_table'\ndata <- dbGetQuery(con, query)\ndbDisconnect(con)\nPrompt 6: Read and write RDS files\nLoad and save objects in R’s native serialized format with `saveRDS()` and `readRDS()`.\nsaveRDS(data, 'mydata.rds')\nloaded_data <- readRDS('mydata.rds')\nPrompt 7: Write a data frame to CSV\nExport a data frame to a CSV file using `write.csv()`.\nwrite.csv(data, 'output.csv', row.names = FALSE)\nPrompt 8: Write data to Excel\nSave a data frame to an Excel workbook with **writexl**.\nlibrary(writexl)\nwrite_xlsx(list(Sheet1 = data), 'output.xlsx')\nPrompt 9: Save workspace to an .RData file\nPersist your current R environment by saving all objects to a file.\nsave.image('workspace.RData')\nPrompt 10: Load a .RData file\nRestore a previously saved R workspace.\nload('workspace.RData')\nData Cleaning\nPrompt 11: Inspect data structure\nUse `str()` to display the internal structure of an R object and see its variables and types.\nstr(data)\nPrompt 12: Identify missing values\nFind missing (NA) values in your dataset using `is.na()` and count them.\nsum(is.na(data))\nPrompt 13: Replace missing values with the mean\nImpute missing numeric values by replacing them with the column mean.\ndata$variable[is.na(data$variable)] <- mean(data$variable, na.rm = TRUE)\nPrompt 14: Remove rows with missing values\nOmit any rows containing missing values using `na.omit()`.\nclean_data <- na.omit(data)\nPrompt 15: Convert characters to factors\nTransform character columns into factors for categorical analysis.\ndata$category <- as.factor(data$category)\nPrompt 16: Rename columns\nChange column names using `names()` or `dplyr::rename()`.\nnames(data)[names(data) == 'old_name'] <- 'new_name'\n# Or with dplyr\nlibrary(dplyr)\ndata <- rename(data, new_name = old_name)\nPrompt 17: Reorder columns\nRearrange the order of columns in a data frame.\ndata <- data[, c('col3', 'col1', 'col2', setdiff(names(data), c('col1','col2','col3')))]\nPrompt 18: Filter rows based on a condition\nSelect only the rows that meet a logical criterion.\nsubset_data <- subset(data, variable > 10)\nPrompt 19: Sort data frame by a column\nOrder data by ascending or descending values using `order()`.\nsorted_data <- data[order(data$variable, decreasing = FALSE), ]\nPrompt 20: Remove duplicate rows\nKeep only unique rows using `unique()` or `distinct()`.\nunique_data <- unique(data)\n# Or with dplyr\nlibrary(dplyr)\nunique_data <- distinct(data)\nData Transformation with dplyr\nPrompt 21: Select specific columns\nUse `select()` to choose a subset of columns from a data frame.\nlibrary(dplyr)\nsubset_data <- select(data, column1, column2, column3)\nPrompt 22: Filter rows by criteria\nExtract rows that satisfy given conditions using `filter()`.\nfiltered_data <- filter(data, column1 == 'A', column2 > 5)\nPrompt 23: Mutate new columns\nCreate new variables derived from existing columns using `mutate()`.\nlibrary(dplyr)\ndata <- mutate(data, ratio = column1 / column2, log_value = log(column3))\nPrompt 24: Summarize data by groups\nGroup data and compute summary statistics with `group_by()` and `summarise()`.\nlibrary(dplyr)\nsumm <- data %>% group_by(category) %>% summarise(mean_value = mean(value, na.rm = TRUE), count = n())\nPrompt 25: Group by multiple variables\nGroup data by more than one variable for multi‑level summaries.\nsummary <- data %>% group_by(category, subgroup) %>% summarise(total = sum(value))\nPrompt 26: Arrange data\nSort data within the pipeline using `arrange()`.\nsorted <- data %>% arrange(desc(value))\nPrompt 27: Count occurrences\nTabulate the number of observations per category with `count()`.\nlibrary(dplyr)\ncounts <- data %>% count(category)\nPrompt 28: Select distinct rows\nExtract unique rows for specified columns using `distinct()`.\nunique_rows <- data %>% distinct(category, value)\nPrompt 29: Join two data frames\nPerform an inner join on two tables with common keys using `inner_join()`.\nmerged_data <- inner_join(df1, df2, by = 'id')\nPrompt 30: Pivot data longer or wider\nReshape data using `pivot_longer()` and `pivot_wider()` from **tidyr**.\nlibrary(tidyr)\nlong <- pivot_longer(data, cols = starts_with('Q'), names_to = 'question', values_to = 'score')\nwide <- pivot_wider(long, names_from = question, values_from = score)\nExploratory Data Analysis\nPrompt 31: Compute summary statistics\nGet an overview of each variable with the `summary()` function, which reports minimum, quartiles, median, mean and maximum【116883529303011†L61-L77】.\nsummary(data)\nPrompt 32: Compute quantiles\nCalculate specific quantiles (e.g., 25th and 75th percentiles) using `quantile()`.\nquantiles <- quantile(data$variable, probs = c(0.25, 0.5, 0.75))\nPrompt 33: Create a frequency table\nTabulate counts of unique values in a vector using `table()`.\nfreq <- table(data$category)\nPrompt 34: Create a cross‑tabulation\nProduce contingency tables for two categorical variables with `xtabs()` or `table()`.\ncrosstab <- table(data$category, data$group)\nPrompt 35: Compute a correlation matrix\nCalculate pairwise correlations for numeric variables using `cor()`.\ncor_matrix <- cor(data[, sapply(data, is.numeric)], use = 'complete.obs')\nPrompt 36: Compute covariance matrix\nAssess covariance between variables with `cov()`.\ncov_matrix <- cov(data[, sapply(data, is.numeric)], use = 'complete.obs')\nPrompt 37: Plot a histogram\nVisualize the distribution of a continuous variable with `hist()`.\nhist(data$variable, breaks = 30, col = 'steelblue', main = 'Histogram', xlab = 'Value')\nPrompt 38: Create a boxplot\nDisplay the distribution and outliers of a variable using `boxplot()`.\nboxplot(data$variable ~ data$group, main = 'Boxplot', xlab = 'Group', ylab = 'Variable')\nPrompt 39: Create a scatter plot\nPlot two numeric variables against each other with `plot()`.\nplot(data$variable1, data$variable2, main = 'Scatter Plot', xlab = 'Variable 1', ylab = 'Variable 2', pch = 19)\nPrompt 40: Make a pairwise scatterplot matrix\nExplore relationships between multiple variables using `pairs()`.\npairs(data[, 1:4], main = 'Pairs Plot')\nBasic Statistics\nPrompt 41: Compute the mean\nCalculate the arithmetic mean of a numeric vector with `mean()`.\navg <- mean(data$variable, na.rm = TRUE)\nPrompt 42: Compute the median\nFind the median (50th percentile) of a numeric vector.\nmed <- median(data$variable, na.rm = TRUE)\nPrompt 43: Compute the standard deviation\nMeasure the spread of values around the mean using `sd()`.\nstd_dev <- sd(data$variable, na.rm = TRUE)\nPrompt 44: Compute the variance\nCompute the sample variance of a numeric vector using `var()`.\nvar_value <- var(data$variable, na.rm = TRUE)\nPrompt 45: Compute the range\nGet the minimum and maximum values with `range()`.\nrange_values <- range(data$variable, na.rm = TRUE)\nPrompt 46: Compute the interquartile range\nCalculate the IQR (difference between 75th and 25th percentiles) using `IQR()`.\niqr_value <- IQR(data$variable, na.rm = TRUE)\nPrompt 47: Generate a random sample from a normal distribution\nCreate a vector of random numbers drawn from a normal distribution using `rnorm()`.\nset.seed(123)\nrandom_values <- rnorm(100, mean = 0, sd = 1)\nPrompt 48: Compute summary of an entire data frame\nSummarize all variables at once using `summary()`【116883529303011†L61-L77】.\nsummary_stats <- summary(data)\nPrompt 49: Compute covariance matrix\nCalculate variances and covariances for numeric variables using `cov()`【116883529303011†L116-L132】.\ncov_mat <- cov(data[, sapply(data, is.numeric)])\nPrompt 50: Compute correlation coefficient\nMeasure linear relationships between two variables using `cor()`.\ncorrelation <- cor(data$variable1, data$variable2, use = 'complete.obs')\nStatistical Tests\nPrompt 51: One‑sample t‑test\nTest whether the mean of a sample differs from a hypothesized value.\nt.test(data$variable, mu = 0)\nPrompt 52: Two‑sample t‑test\nCompare means of two independent groups using a two‑sample t‑test.\nt.test(variable ~ group, data = data)\nPrompt 53: Paired t‑test\nCompare means of paired observations, such as before‑after measurements.\nt.test(data$pre, data$post, paired = TRUE)\nPrompt 54: Chi‑square test of independence\nAssess the association between two categorical variables.\nchisq.test(table(data$category, data$group))\nPrompt 55: Shapiro–Wilk normality test\nCheck normality of a numeric variable using `shapiro.test()`.\nshapiro.test(data$variable)\nPrompt 56: Correlation test\nTest whether the correlation coefficient differs from zero.\ncor.test(data$variable1, data$variable2, method = 'pearson')\nPrompt 57: One‑way ANOVA\nCompare means across more than two groups using analysis of variance.\nanova_result <- aov(variable ~ group, data = data)\nsummary(anova_result)\nPrompt 58: Wilcoxon rank‑sum test\nPerform a non‑parametric test to compare two independent samples.\nwilcox.test(variable ~ group, data = data)\nPrompt 59: Kruskal–Wallis test\nNon‑parametric alternative to one‑way ANOVA for more than two groups.\nkruskal.test(variable ~ group, data = data)\nPrompt 60: Proportion test\nTest equality of proportions for two samples using `prop.test()`.\nprop.test(x = c(40, 50), n = c(100, 120))\nLinear and Generalized Linear Models\nPrompt 61: Fit a simple linear regression\nModel the relationship between a response and a single predictor using `lm()`【496611002125600†L14-L32】.\nlm_fit <- lm(y ~ x, data = data)\nsummary(lm_fit)\nPrompt 62: Fit a multiple linear regression\nInclude multiple predictors in a linear model.\nlm_fit <- lm(y ~ x1 + x2 + x3, data = data)\nsummary(lm_fit)\nPrompt 63: Fit a polynomial regression\nUse higher‑order terms to capture non‑linear relationships.\npoly_fit <- lm(y ~ poly(x, degree = 2, raw = TRUE), data = data)\nsummary(poly_fit)\nPrompt 64: Fit a logistic regression\nModel a binary response variable using `glm()` with the binomial family.\nlogit_fit <- glm(y ~ x1 + x2, data = data, family = binomial)\nsummary(logit_fit)\nPrompt 65: Fit a Poisson regression\nModel count data using `glm()` with the Poisson family.\npois_fit <- glm(count ~ x1 + offset(log(exposure)), data = data, family = poisson)\nsummary(pois_fit)\nPrompt 66: Fit a linear model without an intercept\nSuppress the intercept term by adding `0 +` in the formula【496611002125600†L134-L141】.\nlm_no_intercept <- lm(y ~ 0 + x1 + x2, data = data)\ncoef(lm_no_intercept)\nPrompt 67: Extract coefficients from a model\nObtain estimated coefficients from an `lm` or `glm` object using `coef()`.\ncoefficients <- coef(lm_fit)\nPrompt 68: Predict new values\nGenerate predictions on new data using `predict()`.\nnew_data <- data.frame(x1 = c(1, 2), x2 = c(3, 4))\npredictions <- predict(lm_fit, newdata = new_data)\nPrompt 69: Plot diagnostic plots\nInspect model diagnostics such as residuals and fitted values using `plot(lm_fit)`.\npar(mfrow = c(2, 2))\nplot(lm_fit)\nPrompt 70: Summarize model output\nView summary statistics, coefficients and diagnostic metrics with `summary()`.\nsummary(lm_fit)\nAdvanced Modeling and Machine Learning\nPrompt 71: Split data into training and testing sets\nRandomly partition your dataset into training and testing subsets.\nset.seed(42)\ntrain_index <- sample(seq_len(nrow(data)), size = 0.7 * nrow(data))\ntrain <- data[train_index, ]\ntest <- data[-train_index, ]\nPrompt 72: Perform k‑fold cross‑validation\nUse the **caret** package to perform k‑fold cross‑validation when training models.\nlibrary(caret)\ncontrol <- trainControl(method = 'cv', number = 5)\ncv_model <- train(y ~ ., data = data, method = 'lm', trControl = control)\nPrompt 73: Fit a decision tree\nCreate a classification or regression tree using **rpart**.\nlibrary(rpart)\ntree_model <- rpart(Species ~ ., data = iris, method = 'class')\nprintcp(tree_model)\nPrompt 74: Fit a random forest\nTrain an ensemble of decision trees using **randomForest**.\nlibrary(randomForest)\nrf_model <- randomForest(Species ~ ., data = iris, ntree = 500)\nprint(rf_model)\nPrompt 75: Fit a gradient boosting machine\nUse the **xgboost** package for gradient boosting on numeric matrices.\nlibrary(xgboost)\n# prepare matrices\nlabel <- as.numeric(iris$Species) - 1\ntrain_matrix <- xgb.DMatrix(data = as.matrix(iris[, -5]), label = label)\nparams <- list(objective = 'multi:softprob', num_class = 3)\nmodel <- xgb.train(params, train_matrix, nrounds = 50)\nPrompt 76: Fit a support vector machine\nUse **e1071** or **kernlab** to build an SVM classifier.\nlibrary(e1071)\nsvm_model <- svm(Species ~ ., data = iris, kernel = 'radial')\nsummary(svm_model)\nPrompt 77: Fit k‑nearest neighbors\nImplement KNN classification via the **class** package or **caret**.\nlibrary(class)\nk <- 3\ntrain_x <- iris[ , -5]\ntrain_y <- iris$Species\npred <- knn(train_x, train_x, train_y, k = k)\nPrompt 78: Fit a Naive Bayes classifier\nUse **e1071** to fit a naive Bayes model for categorical data.\nlibrary(e1071)\nnb_model <- naiveBayes(Species ~ ., data = iris)\nnb_pred <- predict(nb_model, iris)\nPrompt 79: Fit a ridge regression\nApply regularization to linear models using **glmnet** with alpha = 0 for ridge.\nlibrary(glmnet)\nx <- model.matrix(y ~ ., data)[, -1]\ny_vec <- data$y\nridge_fit <- cv.glmnet(x, y_vec, alpha = 0)\ncoef(ridge_fit, s = 'lambda.min')\nPrompt 80: Fit a lasso regression\nUse **glmnet** with alpha = 1 to perform lasso penalization.\nlasso_fit <- cv.glmnet(x, y_vec, alpha = 1)\ncoef(lasso_fit, s = 'lambda.min')\nClustering and Unsupervised Learning\nPrompt 81: Perform k‑means clustering\nPartition observations into k clusters using `kmeans()`.\nset.seed(123)\nkm <- kmeans(iris[, -5], centers = 3)\nkm$cluster\nPrompt 82: Determine optimal number of clusters (elbow)\nPlot total within‑cluster sum of squares for various k values to choose the optimal number.\nwss <- sapply(1:10, function(k) {\n  kmeans(iris[, -5], centers = k, nstart = 10)$tot.withinss\n})\nplot(1:10, wss, type = 'b', pch = 19, frame = FALSE, xlab = 'k', ylab = 'Total Within Sum of Squares')\nPrompt 83: Perform hierarchical clustering\nUse `hclust()` on a distance matrix to build a dendrogram.\nd <- dist(iris[, -5])\nhc <- hclust(d, method = 'complete')\nplot(hc, labels = iris$Species)\nPrompt 84: Plot a dendrogram\nVisualize hierarchical clustering results with a dendrogram.\nplot(as.dendrogram(hc), main = 'Hierarchical Clustering Dendrogram')\nPrompt 85: Standardize data before clustering\nScale variables to have mean 0 and unit variance using `scale()`.\nscaled_data <- scale(iris[, -5])\nkm_scaled <- kmeans(scaled_data, centers = 3)\nPrompt 86: Perform principal component analysis\nReduce dimensionality of numeric data using `prcomp()`.\npca <- prcomp(iris[, -5], scale. = TRUE)\nsummary(pca)\nPrompt 87: Plot a PCA biplot\nVisualize principal components and variable loadings.\nbiplot(pca, scale = 0, main = 'PCA Biplot')\nPrompt 88: Perform t‑SNE\nApply t‑distributed stochastic neighbor embedding via **Rtsne** for high‑dimensional data.\nlibrary(Rtsne)\ntsne_out <- Rtsne(as.matrix(iris[, -5]), dims = 2, perplexity = 30)\nplot(tsne_out$Y, col = as.numeric(iris$Species), pch = 19)\nPrompt 89: Perform DBSCAN clustering\nDensity‑based clustering with **dbscan** package.\nlibrary(dbscan)\ncl <- dbscan(iris[, -5], eps = 0.5, minPts = 5)\ncl$cluster\nPrompt 90: Perform factor analysis\nIdentify latent variables influencing observed data using `factanal()`.\nfa <- factanal(iris[, -5], factors = 2, rotation = 'varimax')\nfa\nTime Series Analysis\nPrompt 91: Create a time series object\nUse `ts()` to convert a numeric vector into a time series object.\nmy_ts <- ts(data$variable, start = c(2020, 1), frequency = 12)\nPrompt 92: Plot a time series\nVisualize a time series object using `plot()`.\nplot(my_ts, main = 'Time Series Plot', ylab = 'Value', xlab = 'Time')\nPrompt 93: Decompose a time series\nBreak down a series into trend, seasonal and irregular components using `decompose()`.\ncomponents <- decompose(my_ts, type = 'additive')\nplot(components)\nPrompt 94: Check stationarity (ADF test)\nUse the Augmented Dickey–Fuller test from **tseries** to test for stationarity.\nlibrary(tseries)\nadf.test(my_ts)\nPrompt 95: Fit an ARIMA model\nAutomatically select and fit an ARIMA model using **forecast**.\nlibrary(forecast)\nfit <- auto.arima(my_ts)\nfit\nPrompt 96: Forecast future values\nPredict future observations with the fitted model and plot the forecast.\nfc <- forecast(fit, h = 12)\nplot(fc)\nPrompt 97: Plot forecast results\nVisualize the predicted values and prediction intervals.\nautoplot(fc) + ggtitle('Forecast')\nPrompt 98: Fit exponential smoothing (Holt–Winters)\nUse `HoltWinters()` for exponential smoothing.\nhw <- HoltWinters(my_ts)\nplot(hw)\nPrompt 99: Perform STL decomposition\nApply Seasonal-Trend decomposition using Loess.\nstl_fit <- stl(my_ts, s.window = 'periodic')\nplot(stl_fit)\nPrompt 100: Evaluate forecast accuracy\nCompute accuracy metrics such as MAE and RMSE using `accuracy()`.\nacc <- accuracy(fc)\nacc\nData Visualization with ggplot2\nPrompt 101: Create a scatter plot\nUse `ggplot()` with `geom_point()` to visualize the relationship between two variables.\nlibrary(ggplot2)\nggplot(data, aes(x = variable1, y = variable2)) + geom_point() + ggtitle('Scatter Plot')\nPrompt 102: Create a line plot\nPlot time series or ordered data with `geom_line()`.\nggplot(data, aes(x = time, y = value)) + geom_line(color = 'blue') + labs(title = 'Line Plot', x = 'Time', y = 'Value')\nPrompt 103: Create a bar chart\nRepresent categorical data as bars using `geom_bar()`.\nggplot(data, aes(x = category)) + geom_bar(fill = 'tomato') + labs(title = 'Bar Chart', x = 'Category', y = 'Count')\nPrompt 104: Create a histogram\nVisualize the distribution of a continuous variable with `geom_histogram()`.\nggplot(data, aes(x = variable)) + geom_histogram(binwidth = 1, fill = 'skyblue', color = 'black')\nPrompt 105: Add facets\nUse `facet_wrap()` or `facet_grid()` to create trellis plots.\nggplot(data, aes(x = value)) + geom_histogram(binwidth = 1) + facet_wrap(~ group) + labs(title = 'Faceted Histograms')\nPrompt 106: Customize colors and themes\nApply a color palette and theme to improve plot aesthetics.\nggplot(data, aes(x = variable1, y = variable2, color = group)) + geom_point() + theme_minimal() + scale_color_brewer(palette = 'Set2')\nPrompt 107: Add a smooth line\nOverlay a regression or loess smooth using `geom_smooth()`.\nggplot(data, aes(x = x, y = y)) + geom_point() + geom_smooth(method = 'lm', se = FALSE) + labs(title = 'Scatter with Regression Line')\nPrompt 108: Create a boxplot\nUse `geom_boxplot()` to display distributions for multiple groups.\nggplot(data, aes(x = group, y = value)) + geom_boxplot(fill = 'lightgreen') + labs(title = 'Boxplot')\nPrompt 109: Create a density plot\nPlot a density estimate with `geom_density()`.\nggplot(data, aes(x = variable, fill = group)) + geom_density(alpha = 0.5) + labs(title = 'Density Plot')\nPrompt 110: Save a plot to file\nExport plots to PNG, PDF or other formats using `ggsave()`.\np <- ggplot(data, aes(x = variable1, y = variable2)) + geom_point()\nggsave('scatter_plot.png', p, width = 6, height = 4)\nModel Evaluation and Validation\nPrompt 111: Compute a confusion matrix\nUse `table()` or **caret** to generate a confusion matrix for classification results.\npred <- predict(rf_model, iris)\nconf_matrix <- table(Predicted = pred, Actual = iris$Species)\nPrompt 112: Compute accuracy, precision and recall\nCalculate evaluation metrics from the confusion matrix.\ntp <- conf_matrix[1,1]; fp <- conf_matrix[2,1]; fn <- conf_matrix[1,2]; tn <- conf_matrix[2,2]\naccuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)\nprecision <- tp / (tp + fp)\nrecall <- tp / (tp + fn)\nPrompt 113: Plot a ROC curve and compute AUC\nVisualize trade‑offs between true positive and false positive rates using **pROC**.\nlibrary(pROC)\nprob <- predict(rf_model, iris, type = 'prob')[,1]\nroc_obj <- roc(iris$Species, prob)\nplot(roc_obj)\nauc_value <- auc(roc_obj)\nPrompt 114: Calculate R‑squared\nRetrieve the coefficient of determination for regression models.\nrsq <- summary(lm_fit)$r.squared\nPrompt 115: Compute mean squared error (MSE)\nEvaluate regression performance by averaging squared residuals.\npred <- predict(lm_fit, newdata = data)\nmse <- mean((data$y - pred)^2)\nPrompt 116: Perform cross‑validation with caret\nRun resampling techniques in **caret** for general models.\nset.seed(123)\ncontrol <- trainControl(method = 'repeatedcv', number = 10, repeats = 3)\ncv_result <- train(y ~ ., data = data, method = 'lm', trControl = control)\nPrompt 117: Plot residuals vs fitted values\nAssess homoscedasticity by plotting residuals against fitted values.\nresiduals <- resid(lm_fit)\nfitted_vals <- fitted(lm_fit)\nplot(fitted_vals, residuals, xlab = 'Fitted Values', ylab = 'Residuals', main = 'Residuals vs Fitted')\nabline(h = 0, col = 'red')\nPrompt 118: Identify influential points\nCalculate Cook’s distance to detect influential observations.\ncooks <- cooks.distance(lm_fit)\nplot(cooks, type = 'h', main = \"Cook's distance\")\nPrompt 119: Perform stepwise model selection\nUse `step()` to carry out stepwise selection based on AIC.\nstep_model <- step(lm_full, direction = 'both')\nPrompt 120: Validate model assumptions\nCheck assumptions like normality of residuals, independence and linearity.\npar(mfrow = c(2, 2))\nplot(lm_fit)\nshapiro.test(residuals(lm_fit))\nData Structures\nPrompt 121: Create a vector\nCombine elements into an atomic vector using the `c()` function.\nv <- c(1, 2, 3, 4, 5)\nPrompt 122: Create a matrix\nDefine a two‑dimensional matrix with `matrix()`.\nm <- matrix(1:9, nrow = 3, ncol = 3, byrow = TRUE)\nPrompt 123: Create a list\nStore heterogeneous objects in a list.\nlst <- list(numbers = 1:5, letters = letters[1:3], data = data.frame(x = 1:3, y = 4:6))\nPrompt 124: Create a data frame\nConstruct a data frame from vectors of equal length.\ndf <- data.frame(name = c('A','B','C'), score = c(90, 85, 88))\nPrompt 125: Create a tibble\nUse the **tibble** package to create a modern tibble with enhanced printing.\nlibrary(tibble)\ntbl <- tibble(name = c('A','B'), value = c(1, 2))\nPrompt 126: Convert data frame to tibble\nTransform a base data frame into a tibble.\ntbl <- as_tibble(df)\nPrompt 127: Access elements by index\nRefer to individual elements in vectors, lists or data frames using bracket notation.\nthird_element <- v[3];\nlist_item <- lst$numbers[2];\ncell <- df[1, 'score']\nPrompt 128: Combine objects by rows and columns\nUse `rbind()` and `cbind()` to merge data structures.\ncombined_rows <- rbind(df, data.frame(name = 'D', score = 92))\ncombined_cols <- cbind(df, grade = c('A', 'B', 'A'))\nPrompt 129: Reshape an array\nCreate and manipulate multidimensional arrays with `array()`.\narr <- array(1:24, dim = c(2, 3, 4))\narr[1, , 2]\nPrompt 130: Convert factors\nConvert factor variables to numeric or character to suit analysis.\ndata$factor_var <- as.numeric(as.character(data$factor_var))\nFunctions and Programming Constructs\nPrompt 131: Define a simple function\nEncapsulate reusable code by defining a function using `function()`.\nsquare <- function(x) {\n  x^2\n}\nsquare(4)\nPrompt 132: Use conditional statements\nControl flow with `if`, `else if`, and `else`.\ncheck_number <- function(x) {\n  if (x > 0) {\n    'positive'\n  } else if (x < 0) {\n    'negative'\n  } else {\n    'zero'\n  }\n}\ncheck_number(-5)\nPrompt 133: Use a for loop\nIterate over a sequence of values using a `for` loop.\nsum <- 0\nfor (i in 1:10) {\n  sum <- sum + i\n}\nsum\nPrompt 134: Use a while loop\nExecute a block repeatedly while a condition is TRUE.\ncount <- 1\nwhile (count <= 5) {\n  print(count)\n  count <- count + 1\n}\nPrompt 135: Use a repeat loop\nCreate an infinite loop that must be broken manually using `break()`.\nx <- 1\nrepeat {\n  if (x > 3) break\n  print(x)\n  x <- x + 1\n}\nPrompt 136: Apply a function with `apply()`\nApply a function across rows or columns of a matrix or array.\nm <- matrix(1:9, nrow = 3)\nrow_sums <- apply(m, 1, sum)\ncol_means <- apply(m, 2, mean)\nPrompt 137: Use `lapply()`\nApply a function to each element of a list and return a list.\nresult <- lapply(lst$numbers, function(x) x * 2)\nPrompt 138: Use `sapply()`\nSimplify the result of `lapply()` to a vector or matrix when possible.\nresult_vec <- sapply(lst$numbers, function(x) x * 2)\nPrompt 139: Use `map` from purrr\nIterate over lists or vectors with functional programming using **purrr**.\nlibrary(purrr)\nmap_dbl(1:5, ~ .x^2)\nPrompt 140: Use anonymous functions\nWrite functions without naming them for short, disposable operations.\nsapply(1:5, function(x) x * 3)\nString Manipulation\nPrompt 141: Calculate string length\nUse `nchar()` to obtain the number of characters in a string.\nnchar('R programming')\nPrompt 142: Convert to upper and lower case\nChange the case of characters with `toupper()` and `tolower()`.\ntoupper('hello'); tolower('WORLD')\nPrompt 143: Concatenate strings\nCombine multiple strings using `paste()` or `paste0()`.\nfull <- paste('Hello', 'world', sep = ', ')\nno_space <- paste0('R', 'Stats')\nPrompt 144: Split a string\nDivide a string into parts based on a delimiter using `strsplit()`.\nparts <- strsplit('apple,banana,cherry', split = ',')[[1]]\nPrompt 145: Find and replace patterns\nReplace text patterns with `gsub()` or `sub()`.\ntext <- 'R is great'\nnew_text <- gsub('great', 'awesome', text)\nPrompt 146: Extract substrings\nSelect a portion of a string using `substr()` or `substring()`.\nsubstr('statistics', start = 1, stop = 4)\nPrompt 147: Detect pattern presence\nCheck if a pattern exists in a string with `grepl()`.\ngrepl('data', 'big data analysis')\nPrompt 148: Use regular expressions to match patterns\nMatch complex string patterns using regular expressions via `gregexpr()`.\nmatches <- gregexpr('[0-9]+', 'Room 101, Floor 2')\nregmatches('Room 101, Floor 2', matches)\nPrompt 149: Remove whitespace\nTrim leading and trailing whitespace with `trimws()`.\ntrimws('  hello  ')\nPrompt 150: Convert factors to character strings\nTransform factor variables into strings for text processing.\nchar_var <- as.character(factor_var)\nDate and Time Handling\nPrompt 151: Convert string to Date\nParse a character string into a Date object using `as.Date()`.\ndates <- as.Date(c('2025-10-08', '2025-12-31'))\nPrompt 152: Parse date‑time with lubridate\nUse **lubridate** to handle date‑time formats more flexibly.\nlibrary(lubridate)\ndt <- ymd_hms('2025-10-08 14:30:00')\nPrompt 153: Extract year, month and day\nRetrieve components of a date or date‑time object.\nyear <- year(dt); month <- month(dt); day <- day(dt)\nPrompt 154: Compute difference between dates\nCalculate the time interval between two dates using `difftime()`.\nstart <- as.Date('2025-01-01')\nend <- as.Date('2025-12-31')\ninterval <- difftime(end, start, units = 'days')\nPrompt 155: Add or subtract time durations\nUse lubridate to add or subtract periods and durations.\nnew_date <- dt + days(7) - hours(2)\nPrompt 156: Round dates to the nearest unit\nRound date‑times to a specified unit such as week or month.\nrounded <- round_date(dt, unit = 'hour')\nPrompt 157: Format dates for display\nCustomize date output with `format()` or lubridate’s `stamp()`.\nformatted <- format(dt, '%d-%b-%Y %H:%M')\nPrompt 158: Handle time zones\nSpecify and convert between time zones using `with_tz()` and `force_tz()`.\ndt_local <- ymd_hms('2025-10-08 14:30:00', tz = 'Europe/Madrid')\ndt_utc <- with_tz(dt_local, 'UTC')\nPrompt 159: Create a sequence of dates\nGenerate regularly spaced dates with `seq.Date()`.\ndate_seq <- seq(as.Date('2025-01-01'), as.Date('2025-01-10'), by = 'day')\nPrompt 160: Group data by date components\nAggregate data by year, month or day using `floor_date()` and dplyr.\nlibrary(lubridate)\nmonthly_summary <- data %>% group_by(month = floor_date(date, 'month')) %>% summarise(total = sum(value))\nRandomization and Simulation\nPrompt 161: Set a random seed\nEnsure reproducible results by setting a seed with `set.seed()`.\nset.seed(123)\nPrompt 162: Sample from a vector\nRandomly sample elements from a vector using `sample()`.\nsample_vec <- sample(1:100, size = 10, replace = FALSE)\nPrompt 163: Generate random numbers from distributions\nUse functions like `rnorm()`, `runif()`, and `rbinom()` to sample from normal, uniform and binomial distributions.\nnorm_samples <- rnorm(10, mean = 0, sd = 1)\nunif_samples <- runif(10, min = 0, max = 1)\nbinom_samples <- rbinom(10, size = 20, prob = 0.5)\nPrompt 164: Simulate dice rolls\nRoll a fair six‑sided die multiple times using `sample()`.\ndice_rolls <- sample(1:6, size = 20, replace = TRUE)\nPrompt 165: Perform bootstrap sampling\nGenerate bootstrap samples to estimate variability of statistics.\nset.seed(123)\nboot_means <- replicate(1000, mean(sample(data$variable, replace = TRUE)))\nPrompt 166: Run a Monte Carlo simulation\nUse repeated random sampling to estimate a quantity.\nset.seed(42)\nmonte_carlo <- function(n_sim) {\n  successes <- 0\n  for (i in 1:n_sim) {\n    x <- runif(1)\n    y <- runif(1)\n    if (x^2 + y^2 <= 1) successes <- successes + 1\n  }\n  4 * successes / n_sim\n}\np_estimate <- monte_carlo(10000)\nPrompt 167: Generate a random permutation\nShuffle the order of elements in a vector.\nperm <- sample(1:10)\nPrompt 168: Randomly split a dataset\nDivide data into random subsets (e.g., training and testing).\nset.seed(123)\nindices <- sample(seq_len(nrow(data)))\ntrain_indices <- indices[1:floor(0.8 * length(indices))]\ntest_indices <- indices[-train_indices]\ntrain_set <- data[train_indices, ]\ntest_set <- data[test_indices, ]\nPrompt 169: Simulate a Poisson process\nGenerate arrival times from a Poisson process with rate λ.\nlambda <- 2\nn <- 100\ninterarrival <- rexp(n, rate = lambda)\narrival_times <- cumsum(interarrival)\nPrompt 170: Simulate a Markov chain\nModel transitions between states with a transition matrix.\nstates <- c('A','B','C')\ntransition <- matrix(c(0.5,0.3,0.2,\n                      0.4,0.4,0.2,\n                      0.2,0.5,0.3),\n                    nrow = 3, byrow = TRUE, dimnames = list(states, states))\nset.seed(123)\ncurrent <- 'A'\nchain <- character(10)\nchain[1] <- current\nfor (i in 2:10) {\n  current <- sample(states, 1, prob = transition[current, ])\n  chain[i] <- current\n}\nFile and Directory Management\nPrompt 171: List files in a directory\nUse `list.files()` to get a vector of file names.\nfiles <- list.files(path = '.', pattern = '*.csv', full.names = TRUE)\nPrompt 172: Check if a file exists\nVerify whether a file exists using `file.exists()`.\nexists <- file.exists('myfile.csv')\nPrompt 173: Read multiple files and combine\nUse `lapply()` to read multiple files and `bind_rows()` to merge them.\nlibrary(readr)\nfile_list <- list.files(pattern = '*.csv')\nall_data <- dplyr::bind_rows(lapply(file_list, read_csv))\nPrompt 174: Create a new directory\nCreate directories with `dir.create()`.\ndir.create('new_folder')\nPrompt 175: Delete a file or directory\nRemove files or directories using `file.remove()` and `unlink()`.\nfile.remove('old_file.csv')\nunlink('old_folder', recursive = TRUE)\nPrompt 176: Copy a file\nDuplicate a file using `file.copy()`.\nfile.copy('source.txt', 'destination.txt')\nPrompt 177: Move or rename a file\nChange the name or location of a file using `file.rename()`.\nfile.rename('old_name.txt', 'new_name.txt')\nPrompt 178: Write data to a compressed file\nCompress data when writing to disk using `gzfile()`.\ngz_con <- gzfile('data.csv.gz', 'w')\nwrite.csv(data, gz_con)\nclose(gz_con)\nPrompt 179: Get file information\nRetrieve metadata such as size and modification time using `file.info()`.\ninfo <- file.info('data.csv')\nsize <- info$size; modified <- info$mtime\nPrompt 180: Redirect output to a file\nCapture printed output using `sink()` to write to a text file.\nsink('log.txt')\nprint(summary(data))\nsink()\nWeb Data and API\nPrompt 181: Download a file from a URL\nUse `download.file()` to retrieve files from the web.\ndownload.file('https://example.com/data.csv', destfile = 'downloaded.csv')\nPrompt 182: Read an HTML table\nUse **rvest** to scrape tables from web pages.\nlibrary(rvest)\npage <- read_html('https://example.com')\ntable <- html_table(html_nodes(page, 'table')[[1]])\nPrompt 183: Extract nodes with CSS selectors\nSelect HTML elements using CSS selectors with **rvest**.\ntitles <- html_text(html_nodes(page, 'h2.title'))\nPrompt 184: Parse an XML file\nUse **xml2** to read and parse XML data.\nlibrary(xml2)\nxml <- read_xml('file.xml')\nvalues <- xml_text(xml_find_all(xml, '//tag'))\nPrompt 185: Fetch JSON data from an API\nUse **httr** and **jsonlite** to request and parse JSON.\nlibrary(httr); library(jsonlite)\nresponse <- GET('https://api.example.com/data')\ndata_json <- content(response, as = 'text')\ndata <- fromJSON(data_json)\nPrompt 186: Send an HTTP GET request\nRetrieve data using `GET()` with query parameters.\nres <- GET('https://api.example.com/search', query = list(q = 'R programming'))\ncontent(res, 'text')\nPrompt 187: Convert API data to a data frame\nTransform JSON or list structures into tidy data frames.\ndf <- as.data.frame(data)\nPrompt 188: Scrape multiple pages\nLoop through multiple pages to collect data in a single data set.\nbase_url <- 'https://example.com/page='\nresults <- list()\nfor (i in 1:5) {\n  page <- read_html(paste0(base_url, i))\n  results[[i]] <- html_text(html_nodes(page, '.item'))\n}\nitems <- unlist(results)\nPrompt 189: Extract meta information from a web page\nUse **rvest** to extract metadata such as title and description.\nmeta_title <- html_text(html_nodes(page, 'title'))\nmeta_desc <- html_attr(html_nodes(page, \"meta[name='description']\"), 'content')\nPrompt 190: Handle API authentication\nSend authenticated requests using headers or tokens with **httr**.\ntoken <- 'your_token_here'\nres <- GET('https://api.example.com/protected', add_headers(Authorization = paste('Bearer', token)))\ncontent(res, 'text')\nMiscellaneous Tips and Tricks\nPrompt 191: Install and load packages\nInstall packages with `install.packages()` and load them with `library()`.\ninstall.packages('dplyr')\nlibrary(dplyr)\nPrompt 192: Check installed packages\nList packages currently installed on your system.\ninstalled <- installed.packages()\nhead(installed[, 'Package'])\nPrompt 193: Remove objects from workspace\nClean up memory by removing objects with `rm()` and using `gc()`.\nrm(list = ls())\ngc()\nPrompt 194: Set working directory\nChange the working directory using `setwd()` and verify with `getwd()`.\nsetwd('/path/to/project')\ngetwd()\nPrompt 195: Use pipes (`%>%`)\nMake code more readable by chaining operations with the pipe operator from **magrittr** or **dplyr**.\nlibrary(dplyr)\nresult <- data %>% filter(value > 0) %>% summarise(mean = mean(value))\nPrompt 196: Profile code performance\nMeasure execution time of expressions using `system.time()`.\nexecution <- system.time({\n  Sys.sleep(1)\n})\nPrompt 197: Vectorize operations\nAvoid explicit loops by performing vectorized arithmetic for speed.\nv <- 1:100\nsquared <- v^2\nPrompt 198: Use parallel computing\nLeverage multiple cores with the **parallel** package.\nlibrary(parallel)\ncl <- makeCluster(detectCores() - 1)\nparSapply(cl, 1:4, function(x) x^2)\nstopCluster(cl)\nPrompt 199: Document functions with roxygen2\nUse roxygen2 comments to document your functions for package development.\n#' Calculate the square\n#'\n#' @param x A numeric value\n#' @return The square of x\nsquare <- function(x) { x^2 }\nPrompt 200: Create reproducible analysis\nEnsure reproducibility by setting seeds and recording session information.\nset.seed(123)\n# analysis code here\ninfo <- sessionInfo()\nThe post\n200 R Programming Prompts & Code Snippets for Data Analysis and Modeling\nappeared first on\nR Programming Books\n.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nBlog - R Programming Books\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "main_html": "<article class=\"post-397421 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">200 R Programming Prompts &amp; Code Snippets for Data Analysis and Modeling</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">October 8, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/rprogrammingbooks/\">rprogrammingbooks</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://rprogrammingbooks.com/200-r-programming-prompts-data-analysis/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=200-r-programming-prompts-data-analysis\"> Blog - R Programming Books</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<meta charset=\"utf-8\"/>\n\n<p>R is a versatile programming language designed for statistical computing and graphics. It can act as a calculator, provide numerical and graphical summaries of data and handle a variety of specific analyses:contentReference[oaicite:0]{index=0}. Whether you’re exploring data, running statistical tests or building predictive models, R offers built-in functions and packages to streamline the workflow. The <code>summary()</code> function, for example, gives a quick overview of each variable’s distribution:contentReference[oaicite:1]{index=1}, and the <code>lm()</code> function fits linear models and returns coefficients and diagnostics:contentReference[oaicite:2]{index=2}. The following sections present 200 practical prompts and code snippets organized by topic, from basic data operations to advanced modeling and visualization.</p>\n<h2>Data Input and Output</h2>\n<h3>Prompt 1: Read a CSV file</h3>\n<p>Use `read.csv()` to import a comma‑separated values file and store it in a data frame.</p>\n<pre>data &lt;- read.csv('path/to/file.csv', header = TRUE, stringsAsFactors = FALSE)</pre>\n<h3>Prompt 2: Read an Excel file</h3>\n<p>Load spreadsheet data from Excel files with the **readxl** package.</p>\n<pre>library(readxl)\ndata &lt;- read_excel('path/to/file.xlsx', sheet = 1)</pre>\n<h3>Prompt 3: Import data from a remote CSV</h3>\n<p>Read a CSV file from a web URL directly without downloading it first.</p>\n<pre>url &lt;- 'https://example.com/data.csv'\ndata &lt;- read.csv(url, header = TRUE)</pre>\n<h3>Prompt 4: Read a JSON file</h3>\n<p>Parse JSON data into an R list or data frame using **jsonlite**.</p>\n<pre>library(jsonlite)\njson_data &lt;- fromJSON('data.json')\ndata &lt;- as.data.frame(json_data)</pre>\n<h3>Prompt 5: Read data from a SQL database</h3>\n<p>Connect to an SQLite database and query data via **DBI** and **RSQLite**.</p>\n<pre>library(DBI)\ncon &lt;- dbConnect(RSQLite::SQLite(), 'database.sqlite')\nquery &lt;- 'SELECT * FROM my_table'\ndata &lt;- dbGetQuery(con, query)\ndbDisconnect(con)</pre>\n<h3>Prompt 6: Read and write RDS files</h3>\n<p>Load and save objects in R’s native serialized format with `saveRDS()` and `readRDS()`.</p>\n<pre>saveRDS(data, 'mydata.rds')\nloaded_data &lt;- readRDS('mydata.rds')</pre>\n<h3>Prompt 7: Write a data frame to CSV</h3>\n<p>Export a data frame to a CSV file using `write.csv()`.</p>\n<pre>write.csv(data, 'output.csv', row.names = FALSE)</pre>\n<h3>Prompt 8: Write data to Excel</h3>\n<p>Save a data frame to an Excel workbook with **writexl**.</p>\n<pre>library(writexl)\nwrite_xlsx(list(Sheet1 = data), 'output.xlsx')</pre>\n<h3>Prompt 9: Save workspace to an .RData file</h3>\n<p>Persist your current R environment by saving all objects to a file.</p>\n<pre>save.image('workspace.RData')</pre>\n<h3>Prompt 10: Load a .RData file</h3>\n<p>Restore a previously saved R workspace.</p>\n<pre>load('workspace.RData')</pre>\n<h2>Data Cleaning</h2>\n<h3>Prompt 11: Inspect data structure</h3>\n<p>Use `str()` to display the internal structure of an R object and see its variables and types.</p>\n<pre>str(data)</pre>\n<h3>Prompt 12: Identify missing values</h3>\n<p>Find missing (NA) values in your dataset using `is.na()` and count them.</p>\n<pre>sum(is.na(data))</pre>\n<h3>Prompt 13: Replace missing values with the mean</h3>\n<p>Impute missing numeric values by replacing them with the column mean.</p>\n<pre>data$variable[is.na(data$variable)] &lt;- mean(data$variable, na.rm = TRUE)</pre>\n<h3>Prompt 14: Remove rows with missing values</h3>\n<p>Omit any rows containing missing values using `na.omit()`.</p>\n<pre>clean_data &lt;- na.omit(data)</pre>\n<h3>Prompt 15: Convert characters to factors</h3>\n<p>Transform character columns into factors for categorical analysis.</p>\n<pre>data$category &lt;- as.factor(data$category)</pre>\n<h3>Prompt 16: Rename columns</h3>\n<p>Change column names using `names()` or `dplyr::rename()`.</p>\n<pre>names(data)[names(data) == 'old_name'] &lt;- 'new_name'\n# Or with dplyr\nlibrary(dplyr)\ndata &lt;- rename(data, new_name = old_name)</pre>\n<h3>Prompt 17: Reorder columns</h3>\n<p>Rearrange the order of columns in a data frame.</p>\n<pre>data &lt;- data[, c('col3', 'col1', 'col2', setdiff(names(data), c('col1','col2','col3')))]</pre>\n<h3>Prompt 18: Filter rows based on a condition</h3>\n<p>Select only the rows that meet a logical criterion.</p>\n<pre>subset_data &lt;- subset(data, variable &gt; 10)</pre>\n<h3>Prompt 19: Sort data frame by a column</h3>\n<p>Order data by ascending or descending values using `order()`.</p>\n<pre>sorted_data &lt;- data[order(data$variable, decreasing = FALSE), ]</pre>\n<h3>Prompt 20: Remove duplicate rows</h3>\n<p>Keep only unique rows using `unique()` or `distinct()`.</p>\n<pre>unique_data &lt;- unique(data)\n# Or with dplyr\nlibrary(dplyr)\nunique_data &lt;- distinct(data)</pre>\n<h2>Data Transformation with dplyr</h2>\n<h3>Prompt 21: Select specific columns</h3>\n<p>Use `select()` to choose a subset of columns from a data frame.</p>\n<pre>library(dplyr)\nsubset_data &lt;- select(data, column1, column2, column3)</pre>\n<h3>Prompt 22: Filter rows by criteria</h3>\n<p>Extract rows that satisfy given conditions using `filter()`.</p>\n<pre>filtered_data &lt;- filter(data, column1 == 'A', column2 &gt; 5)</pre>\n<h3>Prompt 23: Mutate new columns</h3>\n<p>Create new variables derived from existing columns using `mutate()`.</p>\n<pre>library(dplyr)\ndata &lt;- mutate(data, ratio = column1 / column2, log_value = log(column3))</pre>\n<h3>Prompt 24: Summarize data by groups</h3>\n<p>Group data and compute summary statistics with `group_by()` and `summarise()`.</p>\n<pre>library(dplyr)\nsumm &lt;- data %&gt;% group_by(category) %&gt;% summarise(mean_value = mean(value, na.rm = TRUE), count = n())</pre>\n<h3>Prompt 25: Group by multiple variables</h3>\n<p>Group data by more than one variable for multi‑level summaries.</p>\n<pre>summary &lt;- data %&gt;% group_by(category, subgroup) %&gt;% summarise(total = sum(value))</pre>\n<h3>Prompt 26: Arrange data</h3>\n<p>Sort data within the pipeline using `arrange()`.</p>\n<pre>sorted &lt;- data %&gt;% arrange(desc(value))</pre>\n<h3>Prompt 27: Count occurrences</h3>\n<p>Tabulate the number of observations per category with `count()`.</p>\n<pre>library(dplyr)\ncounts &lt;- data %&gt;% count(category)</pre>\n<h3>Prompt 28: Select distinct rows</h3>\n<p>Extract unique rows for specified columns using `distinct()`.</p>\n<pre>unique_rows &lt;- data %&gt;% distinct(category, value)</pre>\n<h3>Prompt 29: Join two data frames</h3>\n<p>Perform an inner join on two tables with common keys using `inner_join()`.</p>\n<pre>merged_data &lt;- inner_join(df1, df2, by = 'id')</pre>\n<h3>Prompt 30: Pivot data longer or wider</h3>\n<p>Reshape data using `pivot_longer()` and `pivot_wider()` from **tidyr**.</p>\n<pre>library(tidyr)\nlong &lt;- pivot_longer(data, cols = starts_with('Q'), names_to = 'question', values_to = 'score')\nwide &lt;- pivot_wider(long, names_from = question, values_from = score)</pre>\n<h2>Exploratory Data Analysis</h2>\n<h3>Prompt 31: Compute summary statistics</h3>\n<p>Get an overview of each variable with the `summary()` function, which reports minimum, quartiles, median, mean and maximum【116883529303011†L61-L77】.</p>\n<pre>summary(data)</pre>\n<h3>Prompt 32: Compute quantiles</h3>\n<p>Calculate specific quantiles (e.g., 25th and 75th percentiles) using `quantile()`.</p>\n<pre>quantiles &lt;- quantile(data$variable, probs = c(0.25, 0.5, 0.75))</pre>\n<h3>Prompt 33: Create a frequency table</h3>\n<p>Tabulate counts of unique values in a vector using `table()`.</p>\n<pre>freq &lt;- table(data$category)</pre>\n<h3>Prompt 34: Create a cross‑tabulation</h3>\n<p>Produce contingency tables for two categorical variables with `xtabs()` or `table()`.</p>\n<pre>crosstab &lt;- table(data$category, data$group)</pre>\n<h3>Prompt 35: Compute a correlation matrix</h3>\n<p>Calculate pairwise correlations for numeric variables using `cor()`.</p>\n<pre>cor_matrix &lt;- cor(data[, sapply(data, is.numeric)], use = 'complete.obs')</pre>\n<h3>Prompt 36: Compute covariance matrix</h3>\n<p>Assess covariance between variables with `cov()`.</p>\n<pre>cov_matrix &lt;- cov(data[, sapply(data, is.numeric)], use = 'complete.obs')</pre>\n<h3>Prompt 37: Plot a histogram</h3>\n<p>Visualize the distribution of a continuous variable with `hist()`.</p>\n<pre>hist(data$variable, breaks = 30, col = 'steelblue', main = 'Histogram', xlab = 'Value')</pre>\n<h3>Prompt 38: Create a boxplot</h3>\n<p>Display the distribution and outliers of a variable using `boxplot()`.</p>\n<pre>boxplot(data$variable ~ data$group, main = 'Boxplot', xlab = 'Group', ylab = 'Variable')</pre>\n<h3>Prompt 39: Create a scatter plot</h3>\n<p>Plot two numeric variables against each other with `plot()`.</p>\n<pre>plot(data$variable1, data$variable2, main = 'Scatter Plot', xlab = 'Variable 1', ylab = 'Variable 2', pch = 19)</pre>\n<h3>Prompt 40: Make a pairwise scatterplot matrix</h3>\n<p>Explore relationships between multiple variables using `pairs()`.</p>\n<pre>pairs(data[, 1:4], main = 'Pairs Plot')</pre>\n<h2>Basic Statistics</h2>\n<h3>Prompt 41: Compute the mean</h3>\n<p>Calculate the arithmetic mean of a numeric vector with `mean()`.</p>\n<pre>avg &lt;- mean(data$variable, na.rm = TRUE)</pre>\n<h3>Prompt 42: Compute the median</h3>\n<p>Find the median (50th percentile) of a numeric vector.</p>\n<pre>med &lt;- median(data$variable, na.rm = TRUE)</pre>\n<h3>Prompt 43: Compute the standard deviation</h3>\n<p>Measure the spread of values around the mean using `sd()`.</p>\n<pre>std_dev &lt;- sd(data$variable, na.rm = TRUE)</pre>\n<h3>Prompt 44: Compute the variance</h3>\n<p>Compute the sample variance of a numeric vector using `var()`.</p>\n<pre>var_value &lt;- var(data$variable, na.rm = TRUE)</pre>\n<h3>Prompt 45: Compute the range</h3>\n<p>Get the minimum and maximum values with `range()`.</p>\n<pre>range_values &lt;- range(data$variable, na.rm = TRUE)</pre>\n<h3>Prompt 46: Compute the interquartile range</h3>\n<p>Calculate the IQR (difference between 75th and 25th percentiles) using `IQR()`.</p>\n<pre>iqr_value &lt;- IQR(data$variable, na.rm = TRUE)</pre>\n<h3>Prompt 47: Generate a random sample from a normal distribution</h3>\n<p>Create a vector of random numbers drawn from a normal distribution using `rnorm()`.</p>\n<pre>set.seed(123)\nrandom_values &lt;- rnorm(100, mean = 0, sd = 1)</pre>\n<h3>Prompt 48: Compute summary of an entire data frame</h3>\n<p>Summarize all variables at once using `summary()`【116883529303011†L61-L77】.</p>\n<pre>summary_stats &lt;- summary(data)</pre>\n<h3>Prompt 49: Compute covariance matrix</h3>\n<p>Calculate variances and covariances for numeric variables using `cov()`【116883529303011†L116-L132】.</p>\n<pre>cov_mat &lt;- cov(data[, sapply(data, is.numeric)])</pre>\n<h3>Prompt 50: Compute correlation coefficient</h3>\n<p>Measure linear relationships between two variables using `cor()`.</p>\n<pre>correlation &lt;- cor(data$variable1, data$variable2, use = 'complete.obs')</pre>\n<h2>Statistical Tests</h2>\n<h3>Prompt 51: One‑sample t‑test</h3>\n<p>Test whether the mean of a sample differs from a hypothesized value.</p>\n<pre>t.test(data$variable, mu = 0)</pre>\n<h3>Prompt 52: Two‑sample t‑test</h3>\n<p>Compare means of two independent groups using a two‑sample t‑test.</p>\n<pre>t.test(variable ~ group, data = data)</pre>\n<h3>Prompt 53: Paired t‑test</h3>\n<p>Compare means of paired observations, such as before‑after measurements.</p>\n<pre>t.test(data$pre, data$post, paired = TRUE)</pre>\n<h3>Prompt 54: Chi‑square test of independence</h3>\n<p>Assess the association between two categorical variables.</p>\n<pre>chisq.test(table(data$category, data$group))</pre>\n<h3>Prompt 55: Shapiro–Wilk normality test</h3>\n<p>Check normality of a numeric variable using `shapiro.test()`.</p>\n<pre>shapiro.test(data$variable)</pre>\n<h3>Prompt 56: Correlation test</h3>\n<p>Test whether the correlation coefficient differs from zero.</p>\n<pre>cor.test(data$variable1, data$variable2, method = 'pearson')</pre>\n<h3>Prompt 57: One‑way ANOVA</h3>\n<p>Compare means across more than two groups using analysis of variance.</p>\n<pre>anova_result &lt;- aov(variable ~ group, data = data)\nsummary(anova_result)</pre>\n<h3>Prompt 58: Wilcoxon rank‑sum test</h3>\n<p>Perform a non‑parametric test to compare two independent samples.</p>\n<pre>wilcox.test(variable ~ group, data = data)</pre>\n<h3>Prompt 59: Kruskal–Wallis test</h3>\n<p>Non‑parametric alternative to one‑way ANOVA for more than two groups.</p>\n<pre>kruskal.test(variable ~ group, data = data)</pre>\n<h3>Prompt 60: Proportion test</h3>\n<p>Test equality of proportions for two samples using `prop.test()`.</p>\n<pre>prop.test(x = c(40, 50), n = c(100, 120))</pre>\n<h2>Linear and Generalized Linear Models</h2>\n<h3>Prompt 61: Fit a simple linear regression</h3>\n<p>Model the relationship between a response and a single predictor using `lm()`【496611002125600†L14-L32】.</p>\n<pre>lm_fit &lt;- lm(y ~ x, data = data)\nsummary(lm_fit)</pre>\n<h3>Prompt 62: Fit a multiple linear regression</h3>\n<p>Include multiple predictors in a linear model.</p>\n<pre>lm_fit &lt;- lm(y ~ x1 + x2 + x3, data = data)\nsummary(lm_fit)</pre>\n<h3>Prompt 63: Fit a polynomial regression</h3>\n<p>Use higher‑order terms to capture non‑linear relationships.</p>\n<pre>poly_fit &lt;- lm(y ~ poly(x, degree = 2, raw = TRUE), data = data)\nsummary(poly_fit)</pre>\n<h3>Prompt 64: Fit a logistic regression</h3>\n<p>Model a binary response variable using `glm()` with the binomial family.</p>\n<pre>logit_fit &lt;- glm(y ~ x1 + x2, data = data, family = binomial)\nsummary(logit_fit)</pre>\n<h3>Prompt 65: Fit a Poisson regression</h3>\n<p>Model count data using `glm()` with the Poisson family.</p>\n<pre>pois_fit &lt;- glm(count ~ x1 + offset(log(exposure)), data = data, family = poisson)\nsummary(pois_fit)</pre>\n<h3>Prompt 66: Fit a linear model without an intercept</h3>\n<p>Suppress the intercept term by adding `0 +` in the formula【496611002125600†L134-L141】.</p>\n<pre>lm_no_intercept &lt;- lm(y ~ 0 + x1 + x2, data = data)\ncoef(lm_no_intercept)</pre>\n<h3>Prompt 67: Extract coefficients from a model</h3>\n<p>Obtain estimated coefficients from an `lm` or `glm` object using `coef()`.</p>\n<pre>coefficients &lt;- coef(lm_fit)</pre>\n<h3>Prompt 68: Predict new values</h3>\n<p>Generate predictions on new data using `predict()`.</p>\n<pre>new_data &lt;- data.frame(x1 = c(1, 2), x2 = c(3, 4))\npredictions &lt;- predict(lm_fit, newdata = new_data)</pre>\n<h3>Prompt 69: Plot diagnostic plots</h3>\n<p>Inspect model diagnostics such as residuals and fitted values using `plot(lm_fit)`.</p>\n<pre>par(mfrow = c(2, 2))\nplot(lm_fit)</pre>\n<h3>Prompt 70: Summarize model output</h3>\n<p>View summary statistics, coefficients and diagnostic metrics with `summary()`.</p>\n<pre>summary(lm_fit)</pre>\n<h2>Advanced Modeling and Machine Learning</h2>\n<h3>Prompt 71: Split data into training and testing sets</h3>\n<p>Randomly partition your dataset into training and testing subsets.</p>\n<pre>set.seed(42)\ntrain_index &lt;- sample(seq_len(nrow(data)), size = 0.7 * nrow(data))\ntrain &lt;- data[train_index, ]\ntest &lt;- data[-train_index, ]</pre>\n<h3>Prompt 72: Perform k‑fold cross‑validation</h3>\n<p>Use the **caret** package to perform k‑fold cross‑validation when training models.</p>\n<pre>library(caret)\ncontrol &lt;- trainControl(method = 'cv', number = 5)\ncv_model &lt;- train(y ~ ., data = data, method = 'lm', trControl = control)</pre>\n<h3>Prompt 73: Fit a decision tree</h3>\n<p>Create a classification or regression tree using **rpart**.</p>\n<pre>library(rpart)\ntree_model &lt;- rpart(Species ~ ., data = iris, method = 'class')\nprintcp(tree_model)</pre>\n<h3>Prompt 74: Fit a random forest</h3>\n<p>Train an ensemble of decision trees using **randomForest**.</p>\n<pre>library(randomForest)\nrf_model &lt;- randomForest(Species ~ ., data = iris, ntree = 500)\nprint(rf_model)</pre>\n<h3>Prompt 75: Fit a gradient boosting machine</h3>\n<p>Use the **xgboost** package for gradient boosting on numeric matrices.</p>\n<pre>library(xgboost)\n# prepare matrices\nlabel &lt;- as.numeric(iris$Species) - 1\ntrain_matrix &lt;- xgb.DMatrix(data = as.matrix(iris[, -5]), label = label)\nparams &lt;- list(objective = 'multi:softprob', num_class = 3)\nmodel &lt;- xgb.train(params, train_matrix, nrounds = 50)</pre>\n<h3>Prompt 76: Fit a support vector machine</h3>\n<p>Use **e1071** or **kernlab** to build an SVM classifier.</p>\n<pre>library(e1071)\nsvm_model &lt;- svm(Species ~ ., data = iris, kernel = 'radial')\nsummary(svm_model)</pre>\n<h3>Prompt 77: Fit k‑nearest neighbors</h3>\n<p>Implement KNN classification via the **class** package or **caret**.</p>\n<pre>library(class)\nk &lt;- 3\ntrain_x &lt;- iris[ , -5]\ntrain_y &lt;- iris$Species\npred &lt;- knn(train_x, train_x, train_y, k = k)</pre>\n<h3>Prompt 78: Fit a Naive Bayes classifier</h3>\n<p>Use **e1071** to fit a naive Bayes model for categorical data.</p>\n<pre>library(e1071)\nnb_model &lt;- naiveBayes(Species ~ ., data = iris)\nnb_pred &lt;- predict(nb_model, iris)</pre>\n<h3>Prompt 79: Fit a ridge regression</h3>\n<p>Apply regularization to linear models using **glmnet** with alpha = 0 for ridge.</p>\n<pre>library(glmnet)\nx &lt;- model.matrix(y ~ ., data)[, -1]\ny_vec &lt;- data$y\nridge_fit &lt;- cv.glmnet(x, y_vec, alpha = 0)\ncoef(ridge_fit, s = 'lambda.min')</pre>\n<h3>Prompt 80: Fit a lasso regression</h3>\n<p>Use **glmnet** with alpha = 1 to perform lasso penalization.</p>\n<pre>lasso_fit &lt;- cv.glmnet(x, y_vec, alpha = 1)\ncoef(lasso_fit, s = 'lambda.min')</pre>\n<h2>Clustering and Unsupervised Learning</h2>\n<h3>Prompt 81: Perform k‑means clustering</h3>\n<p>Partition observations into k clusters using `kmeans()`.</p>\n<pre>set.seed(123)\nkm &lt;- kmeans(iris[, -5], centers = 3)\nkm$cluster</pre>\n<h3>Prompt 82: Determine optimal number of clusters (elbow)</h3>\n<p>Plot total within‑cluster sum of squares for various k values to choose the optimal number.</p>\n<pre>wss &lt;- sapply(1:10, function(k) {\n  kmeans(iris[, -5], centers = k, nstart = 10)$tot.withinss\n})\nplot(1:10, wss, type = 'b', pch = 19, frame = FALSE, xlab = 'k', ylab = 'Total Within Sum of Squares')</pre>\n<h3>Prompt 83: Perform hierarchical clustering</h3>\n<p>Use `hclust()` on a distance matrix to build a dendrogram.</p>\n<pre>d &lt;- dist(iris[, -5])\nhc &lt;- hclust(d, method = 'complete')\nplot(hc, labels = iris$Species)</pre>\n<h3>Prompt 84: Plot a dendrogram</h3>\n<p>Visualize hierarchical clustering results with a dendrogram.</p>\n<pre>plot(as.dendrogram(hc), main = 'Hierarchical Clustering Dendrogram')</pre>\n<h3>Prompt 85: Standardize data before clustering</h3>\n<p>Scale variables to have mean 0 and unit variance using `scale()`.</p>\n<pre>scaled_data &lt;- scale(iris[, -5])\nkm_scaled &lt;- kmeans(scaled_data, centers = 3)</pre>\n<h3>Prompt 86: Perform principal component analysis</h3>\n<p>Reduce dimensionality of numeric data using `prcomp()`.</p>\n<pre>pca &lt;- prcomp(iris[, -5], scale. = TRUE)\nsummary(pca)</pre>\n<h3>Prompt 87: Plot a PCA biplot</h3>\n<p>Visualize principal components and variable loadings.</p>\n<pre>biplot(pca, scale = 0, main = 'PCA Biplot')</pre>\n<h3>Prompt 88: Perform t‑SNE</h3>\n<p>Apply t‑distributed stochastic neighbor embedding via **Rtsne** for high‑dimensional data.</p>\n<pre>library(Rtsne)\ntsne_out &lt;- Rtsne(as.matrix(iris[, -5]), dims = 2, perplexity = 30)\nplot(tsne_out$Y, col = as.numeric(iris$Species), pch = 19)</pre>\n<h3>Prompt 89: Perform DBSCAN clustering</h3>\n<p>Density‑based clustering with **dbscan** package.</p>\n<pre>library(dbscan)\ncl &lt;- dbscan(iris[, -5], eps = 0.5, minPts = 5)\ncl$cluster</pre>\n<h3>Prompt 90: Perform factor analysis</h3>\n<p>Identify latent variables influencing observed data using `factanal()`.</p>\n<pre>fa &lt;- factanal(iris[, -5], factors = 2, rotation = 'varimax')\nfa</pre>\n<h2>Time Series Analysis</h2>\n<h3>Prompt 91: Create a time series object</h3>\n<p>Use `ts()` to convert a numeric vector into a time series object.</p>\n<pre>my_ts &lt;- ts(data$variable, start = c(2020, 1), frequency = 12)</pre>\n<h3>Prompt 92: Plot a time series</h3>\n<p>Visualize a time series object using `plot()`.</p>\n<pre>plot(my_ts, main = 'Time Series Plot', ylab = 'Value', xlab = 'Time')</pre>\n<h3>Prompt 93: Decompose a time series</h3>\n<p>Break down a series into trend, seasonal and irregular components using `decompose()`.</p>\n<pre>components &lt;- decompose(my_ts, type = 'additive')\nplot(components)</pre>\n<h3>Prompt 94: Check stationarity (ADF test)</h3>\n<p>Use the Augmented Dickey–Fuller test from **tseries** to test for stationarity.</p>\n<pre>library(tseries)\nadf.test(my_ts)</pre>\n<h3>Prompt 95: Fit an ARIMA model</h3>\n<p>Automatically select and fit an ARIMA model using **forecast**.</p>\n<pre>library(forecast)\nfit &lt;- auto.arima(my_ts)\nfit</pre>\n<h3>Prompt 96: Forecast future values</h3>\n<p>Predict future observations with the fitted model and plot the forecast.</p>\n<pre>fc &lt;- forecast(fit, h = 12)\nplot(fc)</pre>\n<h3>Prompt 97: Plot forecast results</h3>\n<p>Visualize the predicted values and prediction intervals.</p>\n<pre>autoplot(fc) + ggtitle('Forecast')</pre>\n<h3>Prompt 98: Fit exponential smoothing (Holt–Winters)</h3>\n<p>Use `HoltWinters()` for exponential smoothing.</p>\n<pre>hw &lt;- HoltWinters(my_ts)\nplot(hw)</pre>\n<h3>Prompt 99: Perform STL decomposition</h3>\n<p>Apply Seasonal-Trend decomposition using Loess.</p>\n<pre>stl_fit &lt;- stl(my_ts, s.window = 'periodic')\nplot(stl_fit)</pre>\n<h3>Prompt 100: Evaluate forecast accuracy</h3>\n<p>Compute accuracy metrics such as MAE and RMSE using `accuracy()`.</p>\n<pre>acc &lt;- accuracy(fc)\nacc</pre>\n<h2>Data Visualization with ggplot2</h2>\n<h3>Prompt 101: Create a scatter plot</h3>\n<p>Use `ggplot()` with `geom_point()` to visualize the relationship between two variables.</p>\n<pre>library(ggplot2)\nggplot(data, aes(x = variable1, y = variable2)) + geom_point() + ggtitle('Scatter Plot')</pre>\n<h3>Prompt 102: Create a line plot</h3>\n<p>Plot time series or ordered data with `geom_line()`.</p>\n<pre>ggplot(data, aes(x = time, y = value)) + geom_line(color = 'blue') + labs(title = 'Line Plot', x = 'Time', y = 'Value')</pre>\n<h3>Prompt 103: Create a bar chart</h3>\n<p>Represent categorical data as bars using `geom_bar()`.</p>\n<pre>ggplot(data, aes(x = category)) + geom_bar(fill = 'tomato') + labs(title = 'Bar Chart', x = 'Category', y = 'Count')</pre>\n<h3>Prompt 104: Create a histogram</h3>\n<p>Visualize the distribution of a continuous variable with `geom_histogram()`.</p>\n<pre>ggplot(data, aes(x = variable)) + geom_histogram(binwidth = 1, fill = 'skyblue', color = 'black')</pre>\n<h3>Prompt 105: Add facets</h3>\n<p>Use `facet_wrap()` or `facet_grid()` to create trellis plots.</p>\n<pre>ggplot(data, aes(x = value)) + geom_histogram(binwidth = 1) + facet_wrap(~ group) + labs(title = 'Faceted Histograms')</pre>\n<h3>Prompt 106: Customize colors and themes</h3>\n<p>Apply a color palette and theme to improve plot aesthetics.</p>\n<pre>ggplot(data, aes(x = variable1, y = variable2, color = group)) + geom_point() + theme_minimal() + scale_color_brewer(palette = 'Set2')</pre>\n<h3>Prompt 107: Add a smooth line</h3>\n<p>Overlay a regression or loess smooth using `geom_smooth()`.</p>\n<pre>ggplot(data, aes(x = x, y = y)) + geom_point() + geom_smooth(method = 'lm', se = FALSE) + labs(title = 'Scatter with Regression Line')</pre>\n<h3>Prompt 108: Create a boxplot</h3>\n<p>Use `geom_boxplot()` to display distributions for multiple groups.</p>\n<pre>ggplot(data, aes(x = group, y = value)) + geom_boxplot(fill = 'lightgreen') + labs(title = 'Boxplot')</pre>\n<h3>Prompt 109: Create a density plot</h3>\n<p>Plot a density estimate with `geom_density()`.</p>\n<pre>ggplot(data, aes(x = variable, fill = group)) + geom_density(alpha = 0.5) + labs(title = 'Density Plot')</pre>\n<h3>Prompt 110: Save a plot to file</h3>\n<p>Export plots to PNG, PDF or other formats using `ggsave()`.</p>\n<pre>p &lt;- ggplot(data, aes(x = variable1, y = variable2)) + geom_point()\nggsave('scatter_plot.png', p, width = 6, height = 4)</pre>\n<h2>Model Evaluation and Validation</h2>\n<h3>Prompt 111: Compute a confusion matrix</h3>\n<p>Use `table()` or **caret** to generate a confusion matrix for classification results.</p>\n<pre>pred &lt;- predict(rf_model, iris)\nconf_matrix &lt;- table(Predicted = pred, Actual = iris$Species)</pre>\n<h3>Prompt 112: Compute accuracy, precision and recall</h3>\n<p>Calculate evaluation metrics from the confusion matrix.</p>\n<pre>tp &lt;- conf_matrix[1,1]; fp &lt;- conf_matrix[2,1]; fn &lt;- conf_matrix[1,2]; tn &lt;- conf_matrix[2,2]\naccuracy &lt;- sum(diag(conf_matrix)) / sum(conf_matrix)\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)</pre>\n<h3>Prompt 113: Plot a ROC curve and compute AUC</h3>\n<p>Visualize trade‑offs between true positive and false positive rates using **pROC**.</p>\n<pre>library(pROC)\nprob &lt;- predict(rf_model, iris, type = 'prob')[,1]\nroc_obj &lt;- roc(iris$Species, prob)\nplot(roc_obj)\nauc_value &lt;- auc(roc_obj)</pre>\n<h3>Prompt 114: Calculate R‑squared</h3>\n<p>Retrieve the coefficient of determination for regression models.</p>\n<pre>rsq &lt;- summary(lm_fit)$r.squared</pre>\n<h3>Prompt 115: Compute mean squared error (MSE)</h3>\n<p>Evaluate regression performance by averaging squared residuals.</p>\n<pre>pred &lt;- predict(lm_fit, newdata = data)\nmse &lt;- mean((data$y - pred)^2)</pre>\n<h3>Prompt 116: Perform cross‑validation with caret</h3>\n<p>Run resampling techniques in **caret** for general models.</p>\n<pre>set.seed(123)\ncontrol &lt;- trainControl(method = 'repeatedcv', number = 10, repeats = 3)\ncv_result &lt;- train(y ~ ., data = data, method = 'lm', trControl = control)</pre>\n<h3>Prompt 117: Plot residuals vs fitted values</h3>\n<p>Assess homoscedasticity by plotting residuals against fitted values.</p>\n<pre>residuals &lt;- resid(lm_fit)\nfitted_vals &lt;- fitted(lm_fit)\nplot(fitted_vals, residuals, xlab = 'Fitted Values', ylab = 'Residuals', main = 'Residuals vs Fitted')\nabline(h = 0, col = 'red')</pre>\n<h3>Prompt 118: Identify influential points</h3>\n<p>Calculate Cook’s distance to detect influential observations.</p>\n<pre>cooks &lt;- cooks.distance(lm_fit)\nplot(cooks, type = 'h', main = \"Cook's distance\")</pre>\n<h3>Prompt 119: Perform stepwise model selection</h3>\n<p>Use `step()` to carry out stepwise selection based on AIC.</p>\n<pre>step_model &lt;- step(lm_full, direction = 'both')</pre>\n<h3>Prompt 120: Validate model assumptions</h3>\n<p>Check assumptions like normality of residuals, independence and linearity.</p>\n<pre>par(mfrow = c(2, 2))\nplot(lm_fit)\nshapiro.test(residuals(lm_fit))</pre>\n<h2>Data Structures</h2>\n<h3>Prompt 121: Create a vector</h3>\n<p>Combine elements into an atomic vector using the `c()` function.</p>\n<pre>v &lt;- c(1, 2, 3, 4, 5)</pre>\n<h3>Prompt 122: Create a matrix</h3>\n<p>Define a two‑dimensional matrix with `matrix()`.</p>\n<pre>m &lt;- matrix(1:9, nrow = 3, ncol = 3, byrow = TRUE)</pre>\n<h3>Prompt 123: Create a list</h3>\n<p>Store heterogeneous objects in a list.</p>\n<pre>lst &lt;- list(numbers = 1:5, letters = letters[1:3], data = data.frame(x = 1:3, y = 4:6))</pre>\n<h3>Prompt 124: Create a data frame</h3>\n<p>Construct a data frame from vectors of equal length.</p>\n<pre>df &lt;- data.frame(name = c('A','B','C'), score = c(90, 85, 88))</pre>\n<h3>Prompt 125: Create a tibble</h3>\n<p>Use the **tibble** package to create a modern tibble with enhanced printing.</p>\n<pre>library(tibble)\ntbl &lt;- tibble(name = c('A','B'), value = c(1, 2))</pre>\n<h3>Prompt 126: Convert data frame to tibble</h3>\n<p>Transform a base data frame into a tibble.</p>\n<pre>tbl &lt;- as_tibble(df)</pre>\n<h3>Prompt 127: Access elements by index</h3>\n<p>Refer to individual elements in vectors, lists or data frames using bracket notation.</p>\n<pre>third_element &lt;- v[3];\nlist_item &lt;- lst$numbers[2];\ncell &lt;- df[1, 'score']</pre>\n<h3>Prompt 128: Combine objects by rows and columns</h3>\n<p>Use `rbind()` and `cbind()` to merge data structures.</p>\n<pre>combined_rows &lt;- rbind(df, data.frame(name = 'D', score = 92))\ncombined_cols &lt;- cbind(df, grade = c('A', 'B', 'A'))</pre>\n<h3>Prompt 129: Reshape an array</h3>\n<p>Create and manipulate multidimensional arrays with `array()`.</p>\n<pre>arr &lt;- array(1:24, dim = c(2, 3, 4))\narr[1, , 2]</pre>\n<h3>Prompt 130: Convert factors</h3>\n<p>Convert factor variables to numeric or character to suit analysis.</p>\n<pre>data$factor_var &lt;- as.numeric(as.character(data$factor_var))</pre>\n<h2>Functions and Programming Constructs</h2>\n<h3>Prompt 131: Define a simple function</h3>\n<p>Encapsulate reusable code by defining a function using `function()`.</p>\n<pre>square &lt;- function(x) {\n  x^2\n}\nsquare(4)</pre>\n<h3>Prompt 132: Use conditional statements</h3>\n<p>Control flow with `if`, `else if`, and `else`.</p>\n<pre>check_number &lt;- function(x) {\n  if (x &gt; 0) {\n    'positive'\n  } else if (x &lt; 0) {\n    'negative'\n  } else {\n    'zero'\n  }\n}\ncheck_number(-5)</pre>\n<h3>Prompt 133: Use a for loop</h3>\n<p>Iterate over a sequence of values using a `for` loop.</p>\n<pre>sum &lt;- 0\nfor (i in 1:10) {\n  sum &lt;- sum + i\n}\nsum</pre>\n<h3>Prompt 134: Use a while loop</h3>\n<p>Execute a block repeatedly while a condition is TRUE.</p>\n<pre>count &lt;- 1\nwhile (count &lt;= 5) {\n  print(count)\n  count &lt;- count + 1\n}</pre>\n<h3>Prompt 135: Use a repeat loop</h3>\n<p>Create an infinite loop that must be broken manually using `break()`.</p>\n<pre>x &lt;- 1\nrepeat {\n  if (x &gt; 3) break\n  print(x)\n  x &lt;- x + 1\n}</pre>\n<h3>Prompt 136: Apply a function with `apply()`</h3>\n<p>Apply a function across rows or columns of a matrix or array.</p>\n<pre>m &lt;- matrix(1:9, nrow = 3)\nrow_sums &lt;- apply(m, 1, sum)\ncol_means &lt;- apply(m, 2, mean)</pre>\n<h3>Prompt 137: Use `lapply()`</h3>\n<p>Apply a function to each element of a list and return a list.</p>\n<pre>result &lt;- lapply(lst$numbers, function(x) x * 2)</pre>\n<h3>Prompt 138: Use `sapply()`</h3>\n<p>Simplify the result of `lapply()` to a vector or matrix when possible.</p>\n<pre>result_vec &lt;- sapply(lst$numbers, function(x) x * 2)</pre>\n<h3>Prompt 139: Use `map` from purrr</h3>\n<p>Iterate over lists or vectors with functional programming using **purrr**.</p>\n<pre>library(purrr)\nmap_dbl(1:5, ~ .x^2)</pre>\n<h3>Prompt 140: Use anonymous functions</h3>\n<p>Write functions without naming them for short, disposable operations.</p>\n<pre>sapply(1:5, function(x) x * 3)</pre>\n<h2>String Manipulation</h2>\n<h3>Prompt 141: Calculate string length</h3>\n<p>Use `nchar()` to obtain the number of characters in a string.</p>\n<pre>nchar('R programming')</pre>\n<h3>Prompt 142: Convert to upper and lower case</h3>\n<p>Change the case of characters with `toupper()` and `tolower()`.</p>\n<pre>toupper('hello'); tolower('WORLD')</pre>\n<h3>Prompt 143: Concatenate strings</h3>\n<p>Combine multiple strings using `paste()` or `paste0()`.</p>\n<pre>full &lt;- paste('Hello', 'world', sep = ', ')\nno_space &lt;- paste0('R', 'Stats')</pre>\n<h3>Prompt 144: Split a string</h3>\n<p>Divide a string into parts based on a delimiter using `strsplit()`.</p>\n<pre>parts &lt;- strsplit('apple,banana,cherry', split = ',')[[1]]</pre>\n<h3>Prompt 145: Find and replace patterns</h3>\n<p>Replace text patterns with `gsub()` or `sub()`.</p>\n<pre>text &lt;- 'R is great'\nnew_text &lt;- gsub('great', 'awesome', text)</pre>\n<h3>Prompt 146: Extract substrings</h3>\n<p>Select a portion of a string using `substr()` or `substring()`.</p>\n<pre>substr('statistics', start = 1, stop = 4)</pre>\n<h3>Prompt 147: Detect pattern presence</h3>\n<p>Check if a pattern exists in a string with `grepl()`.</p>\n<pre>grepl('data', 'big data analysis')</pre>\n<h3>Prompt 148: Use regular expressions to match patterns</h3>\n<p>Match complex string patterns using regular expressions via `gregexpr()`.</p>\n<pre>matches &lt;- gregexpr('[0-9]+', 'Room 101, Floor 2')\nregmatches('Room 101, Floor 2', matches)</pre>\n<h3>Prompt 149: Remove whitespace</h3>\n<p>Trim leading and trailing whitespace with `trimws()`.</p>\n<pre>trimws('  hello  ')</pre>\n<h3>Prompt 150: Convert factors to character strings</h3>\n<p>Transform factor variables into strings for text processing.</p>\n<pre>char_var &lt;- as.character(factor_var)</pre>\n<h2>Date and Time Handling</h2>\n<h3>Prompt 151: Convert string to Date</h3>\n<p>Parse a character string into a Date object using `as.Date()`.</p>\n<pre>dates &lt;- as.Date(c('2025-10-08', '2025-12-31'))</pre>\n<h3>Prompt 152: Parse date‑time with lubridate</h3>\n<p>Use **lubridate** to handle date‑time formats more flexibly.</p>\n<pre>library(lubridate)\ndt &lt;- ymd_hms('2025-10-08 14:30:00')</pre>\n<h3>Prompt 153: Extract year, month and day</h3>\n<p>Retrieve components of a date or date‑time object.</p>\n<pre>year &lt;- year(dt); month &lt;- month(dt); day &lt;- day(dt)</pre>\n<h3>Prompt 154: Compute difference between dates</h3>\n<p>Calculate the time interval between two dates using `difftime()`.</p>\n<pre>start &lt;- as.Date('2025-01-01')\nend &lt;- as.Date('2025-12-31')\ninterval &lt;- difftime(end, start, units = 'days')</pre>\n<h3>Prompt 155: Add or subtract time durations</h3>\n<p>Use lubridate to add or subtract periods and durations.</p>\n<pre>new_date &lt;- dt + days(7) - hours(2)</pre>\n<h3>Prompt 156: Round dates to the nearest unit</h3>\n<p>Round date‑times to a specified unit such as week or month.</p>\n<pre>rounded &lt;- round_date(dt, unit = 'hour')</pre>\n<h3>Prompt 157: Format dates for display</h3>\n<p>Customize date output with `format()` or lubridate’s `stamp()`.</p>\n<pre>formatted &lt;- format(dt, '%d-%b-%Y %H:%M')</pre>\n<h3>Prompt 158: Handle time zones</h3>\n<p>Specify and convert between time zones using `with_tz()` and `force_tz()`.</p>\n<pre>dt_local &lt;- ymd_hms('2025-10-08 14:30:00', tz = 'Europe/Madrid')\ndt_utc &lt;- with_tz(dt_local, 'UTC')</pre>\n<h3>Prompt 159: Create a sequence of dates</h3>\n<p>Generate regularly spaced dates with `seq.Date()`.</p>\n<pre>date_seq &lt;- seq(as.Date('2025-01-01'), as.Date('2025-01-10'), by = 'day')</pre>\n<h3>Prompt 160: Group data by date components</h3>\n<p>Aggregate data by year, month or day using `floor_date()` and dplyr.</p>\n<pre>library(lubridate)\nmonthly_summary &lt;- data %&gt;% group_by(month = floor_date(date, 'month')) %&gt;% summarise(total = sum(value))</pre>\n<h2>Randomization and Simulation</h2>\n<h3>Prompt 161: Set a random seed</h3>\n<p>Ensure reproducible results by setting a seed with `set.seed()`.</p>\n<pre>set.seed(123)</pre>\n<h3>Prompt 162: Sample from a vector</h3>\n<p>Randomly sample elements from a vector using `sample()`.</p>\n<pre>sample_vec &lt;- sample(1:100, size = 10, replace = FALSE)</pre>\n<h3>Prompt 163: Generate random numbers from distributions</h3>\n<p>Use functions like `rnorm()`, `runif()`, and `rbinom()` to sample from normal, uniform and binomial distributions.</p>\n<pre>norm_samples &lt;- rnorm(10, mean = 0, sd = 1)\nunif_samples &lt;- runif(10, min = 0, max = 1)\nbinom_samples &lt;- rbinom(10, size = 20, prob = 0.5)</pre>\n<h3>Prompt 164: Simulate dice rolls</h3>\n<p>Roll a fair six‑sided die multiple times using `sample()`.</p>\n<pre>dice_rolls &lt;- sample(1:6, size = 20, replace = TRUE)</pre>\n<h3>Prompt 165: Perform bootstrap sampling</h3>\n<p>Generate bootstrap samples to estimate variability of statistics.</p>\n<pre>set.seed(123)\nboot_means &lt;- replicate(1000, mean(sample(data$variable, replace = TRUE)))</pre>\n<h3>Prompt 166: Run a Monte Carlo simulation</h3>\n<p>Use repeated random sampling to estimate a quantity.</p>\n<pre>set.seed(42)\nmonte_carlo &lt;- function(n_sim) {\n  successes &lt;- 0\n  for (i in 1:n_sim) {\n    x &lt;- runif(1)\n    y &lt;- runif(1)\n    if (x^2 + y^2 &lt;= 1) successes &lt;- successes + 1\n  }\n  4 * successes / n_sim\n}\np_estimate &lt;- monte_carlo(10000)</pre>\n<h3>Prompt 167: Generate a random permutation</h3>\n<p>Shuffle the order of elements in a vector.</p>\n<pre>perm &lt;- sample(1:10)</pre>\n<h3>Prompt 168: Randomly split a dataset</h3>\n<p>Divide data into random subsets (e.g., training and testing).</p>\n<pre>set.seed(123)\nindices &lt;- sample(seq_len(nrow(data)))\ntrain_indices &lt;- indices[1:floor(0.8 * length(indices))]\ntest_indices &lt;- indices[-train_indices]\ntrain_set &lt;- data[train_indices, ]\ntest_set &lt;- data[test_indices, ]</pre>\n<h3>Prompt 169: Simulate a Poisson process</h3>\n<p>Generate arrival times from a Poisson process with rate λ.</p>\n<pre>lambda &lt;- 2\nn &lt;- 100\ninterarrival &lt;- rexp(n, rate = lambda)\narrival_times &lt;- cumsum(interarrival)</pre>\n<h3>Prompt 170: Simulate a Markov chain</h3>\n<p>Model transitions between states with a transition matrix.</p>\n<pre>states &lt;- c('A','B','C')\ntransition &lt;- matrix(c(0.5,0.3,0.2,\n                      0.4,0.4,0.2,\n                      0.2,0.5,0.3),\n                    nrow = 3, byrow = TRUE, dimnames = list(states, states))\nset.seed(123)\ncurrent &lt;- 'A'\nchain &lt;- character(10)\nchain[1] &lt;- current\nfor (i in 2:10) {\n  current &lt;- sample(states, 1, prob = transition[current, ])\n  chain[i] &lt;- current\n}\n</pre>\n<h2>File and Directory Management</h2>\n<h3>Prompt 171: List files in a directory</h3>\n<p>Use `list.files()` to get a vector of file names.</p>\n<pre>files &lt;- list.files(path = '.', pattern = '*.csv', full.names = TRUE)</pre>\n<h3>Prompt 172: Check if a file exists</h3>\n<p>Verify whether a file exists using `file.exists()`.</p>\n<pre>exists &lt;- file.exists('myfile.csv')</pre>\n<h3>Prompt 173: Read multiple files and combine</h3>\n<p>Use `lapply()` to read multiple files and `bind_rows()` to merge them.</p>\n<pre>library(readr)\nfile_list &lt;- list.files(pattern = '*.csv')\nall_data &lt;- dplyr::bind_rows(lapply(file_list, read_csv))</pre>\n<h3>Prompt 174: Create a new directory</h3>\n<p>Create directories with `dir.create()`.</p>\n<pre>dir.create('new_folder')</pre>\n<h3>Prompt 175: Delete a file or directory</h3>\n<p>Remove files or directories using `file.remove()` and `unlink()`.</p>\n<pre>file.remove('old_file.csv')\nunlink('old_folder', recursive = TRUE)</pre>\n<h3>Prompt 176: Copy a file</h3>\n<p>Duplicate a file using `file.copy()`.</p>\n<pre>file.copy('source.txt', 'destination.txt')</pre>\n<h3>Prompt 177: Move or rename a file</h3>\n<p>Change the name or location of a file using `file.rename()`.</p>\n<pre>file.rename('old_name.txt', 'new_name.txt')</pre>\n<h3>Prompt 178: Write data to a compressed file</h3>\n<p>Compress data when writing to disk using `gzfile()`.</p>\n<pre>gz_con &lt;- gzfile('data.csv.gz', 'w')\nwrite.csv(data, gz_con)\nclose(gz_con)</pre>\n<h3>Prompt 179: Get file information</h3>\n<p>Retrieve metadata such as size and modification time using `file.info()`.</p>\n<pre>info &lt;- file.info('data.csv')\nsize &lt;- info$size; modified &lt;- info$mtime</pre>\n<h3>Prompt 180: Redirect output to a file</h3>\n<p>Capture printed output using `sink()` to write to a text file.</p>\n<pre>sink('log.txt')\nprint(summary(data))\nsink()</pre>\n<h2>Web Data and API</h2>\n<h3>Prompt 181: Download a file from a URL</h3>\n<p>Use `download.file()` to retrieve files from the web.</p>\n<pre>download.file('https://example.com/data.csv', destfile = 'downloaded.csv')</pre>\n<h3>Prompt 182: Read an HTML table</h3>\n<p>Use **rvest** to scrape tables from web pages.</p>\n<pre>library(rvest)\npage &lt;- read_html('https://example.com')\ntable &lt;- html_table(html_nodes(page, 'table')[[1]])</pre>\n<h3>Prompt 183: Extract nodes with CSS selectors</h3>\n<p>Select HTML elements using CSS selectors with **rvest**.</p>\n<pre>titles &lt;- html_text(html_nodes(page, 'h2.title'))</pre>\n<h3>Prompt 184: Parse an XML file</h3>\n<p>Use **xml2** to read and parse XML data.</p>\n<pre>library(xml2)\nxml &lt;- read_xml('file.xml')\nvalues &lt;- xml_text(xml_find_all(xml, '//tag'))</pre>\n<h3>Prompt 185: Fetch JSON data from an API</h3>\n<p>Use **httr** and **jsonlite** to request and parse JSON.</p>\n<pre>library(httr); library(jsonlite)\nresponse &lt;- GET('https://api.example.com/data')\ndata_json &lt;- content(response, as = 'text')\ndata &lt;- fromJSON(data_json)</pre>\n<h3>Prompt 186: Send an HTTP GET request</h3>\n<p>Retrieve data using `GET()` with query parameters.</p>\n<pre>res &lt;- GET('https://api.example.com/search', query = list(q = 'R programming'))\ncontent(res, 'text')</pre>\n<h3>Prompt 187: Convert API data to a data frame</h3>\n<p>Transform JSON or list structures into tidy data frames.</p>\n<pre>df &lt;- as.data.frame(data)</pre>\n<h3>Prompt 188: Scrape multiple pages</h3>\n<p>Loop through multiple pages to collect data in a single data set.</p>\n<pre>base_url &lt;- 'https://example.com/page='\nresults &lt;- list()\nfor (i in 1:5) {\n  page &lt;- read_html(paste0(base_url, i))\n  results[[i]] &lt;- html_text(html_nodes(page, '.item'))\n}\nitems &lt;- unlist(results)</pre>\n<h3>Prompt 189: Extract meta information from a web page</h3>\n<p>Use **rvest** to extract metadata such as title and description.</p>\n<pre>meta_title &lt;- html_text(html_nodes(page, 'title'))\nmeta_desc &lt;- html_attr(html_nodes(page, \"meta[name='description']\"), 'content')</pre>\n<h3>Prompt 190: Handle API authentication</h3>\n<p>Send authenticated requests using headers or tokens with **httr**.</p>\n<pre>token &lt;- 'your_token_here'\nres &lt;- GET('https://api.example.com/protected', add_headers(Authorization = paste('Bearer', token)))\ncontent(res, 'text')</pre>\n<h2>Miscellaneous Tips and Tricks</h2>\n<h3>Prompt 191: Install and load packages</h3>\n<p>Install packages with `install.packages()` and load them with `library()`.</p>\n<pre>install.packages('dplyr')\nlibrary(dplyr)</pre>\n<h3>Prompt 192: Check installed packages</h3>\n<p>List packages currently installed on your system.</p>\n<pre>installed &lt;- installed.packages()\nhead(installed[, 'Package'])</pre>\n<h3>Prompt 193: Remove objects from workspace</h3>\n<p>Clean up memory by removing objects with `rm()` and using `gc()`.</p>\n<pre>rm(list = ls())\ngc()</pre>\n<h3>Prompt 194: Set working directory</h3>\n<p>Change the working directory using `setwd()` and verify with `getwd()`.</p>\n<pre>setwd('/path/to/project')\ngetwd()</pre>\n<h3>Prompt 195: Use pipes (`%&gt;%`) </h3>\n<p>Make code more readable by chaining operations with the pipe operator from **magrittr** or **dplyr**.</p>\n<pre>library(dplyr)\nresult &lt;- data %&gt;% filter(value &gt; 0) %&gt;% summarise(mean = mean(value))</pre>\n<h3>Prompt 196: Profile code performance</h3>\n<p>Measure execution time of expressions using `system.time()`.</p>\n<pre>execution &lt;- system.time({\n  Sys.sleep(1)\n})</pre>\n<h3>Prompt 197: Vectorize operations</h3>\n<p>Avoid explicit loops by performing vectorized arithmetic for speed.</p>\n<pre>v &lt;- 1:100\nsquared &lt;- v^2</pre>\n<h3>Prompt 198: Use parallel computing</h3>\n<p>Leverage multiple cores with the **parallel** package.</p>\n<pre>library(parallel)\ncl &lt;- makeCluster(detectCores() - 1)\nparSapply(cl, 1:4, function(x) x^2)\nstopCluster(cl)</pre>\n<h3>Prompt 199: Document functions with roxygen2</h3>\n<p>Use roxygen2 comments to document your functions for package development.</p>\n<pre>#' Calculate the square\n#'\n#' @param x A numeric value\n#' @return The square of x\nsquare &lt;- function(x) { x^2 }</pre>\n<h3>Prompt 200: Create reproducible analysis</h3>\n<p>Ensure reproducibility by setting seeds and recording session information.</p>\n<pre>set.seed(123)\n# analysis code here\ninfo &lt;- sessionInfo()</pre>\n\n<p>The post <a href=\"https://rprogrammingbooks.com/200-r-programming-prompts-data-analysis/\" rel=\"nofollow\" target=\"_blank\">200 R Programming Prompts &amp; Code Snippets for Data Analysis and Modeling</a> appeared first on <a href=\"https://rprogrammingbooks.com/\" rel=\"nofollow\" target=\"_blank\">R Programming Books</a>.</p>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://rprogrammingbooks.com/200-r-programming-prompts-data-analysis/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=200-r-programming-prompts-data-analysis\"> Blog - R Programming Books</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div> </div>\n</article>",
    "word_count": 5596,
    "reading_time_min": 28.0,
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/rprogrammingbooks/",
        "text": "rprogrammingbooks"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "external_links": [
      {
        "href": "https://rprogrammingbooks.com/200-r-programming-prompts-data-analysis/?utm_source=rss&utm_medium=rss&utm_campaign=200-r-programming-prompts-data-analysis",
        "text": "Blog - R Programming Books"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://rprogrammingbooks.com/200-r-programming-prompts-data-analysis/",
        "text": "200 R Programming Prompts & Code Snippets for Data Analysis and Modeling"
      },
      {
        "href": "https://rprogrammingbooks.com/",
        "text": "R Programming Books"
      },
      {
        "href": "https://rprogrammingbooks.com/200-r-programming-prompts-data-analysis/?utm_source=rss&utm_medium=rss&utm_campaign=200-r-programming-prompts-data-analysis",
        "text": "Blog - R Programming Books"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "images": [],
    "lang": "en-US",
    "crawled_at_utc": "2026-01-04T05:36:55Z"
  }
}