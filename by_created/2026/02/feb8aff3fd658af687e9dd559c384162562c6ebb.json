{
  "id": "feb8aff3fd658af687e9dd559c384162562c6ebb",
  "url": "https://www.r-bloggers.com/2026/02/designing-sports-betting-systems-in-r-bayesian-probabilities-expected-value-and-kelly-logic/",
  "created_at_utc": "2026-02-02T05:58:25Z",
  "crawled_at_utc": "2026-02-02T05:58:25Z",
  "html_title": "Designing Sports Betting Systems in R: Bayesian Probabilities, Expected Value, and Kelly Logic | R-bloggers",
  "meta_description": "A good sports betting system is not a “pick-winners” machine. It’s an uncertainty engine: it turns data into probabilities, probabilities into expected value, and expected value into position sizes that survive variance. If you can do those three steps consistently, you can build a robust process— even if individual bets lose often. This post is […] The post Designing Sports Betting Systems in R: Bayesian Probabilities, Expected Value, and Kelly Logic appeared first on R Programming Books.",
  "data": {
    "url": "https://www.r-bloggers.com/2026/02/designing-sports-betting-systems-in-r-bayesian-probabilities-expected-value-and-kelly-logic/",
    "canonical_url": "https://www.r-bloggers.com/2026/02/designing-sports-betting-systems-in-r-bayesian-probabilities-expected-value-and-kelly-logic/",
    "html_title": "Designing Sports Betting Systems in R: Bayesian Probabilities, Expected Value, and Kelly Logic | R-bloggers",
    "h1_title": "R-bloggers",
    "meta_description": "A good sports betting system is not a “pick-winners” machine. It’s an uncertainty engine: it turns data into probabilities, probabilities into expected value, and expected value into position sizes that survive variance. If you can do those three steps consistently, you can build a robust process— even if individual bets lose often. This post is […] The post Designing Sports Betting Systems in R: Bayesian Probabilities, Expected Value, and Kelly Logic appeared first on R Programming Books.",
    "meta_keywords": null,
    "og_title": "Designing Sports Betting Systems in R: Bayesian Probabilities, Expected Value, and Kelly Logic | R-bloggers",
    "og_description": "A good sports betting system is not a “pick-winners” machine. It’s an uncertainty engine: it turns data into probabilities, probabilities into expected value, and expected value into position sizes that survive variance. If you can do those three steps consistently, you can build a robust process— even if individual bets lose often. This post is […] The post Designing Sports Betting Systems in R: Bayesian Probabilities, Expected Value, and Kelly Logic appeared first on R Programming Books.",
    "og_image": "https://www.r-bloggers.com/wp-content/uploads/2016/04/R_02_2016-05-01.png",
    "twitter_title": "Designing Sports Betting Systems in R: Bayesian Probabilities, Expected Value, and Kelly Logic | R-bloggers",
    "twitter_description": "A good sports betting system is not a “pick-winners” machine. It’s an uncertainty engine: it turns data into probabilities, probabilities into expected value, and expected value into position sizes that survive variance. If you can do those three steps consistently, you can build a robust process— even if individual bets lose often. This post is […] The post Designing Sports Betting Systems in R: Bayesian Probabilities, Expected Value, and Kelly Logic appeared first on R Programming Books.",
    "raw_jsonld_article": null,
    "article_headline": null,
    "article_section": null,
    "article_tags": null,
    "article_author": null,
    "article_published": null,
    "article_modified": null,
    "main_text": "Designing Sports Betting Systems in R: Bayesian Probabilities, Expected Value, and Kelly Logic\nPosted on\nFebruary 1, 2026\nby\nrprogrammingbooks\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nBlog - R Programming Books\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nA good sports betting system is not a “pick-winners” machine. It’s an\nuncertainty engine\n:\n    it turns data into\nprobabilities\n, probabilities into\nexpected value\n, and expected value into\nposition sizes\nthat survive variance. If you can do those three steps consistently, you can build a robust process—\n    even if individual bets lose often.\nThis post is a\ncode-heavy\nblueprint for designing sports betting systems in\nR\nusing\nBayesian probabilities\n, market odds,\nEV\n, the\nKelly Criterion\n, and practical\n    betting strategies. You’ll also get a backtesting and Monte Carlo framework to evaluate drawdowns, ruin risk, and performance stability.\nTable of Contents\n1. Setup: Packages, Data Schemas, and Conventions\n2. Odds and Probability: Conversions, Vig (Overround), and Fair Prices\n3. Expected Value: Break-even Probability, Edge, and Sensitivity\n4. Bayesian Foundations for Betting: Priors, Posteriors, and Uncertainty\n5. Beta-Binomial Models: Bayesian Win Rates (Conjugate Bayes)\n6. Sequential Updating: Learning Over Time (Online Bayesian Updating)\n7. Shrinkage and Partial Pooling: Stabilizing Team/Player Estimates\n8. Bayesian Logistic Models: Match Win Probabilities from Features\n9. Ratings as Priors: Elo with Uncertainty and Bayesian Flavor\n10. Score Models: Poisson and Skellam for Totals and Spreads\n11. Probability Calibration: Brier, Log Loss, and Reliability Curves\n12. Kelly Logic: Optimal Growth, Fractional Kelly, and Practical Constraints\n13. Portfolio Betting: Correlation, Market Clustering, and Exposure Controls\n14. Concrete Betting Strategies: From Simple Rules to Model-Driven Systems\n15. Backtesting in R: Walk-forward, Leakage Prevention, and Metrics\n16. Monte Carlo Stress Tests: Drawdowns, Ruin, and Regret\n17. A Go-Live Checklist: Operational and Statistical Guardrails\nRecommended Reading\n1. Setup: Packages, Data Schemas, and Conventions\nWe’ll work with an event-level dataset (one row per match) and optionally a bet-level dataset (one row per wager).\n    The minimum fields you want for match win modeling:\ndate\nteam\n,\nopponent\nhome\n(1 home, 0 away)\nresult\n(1 win, 0 loss)\nodds_decimal\n(decimal odds for the bet you want to evaluate)\n# Core data + modeling stack\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(stringr)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(scales)\n\n# Bayesian regression (optional, heavier but powerful)\nlibrary(rstanarm)\nlibrary(posterior)\n\nset.seed(42)\n\n# --- Odds helpers ---\namerican_to_decimal <- function(american) {\n  ifelse(american > 0, 1 + american/100, 1 + 100/abs(american))\n}\n\ndecimal_to_american <- function(decimal) {\n  # returns American odds as numeric (positive/negative)\n  stopifnot(all(decimal > 1))\n  out <- ifelse(decimal >= 2, (decimal - 1) * 100, -100/(decimal - 1))\n  out\n}\n\ndecimal_to_implied <- function(decimal) 1 / decimal\n\n# Remove vig from a two-outcome market (simple proportional normalization)\nremove_vig_two_way <- function(p1_raw, p2_raw) {\n  s <- p1_raw + p2_raw\n  c(p1 = p1_raw/s, p2 = p2_raw/s, overround = s)\n}\n\n# --- EV helpers ---\nev_decimal <- function(p, d) {\n  # expected profit per unit stake for decimal odds d\n  # win: profit = d - 1; lose: -1\n  p*(d - 1) - (1 - p)\n}\n\nbreakeven_p_decimal <- function(d) 1 / d\n\n# --- Kelly helpers ---\nkelly_fraction_decimal <- function(p, d) {\n  # Kelly fraction for decimal odds d, win prob p\n  # b = d - 1, q = 1-p, f* = (bp - q)/b\n  b <- d - 1\n  q <- 1 - p\n  f <- (b*p - q) / b\n  f\n}\n\n# Practical caps\nclip <- function(x, lo, hi) pmax(lo, pmin(hi, x))\n1.1 A toy dataset generator (so you can run everything)\nIn real life, you’ll load your match history and odds. For a self-contained tutorial, we simulate:\n    latent team strengths → win probabilities → outcomes → bookmaker odds with a built-in margin.\nsimulate_league <- function(\n  n_teams = 12,\n  n_games = 2000,\n  home_adv = 0.25,\n  sigma_strength = 0.9,\n  bookmaker_margin = 0.05\n) {\n  teams <- paste0(\"T\", sprintf(\"%02d\", 1:n_teams))\n  strength <- rnorm(n_teams, 0, sigma_strength)\n  names(strength) <- teams\n\n  # schedule\n  team <- sample(teams, n_games, replace = TRUE)\n  opponent <- sample(teams, n_games, replace = TRUE)\n  while(any(team == opponent)) {\n    idx <- which(team == opponent)\n    opponent[idx] <- sample(teams, length(idx), replace = TRUE)\n  }\n\n  home <- rbinom(n_games, 1, 0.5)\n  date <- as.Date(\"2022-01-01\") + sample(0:900, n_games, replace = TRUE)\n\n  # true probability via logistic link\n  lin <- (strength[team] - strength[opponent]) + home_adv * home\n  p_true <- plogis(lin)\n\n  # outcomes\n  result <- rbinom(n_games, 1, p_true)\n\n  # bookmaker sets odds from \"market probability\" with margin\n  # market_prob ~ p_true with noise, then add margin by inflating implied probs\n  p_mkt <- clip(p_true + rnorm(n_games, 0, 0.03), 0.02, 0.98)\n  # apply margin by scaling implied probabilities upward (approx.)\n  p_raw <- clip(p_mkt * (1 + bookmaker_margin), 0.02, 0.995)\n\n  odds_decimal <- 1 / p_raw\n\n  tibble(\n    date = date,\n    team = team,\n    opponent = opponent,\n    home = home,\n    result = result,\n    p_true = p_true,\n    odds_decimal = odds_decimal\n  ) %>%\n    arrange(date)\n}\n\nmatches <- simulate_league()\nglimpse(matches)\nsummary(matches$odds_decimal)\n2. Odds and Probability: Conversions, Vig (Overround), and Fair Prices\nOdds imply probabilities, but sportsbook odds typically include a margin (vig/overround). If you compare your model’s probability to raw implied probability,\n    you might misjudge edges. The right comparison is: your probability vs the market’s\nvig-free\nprobability.\n2.1 Basic conversions\n# Example: decimal odds\nd <- 1.91\np_implied_raw <- decimal_to_implied(d)\np_implied_raw\n# Example: American odds\nam <- -110\nd2 <- american_to_decimal(am)\nc(decimal = d2, implied = decimal_to_implied(d2))\n2.2 Two-way vig removal example\nFor a two-outcome market (like moneyline without draws), you can normalize implied probabilities.\n    Suppose the book offers:\nd_home <- 1.80\nd_away <- 2.10\n\np_home_raw <- 1/d_home\np_away_raw <- 1/d_away\n\nvigfree <- remove_vig_two_way(p_home_raw, p_away_raw)\nvigfree\n# Market \"fair\" probabilities\np_home_fair <- vigfree[\"p1\"]\np_away_fair <- vigfree[\"p2\"]\n\np_home_fair + p_away_fair  # should be 1\nIn practice, you might not always have both sides’ odds, especially if you store only “the odds you bet”.\n    But for sharp evaluation and backtesting, capturing the full market quote (both sides) is ideal.\n3. Expected Value: Break-even Probability, Edge, and Sensitivity\nExpected value (EV) is the bridge between probability and betting decisions. With decimal odds\nd\n,\n    and win probability\np\n, EV per 1 unit stake is:\n# EV for a single bet\np_hat <- 0.56\nd <- 1.95\n\nev <- ev_decimal(p_hat, d)\nev\n# Break-even p (the book's implied probability)\np_be <- breakeven_p_decimal(d)\nc(breakeven_p = p_be, edge = p_hat - p_be)\n3.1 EV sensitivity curve\nev_curve <- function(d, p_grid = seq(0.01, 0.99, by = 0.01)) {\n  tibble(p = p_grid, ev = ev_decimal(p_grid, d))\n}\n\ndf_ev <- ev_curve(1.95)\n\nggplot(df_ev, aes(p, ev)) +\n  geom_line() +\n  geom_hline(yintercept = 0, linetype = 2) +\n  scale_y_continuous(labels = percent_format(accuracy = 0.1)) +\n  labs(\n    title = \"EV per Unit Stake vs Win Probability\",\n    x = \"Win probability p\",\n    y = \"Expected value (profit per 1 unit stake)\"\n  )\nNotice how small probability errors can flip EV from positive to negative when odds are tight. This is why calibration and uncertainty-aware betting matter.\n4. Bayesian Foundations for Betting: Priors, Posteriors, and Uncertainty\nBayesian thinking fits betting naturally: you start with a prior belief about a team/player/strategy,\n    update with evidence, and end up with a posterior distribution over the probability you care about.\n    Crucially, you get\nuncertainty\n, not just a point estimate.\n4.1 A simple Bayesian coin: Beta prior + Binomial likelihood\n# Prior: Beta(a, b)\na0 <- 10\nb0 <- 10\n\n# Observed: k wins out of n\nk <- 12\nn <- 20\n\n# Posterior: Beta(a0 + k, b0 + n - k)\na1 <- a0 + k\nb1 <- b0 + (n - k)\n\n# Posterior mean and interval\npost_mean <- a1 / (a1 + b1)\npost_ci <- qbeta(c(0.05, 0.95), a1, b1)\n\nc(mean = post_mean, lo90 = post_ci[1], hi90 = post_ci[2])\n# Visualize prior vs posterior\ngrid <- seq(0, 1, length.out = 400)\n\ndf_beta <- bind_rows(\n  tibble(p = grid, density = dbeta(grid, a0, b0), dist = \"prior\"),\n  tibble(p = grid, density = dbeta(grid, a1, b1), dist = \"posterior\")\n)\n\nggplot(df_beta, aes(p, density, color = dist)) +\n  geom_line() +\n  labs(\n    title = \"Beta Prior vs Posterior\",\n    x = \"Win probability p\",\n    y = \"Density\"\n  )\nThis is the simplest but most important idea: if your sample is small, your posterior won’t be overly confident.\n    That alone can prevent overbetting.\n5. Beta-Binomial Models: Bayesian Win Rates (Conjugate Bayes)\nThe Beta-Binomial is a workhorse for modeling win rates, conversion rates, “cover rates”, etc.\n    You can use it for:\nTeam win rate vs certain opponents\nOver/Under hit rate for a model-defined filter\nAny binary market outcome you can label as 0/1\n5.1 Team-level posteriors\n# Build per-team counts\nteam_stats <- matches %>%\n  group_by(team) %>%\n  summarise(\n    n = n(),\n    k = sum(result),\n    .groups = \"drop\"\n  )\n\n# Choose a prior: mildly skeptical\na0 <- 8\nb0 <- 8\n\nteam_post <- team_stats %>%\n  mutate(\n    a = a0 + k,\n    b = b0 + (n - k),\n    post_mean = a/(a+b),\n    lo90 = qbeta(0.05, a, b),\n    hi90 = qbeta(0.95, a, b)\n  ) %>%\n  arrange(desc(post_mean))\n\nteam_post %>% slice(1:10)\nggplot(team_post, aes(reorder(team, post_mean), post_mean)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = lo90, ymax = hi90), width = 0.2) +\n  coord_flip() +\n  scale_y_continuous(labels = percent_format(accuracy = 0.1)) +\n  labs(\n    title = \"Team Win Probability Posteriors (Beta-Binomial)\",\n    x = \"Team\",\n    y = \"Posterior mean (90% interval)\"\n  )\n5.2 Betting with uncertainty (posterior sampling)\nInstead of using a single probability, sample from the posterior and compute EV distribution.\n    This helps you avoid betting when your edge is too uncertain.\n# Suppose you want to bet Team X at odds d\nteam_x <- team_post$team[1]\nd <- 1.95\n\na <- team_post$a[team_post$team == team_x]\nb <- team_post$b[team_post$team == team_x]\n\np_draws <- rbeta(20000, a, b)\nev_draws <- ev_decimal(p_draws, d)\n\nquantile(ev_draws, c(0.05, 0.5, 0.95))\n# Probability that EV is positive (posterior probability of an edge)\nmean(ev_draws > 0)\nA simple rule: only bet if\nP(EV > 0)\nexceeds a threshold (e.g., 0.6 or 0.7).\n    That’s a Bayesian risk control.\n6. Sequential Updating: Learning Over Time (Online Bayesian Updating)\nBetting systems are online systems. Your beliefs should update as games happen.\n    Beta-Binomial makes this trivial.\nupdate_beta <- function(a, b, y) {\n  # y is 1 for win, 0 for loss\n  c(a = a + y, b = b + (1 - y))\n}\n\nsequential_posterior <- function(y, a0 = 8, b0 = 8) {\n  a <- a0; b <- b0\n  out <- vector(\"list\", length(y))\n  for (i in seq_along(y)) {\n    ab <- update_beta(a, b, y[i])\n    a <- ab[\"a\"]; b <- ab[\"b\"]\n    out[[i]] <- c(\n      i = i,\n      a = a, b = b,\n      mean = a/(a+b),\n      lo90 = qbeta(0.05, a, b),\n      hi90 = qbeta(0.95, a, b)\n    )\n  }\n  bind_rows(lapply(out, as_tibble_row))\n}\n\n# Pick one team and track posterior over time\nteam_pick <- sample(unique(matches$team), 1)\ny_seq <- matches %>% filter(team == team_pick) %>% arrange(date) %>% pull(result)\n\nseq_df <- sequential_posterior(y_seq, a0 = 8, b0 = 8) %>%\n  mutate(team = team_pick)\n\nggplot(seq_df, aes(i, mean)) +\n  geom_line() +\n  geom_ribbon(aes(ymin = lo90, ymax = hi90), alpha = 0.2) +\n  scale_y_continuous(labels = percent_format(accuracy = 0.1)) +\n  labs(\n    title = paste(\"Sequential Posterior for\", team_pick),\n    x = \"Game index\",\n    y = \"Posterior mean (90% band)\"\n  )\n7. Shrinkage and Partial Pooling: Stabilizing Team/Player Estimates\nRaw win rates are noisy. Fully separate Beta posteriors help, but you can go further: estimate the prior from the league (Empirical Bayes),\n    then use it as a shrinkage prior for each team.\n7.1 Empirical Bayes prior fit (method-of-moments)\nfit_beta_mom <- function(p_hat, w = NULL) {\n  # method of moments for Beta parameters\n  # p_hat: observed proportions, w optional weights (e.g., n games)\n  if (is.null(w)) w <- rep(1, length(p_hat))\n\n  m <- weighted.mean(p_hat, w)\n  v <- weighted.mean((p_hat - m)^2, w)\n\n  # clamp variance to avoid weirdness\n  v <- max(v, 1e-6)\n\n  # Beta variance: m(1-m)/(a+b+1)\n  t <- m*(1-m)/v - 1\n  a <- max(0.5, m*t)\n  b <- max(0.5, (1-m)*t)\n  c(a = a, b = b)\n}\n\np_hat <- team_stats$k / team_stats$n\nprior_ab <- fit_beta_mom(p_hat, w = team_stats$n)\nprior_ab\na0 <- prior_ab[\"a\"]\nb0 <- prior_ab[\"b\"]\n\nteam_post_eb <- team_stats %>%\n  mutate(\n    a = a0 + k,\n    b = b0 + (n - k),\n    post_mean = a/(a+b),\n    lo90 = qbeta(0.05, a, b),\n    hi90 = qbeta(0.95, a, b)\n  ) %>%\n  arrange(desc(post_mean))\n\n# Compare naive sample rates vs EB posterior means\ncompare_df <- team_stats %>%\n  mutate(sample_rate = k/n) %>%\n  left_join(team_post_eb %>% select(team, post_mean), by = \"team\") %>%\n  pivot_longer(cols = c(sample_rate, post_mean), names_to = \"type\", values_to = \"p\")\n\nggplot(compare_df, aes(p, fill = type)) +\n  geom_histogram(bins = 20, alpha = 0.6, position = \"identity\") +\n  labs(\n    title = \"Shrinkage Effect: Sample Rates vs EB Posterior Means\",\n    x = \"Probability\",\n    y = \"Count\"\n  )\nShrinkage reduces overreaction to small samples—one of the most common reasons betting systems look great in backtests and fail live.\n8. Bayesian Logistic Models: Match Win Probabilities from Features\nTeam strength depends on context: home advantage, rest, injuries, travel, matchups, and more.\n    Logistic regression is a natural model for win probabilities. Bayesian logistic regression adds regularization and uncertainty.\nWe’ll create a few simple features from our toy data. In real projects you’d engineer better predictors.\n# Simple feature engineering (toy)\n# Use rolling win rate as a proxy strength feature (in real data: Elo, xG, etc.)\nmatches_feat <- matches %>%\n  arrange(date) %>%\n  group_by(team) %>%\n  mutate(\n    games_played = row_number() - 1,\n    roll_winrate = ifelse(games_played == 0, NA_real_,\n                          cummean(lag(result)))\n  ) %>%\n  ungroup() %>%\n  mutate(\n    roll_winrate = ifelse(is.na(roll_winrate), mean(result), roll_winrate),\n    # center features\n    roll_winrate_c = roll_winrate - mean(roll_winrate),\n    home_c = home - mean(home)\n  )\n\n# Train-test split by time (avoid leakage)\ncut_date <- quantile(matches_feat$date, 0.8)\ntrain <- matches_feat %>% filter(date <= cut_date)\ntest  <- matches_feat %>% filter(date >  cut_date)\n\nnrow(train); nrow(test)\n# Bayesian logistic regression\n# Note: rstanarm can be slower. For a big dataset, adjust iter/chains or use variational inference elsewhere.\nfit_bayes_logit <- stan_glm(\n  result ~ home_c + roll_winrate_c,\n  data = train,\n  family = binomial(link = \"logit\"),\n  prior = normal(location = 0, scale = 1, autoscale = TRUE),\n  prior_intercept = normal(0, 2.5),\n  chains = 2,\n  iter = 800,\n  refresh = 0\n)\n\nprint(fit_bayes_logit)\n# Posterior predictive probabilities on test\np_test <- posterior_linpred(fit_bayes_logit, newdata = test, transform = TRUE)\n# p_test is draws x observations; take posterior mean probability\np_hat <- colMeans(p_test)\n\ntest_pred <- test %>%\n  mutate(p_model = p_hat)\n\ntest_pred %>%\n  summarise(\n    mean_p = mean(p_model),\n    mean_y = mean(result)\n  )\n9. Ratings as Priors: Elo with Uncertainty and Bayesian Flavor\nElo is a practical rating system that translates team strength differences into win probabilities.\n    It’s not “Bayesian” in a strict sense, but it behaves like a sequential updating scheme and can be combined with Bayesian ideas.\n9.1 Simple Elo implementation in R\nelo_update <- function(Ra, Rb, y, k = 20) {\n  # y: 1 if A wins, 0 if B wins\n  Ea <- 1 / (1 + 10^((Rb - Ra)/400))\n  Ra_new <- Ra + k*(y - Ea)\n  Rb_new <- Rb + k*((1 - y) - (1 - Ea))\n  c(Ra = Ra_new, Rb = Rb_new, Ea = Ea)\n}\n\nrun_elo <- function(df, init = 1500, k = 20) {\n  teams <- sort(unique(c(df$team, df$opponent)))\n  R <- setNames(rep(init, length(teams)), teams)\n\n  out <- vector(\"list\", nrow(df))\n  for (i in seq_len(nrow(df))) {\n    a <- df$team[i]\n    b <- df$opponent[i]\n    y <- df$result[i]\n\n    upd <- elo_update(R[a], R[b], y, k = k)\n    R[a] <- upd[\"Ra\"]\n    R[b] <- upd[\"Rb\"]\n\n    out[[i]] <- tibble(\n      date = df$date[i],\n      team = a,\n      opponent = b,\n      result = y,\n      elo_team = R[a],\n      elo_opp = R[b],\n      p_elo = upd[\"Ea\"]\n    )\n  }\n  bind_rows(out)\n}\n\nelo_df <- run_elo(matches %>% arrange(date), k = 18)\nelo_df %>% slice(1:5)\n# Join Elo features back to matches\nmatches_elo <- matches %>%\n  arrange(date) %>%\n  mutate(row_id = row_number()) %>%\n  left_join(\n    elo_df %>% mutate(row_id = row_number()) %>% select(row_id, p_elo),\n    by = \"row_id\"\n  )\n\nsummary(matches_elo$p_elo)\nElo probabilities can serve as baseline priors or features inside a Bayesian model. The key is to evaluate calibration and stability.\n10. Score Models: Poisson and Skellam for Totals and Spreads\nIf you bet totals (Over/Under) or spreads, it’s helpful to model the score distribution.\n    A common starting point is Poisson scoring for each team:\nHomeGoals ~ Poisson(lambda_home)\n,\nAwayGoals ~ Poisson(lambda_away)\n.\n    The goal difference follows a Skellam distribution (difference of two Poissons).\nWe’ll simulate goals here to demonstrate the workflow. Replace this with real score data.\n# Add synthetic goals to the toy dataset (for demonstration)\nadd_goals <- function(df) {\n  # tie lambda to latent p_true to create plausible relationship\n  # this is just for tutorial purposes\n  base <- 1.2\n  spread <- (df$p_true - 0.5) * 2.0\n\n  lambda_home <- pmax(0.2, base + 0.4 + spread)\n  lambda_away <- pmax(0.2, base - 0.1 - spread)\n\n  df %>%\n    mutate(\n      goals_team = rpois(n(), lambda_home),\n      goals_opp  = rpois(n(), lambda_away),\n      total_goals = goals_team + goals_opp,\n      goal_diff = goals_team - goals_opp\n    )\n}\n\nmatches_goals <- add_goals(matches)\nsummary(matches_goals$total_goals)\n10.1 Fit simple Poisson regression for scoring rates\n# Poisson model for \"team goals\" using simple predictors\n# In real data: team/opponent effects, home advantage, pace, etc.\ntrain_g <- matches_goals %>% filter(date <= cut_date)\ntest_g  <- matches_goals %>% filter(date >  cut_date)\n\nfit_pois <- glm(\n  goals_team ~ home + p_true,\n  data = train_g,\n  family = poisson()\n)\n\nsummary(fit_pois)\n# Predict lambdas on test\nlambda_hat <- predict(fit_pois, newdata = test_g, type = \"response\")\n\ntest_g2 <- test_g %>% mutate(lambda_team = lambda_hat)\n\nsummary(test_g2$lambda_team)\n10.2 Convert score distribution into market probabilities (totals/spreads)\nTo price a total (e.g., Over 2.5), you need\nP(Total > 2.5)\n.\n    If we model both sides as Poisson and independent, total is Poisson with rate\nlambda_total = lambda_team + lambda_opp\n.\n    Here we only have a team-goals model; we’ll create a companion lambda for opponent for the demo.\n# Companion opponent lambda (toy)\nfit_pois_opp <- glm(\n  goals_opp ~ home + p_true,\n  data = train_g,\n  family = poisson()\n)\n\ntest_g2 <- test_g2 %>%\n  mutate(lambda_opp = predict(fit_pois_opp, newdata = test_g2, type = \"response\"),\n         lambda_total = lambda_team + lambda_opp)\n\n# Price Over 2.5\np_over_25 <- 1 - ppois(2, lambda = test_g2$lambda_total)\nsummary(p_over_25)\n# Example: bet Over 2.5 at decimal odds 1.95\nd_over <- 1.95\nev_over <- ev_decimal(p_over_25, d_over)\nsummary(ev_over)\nmean(ev_over > 0)\n11. Probability Calibration: Brier, Log Loss, and Reliability Curves\nA betting system needs probabilities that mean what they say. If you claim 60% and you win 60% over time, that’s calibration.\n    Calibration is one of the best predictors that your edge is real rather than backtest noise.\n11.1 Brier score and log loss\nbrier_score <- function(y, p) mean((y - p)^2)\n\nlog_loss <- function(y, p, eps = 1e-12) {\n  p <- pmin(pmax(p, eps), 1 - eps)\n  -mean(y*log(p) + (1-y)*log(1-p))\n}\n\nbrier <- brier_score(test_pred$result, test_pred$p_model)\nll <- log_loss(test_pred$result, test_pred$p_model)\nc(brier = brier, logloss = ll)\n11.2 Reliability curve (calibration plot)\nreliability_curve <- function(y, p, bins = 10) {\n  tibble(y = y, p = p) %>%\n    mutate(bin = ntile(p, bins)) %>%\n    group_by(bin) %>%\n    summarise(\n      p_mean = mean(p),\n      y_mean = mean(y),\n      n = n(),\n      .groups = \"drop\"\n    )\n}\n\nrc <- reliability_curve(test_pred$result, test_pred$p_model, bins = 12)\n\nggplot(rc, aes(p_mean, y_mean, size = n)) +\n  geom_point(alpha = 0.8) +\n  geom_abline(slope = 1, intercept = 0, linetype = 2) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    title = \"Reliability Curve (Calibration)\",\n    x = \"Predicted probability (bin mean)\",\n    y = \"Observed frequency\",\n    size = \"Count\"\n  )\nIf your points drift above the diagonal, you’re underconfident; below it, overconfident. Both can destroy Kelly sizing.\n12. Kelly Logic: Optimal Growth, Fractional Kelly, and Practical Constraints\nKelly sizing maximizes long-run logarithmic bankroll growth\nif\nyour probabilities are correct.\n    In real life, probabilities are noisy—so full Kelly can be too aggressive. Fractional Kelly is often the sweet spot.\n12.1 Kelly fraction for decimal odds\np <- 0.55\nd <- 2.05\n\nf_k <- kelly_fraction_decimal(p, d)\nf_k\n# Fractional Kelly (e.g., half Kelly)\nfractional_kelly <- function(f, frac = 0.5) frac * f\n\nf_half <- fractional_kelly(f_k, 0.5)\n\n# Apply caps (never bet negative Kelly; cap max stake)\nf_bet <- clip(f_half, 0, 0.05)\nf_bet\n12.2 Kelly with uncertainty (posterior integration)\nA Bayesian twist: rather than plug in a point estimate\np\n, integrate over uncertainty by sampling from the posterior.\n    This yields a distribution for Kelly fraction and lets you bet conservatively (e.g., on a lower quantile).\nkelly_draws_decimal <- function(p_draws, d) {\n  b <- d - 1\n  q <- 1 - p_draws\n  (b*p_draws - q)/b\n}\n\n# Example using the earlier Beta posterior (pick some a,b)\na <- 25; b <- 20\np_draws <- rbeta(50000, a, b)\nd <- 1.95\n\nf_draws <- kelly_draws_decimal(p_draws, d)\n\nquantile(f_draws, c(0.05, 0.25, 0.5, 0.75, 0.95))\n# Conservative staking: use 25th percentile of Kelly, then apply fraction + cap\nf_cons <- quantile(f_draws, 0.25)\nf_bet <- clip(0.5 * f_cons, 0, 0.03)\nf_bet\nThis is one of the most practical Bayesian risk controls: uncertainty shrinks position sizes automatically.\n13. Portfolio Betting: Correlation, Market Clustering, and Exposure Controls\nBetting is rarely a sequence of independent wagers. Same league, same teams, same injury news—your bets can be correlated.\n    Correlation increases drawdowns and makes naive Kelly sizing too aggressive.\n13.1 A simple exposure constraint system\n# Imagine we have candidate bets with:\n# date, market, team, p_model, odds_decimal, kelly_f\n\nmake_candidates <- function(df, p_col = \"p_model\", odds_col = \"odds_decimal\") {\n  df %>%\n    transmute(\n      date,\n      team,\n      opponent,\n      p = .data[[p_col]],\n      d = .data[[odds_col]],\n      ev = ev_decimal(p, d),\n      f_kelly = kelly_fraction_decimal(p, d)\n    ) %>%\n    mutate(\n      f_half = 0.5 * f_kelly,\n      f_bet = clip(f_half, 0, 0.03)\n    )\n}\n\n# For demo, use test_pred probabilities against the odds in matches\ncandidates <- test_pred %>%\n  mutate(p_model = p_model, odds_decimal = odds_decimal) %>%\n  make_candidates()\n\nsummary(candidates$f_bet)\nsummary(candidates$ev)\n# Portfolio constraints:\n# - Max stake per day\n# - Max stake per team\n# - Only bet when EV > 0 and Kelly > 0\n\napply_constraints <- function(df, max_daily = 0.08, max_team = 0.05) {\n  df %>%\n    filter(ev > 0, f_bet > 0) %>%\n    arrange(desc(ev)) %>%\n    group_by(date) %>%\n    mutate(\n      daily_cum = cumsum(f_bet),\n      f_bet_day = ifelse(daily_cum <= max_daily, f_bet, 0)\n    ) %>%\n    ungroup() %>%\n    group_by(team) %>%\n    mutate(\n      team_cum = cumsum(f_bet_day),\n      f_bet_final = ifelse(team_cum <= max_team, f_bet_day, 0)\n    ) %>%\n    ungroup()\n}\n\nbets_planned <- apply_constraints(candidates, max_daily = 0.08, max_team = 0.05)\n\nbets_planned %>%\n  summarise(\n    n_candidates = n(),\n    n_bets = sum(f_bet_final > 0),\n    avg_stake = mean(f_bet_final[f_bet_final > 0]),\n    total_stake = sum(f_bet_final)\n  )\nThis looks simple, but constraints are often the difference between a backtest hero and a live survivor.\n14. Concrete Betting Strategies: From Simple Rules to Model-Driven Systems\nBelow are practical strategies you can implement. None is “magic.” The point is to define rules, measure them, and iterate.\n14.1 Strategy A: Simple value betting (probability edge threshold)\nstrategy_value_threshold <- function(df, edge_min = 0.02) {\n  df %>%\n    mutate(\n      p_be = 1/d,\n      edge = p - p_be\n    ) %>%\n    filter(edge >= edge_min) %>%\n    mutate(\n      f_bet = clip(0.5 * kelly_fraction_decimal(p, d), 0, 0.03)\n    )\n}\n\nbets_A <- candidates %>% strategy_value_threshold(edge_min = 0.02)\nsummary(bets_A$f_bet)\n14.2 Strategy B: Bayesian “probability of positive EV” gate\nIf you can produce a posterior distribution for\np\n, you can compute\nP(EV > 0)\n.\n    We’ll demonstrate using a Beta posterior for each team’s win rate as a crude uncertainty model.\n# Build EB Beta posteriors from the training window\nteam_train <- matches %>% filter(date <= cut_date) %>%\n  group_by(team) %>%\n  summarise(n = n(), k = sum(result), .groups = \"drop\")\n\np_hat_train <- team_train$k / team_train$n\nprior_ab <- fit_beta_mom(p_hat_train, w = team_train$n)\na0 <- prior_ab[\"a\"]; b0 <- prior_ab[\"b\"]\n\nteam_params <- team_train %>%\n  mutate(a = a0 + k, b = b0 + (n - k)) %>%\n  select(team, a, b)\n\n# Attach team posterior params to candidates\ncand_B <- candidates %>%\n  left_join(team_params, by = \"team\")\n\nprob_ev_positive_beta <- function(a, b, d, n_draws = 10000) {\n  p_draws <- rbeta(n_draws, a, b)\n  mean(ev_decimal(p_draws, d) > 0)\n}\n\ncand_B2 <- cand_B %>%\n  mutate(\n    p_ev_pos = pmap_dbl(list(a, b, d), ~prob_ev_positive_beta(..1, ..2, ..3, n_draws = 6000)),\n    f_bet = clip(0.5 * kelly_fraction_decimal(p, d), 0, 0.03)\n  )\n\nbets_B <- cand_B2 %>% filter(p_ev_pos >= 0.65, ev > 0, f_bet > 0)\n\nbets_B %>%\n  summarise(n_bets = n(), mean_p_ev_pos = mean(p_ev_pos), mean_ev = mean(ev), mean_f = mean(f_bet))\n14.3 Strategy C: Calibrated model + fractional Kelly + caps\n# If you have a calibrated model probability p_model,\n# apply fractional Kelly and cap. Also: require minimal EV.\nstrategy_fractional_kelly <- function(df, ev_min = 0.01, frac = 0.5, cap = 0.03) {\n  df %>%\n    mutate(\n      f_k = kelly_fraction_decimal(p, d),\n      f_bet = clip(frac * f_k, 0, cap)\n    ) %>%\n    filter(ev >= ev_min, f_bet > 0)\n}\n\nbets_C <- candidates %>% strategy_fractional_kelly(ev_min = 0.01, frac = 0.35, cap = 0.025)\nbets_C %>% summarise(n_bets = n(), mean_ev = mean(ev), mean_f = mean(f_bet))\n15. Backtesting in R: Walk-forward, Leakage Prevention, and Metrics\nMost betting “edges” vanish when you backtest properly. Your backtest must be time-respecting (walk-forward),\n    must avoid target leakage, and must include realistic constraints (limits, stake caps, minimum odds, etc.).\n15.1 A minimal bet settlement engine\nsettle_bets <- function(df, bankroll0 = 1.0) {\n  # df must have: result (1/0), d (decimal odds), f_bet (fraction of bankroll)\n  bankroll <- bankroll0\n  out <- vector(\"list\", nrow(df))\n\n  for (i in seq_len(nrow(df))) {\n    stake <- bankroll * df$f_bet[i]\n    if (stake <= 0) {\n      out[[i]] <- tibble(i = i, bankroll = bankroll, stake = 0, pnl = 0)\n      next\n    }\n\n    pnl <- if (df$result[i] == 1) stake * (df$d[i] - 1) else -stake\n    bankroll <- bankroll + pnl\n\n    out[[i]] <- tibble(i = i, bankroll = bankroll, stake = stake, pnl = pnl)\n  }\n\n  bind_cols(df, bind_rows(out))\n}\n\n# Example: settle Strategy C bets (in arbitrary order; ideally sort by date)\nbt_C <- bets_C %>%\n  mutate(result = test_pred$result[match(paste(date, team, opponent), paste(test_pred$date, test_pred$team, test_pred$opponent))]) %>%\n  arrange(date) %>%\n  select(date, team, opponent, result, d, f_bet)\n\nbt_C2 <- settle_bets(bt_C, bankroll0 = 1.0)\n\ntail(bt_C2)\n15.2 Performance metrics\ncompute_metrics <- function(df) {\n  df %>%\n    summarise(\n      n_bets = sum(stake > 0),\n      final_bankroll = last(bankroll),\n      total_pnl = sum(pnl),\n      roi_on_staked = ifelse(sum(stake) > 0, sum(pnl)/sum(stake), NA_real_),\n      hit_rate = mean(result[stake > 0] == 1),\n      avg_odds = mean(d[stake > 0]),\n      max_drawdown = {\n        peak <- cummax(bankroll)\n        dd <- bankroll/peak - 1\n        min(dd)\n      }\n    )\n}\n\ncompute_metrics(bt_C2)\n# Plot bankroll curve\nggplot(bt_C2, aes(date, bankroll)) +\n  geom_line() +\n  labs(\n    title = \"Backtest Bankroll Curve (Strategy C)\",\n    x = \"Date\",\n    y = \"Bankroll\"\n  )\n15.3 Walk-forward template\nBelow is a simple walk-forward skeleton: refit model on an expanding window, predict the next chunk, generate bets, settle, repeat.\n    Replace the “model” section with your real pipeline.\nwalk_forward <- function(df, initial_frac = 0.6, step_frac = 0.1) {\n  df <- df %>% arrange(date)\n  n <- nrow(df)\n\n  idx0 <- floor(initial_frac * n)\n  step <- floor(step_frac * n)\n\n  start <- idx0\n  bankroll <- 1.0\n  all_bets <- list()\n\n  while (start < n) {\n    train_idx <- 1:start\n    test_idx <- (start + 1):min(n, start + step)\n\n    train <- df[train_idx, ]\n    test  <- df[test_idx, ]\n\n    # --- Model (placeholder) ---\n    # simple baseline: probability = historical mean adjusted by home\n    p0 <- mean(train$result)\n    p_hat <- clip(p0 + 0.03*(test$home - mean(train$home)), 0.02, 0.98)\n\n    cand <- test %>%\n      transmute(\n        date, team, opponent,\n        result,\n        p = p_hat,\n        d = odds_decimal\n      ) %>%\n      mutate(\n        ev = ev_decimal(p, d),\n        f_bet = clip(0.35 * kelly_fraction_decimal(p, d), 0, 0.02)\n      ) %>%\n      filter(ev > 0.01, f_bet > 0)\n\n    # Settle on this chunk\n    if (nrow(cand) > 0) {\n      settled <- settle_bets(cand, bankroll0 = bankroll)\n      bankroll <- last(settled$bankroll)\n      all_bets[[length(all_bets) + 1]] <- settled\n    }\n\n    start <- start + step\n  }\n\n  bind_rows(all_bets)\n}\n\nwf_bt <- walk_forward(matches)\ncompute_metrics(wf_bt)\n16. Monte Carlo Stress Tests: Drawdowns, Ruin, and Regret\nBacktests are one path. Stress tests are another. Monte Carlo simulation answers:\n    “If my estimated edge is real but noisy, what drawdowns should I expect?”\n16.1 Simulate a season of bets with uncertainty around p\nsimulate_betting_path <- function(n_bets = 500, p = 0.54, d = 1.95, f = 0.01, bankroll0 = 1) {\n  bankroll <- bankroll0\n  for (i in 1:n_bets) {\n    stake <- bankroll * f\n    win <- rbinom(1, 1, p)\n    pnl <- if (win == 1) stake*(d - 1) else -stake\n    bankroll <- bankroll + pnl\n  }\n  bankroll\n}\n\n# Many simulations\nsim_paths <- replicate(5000, simulate_betting_path(n_bets = 400, p = 0.53, d = 1.95, f = 0.012))\nquantile(sim_paths, c(0.05, 0.25, 0.5, 0.75, 0.95))\n16.2 Incorporate probability error (model risk)\nYour\np_hat\nis not the true\np\n. Model risk is often larger than market risk.\n    We simulate true p drifting around your estimate.\nsimulate_with_model_error <- function(n_bets = 500, p_hat = 0.54, p_sd = 0.03, d = 1.95, f = 0.01, bankroll0 = 1) {\n  bankroll <- bankroll0\n  for (i in 1:n_bets) {\n    p_true <- clip(rnorm(1, p_hat, p_sd), 0.01, 0.99)\n    stake <- bankroll * f\n    win <- rbinom(1, 1, p_true)\n    pnl <- if (win == 1) stake*(d - 1) else -stake\n    bankroll <- bankroll + pnl\n  }\n  bankroll\n}\n\nsim2 <- replicate(5000, simulate_with_model_error(n_bets = 400, p_hat = 0.53, p_sd = 0.05, d = 1.95, f = 0.012))\nquantile(sim2, c(0.05, 0.25, 0.5, 0.75, 0.95))\n# Compare distributions\ndf_sim <- tibble(\n  bankroll = c(sim_paths, sim2),\n  scenario = rep(c(\"no_model_error\", \"with_model_error\"), each = length(sim_paths))\n)\n\nggplot(df_sim, aes(bankroll)) +\n  geom_histogram(bins = 50) +\n  facet_wrap(~scenario, scales = \"free_y\") +\n  labs(\n    title = \"Monte Carlo Bankroll Distribution\",\n    x = \"Final bankroll\",\n    y = \"Count\"\n  )\nIf model error collapses your distribution, reduce Kelly fraction, add EV thresholds, and improve calibration.\n17. A Go-Live Checklist: Operational and Statistical Guardrails\nTime split always\n: train only on past, predict future.\nLog everything\n: inputs, odds, timestamps, model version, decisions, stakes.\nCalibrate probabilities\n: reliability curves, Brier, log loss.\nRespect uncertainty\n: use posterior bands or conservative probability adjustments.\nSize bets defensively\n: fractional Kelly + caps + daily exposure limits.\nAccount for correlation\n: cluster exposures by league/team/news.\nStress-test\n: Monte Carlo with model error, not just “true p”.\nBeware selection bias\n: strategies discovered by brute force often overfit.\nPrefer stability\n: smaller edge + stable behavior beats fragile high edge.\nRecommended Reading\nIf you’d like a more structured, code-heavy continuation of these ideas (Bayesian probabilities, EV, and Kelly-based sizing),\n  you can find it here:\nBayesian Sports Betting with R\n.\nThe post\nDesigning Sports Betting Systems in R: Bayesian Probabilities, Expected Value, and Kelly Logic\nappeared first on\nR Programming Books\n.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nBlog - R Programming Books\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "main_html": "<article class=\"post-398716 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Designing Sports Betting Systems in R: Bayesian Probabilities, Expected Value, and Kelly Logic</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">February 1, 2026</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/rprogrammingbooks/\">rprogrammingbooks</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r\"> Blog - R Programming Books</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<!-- Macro-post HTML (NO H1/title included). All content in English. -->\n<div class=\"post\">\n<p>\n    A good sports betting system is not a “pick-winners” machine. It’s an <strong>uncertainty engine</strong>:\n    it turns data into <strong>probabilities</strong>, probabilities into <strong>expected value</strong>, and expected value into\n    <strong>position sizes</strong> that survive variance. If you can do those three steps consistently, you can build a robust process—\n    even if individual bets lose often.\n  </p>\n<p>\n    This post is a <strong>code-heavy</strong> blueprint for designing sports betting systems in <strong>R</strong> using\n    <strong>Bayesian probabilities</strong>, market odds, <strong>EV</strong>, the <strong>Kelly Criterion</strong>, and practical\n    betting strategies. You’ll also get a backtesting and Monte Carlo framework to evaluate drawdowns, ruin risk, and performance stability.\n  </p>\n<hr/>\n<h2 id=\"toc\">Table of Contents</h2>\n<ul>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#setup\" rel=\"nofollow\" target=\"_blank\">1. Setup: Packages, Data Schemas, and Conventions</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#odds\" rel=\"nofollow\" target=\"_blank\">2. Odds and Probability: Conversions, Vig (Overround), and Fair Prices</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#ev\" rel=\"nofollow\" target=\"_blank\">3. Expected Value: Break-even Probability, Edge, and Sensitivity</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#bayes-foundations\" rel=\"nofollow\" target=\"_blank\">4. Bayesian Foundations for Betting: Priors, Posteriors, and Uncertainty</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#beta-binomial\" rel=\"nofollow\" target=\"_blank\">5. Beta-Binomial Models: Bayesian Win Rates (Conjugate Bayes)</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#sequential\" rel=\"nofollow\" target=\"_blank\">6. Sequential Updating: Learning Over Time (Online Bayesian Updating)</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#shrinkage\" rel=\"nofollow\" target=\"_blank\">7. Shrinkage and Partial Pooling: Stabilizing Team/Player Estimates</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#logistic\" rel=\"nofollow\" target=\"_blank\">8. Bayesian Logistic Models: Match Win Probabilities from Features</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#rating\" rel=\"nofollow\" target=\"_blank\">9. Ratings as Priors: Elo with Uncertainty and Bayesian Flavor</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#score-models\" rel=\"nofollow\" target=\"_blank\">10. Score Models: Poisson and Skellam for Totals and Spreads</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#calibration\" rel=\"nofollow\" target=\"_blank\">11. Probability Calibration: Brier, Log Loss, and Reliability Curves</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#kelly\" rel=\"nofollow\" target=\"_blank\">12. Kelly Logic: Optimal Growth, Fractional Kelly, and Practical Constraints</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#portfolio\" rel=\"nofollow\" target=\"_blank\">13. Portfolio Betting: Correlation, Market Clustering, and Exposure Controls</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#strategies\" rel=\"nofollow\" target=\"_blank\">14. Concrete Betting Strategies: From Simple Rules to Model-Driven Systems</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#backtesting\" rel=\"nofollow\" target=\"_blank\">15. Backtesting in R: Walk-forward, Leakage Prevention, and Metrics</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#montecarlo\" rel=\"nofollow\" target=\"_blank\">16. Monte Carlo Stress Tests: Drawdowns, Ruin, and Regret</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#checklist\" rel=\"nofollow\" target=\"_blank\">17. A Go-Live Checklist: Operational and Statistical Guardrails</a></li>\n<li><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r#recommended-reading\" rel=\"nofollow\" target=\"_blank\">Recommended Reading</a></li>\n</ul>\n<hr/>\n<h2 id=\"setup\">1. Setup: Packages, Data Schemas, and Conventions</h2>\n<p>\n    We’ll work with an event-level dataset (one row per match) and optionally a bet-level dataset (one row per wager).\n    The minimum fields you want for match win modeling:\n  </p>\n<ul>\n<li><code>date</code></li>\n<li><code>team</code>, <code>opponent</code></li>\n<li><code>home</code> (1 home, 0 away)</li>\n<li><code>result</code> (1 win, 0 loss)</li>\n<li><code>odds_decimal</code> (decimal odds for the bet you want to evaluate)</li>\n</ul>\n<pre># Core data + modeling stack\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(stringr)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(scales)\n\n# Bayesian regression (optional, heavier but powerful)\nlibrary(rstanarm)\nlibrary(posterior)\n\nset.seed(42)\n\n# --- Odds helpers ---\namerican_to_decimal &lt;- function(american) {\n  ifelse(american &gt; 0, 1 + american/100, 1 + 100/abs(american))\n}\n\ndecimal_to_american &lt;- function(decimal) {\n  # returns American odds as numeric (positive/negative)\n  stopifnot(all(decimal &gt; 1))\n  out &lt;- ifelse(decimal &gt;= 2, (decimal - 1) * 100, -100/(decimal - 1))\n  out\n}\n\ndecimal_to_implied &lt;- function(decimal) 1 / decimal\n\n# Remove vig from a two-outcome market (simple proportional normalization)\nremove_vig_two_way &lt;- function(p1_raw, p2_raw) {\n  s &lt;- p1_raw + p2_raw\n  c(p1 = p1_raw/s, p2 = p2_raw/s, overround = s)\n}\n\n# --- EV helpers ---\nev_decimal &lt;- function(p, d) {\n  # expected profit per unit stake for decimal odds d\n  # win: profit = d - 1; lose: -1\n  p*(d - 1) - (1 - p)\n}\n\nbreakeven_p_decimal &lt;- function(d) 1 / d\n\n# --- Kelly helpers ---\nkelly_fraction_decimal &lt;- function(p, d) {\n  # Kelly fraction for decimal odds d, win prob p\n  # b = d - 1, q = 1-p, f* = (bp - q)/b\n  b &lt;- d - 1\n  q &lt;- 1 - p\n  f &lt;- (b*p - q) / b\n  f\n}\n\n# Practical caps\nclip &lt;- function(x, lo, hi) pmax(lo, pmin(hi, x))</pre>\n<h3>1.1 A toy dataset generator (so you can run everything)</h3>\n<p>\n    In real life, you’ll load your match history and odds. For a self-contained tutorial, we simulate:\n    latent team strengths → win probabilities → outcomes → bookmaker odds with a built-in margin.\n  </p>\n<pre>simulate_league &lt;- function(\n  n_teams = 12,\n  n_games = 2000,\n  home_adv = 0.25,\n  sigma_strength = 0.9,\n  bookmaker_margin = 0.05\n) {\n  teams &lt;- paste0(\"T\", sprintf(\"%02d\", 1:n_teams))\n  strength &lt;- rnorm(n_teams, 0, sigma_strength)\n  names(strength) &lt;- teams\n\n  # schedule\n  team &lt;- sample(teams, n_games, replace = TRUE)\n  opponent &lt;- sample(teams, n_games, replace = TRUE)\n  while(any(team == opponent)) {\n    idx &lt;- which(team == opponent)\n    opponent[idx] &lt;- sample(teams, length(idx), replace = TRUE)\n  }\n\n  home &lt;- rbinom(n_games, 1, 0.5)\n  date &lt;- as.Date(\"2022-01-01\") + sample(0:900, n_games, replace = TRUE)\n\n  # true probability via logistic link\n  lin &lt;- (strength[team] - strength[opponent]) + home_adv * home\n  p_true &lt;- plogis(lin)\n\n  # outcomes\n  result &lt;- rbinom(n_games, 1, p_true)\n\n  # bookmaker sets odds from \"market probability\" with margin\n  # market_prob ~ p_true with noise, then add margin by inflating implied probs\n  p_mkt &lt;- clip(p_true + rnorm(n_games, 0, 0.03), 0.02, 0.98)\n  # apply margin by scaling implied probabilities upward (approx.)\n  p_raw &lt;- clip(p_mkt * (1 + bookmaker_margin), 0.02, 0.995)\n\n  odds_decimal &lt;- 1 / p_raw\n\n  tibble(\n    date = date,\n    team = team,\n    opponent = opponent,\n    home = home,\n    result = result,\n    p_true = p_true,\n    odds_decimal = odds_decimal\n  ) %&gt;%\n    arrange(date)\n}\n\nmatches &lt;- simulate_league()\nglimpse(matches)\nsummary(matches$odds_decimal)</pre>\n<hr/>\n<h2 id=\"odds\">2. Odds and Probability: Conversions, Vig (Overround), and Fair Prices</h2>\n<p>\n    Odds imply probabilities, but sportsbook odds typically include a margin (vig/overround). If you compare your model’s probability to raw implied probability,\n    you might misjudge edges. The right comparison is: your probability vs the market’s <em>vig-free</em> probability.\n  </p>\n<h3>2.1 Basic conversions</h3>\n<pre># Example: decimal odds\nd &lt;- 1.91\np_implied_raw &lt;- decimal_to_implied(d)\np_implied_raw\r\n# Example: American odds\nam &lt;- -110\nd2 &lt;- american_to_decimal(am)\nc(decimal = d2, implied = decimal_to_implied(d2))</pre>\n<h3>2.2 Two-way vig removal example</h3>\n<p>\n    For a two-outcome market (like moneyline without draws), you can normalize implied probabilities.\n    Suppose the book offers:\n  </p>\n<pre>d_home &lt;- 1.80\nd_away &lt;- 2.10\n\np_home_raw &lt;- 1/d_home\np_away_raw &lt;- 1/d_away\n\nvigfree &lt;- remove_vig_two_way(p_home_raw, p_away_raw)\nvigfree\r\n# Market \"fair\" probabilities\np_home_fair &lt;- vigfree[\"p1\"]\np_away_fair &lt;- vigfree[\"p2\"]\n\np_home_fair + p_away_fair  # should be 1</pre>\n<p>\n    In practice, you might not always have both sides’ odds, especially if you store only “the odds you bet”.\n    But for sharp evaluation and backtesting, capturing the full market quote (both sides) is ideal.\n  </p>\n<hr/>\n<h2 id=\"ev\">3. Expected Value: Break-even Probability, Edge, and Sensitivity</h2>\n<p>\n    Expected value (EV) is the bridge between probability and betting decisions. With decimal odds <code>d</code>,\n    and win probability <code>p</code>, EV per 1 unit stake is:\n  </p>\n<pre># EV for a single bet\np_hat &lt;- 0.56\nd &lt;- 1.95\n\nev &lt;- ev_decimal(p_hat, d)\nev\r\n# Break-even p (the book's implied probability)\np_be &lt;- breakeven_p_decimal(d)\nc(breakeven_p = p_be, edge = p_hat - p_be)</pre>\n<h3>3.1 EV sensitivity curve</h3>\n<pre>ev_curve &lt;- function(d, p_grid = seq(0.01, 0.99, by = 0.01)) {\n  tibble(p = p_grid, ev = ev_decimal(p_grid, d))\n}\n\ndf_ev &lt;- ev_curve(1.95)\n\nggplot(df_ev, aes(p, ev)) +\n  geom_line() +\n  geom_hline(yintercept = 0, linetype = 2) +\n  scale_y_continuous(labels = percent_format(accuracy = 0.1)) +\n  labs(\n    title = \"EV per Unit Stake vs Win Probability\",\n    x = \"Win probability p\",\n    y = \"Expected value (profit per 1 unit stake)\"\n  )</pre>\n<p>\n    Notice how small probability errors can flip EV from positive to negative when odds are tight. This is why calibration and uncertainty-aware betting matter.\n  </p>\n<hr/>\n<h2 id=\"bayes-foundations\">4. Bayesian Foundations for Betting: Priors, Posteriors, and Uncertainty</h2>\n<p>\n    Bayesian thinking fits betting naturally: you start with a prior belief about a team/player/strategy,\n    update with evidence, and end up with a posterior distribution over the probability you care about.\n    Crucially, you get <strong>uncertainty</strong>, not just a point estimate.\n  </p>\n<h3>4.1 A simple Bayesian coin: Beta prior + Binomial likelihood</h3>\n<pre># Prior: Beta(a, b)\na0 &lt;- 10\nb0 &lt;- 10\n\n# Observed: k wins out of n\nk &lt;- 12\nn &lt;- 20\n\n# Posterior: Beta(a0 + k, b0 + n - k)\na1 &lt;- a0 + k\nb1 &lt;- b0 + (n - k)\n\n# Posterior mean and interval\npost_mean &lt;- a1 / (a1 + b1)\npost_ci &lt;- qbeta(c(0.05, 0.95), a1, b1)\n\nc(mean = post_mean, lo90 = post_ci[1], hi90 = post_ci[2])\r\n# Visualize prior vs posterior\ngrid &lt;- seq(0, 1, length.out = 400)\n\ndf_beta &lt;- bind_rows(\n  tibble(p = grid, density = dbeta(grid, a0, b0), dist = \"prior\"),\n  tibble(p = grid, density = dbeta(grid, a1, b1), dist = \"posterior\")\n)\n\nggplot(df_beta, aes(p, density, color = dist)) +\n  geom_line() +\n  labs(\n    title = \"Beta Prior vs Posterior\",\n    x = \"Win probability p\",\n    y = \"Density\"\n  )</pre>\n<p>\n    This is the simplest but most important idea: if your sample is small, your posterior won’t be overly confident.\n    That alone can prevent overbetting.\n  </p>\n<hr/>\n<h2 id=\"beta-binomial\">5. Beta-Binomial Models: Bayesian Win Rates (Conjugate Bayes)</h2>\n<p>\n    The Beta-Binomial is a workhorse for modeling win rates, conversion rates, “cover rates”, etc.\n    You can use it for:\n  </p>\n<ul>\n<li>Team win rate vs certain opponents</li>\n<li>Over/Under hit rate for a model-defined filter</li>\n<li>Any binary market outcome you can label as 0/1</li>\n</ul>\n<h3>5.1 Team-level posteriors</h3>\n<pre># Build per-team counts\nteam_stats &lt;- matches %&gt;%\n  group_by(team) %&gt;%\n  summarise(\n    n = n(),\n    k = sum(result),\n    .groups = \"drop\"\n  )\n\n# Choose a prior: mildly skeptical\na0 &lt;- 8\nb0 &lt;- 8\n\nteam_post &lt;- team_stats %&gt;%\n  mutate(\n    a = a0 + k,\n    b = b0 + (n - k),\n    post_mean = a/(a+b),\n    lo90 = qbeta(0.05, a, b),\n    hi90 = qbeta(0.95, a, b)\n  ) %&gt;%\n  arrange(desc(post_mean))\n\nteam_post %&gt;% slice(1:10)\r\nggplot(team_post, aes(reorder(team, post_mean), post_mean)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = lo90, ymax = hi90), width = 0.2) +\n  coord_flip() +\n  scale_y_continuous(labels = percent_format(accuracy = 0.1)) +\n  labs(\n    title = \"Team Win Probability Posteriors (Beta-Binomial)\",\n    x = \"Team\",\n    y = \"Posterior mean (90% interval)\"\n  )</pre>\n<h3>5.2 Betting with uncertainty (posterior sampling)</h3>\n<p>\n    Instead of using a single probability, sample from the posterior and compute EV distribution.\n    This helps you avoid betting when your edge is too uncertain.\n  </p>\n<pre># Suppose you want to bet Team X at odds d\nteam_x &lt;- team_post$team[1]\nd &lt;- 1.95\n\na &lt;- team_post$a[team_post$team == team_x]\nb &lt;- team_post$b[team_post$team == team_x]\n\np_draws &lt;- rbeta(20000, a, b)\nev_draws &lt;- ev_decimal(p_draws, d)\n\nquantile(ev_draws, c(0.05, 0.5, 0.95))\r\n# Probability that EV is positive (posterior probability of an edge)\nmean(ev_draws &gt; 0)</pre>\n<p>\n    A simple rule: only bet if <code>P(EV &gt; 0)</code> exceeds a threshold (e.g., 0.6 or 0.7).\n    That’s a Bayesian risk control.\n  </p>\n<hr/>\n<h2 id=\"sequential\">6. Sequential Updating: Learning Over Time (Online Bayesian Updating)</h2>\n<p>\n    Betting systems are online systems. Your beliefs should update as games happen.\n    Beta-Binomial makes this trivial.\n  </p>\n<pre>update_beta &lt;- function(a, b, y) {\n  # y is 1 for win, 0 for loss\n  c(a = a + y, b = b + (1 - y))\n}\n\nsequential_posterior &lt;- function(y, a0 = 8, b0 = 8) {\n  a &lt;- a0; b &lt;- b0\n  out &lt;- vector(\"list\", length(y))\n  for (i in seq_along(y)) {\n    ab &lt;- update_beta(a, b, y[i])\n    a &lt;- ab[\"a\"]; b &lt;- ab[\"b\"]\n    out[[i]] &lt;- c(\n      i = i,\n      a = a, b = b,\n      mean = a/(a+b),\n      lo90 = qbeta(0.05, a, b),\n      hi90 = qbeta(0.95, a, b)\n    )\n  }\n  bind_rows(lapply(out, as_tibble_row))\n}\n\n# Pick one team and track posterior over time\nteam_pick &lt;- sample(unique(matches$team), 1)\ny_seq &lt;- matches %&gt;% filter(team == team_pick) %&gt;% arrange(date) %&gt;% pull(result)\n\nseq_df &lt;- sequential_posterior(y_seq, a0 = 8, b0 = 8) %&gt;%\n  mutate(team = team_pick)\n\nggplot(seq_df, aes(i, mean)) +\n  geom_line() +\n  geom_ribbon(aes(ymin = lo90, ymax = hi90), alpha = 0.2) +\n  scale_y_continuous(labels = percent_format(accuracy = 0.1)) +\n  labs(\n    title = paste(\"Sequential Posterior for\", team_pick),\n    x = \"Game index\",\n    y = \"Posterior mean (90% band)\"\n  )</pre>\n<hr/>\n<h2 id=\"shrinkage\">7. Shrinkage and Partial Pooling: Stabilizing Team/Player Estimates</h2>\n<p>\n    Raw win rates are noisy. Fully separate Beta posteriors help, but you can go further: estimate the prior from the league (Empirical Bayes),\n    then use it as a shrinkage prior for each team.\n  </p>\n<h3>7.1 Empirical Bayes prior fit (method-of-moments)</h3>\n<pre>fit_beta_mom &lt;- function(p_hat, w = NULL) {\n  # method of moments for Beta parameters\n  # p_hat: observed proportions, w optional weights (e.g., n games)\n  if (is.null(w)) w &lt;- rep(1, length(p_hat))\n\n  m &lt;- weighted.mean(p_hat, w)\n  v &lt;- weighted.mean((p_hat - m)^2, w)\n\n  # clamp variance to avoid weirdness\n  v &lt;- max(v, 1e-6)\n\n  # Beta variance: m(1-m)/(a+b+1)\n  t &lt;- m*(1-m)/v - 1\n  a &lt;- max(0.5, m*t)\n  b &lt;- max(0.5, (1-m)*t)\n  c(a = a, b = b)\n}\n\np_hat &lt;- team_stats$k / team_stats$n\nprior_ab &lt;- fit_beta_mom(p_hat, w = team_stats$n)\nprior_ab\r\na0 &lt;- prior_ab[\"a\"]\nb0 &lt;- prior_ab[\"b\"]\n\nteam_post_eb &lt;- team_stats %&gt;%\n  mutate(\n    a = a0 + k,\n    b = b0 + (n - k),\n    post_mean = a/(a+b),\n    lo90 = qbeta(0.05, a, b),\n    hi90 = qbeta(0.95, a, b)\n  ) %&gt;%\n  arrange(desc(post_mean))\n\n# Compare naive sample rates vs EB posterior means\ncompare_df &lt;- team_stats %&gt;%\n  mutate(sample_rate = k/n) %&gt;%\n  left_join(team_post_eb %&gt;% select(team, post_mean), by = \"team\") %&gt;%\n  pivot_longer(cols = c(sample_rate, post_mean), names_to = \"type\", values_to = \"p\")\n\nggplot(compare_df, aes(p, fill = type)) +\n  geom_histogram(bins = 20, alpha = 0.6, position = \"identity\") +\n  labs(\n    title = \"Shrinkage Effect: Sample Rates vs EB Posterior Means\",\n    x = \"Probability\",\n    y = \"Count\"\n  )</pre>\n<p>\n    Shrinkage reduces overreaction to small samples—one of the most common reasons betting systems look great in backtests and fail live.\n  </p>\n<hr/>\n<h2 id=\"logistic\">8. Bayesian Logistic Models: Match Win Probabilities from Features</h2>\n<p>\n    Team strength depends on context: home advantage, rest, injuries, travel, matchups, and more.\n    Logistic regression is a natural model for win probabilities. Bayesian logistic regression adds regularization and uncertainty.\n  </p>\n<p>\n    We’ll create a few simple features from our toy data. In real projects you’d engineer better predictors.\n  </p>\n<pre># Simple feature engineering (toy)\n# Use rolling win rate as a proxy strength feature (in real data: Elo, xG, etc.)\nmatches_feat &lt;- matches %&gt;%\n  arrange(date) %&gt;%\n  group_by(team) %&gt;%\n  mutate(\n    games_played = row_number() - 1,\n    roll_winrate = ifelse(games_played == 0, NA_real_,\n                          cummean(lag(result)))\n  ) %&gt;%\n  ungroup() %&gt;%\n  mutate(\n    roll_winrate = ifelse(is.na(roll_winrate), mean(result), roll_winrate),\n    # center features\n    roll_winrate_c = roll_winrate - mean(roll_winrate),\n    home_c = home - mean(home)\n  )\n\n# Train-test split by time (avoid leakage)\ncut_date &lt;- quantile(matches_feat$date, 0.8)\ntrain &lt;- matches_feat %&gt;% filter(date &lt;= cut_date)\ntest  &lt;- matches_feat %&gt;% filter(date &gt;  cut_date)\n\nnrow(train); nrow(test)\r\n# Bayesian logistic regression\n# Note: rstanarm can be slower. For a big dataset, adjust iter/chains or use variational inference elsewhere.\nfit_bayes_logit &lt;- stan_glm(\n  result ~ home_c + roll_winrate_c,\n  data = train,\n  family = binomial(link = \"logit\"),\n  prior = normal(location = 0, scale = 1, autoscale = TRUE),\n  prior_intercept = normal(0, 2.5),\n  chains = 2,\n  iter = 800,\n  refresh = 0\n)\n\nprint(fit_bayes_logit)\r\n# Posterior predictive probabilities on test\np_test &lt;- posterior_linpred(fit_bayes_logit, newdata = test, transform = TRUE)\n# p_test is draws x observations; take posterior mean probability\np_hat &lt;- colMeans(p_test)\n\ntest_pred &lt;- test %&gt;%\n  mutate(p_model = p_hat)\n\ntest_pred %&gt;%\n  summarise(\n    mean_p = mean(p_model),\n    mean_y = mean(result)\n  )</pre>\n<hr/>\n<h2 id=\"rating\">9. Ratings as Priors: Elo with Uncertainty and Bayesian Flavor</h2>\n<p>\n    Elo is a practical rating system that translates team strength differences into win probabilities.\n    It’s not “Bayesian” in a strict sense, but it behaves like a sequential updating scheme and can be combined with Bayesian ideas.\n  </p>\n<h3>9.1 Simple Elo implementation in R</h3>\n<pre>elo_update &lt;- function(Ra, Rb, y, k = 20) {\n  # y: 1 if A wins, 0 if B wins\n  Ea &lt;- 1 / (1 + 10^((Rb - Ra)/400))\n  Ra_new &lt;- Ra + k*(y - Ea)\n  Rb_new &lt;- Rb + k*((1 - y) - (1 - Ea))\n  c(Ra = Ra_new, Rb = Rb_new, Ea = Ea)\n}\n\nrun_elo &lt;- function(df, init = 1500, k = 20) {\n  teams &lt;- sort(unique(c(df$team, df$opponent)))\n  R &lt;- setNames(rep(init, length(teams)), teams)\n\n  out &lt;- vector(\"list\", nrow(df))\n  for (i in seq_len(nrow(df))) {\n    a &lt;- df$team[i]\n    b &lt;- df$opponent[i]\n    y &lt;- df$result[i]\n\n    upd &lt;- elo_update(R[a], R[b], y, k = k)\n    R[a] &lt;- upd[\"Ra\"]\n    R[b] &lt;- upd[\"Rb\"]\n\n    out[[i]] &lt;- tibble(\n      date = df$date[i],\n      team = a,\n      opponent = b,\n      result = y,\n      elo_team = R[a],\n      elo_opp = R[b],\n      p_elo = upd[\"Ea\"]\n    )\n  }\n  bind_rows(out)\n}\n\nelo_df &lt;- run_elo(matches %&gt;% arrange(date), k = 18)\nelo_df %&gt;% slice(1:5)\r\n# Join Elo features back to matches\nmatches_elo &lt;- matches %&gt;%\n  arrange(date) %&gt;%\n  mutate(row_id = row_number()) %&gt;%\n  left_join(\n    elo_df %&gt;% mutate(row_id = row_number()) %&gt;% select(row_id, p_elo),\n    by = \"row_id\"\n  )\n\nsummary(matches_elo$p_elo)</pre>\n<p>\n    Elo probabilities can serve as baseline priors or features inside a Bayesian model. The key is to evaluate calibration and stability.\n  </p>\n<hr/>\n<h2 id=\"score-models\">10. Score Models: Poisson and Skellam for Totals and Spreads</h2>\n<p>\n    If you bet totals (Over/Under) or spreads, it’s helpful to model the score distribution.\n    A common starting point is Poisson scoring for each team:\n    <code>HomeGoals ~ Poisson(lambda_home)</code>, <code>AwayGoals ~ Poisson(lambda_away)</code>.\n    The goal difference follows a Skellam distribution (difference of two Poissons).\n  </p>\n<p>\n    We’ll simulate goals here to demonstrate the workflow. Replace this with real score data.\n  </p>\n<pre># Add synthetic goals to the toy dataset (for demonstration)\nadd_goals &lt;- function(df) {\n  # tie lambda to latent p_true to create plausible relationship\n  # this is just for tutorial purposes\n  base &lt;- 1.2\n  spread &lt;- (df$p_true - 0.5) * 2.0\n\n  lambda_home &lt;- pmax(0.2, base + 0.4 + spread)\n  lambda_away &lt;- pmax(0.2, base - 0.1 - spread)\n\n  df %&gt;%\n    mutate(\n      goals_team = rpois(n(), lambda_home),\n      goals_opp  = rpois(n(), lambda_away),\n      total_goals = goals_team + goals_opp,\n      goal_diff = goals_team - goals_opp\n    )\n}\n\nmatches_goals &lt;- add_goals(matches)\nsummary(matches_goals$total_goals)</pre>\n<h3>10.1 Fit simple Poisson regression for scoring rates</h3>\n<pre># Poisson model for \"team goals\" using simple predictors\n# In real data: team/opponent effects, home advantage, pace, etc.\ntrain_g &lt;- matches_goals %&gt;% filter(date &lt;= cut_date)\ntest_g  &lt;- matches_goals %&gt;% filter(date &gt;  cut_date)\n\nfit_pois &lt;- glm(\n  goals_team ~ home + p_true,\n  data = train_g,\n  family = poisson()\n)\n\nsummary(fit_pois)\r\n# Predict lambdas on test\nlambda_hat &lt;- predict(fit_pois, newdata = test_g, type = \"response\")\n\ntest_g2 &lt;- test_g %&gt;% mutate(lambda_team = lambda_hat)\n\nsummary(test_g2$lambda_team)</pre>\n<h3>10.2 Convert score distribution into market probabilities (totals/spreads)</h3>\n<p>\n    To price a total (e.g., Over 2.5), you need <code>P(Total &gt; 2.5)</code>.\n    If we model both sides as Poisson and independent, total is Poisson with rate <code>lambda_total = lambda_team + lambda_opp</code>.\n    Here we only have a team-goals model; we’ll create a companion lambda for opponent for the demo.\n  </p>\n<pre># Companion opponent lambda (toy)\nfit_pois_opp &lt;- glm(\n  goals_opp ~ home + p_true,\n  data = train_g,\n  family = poisson()\n)\n\ntest_g2 &lt;- test_g2 %&gt;%\n  mutate(lambda_opp = predict(fit_pois_opp, newdata = test_g2, type = \"response\"),\n         lambda_total = lambda_team + lambda_opp)\n\n# Price Over 2.5\np_over_25 &lt;- 1 - ppois(2, lambda = test_g2$lambda_total)\nsummary(p_over_25)\r\n# Example: bet Over 2.5 at decimal odds 1.95\nd_over &lt;- 1.95\nev_over &lt;- ev_decimal(p_over_25, d_over)\nsummary(ev_over)\nmean(ev_over &gt; 0)</pre>\n<hr/>\n<h2 id=\"calibration\">11. Probability Calibration: Brier, Log Loss, and Reliability Curves</h2>\n<p>\n    A betting system needs probabilities that mean what they say. If you claim 60% and you win 60% over time, that’s calibration.\n    Calibration is one of the best predictors that your edge is real rather than backtest noise.\n  </p>\n<h3>11.1 Brier score and log loss</h3>\n<pre>brier_score &lt;- function(y, p) mean((y - p)^2)\n\nlog_loss &lt;- function(y, p, eps = 1e-12) {\n  p &lt;- pmin(pmax(p, eps), 1 - eps)\n  -mean(y*log(p) + (1-y)*log(1-p))\n}\n\nbrier &lt;- brier_score(test_pred$result, test_pred$p_model)\nll &lt;- log_loss(test_pred$result, test_pred$p_model)\nc(brier = brier, logloss = ll)</pre>\n<h3>11.2 Reliability curve (calibration plot)</h3>\n<pre>reliability_curve &lt;- function(y, p, bins = 10) {\n  tibble(y = y, p = p) %&gt;%\n    mutate(bin = ntile(p, bins)) %&gt;%\n    group_by(bin) %&gt;%\n    summarise(\n      p_mean = mean(p),\n      y_mean = mean(y),\n      n = n(),\n      .groups = \"drop\"\n    )\n}\n\nrc &lt;- reliability_curve(test_pred$result, test_pred$p_model, bins = 12)\n\nggplot(rc, aes(p_mean, y_mean, size = n)) +\n  geom_point(alpha = 0.8) +\n  geom_abline(slope = 1, intercept = 0, linetype = 2) +\n  scale_x_continuous(labels = percent_format(accuracy = 1)) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    title = \"Reliability Curve (Calibration)\",\n    x = \"Predicted probability (bin mean)\",\n    y = \"Observed frequency\",\n    size = \"Count\"\n  )</pre>\n<p>\n    If your points drift above the diagonal, you’re underconfident; below it, overconfident. Both can destroy Kelly sizing.\n  </p>\n<hr/>\n<h2 id=\"kelly\">12. Kelly Logic: Optimal Growth, Fractional Kelly, and Practical Constraints</h2>\n<p>\n    Kelly sizing maximizes long-run logarithmic bankroll growth <em>if</em> your probabilities are correct.\n    In real life, probabilities are noisy—so full Kelly can be too aggressive. Fractional Kelly is often the sweet spot.\n  </p>\n<h3>12.1 Kelly fraction for decimal odds</h3>\n<pre>p &lt;- 0.55\nd &lt;- 2.05\n\nf_k &lt;- kelly_fraction_decimal(p, d)\nf_k\r\n# Fractional Kelly (e.g., half Kelly)\nfractional_kelly &lt;- function(f, frac = 0.5) frac * f\n\nf_half &lt;- fractional_kelly(f_k, 0.5)\n\n# Apply caps (never bet negative Kelly; cap max stake)\nf_bet &lt;- clip(f_half, 0, 0.05)\nf_bet</pre>\n<h3>12.2 Kelly with uncertainty (posterior integration)</h3>\n<p>\n    A Bayesian twist: rather than plug in a point estimate <code>p</code>, integrate over uncertainty by sampling from the posterior.\n    This yields a distribution for Kelly fraction and lets you bet conservatively (e.g., on a lower quantile).\n  </p>\n<pre>kelly_draws_decimal &lt;- function(p_draws, d) {\n  b &lt;- d - 1\n  q &lt;- 1 - p_draws\n  (b*p_draws - q)/b\n}\n\n# Example using the earlier Beta posterior (pick some a,b)\na &lt;- 25; b &lt;- 20\np_draws &lt;- rbeta(50000, a, b)\nd &lt;- 1.95\n\nf_draws &lt;- kelly_draws_decimal(p_draws, d)\n\nquantile(f_draws, c(0.05, 0.25, 0.5, 0.75, 0.95))\r\n# Conservative staking: use 25th percentile of Kelly, then apply fraction + cap\nf_cons &lt;- quantile(f_draws, 0.25)\nf_bet &lt;- clip(0.5 * f_cons, 0, 0.03)\nf_bet</pre>\n<p>\n    This is one of the most practical Bayesian risk controls: uncertainty shrinks position sizes automatically.\n  </p>\n<hr/>\n<h2 id=\"portfolio\">13. Portfolio Betting: Correlation, Market Clustering, and Exposure Controls</h2>\n<p>\n    Betting is rarely a sequence of independent wagers. Same league, same teams, same injury news—your bets can be correlated.\n    Correlation increases drawdowns and makes naive Kelly sizing too aggressive.\n  </p>\n<h3>13.1 A simple exposure constraint system</h3>\n<pre># Imagine we have candidate bets with:\n# date, market, team, p_model, odds_decimal, kelly_f\n\nmake_candidates &lt;- function(df, p_col = \"p_model\", odds_col = \"odds_decimal\") {\n  df %&gt;%\n    transmute(\n      date,\n      team,\n      opponent,\n      p = .data[[p_col]],\n      d = .data[[odds_col]],\n      ev = ev_decimal(p, d),\n      f_kelly = kelly_fraction_decimal(p, d)\n    ) %&gt;%\n    mutate(\n      f_half = 0.5 * f_kelly,\n      f_bet = clip(f_half, 0, 0.03)\n    )\n}\n\n# For demo, use test_pred probabilities against the odds in matches\ncandidates &lt;- test_pred %&gt;%\n  mutate(p_model = p_model, odds_decimal = odds_decimal) %&gt;%\n  make_candidates()\n\nsummary(candidates$f_bet)\nsummary(candidates$ev)\r\n# Portfolio constraints:\n# - Max stake per day\n# - Max stake per team\n# - Only bet when EV &gt; 0 and Kelly &gt; 0\n\napply_constraints &lt;- function(df, max_daily = 0.08, max_team = 0.05) {\n  df %&gt;%\n    filter(ev &gt; 0, f_bet &gt; 0) %&gt;%\n    arrange(desc(ev)) %&gt;%\n    group_by(date) %&gt;%\n    mutate(\n      daily_cum = cumsum(f_bet),\n      f_bet_day = ifelse(daily_cum &lt;= max_daily, f_bet, 0)\n    ) %&gt;%\n    ungroup() %&gt;%\n    group_by(team) %&gt;%\n    mutate(\n      team_cum = cumsum(f_bet_day),\n      f_bet_final = ifelse(team_cum &lt;= max_team, f_bet_day, 0)\n    ) %&gt;%\n    ungroup()\n}\n\nbets_planned &lt;- apply_constraints(candidates, max_daily = 0.08, max_team = 0.05)\n\nbets_planned %&gt;%\n  summarise(\n    n_candidates = n(),\n    n_bets = sum(f_bet_final &gt; 0),\n    avg_stake = mean(f_bet_final[f_bet_final &gt; 0]),\n    total_stake = sum(f_bet_final)\n  )</pre>\n<p>\n    This looks simple, but constraints are often the difference between a backtest hero and a live survivor.\n  </p>\n<hr/>\n<h2 id=\"strategies\">14. Concrete Betting Strategies: From Simple Rules to Model-Driven Systems</h2>\n<p>\n    Below are practical strategies you can implement. None is “magic.” The point is to define rules, measure them, and iterate.\n  </p>\n<h3>14.1 Strategy A: Simple value betting (probability edge threshold)</h3>\n<pre>strategy_value_threshold &lt;- function(df, edge_min = 0.02) {\n  df %&gt;%\n    mutate(\n      p_be = 1/d,\n      edge = p - p_be\n    ) %&gt;%\n    filter(edge &gt;= edge_min) %&gt;%\n    mutate(\n      f_bet = clip(0.5 * kelly_fraction_decimal(p, d), 0, 0.03)\n    )\n}\n\nbets_A &lt;- candidates %&gt;% strategy_value_threshold(edge_min = 0.02)\nsummary(bets_A$f_bet)</pre>\n<h3>14.2 Strategy B: Bayesian “probability of positive EV” gate</h3>\n<p>\n    If you can produce a posterior distribution for <code>p</code>, you can compute <code>P(EV &gt; 0)</code>.\n    We’ll demonstrate using a Beta posterior for each team’s win rate as a crude uncertainty model.\n  </p>\n<pre># Build EB Beta posteriors from the training window\nteam_train &lt;- matches %&gt;% filter(date &lt;= cut_date) %&gt;%\n  group_by(team) %&gt;%\n  summarise(n = n(), k = sum(result), .groups = \"drop\")\n\np_hat_train &lt;- team_train$k / team_train$n\nprior_ab &lt;- fit_beta_mom(p_hat_train, w = team_train$n)\na0 &lt;- prior_ab[\"a\"]; b0 &lt;- prior_ab[\"b\"]\n\nteam_params &lt;- team_train %&gt;%\n  mutate(a = a0 + k, b = b0 + (n - k)) %&gt;%\n  select(team, a, b)\n\n# Attach team posterior params to candidates\ncand_B &lt;- candidates %&gt;%\n  left_join(team_params, by = \"team\")\n\nprob_ev_positive_beta &lt;- function(a, b, d, n_draws = 10000) {\n  p_draws &lt;- rbeta(n_draws, a, b)\n  mean(ev_decimal(p_draws, d) &gt; 0)\n}\n\ncand_B2 &lt;- cand_B %&gt;%\n  mutate(\n    p_ev_pos = pmap_dbl(list(a, b, d), ~prob_ev_positive_beta(..1, ..2, ..3, n_draws = 6000)),\n    f_bet = clip(0.5 * kelly_fraction_decimal(p, d), 0, 0.03)\n  )\n\nbets_B &lt;- cand_B2 %&gt;% filter(p_ev_pos &gt;= 0.65, ev &gt; 0, f_bet &gt; 0)\n\nbets_B %&gt;%\n  summarise(n_bets = n(), mean_p_ev_pos = mean(p_ev_pos), mean_ev = mean(ev), mean_f = mean(f_bet))</pre>\n<h3>14.3 Strategy C: Calibrated model + fractional Kelly + caps</h3>\n<pre># If you have a calibrated model probability p_model,\n# apply fractional Kelly and cap. Also: require minimal EV.\nstrategy_fractional_kelly &lt;- function(df, ev_min = 0.01, frac = 0.5, cap = 0.03) {\n  df %&gt;%\n    mutate(\n      f_k = kelly_fraction_decimal(p, d),\n      f_bet = clip(frac * f_k, 0, cap)\n    ) %&gt;%\n    filter(ev &gt;= ev_min, f_bet &gt; 0)\n}\n\nbets_C &lt;- candidates %&gt;% strategy_fractional_kelly(ev_min = 0.01, frac = 0.35, cap = 0.025)\nbets_C %&gt;% summarise(n_bets = n(), mean_ev = mean(ev), mean_f = mean(f_bet))</pre>\n<hr/>\n<h2 id=\"backtesting\">15. Backtesting in R: Walk-forward, Leakage Prevention, and Metrics</h2>\n<p>\n    Most betting “edges” vanish when you backtest properly. Your backtest must be time-respecting (walk-forward),\n    must avoid target leakage, and must include realistic constraints (limits, stake caps, minimum odds, etc.).\n  </p>\n<h3>15.1 A minimal bet settlement engine</h3>\n<pre>settle_bets &lt;- function(df, bankroll0 = 1.0) {\n  # df must have: result (1/0), d (decimal odds), f_bet (fraction of bankroll)\n  bankroll &lt;- bankroll0\n  out &lt;- vector(\"list\", nrow(df))\n\n  for (i in seq_len(nrow(df))) {\n    stake &lt;- bankroll * df$f_bet[i]\n    if (stake &lt;= 0) {\n      out[[i]] &lt;- tibble(i = i, bankroll = bankroll, stake = 0, pnl = 0)\n      next\n    }\n\n    pnl &lt;- if (df$result[i] == 1) stake * (df$d[i] - 1) else -stake\n    bankroll &lt;- bankroll + pnl\n\n    out[[i]] &lt;- tibble(i = i, bankroll = bankroll, stake = stake, pnl = pnl)\n  }\n\n  bind_cols(df, bind_rows(out))\n}\n\n# Example: settle Strategy C bets (in arbitrary order; ideally sort by date)\nbt_C &lt;- bets_C %&gt;%\n  mutate(result = test_pred$result[match(paste(date, team, opponent), paste(test_pred$date, test_pred$team, test_pred$opponent))]) %&gt;%\n  arrange(date) %&gt;%\n  select(date, team, opponent, result, d, f_bet)\n\nbt_C2 &lt;- settle_bets(bt_C, bankroll0 = 1.0)\n\ntail(bt_C2)</pre>\n<h3>15.2 Performance metrics</h3>\n<pre>compute_metrics &lt;- function(df) {\n  df %&gt;%\n    summarise(\n      n_bets = sum(stake &gt; 0),\n      final_bankroll = last(bankroll),\n      total_pnl = sum(pnl),\n      roi_on_staked = ifelse(sum(stake) &gt; 0, sum(pnl)/sum(stake), NA_real_),\n      hit_rate = mean(result[stake &gt; 0] == 1),\n      avg_odds = mean(d[stake &gt; 0]),\n      max_drawdown = {\n        peak &lt;- cummax(bankroll)\n        dd &lt;- bankroll/peak - 1\n        min(dd)\n      }\n    )\n}\n\ncompute_metrics(bt_C2)\r\n# Plot bankroll curve\nggplot(bt_C2, aes(date, bankroll)) +\n  geom_line() +\n  labs(\n    title = \"Backtest Bankroll Curve (Strategy C)\",\n    x = \"Date\",\n    y = \"Bankroll\"\n  )</pre>\n<h3>15.3 Walk-forward template</h3>\n<p>\n    Below is a simple walk-forward skeleton: refit model on an expanding window, predict the next chunk, generate bets, settle, repeat.\n    Replace the “model” section with your real pipeline.\n  </p>\n<pre>walk_forward &lt;- function(df, initial_frac = 0.6, step_frac = 0.1) {\n  df &lt;- df %&gt;% arrange(date)\n  n &lt;- nrow(df)\n\n  idx0 &lt;- floor(initial_frac * n)\n  step &lt;- floor(step_frac * n)\n\n  start &lt;- idx0\n  bankroll &lt;- 1.0\n  all_bets &lt;- list()\n\n  while (start &lt; n) {\n    train_idx &lt;- 1:start\n    test_idx &lt;- (start + 1):min(n, start + step)\n\n    train &lt;- df[train_idx, ]\n    test  &lt;- df[test_idx, ]\n\n    # --- Model (placeholder) ---\n    # simple baseline: probability = historical mean adjusted by home\n    p0 &lt;- mean(train$result)\n    p_hat &lt;- clip(p0 + 0.03*(test$home - mean(train$home)), 0.02, 0.98)\n\n    cand &lt;- test %&gt;%\n      transmute(\n        date, team, opponent,\n        result,\n        p = p_hat,\n        d = odds_decimal\n      ) %&gt;%\n      mutate(\n        ev = ev_decimal(p, d),\n        f_bet = clip(0.35 * kelly_fraction_decimal(p, d), 0, 0.02)\n      ) %&gt;%\n      filter(ev &gt; 0.01, f_bet &gt; 0)\n\n    # Settle on this chunk\n    if (nrow(cand) &gt; 0) {\n      settled &lt;- settle_bets(cand, bankroll0 = bankroll)\n      bankroll &lt;- last(settled$bankroll)\n      all_bets[[length(all_bets) + 1]] &lt;- settled\n    }\n\n    start &lt;- start + step\n  }\n\n  bind_rows(all_bets)\n}\n\nwf_bt &lt;- walk_forward(matches)\ncompute_metrics(wf_bt)</pre>\n<hr/>\n<h2 id=\"montecarlo\">16. Monte Carlo Stress Tests: Drawdowns, Ruin, and Regret</h2>\n<p>\n    Backtests are one path. Stress tests are another. Monte Carlo simulation answers:\n    “If my estimated edge is real but noisy, what drawdowns should I expect?”\n  </p>\n<h3>16.1 Simulate a season of bets with uncertainty around p</h3>\n<pre>simulate_betting_path &lt;- function(n_bets = 500, p = 0.54, d = 1.95, f = 0.01, bankroll0 = 1) {\n  bankroll &lt;- bankroll0\n  for (i in 1:n_bets) {\n    stake &lt;- bankroll * f\n    win &lt;- rbinom(1, 1, p)\n    pnl &lt;- if (win == 1) stake*(d - 1) else -stake\n    bankroll &lt;- bankroll + pnl\n  }\n  bankroll\n}\n\n# Many simulations\nsim_paths &lt;- replicate(5000, simulate_betting_path(n_bets = 400, p = 0.53, d = 1.95, f = 0.012))\nquantile(sim_paths, c(0.05, 0.25, 0.5, 0.75, 0.95))</pre>\n<h3>16.2 Incorporate probability error (model risk)</h3>\n<p>\n    Your <code>p_hat</code> is not the true <code>p</code>. Model risk is often larger than market risk.\n    We simulate true p drifting around your estimate.\n  </p>\n<pre>simulate_with_model_error &lt;- function(n_bets = 500, p_hat = 0.54, p_sd = 0.03, d = 1.95, f = 0.01, bankroll0 = 1) {\n  bankroll &lt;- bankroll0\n  for (i in 1:n_bets) {\n    p_true &lt;- clip(rnorm(1, p_hat, p_sd), 0.01, 0.99)\n    stake &lt;- bankroll * f\n    win &lt;- rbinom(1, 1, p_true)\n    pnl &lt;- if (win == 1) stake*(d - 1) else -stake\n    bankroll &lt;- bankroll + pnl\n  }\n  bankroll\n}\n\nsim2 &lt;- replicate(5000, simulate_with_model_error(n_bets = 400, p_hat = 0.53, p_sd = 0.05, d = 1.95, f = 0.012))\nquantile(sim2, c(0.05, 0.25, 0.5, 0.75, 0.95))\r\n# Compare distributions\ndf_sim &lt;- tibble(\n  bankroll = c(sim_paths, sim2),\n  scenario = rep(c(\"no_model_error\", \"with_model_error\"), each = length(sim_paths))\n)\n\nggplot(df_sim, aes(bankroll)) +\n  geom_histogram(bins = 50) +\n  facet_wrap(~scenario, scales = \"free_y\") +\n  labs(\n    title = \"Monte Carlo Bankroll Distribution\",\n    x = \"Final bankroll\",\n    y = \"Count\"\n  )</pre>\n<p>\n    If model error collapses your distribution, reduce Kelly fraction, add EV thresholds, and improve calibration.\n  </p>\n<hr/>\n<h2 id=\"checklist\">17. A Go-Live Checklist: Operational and Statistical Guardrails</h2>\n<ul>\n<li><strong>Time split always</strong>: train only on past, predict future.</li>\n<li><strong>Log everything</strong>: inputs, odds, timestamps, model version, decisions, stakes.</li>\n<li><strong>Calibrate probabilities</strong>: reliability curves, Brier, log loss.</li>\n<li><strong>Respect uncertainty</strong>: use posterior bands or conservative probability adjustments.</li>\n<li><strong>Size bets defensively</strong>: fractional Kelly + caps + daily exposure limits.</li>\n<li><strong>Account for correlation</strong>: cluster exposures by league/team/news.</li>\n<li><strong>Stress-test</strong>: Monte Carlo with model error, not just “true p”.</li>\n<li><strong>Beware selection bias</strong>: strategies discovered by brute force often overfit.</li>\n<li><strong>Prefer stability</strong>: smaller edge + stable behavior beats fragile high edge.</li>\n</ul>\n<hr/>\n<h2 id=\"recommended-reading\">Recommended Reading</h2>\n<p>\n  If you’d like a more structured, code-heavy continuation of these ideas (Bayesian probabilities, EV, and Kelly-based sizing),\n  you can find it here:\n  <a href=\"https://rprogrammingbooks.com/product/bayesian-sports-betting-with-r/\" rel=\"nofollow\" target=\"_blank\">Bayesian Sports Betting with R</a>.\n</p>\n</div>\n<p>The post <a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/\" rel=\"nofollow\" target=\"_blank\">Designing Sports Betting Systems in R: Bayesian Probabilities, Expected Value, and Kelly Logic</a> appeared first on <a href=\"https://rprogrammingbooks.com/\" rel=\"nofollow\" target=\"_blank\">R Programming Books</a>.</p>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=designing-sports-betting-systems-in-r\"> Blog - R Programming Books</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div> </div>\n</article>",
    "word_count": 4757,
    "reading_time_min": 23.8,
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/rprogrammingbooks/",
        "text": "rprogrammingbooks"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "external_links": [
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r",
        "text": "Blog - R Programming Books"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#setup",
        "text": "1. Setup: Packages, Data Schemas, and Conventions"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#odds",
        "text": "2. Odds and Probability: Conversions, Vig (Overround), and Fair Prices"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#ev",
        "text": "3. Expected Value: Break-even Probability, Edge, and Sensitivity"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#bayes-foundations",
        "text": "4. Bayesian Foundations for Betting: Priors, Posteriors, and Uncertainty"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#beta-binomial",
        "text": "5. Beta-Binomial Models: Bayesian Win Rates (Conjugate Bayes)"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#sequential",
        "text": "6. Sequential Updating: Learning Over Time (Online Bayesian Updating)"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#shrinkage",
        "text": "7. Shrinkage and Partial Pooling: Stabilizing Team/Player Estimates"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#logistic",
        "text": "8. Bayesian Logistic Models: Match Win Probabilities from Features"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#rating",
        "text": "9. Ratings as Priors: Elo with Uncertainty and Bayesian Flavor"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#score-models",
        "text": "10. Score Models: Poisson and Skellam for Totals and Spreads"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#calibration",
        "text": "11. Probability Calibration: Brier, Log Loss, and Reliability Curves"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#kelly",
        "text": "12. Kelly Logic: Optimal Growth, Fractional Kelly, and Practical Constraints"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#portfolio",
        "text": "13. Portfolio Betting: Correlation, Market Clustering, and Exposure Controls"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#strategies",
        "text": "14. Concrete Betting Strategies: From Simple Rules to Model-Driven Systems"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#backtesting",
        "text": "15. Backtesting in R: Walk-forward, Leakage Prevention, and Metrics"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#montecarlo",
        "text": "16. Monte Carlo Stress Tests: Drawdowns, Ruin, and Regret"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#checklist",
        "text": "17. A Go-Live Checklist: Operational and Statistical Guardrails"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r#recommended-reading",
        "text": "Recommended Reading"
      },
      {
        "href": "https://rprogrammingbooks.com/product/bayesian-sports-betting-with-r/",
        "text": "Bayesian Sports Betting with R"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/",
        "text": "Designing Sports Betting Systems in R: Bayesian Probabilities, Expected Value, and Kelly Logic"
      },
      {
        "href": "https://rprogrammingbooks.com/",
        "text": "R Programming Books"
      },
      {
        "href": "https://rprogrammingbooks.com/designing-sports-betting-systems-in-r/?utm_source=rss&utm_medium=rss&utm_campaign=designing-sports-betting-systems-in-r",
        "text": "Blog - R Programming Books"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "images": [],
    "lang": "en-US",
    "crawled_at_utc": "2026-02-02T05:58:25Z"
  }
}