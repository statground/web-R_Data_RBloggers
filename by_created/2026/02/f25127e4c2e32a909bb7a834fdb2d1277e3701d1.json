{
  "id": "f25127e4c2e32a909bb7a834fdb2d1277e3701d1",
  "url": "https://www.r-bloggers.com/2026/02/software-review-in-the-era-of-ai-what-we-are-testing-at-ropensci/",
  "created_at_utc": "2026-02-26T15:44:49Z",
  "crawled_at_utc": "2026-02-26T15:44:49Z",
  "html_title": "Software Review in the Era of AI: What We Are Testing at rOpenSci | R-bloggers",
  "meta_description": "The advent of large language models (LLMs) and generative AI tools has changed the nature of software development and of software review. These developments are complex, challenging, and controversial, but require action to maintain and grow rOpenSci&...",
  "data": {
    "url": "https://www.r-bloggers.com/2026/02/software-review-in-the-era-of-ai-what-we-are-testing-at-ropensci/",
    "canonical_url": "https://www.r-bloggers.com/2026/02/software-review-in-the-era-of-ai-what-we-are-testing-at-ropensci/",
    "html_title": "Software Review in the Era of AI: What We Are Testing at rOpenSci | R-bloggers",
    "h1_title": "R-bloggers",
    "meta_description": "The advent of large language models (LLMs) and generative AI tools has changed the nature of software development and of software review. These developments are complex, challenging, and controversial, but require action to maintain and grow rOpenSci&...",
    "meta_keywords": null,
    "og_title": "Software Review in the Era of AI: What We Are Testing at rOpenSci | R-bloggers",
    "og_description": "The advent of large language models (LLMs) and generative AI tools has changed the nature of software development and of software review. These developments are complex, challenging, and controversial, but require action to maintain and grow rOpenSci&...",
    "og_image": "https://www.r-bloggers.com/wp-content/uploads/2016/04/R_02_2016-05-01.png",
    "twitter_title": "Software Review in the Era of AI: What We Are Testing at rOpenSci | R-bloggers",
    "twitter_description": "The advent of large language models (LLMs) and generative AI tools has changed the nature of software development and of software review. These developments are complex, challenging, and controversial, but require action to maintain and grow rOpenSci&...",
    "raw_jsonld_article": null,
    "article_headline": null,
    "article_section": null,
    "article_tags": null,
    "article_author": null,
    "article_published": null,
    "article_modified": null,
    "main_text": "Software Review in the Era of AI: What We Are Testing at rOpenSci\nPosted on\nFebruary 25, 2026\nby\nrOpenSci - open tools for open science\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nrOpenSci - open tools for open science\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nThe advent of large language models (LLMs) and generative AI tools has changed the nature of software development and of software review.\nThese developments are complex, challenging, and controversial, but require action to maintain and grow rOpenSci’s programs and community.\nIn response, we are starting with a preliminary set of policies to clarify our expectations for use of generative AI tools by authors, reviewers, and editors in software peer-review.\nThis blog post describes the challenges ahead and initial changes we are making.\nChallenge: Maintaining our core values\nOur top challenge is maintaining our core values.\nA central value for rOpenSci is fostering a welcoming community, in particular through supporting and encouraging people who might otherwise feel excluded. Generative AI tools can help with that.\nLarge language models and generative AI tools may make many coding tasks easier and quicker, and can expand the community of people able to contribute to open source software and the OSS community.\nYet there are many downsides to generative AI tools which challenge our core values. pyOpenSci has done an excellent job\nexploring these in this blog post\n.\nThey fall into two broad areas.\nFirst, use of AI can in many cases degrade the quality of both open-source scientific code and the process by which we create it.\nLLMs can in many cases produce incorrect outputs, fail to generate time or efficiency benefits, or degrade the process of learning to code or the social cohesion of the community.\nA core design of our software peer-review is to drive community building through healthy interactions between authors, reviewers, and contributors.\nWe aim to improve and promote the quality of research software, to facilitate good development practices among researchers, to foster collaboration, and to curate a community of practice.\nAny use of AI must be compatible with that goal.\nSecond, AI has the potential for tremendous broader impacts or externalities: environmental impacts, amplification of bias, infringement of creative and intellectual rights, or even driving increases in\nsocial and economic inequality\n.\nWe have both collective and individual responsibilities to address these impacts, which include the right to opt out of uses of AI.\nChallenge: Changing the focus of software reviews\nEditors and reviewers at rOpenSci are volunteers who devote their own time to help others improve the quality of their software.\nOur review system works because they have always been able to assume that all aspects of code submitted for review have reflected decisions made by the human authors of software.\nThat, in turn, has ensured that the efforts of editors and reviewers are proportional to the primary efforts of software authors.\nGenerative AI tools potentially change both of these situations.\nThey enable software to be produced with relatively little human input or oversight, which means editors and reviewers may put more consideration into software design, structure, and function than submitting authors.\nWe do not want software review to become a service in which our human volunteers validate largely AI-generated software.\nThat would put at risk the equal and constructive interaction of review, and likely reduce the motivation of editors and reviewers.\nWe need to ensure that our software review process remains focused on the decisions, designs, and implementations of the submitting authors.\nOne option is requesting authors to outline the areas that have been AI generated, and specifying the scope of their own work.\nHowever, this could result in our previously holistic process becoming one where only defined aspects or sections of software end up being reviewed.\nAuthors declaring that a certain tool was used to generate all tests may lead one reviewer to completely ignore those tests, while another reviewer may be passionately engaged in the ways by which exactly that tool writes tests.\nIn any case, this will require everybody to be as open as possible about what, where, and how generative AI tools may have been used.\nResponse: Preliminary policies\nOur initial policy updates are not intended to restrict use of generative AI tools, but to encourage the rOpenSci community to approach these tools in ways that encourage, rather than diminish, healthy community interactions.\nSimilar updates have already been implemented by both the\nJournal of Open Source Software\nand\npyOpenSci\n, and we are indebted to the work of all those who contributed to these policy statements.\nImportantly, our software review policies and practices have evolved over many years in response to community engagement and feedback.\nThe introduction of policies addressing generative AI tools is a part of that evolution, and these policies will also evolve further in responses to community engagement, and changing community practices.\nNo change in scope\nOne potential response would be a change in the scope of packages we review.\nJOSS has updated their\nscope definition\nto, among other things, require a longer record of continuous development, along with other criteria, such as evidence of impact and design.\nAt rOpenSci, authors often seek feedback on early-stage software.\nOur review process commonly involves deep and broad consideration through extensive exchanges between authors, reviewers, and editors.\nWe are confident that this extends to many of the areas emphasized by JOSS’s updated criteria, and we therefore see no need to explicitly change either the scope or focus of review.\nRequiring openness of AI usage\nOur policy updates aim to retain the same degree of openness and transparency we have always practiced, while extending to the new area of generative AI tools and practices.\nWe cannot know the eventual impact that generative AI tools may have on software review processes and practices at rOpenSci, and can ask only for an utmost degree of transparency from all involved.\nWe now describe specific updates to both our practices and policies for authors, for editors, and for reviewers.\nSoftware review aims to provide authors with feedback on their practices and choices, and not just on the lines of code they or an AI generated.\nWe also value the time and effort of editors and reviewers, and want them to be able to focus on the practices and choices of authors.\nPractical application: for authors\nAuthors who do not use generative AI tools will submit as always, with no extra requirements.\nThose who do use such tools will be asked to describe their use, and to affirm that all generated material has been carefully reviewed by the authors.\nWe want these descriptions to help reviewers and editors to understand how they can best review code and provide useful feedback.\nWe will be modifying our submission template to include this required section, and will be updating the\nGuide for Authors\nwith additional guidance.\nA minimal example might be a statement that “we’re not very proficient in C, so we used an LLM to generate most of the code for the C algorithm.”\nThis might guide reviewers to pay particular attention to the tests for that part of the package.\nA more extensive description might be that, “We used\nto generate all tests, but have read, edited, and manually stepped through each test ourselves.”\nThis can help reviewers decide whether to pay more or less attention to the tests depending on their interests.\nEither way, knowing that tests were generated by AI tools is useful and important to the review process.\nDescriptions may refer to relevant documentation in the repository, such as:\nDesign documents which highlight key components and explain their design;\n“agents.md” or equivalent files, along with explanations of how these have been used, along with clear description of the roles of the submitting authors;\nOverviews of developmental histories, for example in “NEWS.md” or equivalent files.\nWe intend to maintain our requirement for “CONTRIBUTING.md” files, as any generative AI tools can also be directed to treat that as an “agents.md” file.\nThis is our intended addition to the templates for authors submitting software for review:\n## Use of Generative AI\n- [ ] Generative AI tools were used to produce some of the material in this submission.\nIf so, please describe: <!-- refer to our AI policies at http:// ... -->\nIf your repository includes an \"agents.md\" file or equivalent, please provide a link, and describe how this has been used in the development of your package.\nAn example of such a description can be found in this\nrecent software review submission\n.\nPractical application: for editors\nEditors are the first to view software submitted to rOpenSci, and generally complete an initial\nEditors checklist\nindicating whether they think a package may proceed to review.\nThis checklist will also include an additional item:\n- [ ] **Use of generative AI tools**: If the authors have used generative AI tools, have they sufficiently described their usage?\nThis item will also require no additional action by editors unless authors have used generative AI tools.\nInitial editorial considerations have until now been largely technical, including many of the aspects now automated by\nour\npkgcheck\nsystem\n.\nIn response to this new checklist item, editors may broaden their consideration to whether a package has had sufficient human contribution to be worth reviewing, alongside considerations of additional factors such as:\nClear statements of package motivation and importance.\nPackage development history.\nEvidence of design decisions motivating the software.\nWhen recruiting reviewers for a package, editors may describe authors’ AI usage where relevant to help them understand the nature of the package and demands of review.\nPractical application: for reviewers\nReview processes at rOpenSci frequently involve reviewers recommending potential improvements, and authors then implementing those.\nIn adapting to use of generative AI tools, we will strive to maintain the same culture of constructive feedback.\nWe hope that authors will provide sufficient information on any use of generative AI tools to guide reviewers towards aspects of their software requiring particular attention.\nReviewers are permitted to use generative AI tools in preparing reviews for rOpenSci, but their use must meet the same criteria of supporting the goals of review.\nOur\nGuide for Reviewers\nwill be updated to note the following points:\nGenerative AI tools may be used to aid the review process, but all review text must reflect the judgement of the reviewer.\nTypical and acceptable use of generative AI tools in software review includes getting an overview of software design, structure, and function.\nUpdates to the\nGuide for Reviewers\nwill also include examples of productive use of generative AI tools in the review process.\nWe aim to run pilots over the course of this year to test where in the review process AI can best be used to improve everyone’s experience, and to provide more robust guidelines and custom tools.\nReviewers may also consider AI use in choosing whether to volunteer as a reviewer of a package, and authors should be aware that extensive AI use could increase the time to find reviewers.\nMoving forward\nThis is our first pass at providing guidelines governing the use of generative AI to ensure rOpenSci software review continues to improve while retaining its essential values.\nWith more package submissions having some component of AI contribution, the editorial board thought it essential to provide these updates to manage the process as we learn more about what works and what does not.\nWe invite you to further discuss the evolving role of AI in software review in\nthis issue\n, and more importantly to join us as an author or reviewer in peer review, so we can learn together!\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nrOpenSci - open tools for open science\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "main_html": "<article class=\"post-399330 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Software Review in the Era of AI: What We Are Testing at rOpenSci</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">February 25, 2026</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/ropensci-open-tools-for-open-science/\">rOpenSci - open tools for open science</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://ropensci.org/blog/2026/02/26/ropensci-ai-policy/\"> rOpenSci - open tools for open science</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<p>The advent of large language models (LLMs) and generative AI tools has changed the nature of software development and of software review.\nThese developments are complex, challenging, and controversial, but require action to maintain and grow rOpenSci’s programs and community.\nIn response, we are starting with a preliminary set of policies to clarify our expectations for use of generative AI tools by authors, reviewers, and editors in software peer-review.\nThis blog post describes the challenges ahead and initial changes we are making.</p>\n<h2>\nChallenge: Maintaining our core values\n</h2><p>Our top challenge is maintaining our core values.</p>\n<p>A central value for rOpenSci is fostering a welcoming community, in particular through supporting and encouraging people who might otherwise feel excluded. Generative AI tools can help with that.\nLarge language models and generative AI tools may make many coding tasks easier and quicker, and can expand the community of people able to contribute to open source software and the OSS community.</p>\n<p>Yet there are many downsides to generative AI tools which challenge our core values. pyOpenSci has done an excellent job <a href=\"https://www.pyopensci.org/blog/generative-ai-peer-review-policy.html\" rel=\"nofollow\" target=\"_blank\">exploring these in this blog post</a>.\nThey fall into two broad areas.</p>\n<p>First, use of AI can in many cases degrade the quality of both open-source scientific code and the process by which we create it.\nLLMs can in many cases produce incorrect outputs, fail to generate time or efficiency benefits, or degrade the process of learning to code or the social cohesion of the community.\nA core design of our software peer-review is to drive community building through healthy interactions between authors, reviewers, and contributors.\nWe aim to improve and promote the quality of research software, to facilitate good development practices among researchers, to foster collaboration, and to curate a community of practice.\nAny use of AI must be compatible with that goal.</p>\n<p>Second, AI has the potential for tremendous broader impacts or externalities: environmental impacts, amplification of bias, infringement of creative and intellectual rights, or even driving increases in <a href=\"https://pluralistic.net/2025/12/05/pop-that-bubble/#u-washington\" rel=\"nofollow\" target=\"_blank\">social and economic inequality</a>.\nWe have both collective and individual responsibilities to address these impacts, which include the right to opt out of uses of AI.</p>\n<h2>\nChallenge: Changing the focus of software reviews\n</h2><p>Editors and reviewers at rOpenSci are volunteers who devote their own time to help others improve the quality of their software.\nOur review system works because they have always been able to assume that all aspects of code submitted for review have reflected decisions made by the human authors of software.\nThat, in turn, has ensured that the efforts of editors and reviewers are proportional to the primary efforts of software authors.</p>\n<p>Generative AI tools potentially change both of these situations.\nThey enable software to be produced with relatively little human input or oversight, which means editors and reviewers may put more consideration into software design, structure, and function than submitting authors.\nWe do not want software review to become a service in which our human volunteers validate largely AI-generated software.\nThat would put at risk the equal and constructive interaction of review, and likely reduce the motivation of editors and reviewers.\nWe need to ensure that our software review process remains focused on the decisions, designs, and implementations of the submitting authors.</p>\n<p>One option is requesting authors to outline the areas that have been AI generated, and specifying the scope of their own work.\nHowever, this could result in our previously holistic process becoming one where only defined aspects or sections of software end up being reviewed.\nAuthors declaring that a certain tool was used to generate all tests may lead one reviewer to completely ignore those tests, while another reviewer may be passionately engaged in the ways by which exactly that tool writes tests.</p>\n<p>In any case, this will require everybody to be as open as possible about what, where, and how generative AI tools may have been used.</p>\n<h2>\nResponse: Preliminary policies\n</h2><p>Our initial policy updates are not intended to restrict use of generative AI tools, but to encourage the rOpenSci community to approach these tools in ways that encourage, rather than diminish, healthy community interactions.</p>\n<p>Similar updates have already been implemented by both the <a href=\"https://blog.joss.theoj.org/2026/01/preparing-joss-for-a-generative-ai-future\" rel=\"nofollow\" target=\"_blank\">Journal of Open Source Software</a> and <a href=\"https://www.pyopensci.org/blog/generative-ai-peer-review-policy.html\" rel=\"nofollow\" target=\"_blank\">pyOpenSci</a>, and we are indebted to the work of all those who contributed to these policy statements.</p>\n<p>Importantly, our software review policies and practices have evolved over many years in response to community engagement and feedback.\nThe introduction of policies addressing generative AI tools is a part of that evolution, and these policies will also evolve further in responses to community engagement, and changing community practices.</p>\n<h3>\nNo change in scope\n</h3><p>One potential response would be a change in the scope of packages we review.\nJOSS has updated their <a href=\"https://joss.theoj.org/about#ai-policy\" rel=\"nofollow\" target=\"_blank\">scope definition</a> to, among other things, require a longer record of continuous development, along with other criteria, such as evidence of impact and design.\nAt rOpenSci, authors often seek feedback on early-stage software.\nOur review process commonly involves deep and broad consideration through extensive exchanges between authors, reviewers, and editors.\nWe are confident that this extends to many of the areas emphasized by JOSS’s updated criteria, and we therefore see no need to explicitly change either the scope or focus of review.</p>\n<h3>\nRequiring openness of AI usage\n</h3><p>Our policy updates aim to retain the same degree of openness and transparency we have always practiced, while extending to the new area of generative AI tools and practices.\nWe cannot know the eventual impact that generative AI tools may have on software review processes and practices at rOpenSci, and can ask only for an utmost degree of transparency from all involved.</p>\n<p>We now describe specific updates to both our practices and policies for authors, for editors, and for reviewers.\nSoftware review aims to provide authors with feedback on their practices and choices, and not just on the lines of code they or an AI generated.\nWe also value the time and effort of editors and reviewers, and want them to be able to focus on the practices and choices of authors.</p>\n<h3>\nPractical application: for authors\n</h3><p>Authors who do not use generative AI tools will submit as always, with no extra requirements.\nThose who do use such tools will be asked to describe their use, and to affirm that all generated material has been carefully reviewed by the authors.\nWe want these descriptions to help reviewers and editors to understand how they can best review code and provide useful feedback.</p>\n<p>We will be modifying our submission template to include this required section, and will be updating the <a href=\"https://devguide.ropensci.org/softwarereview_author.html\" rel=\"nofollow\" target=\"_blank\">Guide for Authors</a> with additional guidance.</p>\n<p>A minimal example might be a statement that “we’re not very proficient in C, so we used an LLM to generate most of the code for the C algorithm.”\nThis might guide reviewers to pay particular attention to the tests for that part of the package.\nA more extensive description might be that, “We used <tool-of-choice> to generate all tests, but have read, edited, and manually stepped through each test ourselves.”\nThis can help reviewers decide whether to pay more or less attention to the tests depending on their interests.\nEither way, knowing that tests were generated by AI tools is useful and important to the review process.</tool-of-choice></p>\n<p>Descriptions may refer to relevant documentation in the repository, such as:</p>\n<ul>\n<li>Design documents which highlight key components and explain their design;</li>\n<li>“agents.md” or equivalent files, along with explanations of how these have been used, along with clear description of the roles of the submitting authors;</li>\n<li>Overviews of developmental histories, for example in “NEWS.md” or equivalent files.</li>\n</ul>\n<p>We intend to maintain our requirement for “CONTRIBUTING.md” files, as any generative AI tools can also be directed to treat that as an “agents.md” file.</p>\n<p>This is our intended addition to the templates for authors submitting software for review:</p>\n<pre>## Use of Generative AI\n- [ ] Generative AI tools were used to produce some of the material in this submission.\nIf so, please describe: &lt;!-- refer to our AI policies at http:// ... --&gt;\nIf your repository includes an \"agents.md\" file or equivalent, please provide a link, and describe how this has been used in the development of your package.\n</pre><p>An example of such a description can be found in this <a href=\"https://github.com/ropensci/software-review/issues/752#issuecomment-3938097125\" rel=\"nofollow\" target=\"_blank\">recent software review submission</a>.</p>\n<h3>\nPractical application: for editors\n</h3><p>Editors are the first to view software submitted to rOpenSci, and generally complete an initial <a href=\"https://devguide.ropensci.org/editortemplate.html\" rel=\"nofollow\" target=\"_blank\">Editors checklist</a> indicating whether they think a package may proceed to review.\nThis checklist will also include an additional item:</p>\n<pre>- [ ] **Use of generative AI tools**: If the authors have used generative AI tools, have they sufficiently described their usage?\n</pre><p>This item will also require no additional action by editors unless authors have used generative AI tools.</p>\n<p>Initial editorial considerations have until now been largely technical, including many of the aspects now automated by <a href=\"https://docs.ropensci.org/pkgcheck/\" rel=\"nofollow\" target=\"_blank\">our <code>pkgcheck</code> system</a>.\nIn response to this new checklist item, editors may broaden their consideration to whether a package has had sufficient human contribution to be worth reviewing, alongside considerations of additional factors such as:</p>\n<ul>\n<li>Clear statements of package motivation and importance.</li>\n<li>Package development history.</li>\n<li>Evidence of design decisions motivating the software.</li>\n</ul>\n<p>When recruiting reviewers for a package, editors may describe authors’ AI usage where relevant to help them understand the nature of the package and demands of review.</p>\n<h3>\nPractical application: for reviewers\n</h3><p>Review processes at rOpenSci frequently involve reviewers recommending potential improvements, and authors then implementing those.\nIn adapting to use of generative AI tools, we will strive to maintain the same culture of constructive feedback.\nWe hope that authors will provide sufficient information on any use of generative AI tools to guide reviewers towards aspects of their software requiring particular attention.</p>\n<p>Reviewers are permitted to use generative AI tools in preparing reviews for rOpenSci, but their use must meet the same criteria of supporting the goals of review.\nOur <a href=\"https://devguide.ropensci.org/softwarereview_reviewer.html\" rel=\"nofollow\" target=\"_blank\">Guide for Reviewers</a> will be updated to note the following points:</p>\n<ul>\n<li>Generative AI tools may be used to aid the review process, but all review text must reflect the judgement of the reviewer.</li>\n<li>Typical and acceptable use of generative AI tools in software review includes getting an overview of software design, structure, and function.</li>\n</ul>\n<p>Updates to the <a href=\"https://devguide.ropensci.org/softwarereview_reviewer.html\" rel=\"nofollow\" target=\"_blank\">Guide for Reviewers</a> will also include examples of productive use of generative AI tools in the review process.\nWe aim to run pilots over the course of this year to test where in the review process AI can best be used to improve everyone’s experience, and to provide more robust guidelines and custom tools.</p>\n<p>Reviewers may also consider AI use in choosing whether to volunteer as a reviewer of a package, and authors should be aware that extensive AI use could increase the time to find reviewers.</p>\n<h2>\nMoving forward\n</h2><p>This is our first pass at providing guidelines governing the use of generative AI to ensure rOpenSci software review continues to improve while retaining its essential values.</p>\n<p>With more package submissions having some component of AI contribution, the editorial board thought it essential to provide these updates to manage the process as we learn more about what works and what does not.</p>\n<p>We invite you to further discuss the evolving role of AI in software review in <a href=\"https://github.com/ropensci/software-review-meta/issues/107\" rel=\"nofollow\" target=\"_blank\">this issue</a>, and more importantly to join us as an author or reviewer in peer review, so we can learn together!</p>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://ropensci.org/blog/2026/02/26/ropensci-ai-policy/\"> rOpenSci - open tools for open science</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div> </div>\n</article>",
    "word_count": 2044,
    "reading_time_min": 10.2,
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/ropensci-open-tools-for-open-science/",
        "text": "rOpenSci - open tools for open science"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "external_links": [
      {
        "href": "https://ropensci.org/blog/2026/02/26/ropensci-ai-policy/",
        "text": "rOpenSci - open tools for open science"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://www.pyopensci.org/blog/generative-ai-peer-review-policy.html",
        "text": "exploring these in this blog post"
      },
      {
        "href": "https://pluralistic.net/2025/12/05/pop-that-bubble/#u-washington",
        "text": "social and economic inequality"
      },
      {
        "href": "https://blog.joss.theoj.org/2026/01/preparing-joss-for-a-generative-ai-future",
        "text": "Journal of Open Source Software"
      },
      {
        "href": "https://www.pyopensci.org/blog/generative-ai-peer-review-policy.html",
        "text": "pyOpenSci"
      },
      {
        "href": "https://joss.theoj.org/about#ai-policy",
        "text": "scope definition"
      },
      {
        "href": "https://devguide.ropensci.org/softwarereview_author.html",
        "text": "Guide for Authors"
      },
      {
        "href": "https://github.com/ropensci/software-review/issues/752#issuecomment-3938097125",
        "text": "recent software review submission"
      },
      {
        "href": "https://devguide.ropensci.org/editortemplate.html",
        "text": "Editors checklist"
      },
      {
        "href": "https://docs.ropensci.org/pkgcheck/",
        "text": "ourpkgchecksystem"
      },
      {
        "href": "https://devguide.ropensci.org/softwarereview_reviewer.html",
        "text": "Guide for Reviewers"
      },
      {
        "href": "https://devguide.ropensci.org/softwarereview_reviewer.html",
        "text": "Guide for Reviewers"
      },
      {
        "href": "https://github.com/ropensci/software-review-meta/issues/107",
        "text": "this issue"
      },
      {
        "href": "https://ropensci.org/blog/2026/02/26/ropensci-ai-policy/",
        "text": "rOpenSci - open tools for open science"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "images": [],
    "lang": "en-US",
    "crawled_at_utc": "2026-02-26T15:44:49Z"
  }
}