{
  "id": "44ae2ea8c5269fb39820ba264de8072f4b8f6dfa",
  "url": "https://www.r-bloggers.com/2025/12/haskell-is-a-great-language-for-data-science/",
  "created_at_utc": "2025-12-05T23:55:36Z",
  "data": null,
  "raw_original": {
    "uuid": "1a834657-da61-4e17-a524-d21068aac68f",
    "created_at": "2025-12-05 23:55:36",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2025/12/haskell-is-a-great-language-for-data-science/",
      "crawled_at": "2025-12-05T14:55:06.942413",
      "external_links": [
        {
          "href": "https://jcarroll.com.au/2025/12/05/haskell-is-a-great-language-for-data-science/",
          "text": "rstats on Irregularly Scheduled Programming"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://www.datahaskell.org/",
          "text": "dataHaskell"
        },
        {
          "href": "https://vapour.run/",
          "text": "vapour"
        },
        {
          "href": "https://github.com/we-data-ch/typr",
          "text": "typr"
        },
        {
          "href": "https://josiahparry.com/posts/2024-06-30-type-safety/",
          "text": "{rlang}’s checks"
        },
        {
          "href": "https://stat.ethz.ch/pipermail/r-devel/2025-September/084164.html",
          "text": "in September 2025"
        },
        {
          "href": "https://stat.ethz.ch/pipermail/r-devel/2025-November/084223.html",
          "text": "in November 2025"
        },
        {
          "href": "https://jcarroll.com.au/tags/haskell/",
          "text": "more than a handful of times"
        },
        {
          "href": "https://github.com/DataHaskell/datahaskell-starter/blob/main/hscript",
          "text": "awkscript"
        },
        {
          "href": "https://sanj.ink/posts/2018-08-09-defining-a-multiline-function-in-haskell-using-ghci.html",
          "text": "multi-line statements"
        },
        {
          "href": "https://dataframe.readthedocs.io/en/latest/",
          "text": "dataframe"
        },
        {
          "href": "https://en.wikipedia.org/wiki/Currying",
          "text": "currying"
        },
        {
          "href": "https://blog.genesmindsmachines.com/p/python-is-not-a-great-language-for-2e0",
          "text": "this (follow-up) post"
        },
        {
          "href": "https://www.datahaskell.org/blog/2025/11/11/welcome-to-datahaskell.html",
          "text": "dataHaskell ecosystem"
        },
        {
          "href": "https://pandas.pydata.org/",
          "text": "Pandas"
        },
        {
          "href": "https://docs.pola.rs/api/python/stable/reference/index.html",
          "text": "Polars"
        },
        {
          "href": "https://dataframes.juliadata.org/stable/",
          "text": "DataFrames.jl"
        },
        {
          "href": "https://kotlin.github.io/dataframe/home.html",
          "text": "even Kotlin has a DataFrame"
        },
        {
          "href": "https://dataframe.readthedocs.io/",
          "text": "dataframe"
        },
        {
          "href": "https://github.com/DataHaskell/datahaskell-starter/blob/main/hscript",
          "text": "pre-processing trick"
        },
        {
          "href": "https://www.tweag.io/blog/2017-10-12-vector-package/#array-fusion",
          "text": "intermediate vector isn’t actually used at all"
        },
        {
          "href": "https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/rewrite_rules.html",
          "text": "rewrite rules"
        },
        {
          "href": "https://dataframe.readthedocs.io/en/latest/",
          "text": "dataframe"
        },
        {
          "href": "https://jcarroll.com.au/2025/12/05/haskell-is-a-great-language-for-data-science/#syntax",
          "text": "above"
        },
        {
          "href": "https://blog.djnavarro.net/posts/2021-04-18_pretty-little-clis/",
          "text": "https://blog.djnavarro.net/posts/2021-04-18_pretty-little-clis/"
        },
        {
          "href": "https://dataframe.readthedocs.io/en/latest/coming_from_other_implementations.html#coming-from-dplyr",
          "text": "the dataframe documentation"
        },
        {
          "href": "https://www.datahaskell.org/blog/2025/11/11/welcome-to-datahaskell.html",
          "text": "this post"
        },
        {
          "href": "https://fosstodon.org/@jonocarroll",
          "text": "Mastodon"
        },
        {
          "href": "https://jcarroll.com.au/2025/12/05/haskell-is-a-great-language-for-data-science/",
          "text": "rstats on Irregularly Scheduled Programming"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Haskell IS a Great Language for Data Science | R-bloggers",
      "images": [],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/jonathan-carroll/",
          "text": "Jonathan Carroll"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-397373 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Haskell IS a Great Language for Data Science</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">December 4, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/jonathan-carroll/\">Jonathan Carroll</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://jcarroll.com.au/2025/12/05/haskell-is-a-great-language-for-data-science/\"> rstats on Irregularly Scheduled Programming</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47--><p>I’ve been learning Haskell for a few years now and I am really liking a lot of\nthe features, not least the strong typing and functional approach. I thought it\nwas lacking some of the things I missed from R until I found the\n<a href=\"https://www.datahaskell.org/\" rel=\"nofollow\" target=\"_blank\">dataHaskell</a> project.</p>\n<p>There have been several attempts recently to enhance R with some strong types, e.g. \n<a href=\"https://vapour.run/\" rel=\"nofollow\" target=\"_blank\">vapour</a>, <a href=\"https://github.com/we-data-ch/typr\" rel=\"nofollow\" target=\"_blank\">typr</a>, using\n<a href=\"https://josiahparry.com/posts/2024-06-30-type-safety/\" rel=\"nofollow\" target=\"_blank\">{rlang}’s checks</a>, and even\ndiscussions about implementations at the core level e.g. \n<a href=\"https://stat.ethz.ch/pipermail/r-devel/2025-September/084164.html\" rel=\"nofollow\" target=\"_blank\">in September 2025</a>\ncontinued <a href=\"https://stat.ethz.ch/pipermail/r-devel/2025-November/084223.html\" rel=\"nofollow\" target=\"_blank\">in November 2025</a>.\nWhile these try to bend R towards types, perhaps an all-in solution makes more sense.</p>\n<p>In this post I’ll demonstrate some of the features and explain why I think it\nmakes for a good (great?) data science language.</p>\n<p>I’ve posted <a href=\"https://jcarroll.com.au/tags/haskell/\" rel=\"nofollow\" target=\"_blank\">more than a handful of times</a>\nabout Haskell but maybe not so much the benefits of a real-world usage, more\ntoy problems (e.g. I did a lot of Advent of Code using it last year). I’ve been\nworking towards using it more, and even managed to get a custom {knitr} engine\nworking – here’s the special sauce that makes a <code>```{haskell}</code> block work:</p>\n<pre>knitr::knit_engines$set(haskell = function(options) {\n  code &lt;- options$code\n  codefile &lt;- tempfile(fileext = \".hs\")\n  codefile_brace &lt;- tempfile(fileext = \".hs\")\n  on.exit(file.remove(codefile, codefile_brace))\n  writeLines(c(\":script dataframe\", \"\", code), con = codefile)\n  system2('hscript', codefile, stdout = codefile_brace)\n  out  &lt;- system2(\n    file.path(path.expand('~'), '.ghcup/bin/ghc'),\n    c('-e',\"':script \", codefile_brace, \"'\"),\n    stdout = TRUE\n  )\n\n  knitr::engine_output(options, code, out)\n})</pre>\n<p>This writes the lines of code to a temporary file, prepended with some\nconfiguration options, then runs essentially <code>ghc -e ':script file.txt'</code> and\ndeletes the temporary file. For the purposes of making cleaner code blocks, the\ncode detours through an <a href=\"https://github.com/DataHaskell/datahaskell-starter/blob/main/hscript\" rel=\"nofollow\" target=\"_blank\"><code>awk</code> script</a>\nwhich inserts some <code>:{</code> blocks around\n<a href=\"https://sanj.ink/posts/2018-08-09-defining-a-multiline-function-in-haskell-using-ghci.html\" rel=\"nofollow\" target=\"_blank\">multi-line statements</a>,\nhelping to reproduce how these look in a Jupyter notebook.\nThe result is then shown in the code block, so this is a “live” output</p>\n<pre>map (+5) [2..8]\n## [7,8,9,10,11,12,13]\n</pre>\n<p>Neat, right?</p>\n<p>Because I’m treating each code block as an independent script, it means there is\n<em>some</em> repetition between blocks. I’ll hide that away with some judicious <code>echo</code>\noptions where necessary, but otherwise each block should be able to be run\nas a ‘script’ with the right pre-processing.</p>\n<p><a id=\"syntax\"></a></p>\n<div class=\"section level2\" id=\"a-brief-intro-to-haskell-syntax\">\n<h2>A Brief intro to Haskell Syntax</h2>\n<p>Haskell <em>is</em> a bit different if you’ve only ever seen R or Python, but it doesn’t\ntake too much effort to understand what’s going on. Firstly, while parentheses are\nused for function calls in R, a space is used in Haskell, so instead of <code>sum(x)</code>\nyou use <code>sum x</code>. Parentheses are still used for grouping together combinations of\nthings that need to be evaluated together.</p>\n<p>Lists are a fundamental data type and are denoted by square brackets, e.g. <code>[3,4,5]</code>\nand they need to contain a single type. For a strongly typed language, that shouldn’t\ncome as a surprise. A single number might be of type <code>Double</code> and a list of these\nwould be of type <code>[Double]</code>.</p>\n<p>If you’re worried that you’ve become too reliant on a piped workflow, fear not!\ndataHaskell’s <a href=\"https://dataframe.readthedocs.io/en/latest/\" rel=\"nofollow\" target=\"_blank\">dataframe</a> package\nadds the familiar pipe operator</p>\n<pre>[2,8,7,10,1,9,5,3,4,6] |&gt;\n  reverse |&gt;\n  take 5\n## [6,4,3,5,9]\n</pre>\n<p>with the important distinction that it passes the left side to the <em>end</em> of the\nright side (not to the first argument) which flows cleaner given how Haskell\nfunctions are typically written, e.g.</p>\n<pre>take 3 [1,2,3,4,5,6]\n\n-- vs \n\n[1,2,3,4,5,6] |&gt;\n  take 3\n## [1,2,3]\n## [1,2,3]\n</pre>\n<p>The line in the middle there demonstrates that comments start with two hyphens <code>--</code>,\nor for multi-line comments, between <code>{-</code> and <code>-}</code>.</p>\n<p>If you need to write a function (for which you use camelCase) you can annotate\nit with a definition, though the compiler can figure this out itself most of the\ntime (plus it helps for readability). The way to do this is with one extra line\nabove the implementation. If the type is generic, you can use a placeholder e.g. \n<code>a</code> rather than a <em>specific</em> type. Technically all functions take only one argument,\npossibly returning another function (see <a href=\"https://en.wikipedia.org/wiki/Currying\" rel=\"nofollow\" target=\"_blank\">currying</a>)\nbut this is more explicit in the signature; e.g. <code>[a] -&gt; a -&gt; [a]</code> represents a\nfunction which takes a list and a value and returns a list</p>\n<pre>appendValueToList :: [a] -&gt; a -&gt; [a]\nappendValueToList xs y = xs ++ [y]\n\nappendValueToList [2,4,6] 8\n\nappendValueToList [\"f\", \"o\", \"o\"] \"t\"\n## [2,4,6,8]\n## [\"f\",\"o\",\"o\",\"t\"]\n</pre>\n<p>The period is used for function composition, i.e.</p>\n<pre>import Data.List (sort)\n\n(reverse . sort) [2,8,7,10,1,9,5,3,4,6]\n## [10,9,8,7,6,5,4,3,2,1]\n</pre>\n<p>applies a composed ‘sort and reverse’ operation to the list. The <code>import</code> is there\nbecause the ‘base’ library (“Prelude”) doesn’t have the <code>sort</code> function, so it’s\nimported. There’s actually a few of these which need to be imported to use the\ncode I’m showing below, but it’s inserted into the codeblocks via the <code>:script dataframe</code>\nline in the engine definition above. That calls out to an executable which runs\nthe code block as if it was contained in a <code>main</code> function in a full program,\nwhich enables us to use <code>IO</code> operations inline, such as reading from files and\nprinting results. That all gets a little trickier without this ‘scripting’ context,\nbut I’m here to make the point that such a scripting context <em>works well</em> for\ndoing data science.</p>\n<p>So, what would one use this for?</p>\n<p>I saw <a href=\"https://blog.genesmindsmachines.com/p/python-is-not-a-great-language-for-2e0\" rel=\"nofollow\" target=\"_blank\">this (follow-up) post</a>\nfrom Claus Wilke about Python not being a great language for data science and\nwhile I concur with the points made there, I do believe some of them are\npersonal preference. I’m a proponent of “use the tools you’re comfortable with”\nand I can’t argue with however many thousands of data scientists are\nsuccessfully using Python to do data science.</p>\n<p>The point about “what makes for a good data science language” made me pause to\nthink and I came to the conclusion that Haskell actually ticks the boxes, at least\nwith the <a href=\"https://www.datahaskell.org/blog/2025/11/11/welcome-to-datahaskell.html\" rel=\"nofollow\" target=\"_blank\">dataHaskell ecosystem</a>\nand the dataframe package. What follows is not to\nbe taken as a pile-on against Python or even a complaint about R, but rather\nsomething in the style of “if you like that, check this out!”</p>\n<p>Lots of languages seem to have some sort of dataframe these days - thanks R! - e.g. \nPython has <a href=\"https://pandas.pydata.org/\" rel=\"nofollow\" target=\"_blank\">Pandas</a>/<a href=\"https://docs.pola.rs/api/python/stable/reference/index.html\" rel=\"nofollow\" target=\"_blank\">Polars</a>,\nJulia has <a href=\"https://dataframes.juliadata.org/stable/\" rel=\"nofollow\" target=\"_blank\">DataFrames.jl</a>,\n<a href=\"https://kotlin.github.io/dataframe/home.html\" rel=\"nofollow\" target=\"_blank\">even Kotlin has a DataFrame</a>.\nHaskell does, too with <a href=\"https://dataframe.readthedocs.io/\" rel=\"nofollow\" target=\"_blank\">dataframe</a> and I’ve\nbeen learning how to use this recently.</p>\n<p>The points made in Claus’ post were that the features which make R a better language\nfor data science over Python are (paraphrasing):</p>\n<ul>\n<li>call-by-value semantics (non-mutability)</li>\n<li>built-in missing values</li>\n<li>built-in vectorization</li>\n<li>non-standard evaluation (NSE)</li>\n</ul>\n<p>Let’s look at how Haskell deals with each of these.</p>\n</div>\n<div class=\"section level2\" id=\"non-mutability\">\n<h2>Non-mutability</h2>\n<p>Claus details how Python’s call-by-reference semantics enables one to modify\nvariables unintentionally, since they’re scoped across functions. Haskell certainly\ndoesn’t have this problem - everything is immutable, and functions are “pure” (no\nside-effects, though you can interact with typed side-effect ‘instructions’). If you\nwant to “do” anything to a data object you pass it into a function and get a new\nobject out. There’s no risk of accidentally modifying a variable, but of course\nthe downside of this is that you <em>can’t</em> do so without a function. While in R it’s\nstraightforward to do</p>\n<pre>a &lt;- c(2, 9, 6)\na[2] &lt;- 4\na\n## [1] 2 4 6\n</pre>\n<p>in Haskell that sort of thing is off limits - you can use an operator to extract\na value from a list (0-indexed), e.g. </p>\n<pre>a = [2,9,6]\n\na !! 1\n## 9\n</pre>\n<p>but there’s no way to assign the second element to some other value. Instead,\nyou need to break the vector apart and stitch the new value inside</p>\n<pre>a = [2,9,6]\n\nupdateSecond :: [a] -&gt; a -&gt; [a]\nupdateSecond (x:_:z) y = x : y : z\nupdateSecond xs _ = xs\n\nupdateSecond a 4\n## [2,4,6]\n</pre>\n<p>No risk of accidentally writing that, I’m sure.</p>\n<p>I’ve also included the type definition in this case which reads as “a function\nwhich takes a list of some type <code>a</code> (<code>[a]</code>) and a single value of type <code>a</code> and\nreturns a list of that same type, <code>[a]</code>.” FYI, this is one example where you may\nneed the definition to be enclosed between <code>:{</code> and <code>:}</code>, if you’re running\ninteractively in <code>ghci</code>, but here I’m using the<br/>\n<a href=\"https://github.com/DataHaskell/datahaskell-starter/blob/main/hscript\" rel=\"nofollow\" target=\"_blank\">pre-processing trick</a>\nmentioned above.</p>\n<p>A tick for <em>truly</em> immutable data - the only way to “alter” a value is to operate\non it with a function and reassign it.</p>\n</div>\n<div class=\"section level2\" id=\"built-in-missing-values\">\n<h2>Built-in missing values</h2>\n<p>This is somewhere that Haskell shines - if you want a value that <em>might</em> not be\navailable in R you use an <code>NA</code> (which is a shorthand for whichever flavour/class\nyou actually want, e.g. <code>NA_character_</code>). Using one of these in any mathematical\ncalculation ‘poisons’ it and returns <code>NA</code>, e.g.</p>\n<pre>sum(1, NA, 3)\n## [1] NA\n</pre>\n<p>To avoid this, most functions offer a <code>na.rm</code> argument which instructs to remove\nthe missing values prior to performing the calculation</p>\n<pre>sum(1, NA, 3, na.rm = TRUE)\n## [1] 4\n</pre>\n<p>What’s happening here is that R encodes a value that is <em>maybe</em> missing. Haskell\nformalises this into the <code>Data.Maybe</code> package and you have to be explicit in\ndealing with a missing value (<code>Nothing</code>) or a definitely-not-missing value (<code>Just x</code>)</p>\n<pre>non_missing = [1, 2, 3, 4]\nhas_missing = [Just 1,Just 2,Nothing,Just 4]\n\n:t non_missing\n:t has_missing\n## non_missing :: Num a =&gt; [a]\n## has_missing :: Num a =&gt; [Maybe a]\n</pre>\n<p>where we see that <code>has_missing</code> is a <code>Maybe</code> type.</p>\n<pre>sum non_missing\n## 10\n</pre>\n<p>You can’t just <code>sum</code> the latter; it produces an error because it doesn’t have a\nfunction which can sum a <code>Maybe Integer</code></p>\n<pre>sum has_missing\ns:7:1: error: [GHC-39999]\n    • No instance for ‘Num (Maybe Integer)’ arising from a use of ‘it’\n    • In the first argument of ‘print’, namely ‘it’\n      In a stmt of an interactive GHCi command: print it\n  |\n7 | sum has_missing\n  | ^^^^^^^^^^^^^^^</pre>\n<p>you need to remove any <code>Nothing</code> first, then most likely ‘unwrap’ from the\n<code>Maybe</code> context</p>\n<pre>import Data.Maybe\n\nsum $ map fromJust $ filter isJust has_missing\n## 7\n</pre>\n<p>or alternatively</p>\n<pre>sum (catMaybes has_missing) \n## 7\n</pre>\n<p>or you can get fancy</p>\n<pre>sum [x | Just x &lt;- has_missing]\n## 7\n</pre>\n<p>The point is that you <em>have to</em> deal with the missingness if it’s there. What this\nalso means is that if you have a <code>Double</code> column, it <em>does NOT</em> have missing values,\nso you can safely sum those values (plus get all sorts of performance benefits from\nthe compiler because it, too, knows there’s no missing values).</p>\n<p>For Claus’ example, we can produce a proper <code>Nothing</code> at the end of this calculation</p>\n<pre>fmap (fmap (&gt; 3)) x\n## [Just False,Just False,Nothing,Just True,Just True]\n</pre>\n<p>Another tick - proper missing values.</p>\n</div>\n<div class=\"section level2\" id=\"built-in-vectorisation\">\n<h2>Built-in vectorisation</h2>\n<p>Haskell is NOT an array language, so sure, it doesn’t have vectorisation built-in,\nbut it’s worth noting that at the end of Claus’ post he details some limitations\nof R and acknowledges that “R does not have any scalar data types”. Haskell has\nscalars, vectors, and arrays, and you need to be specific when you want to iterate\nover those - the “type” of a variable includes the dimensionality, so <code>Double</code> is\nnot the same as <code>[Double]</code> (a list of doubles).</p>\n<p>Since Haskell is a functional programming language it has every type of <code>map</code> you\ncould want, including specialities for monads and applicatives. While this means\nyou <em>do</em> need to write <code>map</code> when you want to iterate, it also means you’re never\nsurprised that there was more than one value there.</p>\n<p>What’s more, because it’s a compiled language, the compiler can optimise all sorts\nof vector operations. One example is using “fusion” to combine a <code>filter</code> and a\n<code>map</code> such that the\n<a href=\"https://www.tweag.io/blog/2017-10-12-vector-package/#array-fusion\" rel=\"nofollow\" target=\"_blank\">intermediate vector isn’t actually used at all</a>.</p>\n<p>This means that a stack of functions like</p>\n<pre>foldr (+) 0 . map (*2) . filter even</pre>\n<p>which would naively require a full pass to filter the even values, a half pass\nto double those, then anther half pass to add them up, can be done in a single\npass.</p>\n<p>You can also add <a href=\"https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/rewrite_rules.html\" rel=\"nofollow\" target=\"_blank\">rewrite rules</a>\nif you’re sure your replacement holds (and many libraries can assert these\nconditions, so implement such rules) so that some operations can be entirely\ncompiled away. Reversing a finite list twice is a no-op, so takes no time, so\none could add</p>\n<pre>{-# RULES\n\"reverse.reverse/id\" reverse . reverse = id\n  #-}</pre>\n<p>which means a double reverse can be replaced with the identity function.</p>\n<p>Even without such a rule, Haskell (being a compiled language) is <em>fast</em></p>\n<pre>x = [1..1000000000]\n:set +s\na = reverse $ reverse x\n(0.00 secs, 0 bytes)</pre>\n<p>This is disappointing to run inline in R</p>\n<pre>x &lt;- seq_len(1e9)\nsystem.time(rev(rev(x)))\n   user  system elapsed \n  4.596   2.543   8.824 </pre>\n<p>This ins’t just about compiling; R <em>does</em> have just-in-time compilation of\nfunctions, but lacks the compiler tricks that Haskell uses, so a compiled\nversion of this doesn’t do a lot better</p>\n<pre>revrev &lt;- function(x) {\n  rev(rev(x))\n}\nrevrev_comp &lt;- compiler::cmpfun(revrev)\nsystem.time(revrev_comp(x))\n   user  system elapsed \n  4.035   0.739   4.777</pre>\n<p>So, no vectorisation, but possibly enough compiler tricks to make up for it - tick.</p>\n</div>\n<div class=\"section level2\" id=\"non-standard-evaluation-nse\">\n<h2>Non-standard evaluation (NSE)</h2>\n<p>This is where the fun really starts - the <a href=\"https://dataframe.readthedocs.io/en/latest/\" rel=\"nofollow\" target=\"_blank\">dataframe</a>\npackage from the dataHaskell ecosystem adds the sort of slicing and dicing\nyou’re probably familiar with. Apart from general inspection of data frames</p>\n<pre>df &lt;- D.readParquet \"iris.parquet\"\n\nD.describeColumns df\n## ---------------------------------------------------------\n## Column Name  | # Non-null Values | # Null Values |  Type \n## -------------|-------------------|---------------|-------\n##     Text     |        Int        |      Int      |  Text \n## -------------|-------------------|---------------|-------\n## variety      | 150               | 0             | Text  \n## petal.width  | 150               | 0             | Double\n## petal.length | 150               | 0             | Double\n## sepal.width  | 150               | 0             | Double\n## sepal.length | 150               | 0             | Double\n</pre>\n<p>(don’t be fooled by that <code>&lt;-</code> - that’s Haskell’s way of doing something that reaches\noutside of the CPU, e.g. to the disk to read a file) we can use <code>D.dimensions</code> to get the\noverall shape, and more specific helpers like <code>D.nRows</code> and <code>D.nColumns</code> are available\nwhich we can incorporate into e.g. text output</p>\n<pre>import Text.Printf (printf)\n\ndf &lt;- D.readParquet \"iris.parquet\"\n\nD.dimensions df\n\nprintf \"%d rows, %d columns\" (D.nRows df) (D.nColumns df)\n## (150,5)\n## 150 rows, 5 columns\n</pre>\n<p>Many of the <code>dplyr</code>-esqe operations are available, with a lot of thought put into\nhow these would interact with a strongly typed structure</p>\n<pre>iris &lt;- D.readParquet \"iris.parquet\"\n\niris |&gt; \n  D.filterWhere (F.col @Text \"variety\" .== \"Setosa\") |&gt; \n  D.filterWhere (F.col @Double \"sepal.length\" .&gt; 5.4)\n## -----------------------------------------------------------------\n## sepal.length | sepal.width | petal.length | petal.width | variety\n## -------------|-------------|--------------|-------------|--------\n##    Double    |   Double    |    Double    |   Double    |  Text  \n## -------------|-------------|--------------|-------------|--------\n## 5.8          | 4.0         | 1.2          | 0.2         | Setosa \n## 5.7          | 4.4         | 1.5          | 0.4         | Setosa \n## 5.7          | 3.8         | 1.7          | 0.3         | Setosa \n## 5.5          | 4.2         | 1.4          | 0.2         | Setosa \n## 5.5          | 3.5         | 1.3          | 0.2         | Setosa\n</pre>\n<p>but dataframe goes one step further via template haskell… you can expose the\ncolumns as variables (admittedly, in the wider scope) so this works</p>\n<pre>iris &lt;- D.readParquet \"iris.parquet\"\n\n-- make columns available as expressions\n:exposeColumns iris\n\niris |&gt; \n  D.derive \"sepal.ratio\" (sepal_width / sepal_length) |&gt;\n  D.take 5 \n## sepal_length :: Expr Double\n## sepal_width :: Expr Double\n## petal_length :: Expr Double\n## petal_width :: Expr Double\n## variety :: Expr Text\n## --------------------------------------------------------------------------------------\n## sepal.length | sepal.width | petal.length | petal.width | variety |    sepal.ratio    \n## -------------|-------------|--------------|-------------|---------|-------------------\n##    Double    |   Double    |    Double    |   Double    |  Text   |       Double      \n## -------------|-------------|--------------|-------------|---------|-------------------\n## 5.1          | 3.5         | 1.4          | 0.2         | Setosa  | 0.6862745098039216\n## 4.9          | 3.0         | 1.4          | 0.2         | Setosa  | 0.6122448979591836\n## 4.7          | 3.2         | 1.3          | 0.2         | Setosa  | 0.6808510638297872\n## 4.6          | 3.1         | 1.5          | 0.2         | Setosa  | 0.673913043478261 \n## 5.0          | 3.6         | 1.4          | 0.2         | Setosa  | 0.72\n</pre>\n<p>The info printed prior to the result is the about the exposed columns, and it’s\nworth noting that the dots/periods have been replaced by underscores. That’s\nbecause in Haskell the period is used for composition, as described <a href=\"https://jcarroll.com.au/2025/12/05/haskell-is-a-great-language-for-data-science/#syntax\" rel=\"nofollow\" target=\"_blank\">above</a>.</p>\n<p>Many verbs are supported, so we can do some more detailed transformations</p>\n<pre>iris &lt;- D.readParquet \"iris.parquet\"\n\n:exposeColumns iris\n\niris |&gt; \n  D.filterWhere ( sepal_width .&gt; 2.6 ) |&gt;\n  D.groupBy [\"variety\"] |&gt; \n  D.aggregate\n      [ \"n\"       .= F.count petal_length\n      , \"sl_mean\" .= F.mean sepal_length\n      , \"pl_mean\" .= F.mean petal_length\n      ]\n## sepal_length :: Expr Double\n## sepal_width :: Expr Double\n## petal_length :: Expr Double\n## petal_width :: Expr Double\n## variety :: Expr Text\n## ---------------------------------------------------------\n##  variety   |  n  |      sl_mean      |      pl_mean      \n## -----------|-----|-------------------|-------------------\n##    Text    | Int |      Double       |       Double      \n## -----------|-----|-------------------|-------------------\n## Versicolor | 34  | 6.099999999999998 | 4.435294117647058 \n## Setosa     | 49  | 5.016326530612244 | 1.4653061224489798\n## Virginica  | 43  | 6.651162790697675 | 5.57674418604651\n</pre>\n<p>and remember, because we <em>know</em> there’s no missing values in a column of <code>Double</code>s\n(not <code>Maybe Double</code>s) we can take averages without worrying about any <code>na.rm</code>\ncomplications.</p>\n<p>The NSE bit doesn’t <em>quite</em> work everywhere, but sometimes a string is just fine, e.g.</p>\n<pre>iris &lt;- D.readParquet \"iris.parquet\"\n\nD.plotScatter \"sepal.length\" \"sepal.width\" iris\n##    4.5│                                                            \n##       │                       ⠈                                    \n##       │                    ⠠                                       \n##       │                ⠂                                           \n##       │                   ⡀     ⠁                                  \n##       │              ⠠        ⠠                              ⠄  ⠄  \n##       │              ⠐  ⠐ ⠂                                        \n##       │       ⠁   ⠈ ⡁⢀ ⡀   ⢀                         ⠈             \n##       │       ⠄  ⠄  ⠄⠠ ⠄  ⠄        ⠄  ⠠ ⠄                          \n##       │    ⡀  ⡀⢀    ⡂⠐           ⢀      ⠂⢀ ⡀  ⠂⢀ ⡀⢀  ⢀             \n##    3.2│       ⠄  ⠄⠠                      ⠠    ⠄  ⠄                 \n##       │  ⠐ ⠂     ⠂⠐ ⠂     ⠂  ⠂⠐  ⠐ ⠂⠐      ⠂⠐ ⠂⠐    ⠂⠐     ⠐ ⠂     \n##       │    ⠁                 ⡁⢈ ⡀  ⠁⢈ ⢈ ⡁⢈ ⡀⠈  ⢀       ⠁⢀    ⡀     \n##       │                ⠄     ⠄  ⠄  ⠄    ⠄⠠                         \n##       │                    ⠐  ⠐ ⠂   ⠐                        ⠂     \n##       │           ⢈  ⠈     ⢈ ⠁⠈         ⠁     ⠁                    \n##       │     ⠠       ⠄      ⠠            ⠄                          \n##       │                            ⠂  ⠐                            \n##       │             ⡀                                              \n##    1.9│                                                            \n##       └────────────────────────────────────────────────────────────\n##        4.1                           6.1                          8.1\n## \n## ⣿ sepal.length vs sepal.width\n</pre>\n<p>(following <a class=\"uri\" href=\"https://blog.djnavarro.net/posts/2021-04-18_pretty-little-clis/\" rel=\"nofollow\" target=\"_blank\">https://blog.djnavarro.net/posts/2021-04-18_pretty-little-clis/</a> to get\nthe ANSI sequences to work in a code block).</p>\n<p>A more detailed comparison to <code>dplyr</code> is provided in\n<a href=\"https://dataframe.readthedocs.io/en/latest/coming_from_other_implementations.html#coming-from-dplyr\" rel=\"nofollow\" target=\"_blank\">the dataframe documentation</a>.</p>\n<p>So, NSE? Tick!</p>\n</div>\n<div class=\"section level2\" id=\"conclusion\">\n<h2>Conclusion</h2>\n<p>I’ve hopefully demonstrated some of the power of a strongly typed language and\na package focused on data science enabling the sort of functionality that an\nR (or Python) user might be looking for. I am hopeful that Haskell (and the\ndataHaskell ecosystem) can be a viable option for those of us wanting to do\ndata science in a strongly typed language with a very clever compiler capable\nof making significant performance improvements.</p>\n<p>If you’re interested in dataHaskell then check out\n<a href=\"https://www.datahaskell.org/blog/2025/11/11/welcome-to-datahaskell.html\" rel=\"nofollow\" target=\"_blank\">this post</a>\nand consider taking it for a spin - we’re working on reducing friction to get\nstarted via devcontainers and hosted notebook solutions, and are keen to hear from\nmore data scientists about what they’d like the ecosystem to be able to support.</p>\n<p><em>I believe Haskell IS a great language for data science!</em></p>\n<p>As always, I can be found on\n<a href=\"https://fosstodon.org/@jonocarroll\" rel=\"nofollow\" target=\"_blank\">Mastodon</a> and the comment section below.</p>\n<br/>\n<details>\n<summary>\n<tt>devtools::session_info()</tt>\n</summary>\n<pre>## ─ Session info ───────────────────────────────────────────────────────────────\n##  setting  value\n##  version  R version 4.4.1 (2024-06-14)\n##  os       macOS 15.6.1\n##  system   aarch64, darwin20\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       Australia/Adelaide\n##  date     2025-12-05\n##  pandoc   3.8.2.1 @ /opt/homebrew/bin/ (via rmarkdown)\n##  quarto   1.7.31 @ /usr/local/bin/quarto\n## \n## ─ Packages ───────────────────────────────────────────────────────────────────\n##  package     * version date (UTC) lib source\n##  blogdown      1.21.1  2025-06-28 [1] Github (rstudio/blogdown@33313a5)\n##  bookdown      0.41    2024-10-16 [1] CRAN (R 4.4.1)\n##  bslib         0.9.0   2025-01-30 [1] CRAN (R 4.4.1)\n##  cachem        1.1.0   2024-05-16 [1] CRAN (R 4.4.0)\n##  cli           3.6.5   2025-04-23 [1] CRAN (R 4.4.1)\n##  devtools      2.4.6   2025-10-03 [1] CRAN (R 4.4.1)\n##  digest        0.6.38  2025-11-12 [1] CRAN (R 4.4.1)\n##  ellipsis      0.3.2   2021-04-29 [1] CRAN (R 4.4.0)\n##  evaluate      1.0.5   2025-08-27 [1] CRAN (R 4.4.1)\n##  fansi         1.0.7   2025-11-19 [1] CRAN (R 4.4.3)\n##  fastmap       1.2.0   2024-05-15 [1] CRAN (R 4.4.0)\n##  fs            1.6.6   2025-04-12 [1] CRAN (R 4.4.1)\n##  glue          1.8.0   2024-09-30 [1] CRAN (R 4.4.1)\n##  htmltools     0.5.8.1 2024-04-04 [1] CRAN (R 4.4.0)\n##  jquerylib     0.1.4   2021-04-26 [1] CRAN (R 4.4.0)\n##  jsonlite      2.0.0   2025-03-27 [1] CRAN (R 4.4.1)\n##  knitr         1.50    2025-03-16 [1] CRAN (R 4.4.1)\n##  lifecycle     1.0.4   2023-11-07 [1] CRAN (R 4.4.0)\n##  magrittr      2.0.4   2025-09-12 [1] CRAN (R 4.4.1)\n##  memoise       2.0.1   2021-11-26 [1] CRAN (R 4.4.0)\n##  pkgbuild      1.4.8   2025-05-26 [1] CRAN (R 4.4.1)\n##  pkgload       1.4.1   2025-09-23 [1] CRAN (R 4.4.1)\n##  purrr         1.2.0   2025-11-04 [1] CRAN (R 4.4.1)\n##  R6            2.6.1   2025-02-15 [1] CRAN (R 4.4.1)\n##  remotes       2.5.0   2024-03-17 [1] CRAN (R 4.4.1)\n##  rlang         1.1.6   2025-04-11 [1] CRAN (R 4.4.1)\n##  rmarkdown     2.30    2025-09-28 [1] CRAN (R 4.4.1)\n##  rstudioapi    0.17.1  2024-10-22 [1] CRAN (R 4.4.1)\n##  sass          0.4.10  2025-04-11 [1] CRAN (R 4.4.1)\n##  sessioninfo   1.2.3   2025-02-05 [1] CRAN (R 4.4.1)\n##  usethis       3.2.1   2025-09-06 [1] CRAN (R 4.4.1)\n##  vctrs         0.6.5   2023-12-01 [1] CRAN (R 4.4.0)\n##  xfun          0.54    2025-10-30 [1] CRAN (R 4.4.1)\n##  yaml          2.3.10  2024-07-26 [1] CRAN (R 4.4.0)\n## \n##  [1] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n## \n## ──────────────────────────────────────────────────────────────────────────────\n</pre>\n</details>\n<p><br/></p>\n</div>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://jcarroll.com.au/2025/12/05/haskell-is-a-great-language-for-data-science/\"> rstats on Irregularly Scheduled Programming</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
      "main_text": "Haskell IS a Great Language for Data Science\nPosted on\nDecember 4, 2025\nby\nJonathan Carroll\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nrstats on Irregularly Scheduled Programming\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nI’ve been learning Haskell for a few years now and I am really liking a lot of\nthe features, not least the strong typing and functional approach. I thought it\nwas lacking some of the things I missed from R until I found the\ndataHaskell\nproject.\nThere have been several attempts recently to enhance R with some strong types, e.g.\nvapour\n,\ntypr\n, using\n{rlang}’s checks\n, and even\ndiscussions about implementations at the core level e.g.\nin September 2025\ncontinued\nin November 2025\n.\nWhile these try to bend R towards types, perhaps an all-in solution makes more sense.\nIn this post I’ll demonstrate some of the features and explain why I think it\nmakes for a good (great?) data science language.\nI’ve posted\nmore than a handful of times\nabout Haskell but maybe not so much the benefits of a real-world usage, more\ntoy problems (e.g. I did a lot of Advent of Code using it last year). I’ve been\nworking towards using it more, and even managed to get a custom {knitr} engine\nworking – here’s the special sauce that makes a\n```{haskell}\nblock work:\nknitr::knit_engines$set(haskell = function(options) {\n  code <- options$code\n  codefile <- tempfile(fileext = \".hs\")\n  codefile_brace <- tempfile(fileext = \".hs\")\n  on.exit(file.remove(codefile, codefile_brace))\n  writeLines(c(\":script dataframe\", \"\", code), con = codefile)\n  system2('hscript', codefile, stdout = codefile_brace)\n  out  <- system2(\n    file.path(path.expand('~'), '.ghcup/bin/ghc'),\n    c('-e',\"':script \", codefile_brace, \"'\"),\n    stdout = TRUE\n  )\n\n  knitr::engine_output(options, code, out)\n})\nThis writes the lines of code to a temporary file, prepended with some\nconfiguration options, then runs essentially\nghc -e ':script file.txt'\nand\ndeletes the temporary file. For the purposes of making cleaner code blocks, the\ncode detours through an\nawk\nscript\nwhich inserts some\n:{\nblocks around\nmulti-line statements\n,\nhelping to reproduce how these look in a Jupyter notebook.\nThe result is then shown in the code block, so this is a “live” output\nmap (+5) [2..8]\n## [7,8,9,10,11,12,13]\nNeat, right?\nBecause I’m treating each code block as an independent script, it means there is\nsome\nrepetition between blocks. I’ll hide that away with some judicious\necho\noptions where necessary, but otherwise each block should be able to be run\nas a ‘script’ with the right pre-processing.\nA Brief intro to Haskell Syntax\nHaskell\nis\na bit different if you’ve only ever seen R or Python, but it doesn’t\ntake too much effort to understand what’s going on. Firstly, while parentheses are\nused for function calls in R, a space is used in Haskell, so instead of\nsum(x)\nyou use\nsum x\n. Parentheses are still used for grouping together combinations of\nthings that need to be evaluated together.\nLists are a fundamental data type and are denoted by square brackets, e.g.\n[3,4,5]\nand they need to contain a single type. For a strongly typed language, that shouldn’t\ncome as a surprise. A single number might be of type\nDouble\nand a list of these\nwould be of type\n[Double]\n.\nIf you’re worried that you’ve become too reliant on a piped workflow, fear not!\ndataHaskell’s\ndataframe\npackage\nadds the familiar pipe operator\n[2,8,7,10,1,9,5,3,4,6] |>\n  reverse |>\n  take 5\n## [6,4,3,5,9]\nwith the important distinction that it passes the left side to the\nend\nof the\nright side (not to the first argument) which flows cleaner given how Haskell\nfunctions are typically written, e.g.\ntake 3 [1,2,3,4,5,6]\n\n-- vs \n\n[1,2,3,4,5,6] |>\n  take 3\n## [1,2,3]\n## [1,2,3]\nThe line in the middle there demonstrates that comments start with two hyphens\n--\n,\nor for multi-line comments, between\n{-\nand\n-}\n.\nIf you need to write a function (for which you use camelCase) you can annotate\nit with a definition, though the compiler can figure this out itself most of the\ntime (plus it helps for readability). The way to do this is with one extra line\nabove the implementation. If the type is generic, you can use a placeholder e.g.\na\nrather than a\nspecific\ntype. Technically all functions take only one argument,\npossibly returning another function (see\ncurrying\n)\nbut this is more explicit in the signature; e.g.\n[a] -> a -> [a]\nrepresents a\nfunction which takes a list and a value and returns a list\nappendValueToList :: [a] -> a -> [a]\nappendValueToList xs y = xs ++ [y]\n\nappendValueToList [2,4,6] 8\n\nappendValueToList [\"f\", \"o\", \"o\"] \"t\"\n## [2,4,6,8]\n## [\"f\",\"o\",\"o\",\"t\"]\nThe period is used for function composition, i.e.\nimport Data.List (sort)\n\n(reverse . sort) [2,8,7,10,1,9,5,3,4,6]\n## [10,9,8,7,6,5,4,3,2,1]\napplies a composed ‘sort and reverse’ operation to the list. The\nimport\nis there\nbecause the ‘base’ library (“Prelude”) doesn’t have the\nsort\nfunction, so it’s\nimported. There’s actually a few of these which need to be imported to use the\ncode I’m showing below, but it’s inserted into the codeblocks via the\n:script dataframe\nline in the engine definition above. That calls out to an executable which runs\nthe code block as if it was contained in a\nmain\nfunction in a full program,\nwhich enables us to use\nIO\noperations inline, such as reading from files and\nprinting results. That all gets a little trickier without this ‘scripting’ context,\nbut I’m here to make the point that such a scripting context\nworks well\nfor\ndoing data science.\nSo, what would one use this for?\nI saw\nthis (follow-up) post\nfrom Claus Wilke about Python not being a great language for data science and\nwhile I concur with the points made there, I do believe some of them are\npersonal preference. I’m a proponent of “use the tools you’re comfortable with”\nand I can’t argue with however many thousands of data scientists are\nsuccessfully using Python to do data science.\nThe point about “what makes for a good data science language” made me pause to\nthink and I came to the conclusion that Haskell actually ticks the boxes, at least\nwith the\ndataHaskell ecosystem\nand the dataframe package. What follows is not to\nbe taken as a pile-on against Python or even a complaint about R, but rather\nsomething in the style of “if you like that, check this out!”\nLots of languages seem to have some sort of dataframe these days - thanks R! - e.g. \nPython has\nPandas\n/\nPolars\n,\nJulia has\nDataFrames.jl\n,\neven Kotlin has a DataFrame\n.\nHaskell does, too with\ndataframe\nand I’ve\nbeen learning how to use this recently.\nThe points made in Claus’ post were that the features which make R a better language\nfor data science over Python are (paraphrasing):\ncall-by-value semantics (non-mutability)\nbuilt-in missing values\nbuilt-in vectorization\nnon-standard evaluation (NSE)\nLet’s look at how Haskell deals with each of these.\nNon-mutability\nClaus details how Python’s call-by-reference semantics enables one to modify\nvariables unintentionally, since they’re scoped across functions. Haskell certainly\ndoesn’t have this problem - everything is immutable, and functions are “pure” (no\nside-effects, though you can interact with typed side-effect ‘instructions’). If you\nwant to “do” anything to a data object you pass it into a function and get a new\nobject out. There’s no risk of accidentally modifying a variable, but of course\nthe downside of this is that you\ncan’t\ndo so without a function. While in R it’s\nstraightforward to do\na <- c(2, 9, 6)\na[2] <- 4\na\n## [1] 2 4 6\nin Haskell that sort of thing is off limits - you can use an operator to extract\na value from a list (0-indexed), e.g.\na = [2,9,6]\n\na !! 1\n## 9\nbut there’s no way to assign the second element to some other value. Instead,\nyou need to break the vector apart and stitch the new value inside\na = [2,9,6]\n\nupdateSecond :: [a] -> a -> [a]\nupdateSecond (x:_:z) y = x : y : z\nupdateSecond xs _ = xs\n\nupdateSecond a 4\n## [2,4,6]\nNo risk of accidentally writing that, I’m sure.\nI’ve also included the type definition in this case which reads as “a function\nwhich takes a list of some type\na\n(\n[a]\n) and a single value of type\na\nand\nreturns a list of that same type,\n[a]\n.” FYI, this is one example where you may\nneed the definition to be enclosed between\n:{\nand\n:}\n, if you’re running\ninteractively in\nghci\n, but here I’m using the\npre-processing trick\nmentioned above.\nA tick for\ntruly\nimmutable data - the only way to “alter” a value is to operate\non it with a function and reassign it.\nBuilt-in missing values\nThis is somewhere that Haskell shines - if you want a value that\nmight\nnot be\navailable in R you use an\nNA\n(which is a shorthand for whichever flavour/class\nyou actually want, e.g.\nNA_character_\n). Using one of these in any mathematical\ncalculation ‘poisons’ it and returns\nNA\n, e.g.\nsum(1, NA, 3)\n## [1] NA\nTo avoid this, most functions offer a\nna.rm\nargument which instructs to remove\nthe missing values prior to performing the calculation\nsum(1, NA, 3, na.rm = TRUE)\n## [1] 4\nWhat’s happening here is that R encodes a value that is\nmaybe\nmissing. Haskell\nformalises this into the\nData.Maybe\npackage and you have to be explicit in\ndealing with a missing value (\nNothing\n) or a definitely-not-missing value (\nJust x\n)\nnon_missing = [1, 2, 3, 4]\nhas_missing = [Just 1,Just 2,Nothing,Just 4]\n\n:t non_missing\n:t has_missing\n## non_missing :: Num a => [a]\n## has_missing :: Num a => [Maybe a]\nwhere we see that\nhas_missing\nis a\nMaybe\ntype.\nsum non_missing\n## 10\nYou can’t just\nsum\nthe latter; it produces an error because it doesn’t have a\nfunction which can sum a\nMaybe Integer\nsum has_missing\ns:7:1: error: [GHC-39999]\n    • No instance for ‘Num (Maybe Integer)’ arising from a use of ‘it’\n    • In the first argument of ‘print’, namely ‘it’\n      In a stmt of an interactive GHCi command: print it\n  |\n7 | sum has_missing\n  | ^^^^^^^^^^^^^^^\nyou need to remove any\nNothing\nfirst, then most likely ‘unwrap’ from the\nMaybe\ncontext\nimport Data.Maybe\n\nsum $ map fromJust $ filter isJust has_missing\n## 7\nor alternatively\nsum (catMaybes has_missing) \n## 7\nor you can get fancy\nsum [x | Just x <- has_missing]\n## 7\nThe point is that you\nhave to\ndeal with the missingness if it’s there. What this\nalso means is that if you have a\nDouble\ncolumn, it\ndoes NOT\nhave missing values,\nso you can safely sum those values (plus get all sorts of performance benefits from\nthe compiler because it, too, knows there’s no missing values).\nFor Claus’ example, we can produce a proper\nNothing\nat the end of this calculation\nfmap (fmap (> 3)) x\n## [Just False,Just False,Nothing,Just True,Just True]\nAnother tick - proper missing values.\nBuilt-in vectorisation\nHaskell is NOT an array language, so sure, it doesn’t have vectorisation built-in,\nbut it’s worth noting that at the end of Claus’ post he details some limitations\nof R and acknowledges that “R does not have any scalar data types”. Haskell has\nscalars, vectors, and arrays, and you need to be specific when you want to iterate\nover those - the “type” of a variable includes the dimensionality, so\nDouble\nis\nnot the same as\n[Double]\n(a list of doubles).\nSince Haskell is a functional programming language it has every type of\nmap\nyou\ncould want, including specialities for monads and applicatives. While this means\nyou\ndo\nneed to write\nmap\nwhen you want to iterate, it also means you’re never\nsurprised that there was more than one value there.\nWhat’s more, because it’s a compiled language, the compiler can optimise all sorts\nof vector operations. One example is using “fusion” to combine a\nfilter\nand a\nmap\nsuch that the\nintermediate vector isn’t actually used at all\n.\nThis means that a stack of functions like\nfoldr (+) 0 . map (*2) . filter even\nwhich would naively require a full pass to filter the even values, a half pass\nto double those, then anther half pass to add them up, can be done in a single\npass.\nYou can also add\nrewrite rules\nif you’re sure your replacement holds (and many libraries can assert these\nconditions, so implement such rules) so that some operations can be entirely\ncompiled away. Reversing a finite list twice is a no-op, so takes no time, so\none could add\n{-# RULES\n\"reverse.reverse/id\" reverse . reverse = id\n  #-}\nwhich means a double reverse can be replaced with the identity function.\nEven without such a rule, Haskell (being a compiled language) is\nfast\nx = [1..1000000000]\n:set +s\na = reverse $ reverse x\n(0.00 secs, 0 bytes)\nThis is disappointing to run inline in R\nx <- seq_len(1e9)\nsystem.time(rev(rev(x)))\n   user  system elapsed \n  4.596   2.543   8.824\nThis ins’t just about compiling; R\ndoes\nhave just-in-time compilation of\nfunctions, but lacks the compiler tricks that Haskell uses, so a compiled\nversion of this doesn’t do a lot better\nrevrev <- function(x) {\n  rev(rev(x))\n}\nrevrev_comp <- compiler::cmpfun(revrev)\nsystem.time(revrev_comp(x))\n   user  system elapsed \n  4.035   0.739   4.777\nSo, no vectorisation, but possibly enough compiler tricks to make up for it - tick.\nNon-standard evaluation (NSE)\nThis is where the fun really starts - the\ndataframe\npackage from the dataHaskell ecosystem adds the sort of slicing and dicing\nyou’re probably familiar with. Apart from general inspection of data frames\ndf <- D.readParquet \"iris.parquet\"\n\nD.describeColumns df\n## ---------------------------------------------------------\n## Column Name  | # Non-null Values | # Null Values |  Type \n## -------------|-------------------|---------------|-------\n##     Text     |        Int        |      Int      |  Text \n## -------------|-------------------|---------------|-------\n## variety      | 150               | 0             | Text  \n## petal.width  | 150               | 0             | Double\n## petal.length | 150               | 0             | Double\n## sepal.width  | 150               | 0             | Double\n## sepal.length | 150               | 0             | Double\n(don’t be fooled by that\n<-\n- that’s Haskell’s way of doing something that reaches\noutside of the CPU, e.g. to the disk to read a file) we can use\nD.dimensions\nto get the\noverall shape, and more specific helpers like\nD.nRows\nand\nD.nColumns\nare available\nwhich we can incorporate into e.g. text output\nimport Text.Printf (printf)\n\ndf <- D.readParquet \"iris.parquet\"\n\nD.dimensions df\n\nprintf \"%d rows, %d columns\" (D.nRows df) (D.nColumns df)\n## (150,5)\n## 150 rows, 5 columns\nMany of the\ndplyr\n-esqe operations are available, with a lot of thought put into\nhow these would interact with a strongly typed structure\niris <- D.readParquet \"iris.parquet\"\n\niris |> \n  D.filterWhere (F.col @Text \"variety\" .== \"Setosa\") |> \n  D.filterWhere (F.col @Double \"sepal.length\" .> 5.4)\n## -----------------------------------------------------------------\n## sepal.length | sepal.width | petal.length | petal.width | variety\n## -------------|-------------|--------------|-------------|--------\n##    Double    |   Double    |    Double    |   Double    |  Text  \n## -------------|-------------|--------------|-------------|--------\n## 5.8          | 4.0         | 1.2          | 0.2         | Setosa \n## 5.7          | 4.4         | 1.5          | 0.4         | Setosa \n## 5.7          | 3.8         | 1.7          | 0.3         | Setosa \n## 5.5          | 4.2         | 1.4          | 0.2         | Setosa \n## 5.5          | 3.5         | 1.3          | 0.2         | Setosa\nbut dataframe goes one step further via template haskell… you can expose the\ncolumns as variables (admittedly, in the wider scope) so this works\niris <- D.readParquet \"iris.parquet\"\n\n-- make columns available as expressions\n:exposeColumns iris\n\niris |> \n  D.derive \"sepal.ratio\" (sepal_width / sepal_length) |>\n  D.take 5 \n## sepal_length :: Expr Double\n## sepal_width :: Expr Double\n## petal_length :: Expr Double\n## petal_width :: Expr Double\n## variety :: Expr Text\n## --------------------------------------------------------------------------------------\n## sepal.length | sepal.width | petal.length | petal.width | variety |    sepal.ratio    \n## -------------|-------------|--------------|-------------|---------|-------------------\n##    Double    |   Double    |    Double    |   Double    |  Text   |       Double      \n## -------------|-------------|--------------|-------------|---------|-------------------\n## 5.1          | 3.5         | 1.4          | 0.2         | Setosa  | 0.6862745098039216\n## 4.9          | 3.0         | 1.4          | 0.2         | Setosa  | 0.6122448979591836\n## 4.7          | 3.2         | 1.3          | 0.2         | Setosa  | 0.6808510638297872\n## 4.6          | 3.1         | 1.5          | 0.2         | Setosa  | 0.673913043478261 \n## 5.0          | 3.6         | 1.4          | 0.2         | Setosa  | 0.72\nThe info printed prior to the result is the about the exposed columns, and it’s\nworth noting that the dots/periods have been replaced by underscores. That’s\nbecause in Haskell the period is used for composition, as described\nabove\n.\nMany verbs are supported, so we can do some more detailed transformations\niris <- D.readParquet \"iris.parquet\"\n\n:exposeColumns iris\n\niris |> \n  D.filterWhere ( sepal_width .> 2.6 ) |>\n  D.groupBy [\"variety\"] |> \n  D.aggregate\n      [ \"n\"       .= F.count petal_length\n      , \"sl_mean\" .= F.mean sepal_length\n      , \"pl_mean\" .= F.mean petal_length\n      ]\n## sepal_length :: Expr Double\n## sepal_width :: Expr Double\n## petal_length :: Expr Double\n## petal_width :: Expr Double\n## variety :: Expr Text\n## ---------------------------------------------------------\n##  variety   |  n  |      sl_mean      |      pl_mean      \n## -----------|-----|-------------------|-------------------\n##    Text    | Int |      Double       |       Double      \n## -----------|-----|-------------------|-------------------\n## Versicolor | 34  | 6.099999999999998 | 4.435294117647058 \n## Setosa     | 49  | 5.016326530612244 | 1.4653061224489798\n## Virginica  | 43  | 6.651162790697675 | 5.57674418604651\nand remember, because we\nknow\nthere’s no missing values in a column of\nDouble\ns\n(not\nMaybe Double\ns) we can take averages without worrying about any\nna.rm\ncomplications.\nThe NSE bit doesn’t\nquite\nwork everywhere, but sometimes a string is just fine, e.g.\niris <- D.readParquet \"iris.parquet\"\n\nD.plotScatter \"sepal.length\" \"sepal.width\" iris\n##    4.5│                                                            \n##       │                       ⠈                                    \n##       │                    ⠠                                       \n##       │                ⠂                                           \n##       │                   ⡀     ⠁                                  \n##       │              ⠠        ⠠                              ⠄  ⠄  \n##       │              ⠐  ⠐ ⠂                                        \n##       │       ⠁   ⠈ ⡁⢀ ⡀   ⢀                         ⠈             \n##       │       ⠄  ⠄  ⠄⠠ ⠄  ⠄        ⠄  ⠠ ⠄                          \n##       │    ⡀  ⡀⢀    ⡂⠐           ⢀      ⠂⢀ ⡀  ⠂⢀ ⡀⢀  ⢀             \n##    3.2│       ⠄  ⠄⠠                      ⠠    ⠄  ⠄                 \n##       │  ⠐ ⠂     ⠂⠐ ⠂     ⠂  ⠂⠐  ⠐ ⠂⠐      ⠂⠐ ⠂⠐    ⠂⠐     ⠐ ⠂     \n##       │    ⠁                 ⡁⢈ ⡀  ⠁⢈ ⢈ ⡁⢈ ⡀⠈  ⢀       ⠁⢀    ⡀     \n##       │                ⠄     ⠄  ⠄  ⠄    ⠄⠠                         \n##       │                    ⠐  ⠐ ⠂   ⠐                        ⠂     \n##       │           ⢈  ⠈     ⢈ ⠁⠈         ⠁     ⠁                    \n##       │     ⠠       ⠄      ⠠            ⠄                          \n##       │                            ⠂  ⠐                            \n##       │             ⡀                                              \n##    1.9│                                                            \n##       └────────────────────────────────────────────────────────────\n##        4.1                           6.1                          8.1\n## \n## ⣿ sepal.length vs sepal.width\n(following\nhttps://blog.djnavarro.net/posts/2021-04-18_pretty-little-clis/\nto get\nthe ANSI sequences to work in a code block).\nA more detailed comparison to\ndplyr\nis provided in\nthe dataframe documentation\n.\nSo, NSE? Tick!\nConclusion\nI’ve hopefully demonstrated some of the power of a strongly typed language and\na package focused on data science enabling the sort of functionality that an\nR (or Python) user might be looking for. I am hopeful that Haskell (and the\ndataHaskell ecosystem) can be a viable option for those of us wanting to do\ndata science in a strongly typed language with a very clever compiler capable\nof making significant performance improvements.\nIf you’re interested in dataHaskell then check out\nthis post\nand consider taking it for a spin - we’re working on reducing friction to get\nstarted via devcontainers and hosted notebook solutions, and are keen to hear from\nmore data scientists about what they’d like the ecosystem to be able to support.\nI believe Haskell IS a great language for data science!\nAs always, I can be found on\nMastodon\nand the comment section below.\ndevtools::session_info()\n## ─ Session info ───────────────────────────────────────────────────────────────\n##  setting  value\n##  version  R version 4.4.1 (2024-06-14)\n##  os       macOS 15.6.1\n##  system   aarch64, darwin20\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       Australia/Adelaide\n##  date     2025-12-05\n##  pandoc   3.8.2.1 @ /opt/homebrew/bin/ (via rmarkdown)\n##  quarto   1.7.31 @ /usr/local/bin/quarto\n## \n## ─ Packages ───────────────────────────────────────────────────────────────────\n##  package     * version date (UTC) lib source\n##  blogdown      1.21.1  2025-06-28 [1] Github (rstudio/blogdown@33313a5)\n##  bookdown      0.41    2024-10-16 [1] CRAN (R 4.4.1)\n##  bslib         0.9.0   2025-01-30 [1] CRAN (R 4.4.1)\n##  cachem        1.1.0   2024-05-16 [1] CRAN (R 4.4.0)\n##  cli           3.6.5   2025-04-23 [1] CRAN (R 4.4.1)\n##  devtools      2.4.6   2025-10-03 [1] CRAN (R 4.4.1)\n##  digest        0.6.38  2025-11-12 [1] CRAN (R 4.4.1)\n##  ellipsis      0.3.2   2021-04-29 [1] CRAN (R 4.4.0)\n##  evaluate      1.0.5   2025-08-27 [1] CRAN (R 4.4.1)\n##  fansi         1.0.7   2025-11-19 [1] CRAN (R 4.4.3)\n##  fastmap       1.2.0   2024-05-15 [1] CRAN (R 4.4.0)\n##  fs            1.6.6   2025-04-12 [1] CRAN (R 4.4.1)\n##  glue          1.8.0   2024-09-30 [1] CRAN (R 4.4.1)\n##  htmltools     0.5.8.1 2024-04-04 [1] CRAN (R 4.4.0)\n##  jquerylib     0.1.4   2021-04-26 [1] CRAN (R 4.4.0)\n##  jsonlite      2.0.0   2025-03-27 [1] CRAN (R 4.4.1)\n##  knitr         1.50    2025-03-16 [1] CRAN (R 4.4.1)\n##  lifecycle     1.0.4   2023-11-07 [1] CRAN (R 4.4.0)\n##  magrittr      2.0.4   2025-09-12 [1] CRAN (R 4.4.1)\n##  memoise       2.0.1   2021-11-26 [1] CRAN (R 4.4.0)\n##  pkgbuild      1.4.8   2025-05-26 [1] CRAN (R 4.4.1)\n##  pkgload       1.4.1   2025-09-23 [1] CRAN (R 4.4.1)\n##  purrr         1.2.0   2025-11-04 [1] CRAN (R 4.4.1)\n##  R6            2.6.1   2025-02-15 [1] CRAN (R 4.4.1)\n##  remotes       2.5.0   2024-03-17 [1] CRAN (R 4.4.1)\n##  rlang         1.1.6   2025-04-11 [1] CRAN (R 4.4.1)\n##  rmarkdown     2.30    2025-09-28 [1] CRAN (R 4.4.1)\n##  rstudioapi    0.17.1  2024-10-22 [1] CRAN (R 4.4.1)\n##  sass          0.4.10  2025-04-11 [1] CRAN (R 4.4.1)\n##  sessioninfo   1.2.3   2025-02-05 [1] CRAN (R 4.4.1)\n##  usethis       3.2.1   2025-09-06 [1] CRAN (R 4.4.1)\n##  vctrs         0.6.5   2023-12-01 [1] CRAN (R 4.4.0)\n##  xfun          0.54    2025-10-30 [1] CRAN (R 4.4.1)\n##  yaml          2.3.10  2024-07-26 [1] CRAN (R 4.4.0)\n## \n##  [1] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n## \n## ──────────────────────────────────────────────────────────────────────────────\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nrstats on Irregularly Scheduled Programming\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "I’ve been learning Haskell for a few years now and I am really liking a lot of the features, not least the strong typing and functional approach. I thought it was lacking some of the things I missed from R until I found the dataHaskell project. There h...",
      "meta_keywords": null,
      "og_description": "I’ve been learning Haskell for a few years now and I am really liking a lot of the features, not least the strong typing and functional approach. I thought it was lacking some of the things I missed from R until I found the dataHaskell project. There h...",
      "og_image": "https://www.r-bloggers.com/wp-content/uploads/2016/04/R_02_2016-05-01.png",
      "og_title": "Haskell IS a Great Language for Data Science | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 18.7,
      "sitemap_lastmod": null,
      "twitter_description": "I’ve been learning Haskell for a few years now and I am really liking a lot of the features, not least the strong typing and functional approach. I thought it was lacking some of the things I missed from R until I found the dataHaskell project. There h...",
      "twitter_title": "Haskell IS a Great Language for Data Science | R-bloggers",
      "url": "https://www.r-bloggers.com/2025/12/haskell-is-a-great-language-for-data-science/",
      "word_count": 3746
    }
  }
}