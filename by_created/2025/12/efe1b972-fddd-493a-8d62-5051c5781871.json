{
  "uuid": "efe1b972-fddd-493a-8d62-5051c5781871",
  "created_at": "2025-12-12 22:44:44",
  "raw_json": {
    "article_author": null,
    "article_headline": null,
    "article_modified": null,
    "article_published": null,
    "article_section": null,
    "article_tags": null,
    "canonical_url": "https://www.r-bloggers.com/2025/12/counterfactual-scenario-analysis-with-aheadridge2f/",
    "crawled_at": "2025-12-12T13:44:18.696249",
    "external_links": [
      {
        "href": "https://thierrymoudiki.github.io//blog/2025/12/11/r/Counterfactual-Scenario-Analysis-with-ridge2f",
        "text": "T. Moudiki's Webpage - R"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://thierrymoudiki.github.io//blog/2025/12/11/r/Counterfactual-Scenario-Analysis-with-ridge2f",
        "text": "T. Moudiki's Webpage - R"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "h1_title": "R-bloggers",
    "html_title": "Counterfactual Scenario Analysis with ahead::ridge2f | R-bloggers",
    "images": [
      {
        "alt": "image-title-here",
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": "image-title-here",
        "base64": null,
        "src": "https://i2.wp.com/thierrymoudiki.github.io/images/2025-12-11/2025-12-11-Counterfactual-Scenario-Analysis-with-ridge2f_4_1.png?w=578&ssl=1"
      },
      {
        "alt": "image-title-here",
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": "image-title-here",
        "base64": null,
        "src": "https://i2.wp.com/thierrymoudiki.github.io/images/2025-12-11/2025-12-11-Counterfactual-Scenario-Analysis-with-ridge2f_4_0.png?w=578&ssl=1"
      }
    ],
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/t-moudiki/",
        "text": "T. Moudiki"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "lang": "en-US",
    "main_html": "<article class=\"post-397551 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Counterfactual Scenario Analysis with ahead::ridge2f</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">December 10, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/t-moudiki/\">T. Moudiki</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://thierrymoudiki.github.io//blog/2025/12/11/r/Counterfactual-Scenario-Analysis-with-ridge2f\"> T. Moudiki's Webpage - R</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47--><p>In this post, we will explore how to perform counterfactual scenario analysis using the <code>ridge2f</code> function from the <code>ahead</code> package in R.</p>\n<p>Counterfactual scenario analysis is a powerful tool for understanding the impact of different scenarios on time series data. It allows us to evaluate the performance of different models under different scenarios, and to compare the performance of different models under different scenarios.</p>\n<p>We will use the <code>insurance</code> dataset from the <code>ahead</code> package, which contains monthly data on insurance quotes and TV advertising.</p>\n<p>The data set is split into three parts:</p>\n<ul>\n<li><code>train</code>: historical data to learn from</li>\n<li><code>scenario</code>: period where we apply “what-if” scenarios</li>\n<li><code>test</code>: true future where we evaluate forecasts</li>\n</ul>\n<p>The <code>train</code> data is used to fit the model, the <code>scenario</code> data is used to generate counterfactual scenarios, and the <code>test</code> data is used to evaluate the performance of the model under the counterfactual scenarios.</p>\n<pre>install.packages(\"remotes\")\ninstall.packages(\"gridExtra\")\n\nremotes::install_github(\"Techtonique/ahead\")\n\nurl &lt;- \"https://raw.githubusercontent.com/Techtonique/datasets/refs/heads/main/time_series/multivariate/insurance_quotes_advert.csv\"\ninsurance &lt;- read.csv(url)\n\ninsurance &lt;- ts(insurance, start=c(2002, 1), frequency = 12L)\n\nlibrary(ahead)\nlibrary(ggplot2)\nlibrary(gridExtra)\n\ny &lt;- insurance[, \"Quotes\"]\nTV &lt;- insurance[, \"TV.advert\"]\nt  &lt;- as.numeric(time(insurance))\nT &lt;- length(y)\n\n# ========== 3-PART SPLIT ==========\n# TRAIN: Historical data to learn from\n# SCENARIO: Period where we apply \"what-if\" scenarios\n# TEST: True future where we evaluate forecasts\n\ntrain_pct &lt;- 0.50\nscenario_pct &lt;- 0.30\n# test_pct &lt;- 0.20 (remainder)\n\ntrain_end &lt;- floor(train_pct * T)\nscenario_end &lt;- floor((train_pct + scenario_pct) * T)\n\n# Split data\ny_train &lt;- y[1:train_end]\ny_scenario &lt;- y[(train_end + 1):scenario_end]\ny_test &lt;- y[(scenario_end + 1):T]\n\nTV_train &lt;- TV[1:train_end]\nTV_scenario &lt;- TV[(train_end + 1):scenario_end]\nTV_test &lt;- TV[(scenario_end + 1):T]\n\nt_train &lt;- t[1:train_end]\nt_scenario &lt;- t[(train_end + 1):scenario_end]\nt_test &lt;- t[(scenario_end + 1):T]\n\nh_test &lt;- length(y_test)\n\ncat(\"\\n=== 3-PART DATA SPLIT ===\\n\")\ncat(\"TRAIN:    periods\", 1, \"to\", train_end, \"(n =\", train_end, \")\\n\")\ncat(\"SCENARIO: periods\", train_end + 1, \"to\", scenario_end, \"(n =\", length(y_scenario), \")\\n\")\ncat(\"TEST:     periods\", scenario_end + 1, \"to\", T, \"(n =\", h_test, \")\\n\\n\")\n\n# ========== THE KEY INSIGHT ==========\ncat(\"=== THE APPROACH ===\\n\")\ncat(\"1. Train on: TRAIN data only\\n\")\ncat(\"2. Apply scenarios to: SCENARIO period (with actual y values)\\n\")\ncat(\"3. Forecast into: TEST period (what we're evaluating)\\n\")\ncat(\"4. Compare: How do different SCENARIO assumptions affect TEST forecasts?\\n\\n\")\n\n# ========== DEFINE SCENARIOS ==========\n# Baseline: TV advertising unchanged\n# Scenario A: TV advertising was +1 higher during scenario period\n# Scenario B: TV advertising was -1 lower during scenario period\n\nTV_scenario_A &lt;- TV_scenario + 1\nTV_scenario_B &lt;- TV_scenario - 1\n\ncat(\"=== SCENARIOS ===\\n\")\ncat(\"Scenario A: TV during scenario period = actual +1\\n\")\ncat(\"Scenario B: TV during scenario period = actual -1\\n\")\ncat(\"(We're asking: 'What if TV had been different in the recent past?')\\n\\n\")\n\n# ========== BUILD TRAINING DATA WITH SCENARIOS ==========\n\n# For Baseline scenario\ny_train_Baseline &lt;- c(y_train, y_scenario)\nxreg_train_Baseline &lt;- rbind(\n  cbind(TV = TV_train, trend = t_train),\n  cbind(TV = TV_scenario, trend = t_scenario)\n)\n\n# For Scenario A: combine TRAIN + SCENARIO (with modified TV)\ny_train_A &lt;- y_train_Baseline\nxreg_train_A &lt;- rbind(\n  cbind(TV = TV_train, trend = t_train),\n  cbind(TV = TV_scenario_A, trend = t_scenario)\n)\n\n# For Scenario B: combine TRAIN + SCENARIO (with different TV)\ny_train_B &lt;- y_train_Baseline\nxreg_train_B &lt;- rbind(\n  cbind(TV = TV_train, trend = t_train),\n  cbind(TV = TV_scenario_B, trend = t_scenario)\n)\n\n# ========== FIT MODELS ==========\n\n\ncat(\"Fitting Scenario A model...\\n\")\nset.seed(123)\nres_Baseline &lt;- ridge2f(\n  y_train_Baseline,\n  h = h_test,\n  xreg = xreg_train_Baseline,\n  lags = 5,\n  type_pi = \"blockbootstrap\",\n  B = 200\n)\n\ncat(\"Fitting Scenario A model...\\n\")\nset.seed(123)\nres_A &lt;- ridge2f(\n  y_train_A,\n  h = h_test,\n  xreg = xreg_train_A,\n  lags = 5,\n  type_pi = \"blockbootstrap\",\n  B = 200\n)\n\ncat(\"Fitting Scenario B model...\\n\")\nset.seed(123)\nres_B &lt;- ridge2f(\n  y_train_B,\n  h = h_test,\n  xreg = xreg_train_B,\n  lags = 5,\n  type_pi = \"blockbootstrap\",\n  B = 200\n)\n\n# ========== COMPARISON TABLE ==========\ncomparison &lt;- data.frame(\n  Period = time(y_test),\n  Actual = as.numeric(y_test),\n  Forecast_Baseline = as.numeric(res_Baseline$mean),\n  Forecast_A = as.numeric(res_A$mean),\n  Forecast_B = as.numeric(res_B$mean),\n  Diff_A_B = as.numeric(res_A$mean) - as.numeric(res_B$mean),\n  Diff_A_Baseline = as.numeric(res_A$mean) - as.numeric(res_Baseline$mean),\n  Diff_B_Baseline = as.numeric(res_B$mean) - as.numeric(res_Baseline$mean),\n  Impact_A = as.numeric(res_A$mean) - as.numeric(y_test),\n  Impact_B = as.numeric(res_B$mean) - as.numeric(y_test),\n  Lower_A = as.numeric(res_A$lower),\n  Upper_A = as.numeric(res_A$upper),\n  Lower_B = as.numeric(res_B$lower),\n  Upper_B = as.numeric(res_B$upper)\n)\n\ncat(\"\\n=== TEST PERIOD FORECASTS ===\\n\")\nprint(round(comparison, 2))\n\n\n# ========== SCENARIO IMPACT ==========\n\ncolnames_comparison &lt;- colnames(comparison)\nprint(summary(comparison[, 6:10]))\nfor (i in 6:10)\n{\n  print(colnames_comparison[i])\n  print(t.test(comparison[, i]))\n}\n\n# ========== COVERAGE ANALYSIS ==========\nin_A &lt;- sum(comparison$Actual &gt;= comparison$Lower_A &amp;\n              comparison$Actual &lt;= comparison$Upper_A)\nin_B &lt;- sum(comparison$Actual &gt;= comparison$Lower_B &amp;\n              comparison$Actual &lt;= comparison$Upper_B)\ncoverage_A &lt;- in_A / h_test * 100\ncoverage_B &lt;- in_B / h_test * 100\n\ncat(\"\\n=== PREDICTION INTERVAL COVERAGE ===\\n\")\ncat(sprintf(\"Scenario A: %.1f%% (%d/%d)\\n\", coverage_A, in_A, h_test))\ncat(sprintf(\"Scenario B: %.1f%% (%d/%d)\\n\", coverage_B, in_B, h_test))\n\n# ========== PLOTS ==========\n\n\n\n=== 3-PART DATA SPLIT ===\nTRAIN:    periods 1 to 20 (n = 20 )\nSCENARIO: periods 21 to 32 (n = 12 )\nTEST:     periods 33 to 40 (n = 8 )\n\n=== THE APPROACH ===\n1. Train on: TRAIN data only\n2. Apply scenarios to: SCENARIO period (with actual y values)\n3. Forecast into: TEST period (what we're evaluating)\n4. Compare: How do different SCENARIO assumptions affect TEST forecasts?\n\n=== SCENARIOS ===\nScenario A: TV during scenario period = actual +1\nScenario B: TV during scenario period = actual -1\n(We're asking: 'What if TV had been different in the recent past?')\n\nFitting Scenario A model...\n  |======================================================================| 100%\nFitting Scenario A model...\n  |======================================================================| 100%\nFitting Scenario B model...\n  |======================================================================| 100%\n\n=== TEST PERIOD FORECASTS ===\n  Period Actual Forecast_Baseline Forecast_A Forecast_B Diff_A_B\n1      1  12.86             12.44      12.08      12.49    -0.42\n2      2  12.09             12.16      11.43      12.75    -1.33\n3      3  12.93             11.49      10.29      11.53    -1.24\n4      4  11.72             10.70       9.23       9.41    -0.19\n5      5  15.47             10.93      11.11       8.83     2.28\n6      6  18.44             11.47      14.21      11.22     2.99\n7      7  17.49             12.03      14.38      14.36     0.02\n8      8  14.49             12.59      13.28      16.04    -2.76\n  Diff_A_Baseline Diff_B_Baseline Impact_A Impact_B Lower_A Upper_A Lower_B\n1           -0.36            0.05    -0.78    -0.37   10.97   12.80   10.50\n2           -0.74            0.59    -0.66     0.66   10.51   12.12   10.58\n3           -1.20            0.04    -2.64    -1.40    7.65   12.97    9.90\n4           -1.47           -1.28    -2.50    -2.31    6.77   11.75    6.25\n5            0.18           -2.10    -4.36    -6.64    8.64   13.69    5.16\n6            2.74           -0.24    -4.23    -7.21   10.70   18.00    6.87\n7            2.35            2.33    -3.11    -3.13   11.35   19.12    9.14\n8            0.69            3.45    -1.21     1.54   10.56   17.72   12.62\n  Upper_B\n1   13.81\n2   15.34\n3   13.73\n4   12.89\n5   12.38\n6   15.08\n7   19.60\n8   20.18\n    Diff_A_B        Diff_A_Baseline    Diff_B_Baseline       Impact_A      \n Min.   :-2.75662   Min.   :-1.46811   Min.   :-2.10057   Min.   :-4.3592  \n 1st Qu.:-1.26217   1st Qu.:-0.85445   1st Qu.:-0.50317   1st Qu.:-3.3915  \n Median :-0.30014   Median :-0.09231   Median : 0.04573   Median :-2.5692  \n Mean   :-0.08017   Mean   : 0.27400   Mean   : 0.35417   Mean   :-2.4371  \n 3rd Qu.: 0.58402   3rd Qu.: 1.10542   3rd Qu.: 1.02461   3rd Qu.:-1.1051  \n Max.   : 2.98501   Max.   : 2.74174   Max.   : 3.44581   Max.   :-0.6627  \n    Impact_B      \n Min.   :-7.2143  \n 1st Qu.:-4.0080  \n Median :-1.8562  \n Mean   :-2.3569  \n 3rd Qu.:-0.1095  \n Max.   : 1.5440  \n[1] \"Diff_A_B\"\n\n\tOne Sample t-test\n\ndata:  comparison[, i]\nt = -0.11961, df = 7, p-value = 0.9082\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -1.665035  1.504705\nsample estimates:\n  mean of x \n-0.08016502 \n\n[1] \"Diff_A_Baseline\"\n\n\tOne Sample t-test\n\ndata:  comparison[, i]\nt = 0.49381, df = 7, p-value = 0.6366\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -1.038059  1.586063\nsample estimates:\nmean of x \n0.2740019 \n\n[1] \"Diff_B_Baseline\"\n\n\tOne Sample t-test\n\ndata:  comparison[, i]\nt = 0.55518, df = 7, p-value = 0.5961\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -1.154295  1.862629\nsample estimates:\nmean of x \n0.3541669 \n\n[1] \"Impact_A\"\n\n\tOne Sample t-test\n\ndata:  comparison[, i]\nt = -4.7416, df = 7, p-value = 0.002104\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -3.652457 -1.221723\nsample estimates:\nmean of x \n -2.43709 \n\n[1] \"Impact_B\"\n\n\tOne Sample t-test\n\ndata:  comparison[, i]\nt = -2.0825, df = 7, p-value = 0.07581\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -5.0332109  0.3193609\nsample estimates:\nmean of x \n-2.356925 \n\n\n=== PREDICTION INTERVAL COVERAGE ===\nScenario A: 62.5% (5/8)\nScenario B: 75.0% (6/8)\n\nlibrary(ggplot2)\nlibrary(tidyr)\n\ndf_long &lt;- comparison[, 6:10] %&gt;%\n  pivot_longer(cols = everything(),\n               names_to = \"Variable\",\n               values_to = \"Value\")\n\n# Create violin plot\nggplot(df_long, aes(x = Variable, y = Value, fill = Variable)) +\n  geom_violin(trim = FALSE) +\n  geom_jitter(width = 0.1, size = 1, alpha = 0.7) + # optional: show individual points\n  theme_minimal() +\n  labs(title = \"Violin Plot of Comparison Columns\",\n       y = \"Value\",\n       x = \"Variable\")\n\n\n# 1. Time series plot showing the full picture\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Combine all periods for context\nfull_data &lt;- data.frame(\n  Time = c(t_train, t_scenario, time(y_test)),\n  Actual = c(y_train, y_scenario, y_test),\n  Period = c(rep(\"Train\", length(y_train)), \n             rep(\"Scenario\", length(y_scenario)),\n             rep(\"Test\", length(y_test)))\n)\n\nforecast_data &lt;- data.frame(\n  Time = rep(time(y_test), 3),\n  Forecast = c(res_Baseline$mean, res_A$mean, res_B$mean),\n  Scenario = rep(c(\"Baseline\", \"TV +1\", \"TV -1\"), each = h_test)\n)\n\nggplot() +\n  geom_line(data = full_data, aes(x = Time, y = Actual), color = \"black\", size = 1) +\n  geom_vline(xintercept = t_scenario[1], linetype = \"dashed\", color = \"gray50\", alpha = 0.7) +\n  geom_vline(xintercept = time(y_test)[1], linetype = \"dashed\", color = \"gray50\", alpha = 0.7) +\n  geom_line(data = forecast_data, aes(x = Time, y = Forecast, color = Scenario), size = 1) +\n  annotate(\"text\", x = mean(t_train), y = max(full_data$Actual), label = \"TRAIN\") +\n  annotate(\"text\", x = mean(t_scenario), y = max(full_data$Actual), label = \"SCENARIO\") +\n  annotate(\"text\", x = mean(time(y_test)), y = max(full_data$Actual), label = \"TEST\") +\n  theme_minimal() +\n  labs(title = \"Counterfactual Forecasts: How Past TV Changes Affect Future Predictions\",\n       subtitle = \"Different scenario assumptions in the recent past lead to different test forecasts\",\n       y = \"Insurance Quotes\", x = \"Time\") +\n  scale_color_manual(values = c(\"Baseline\" = \"blue\", \"TV +1\" = \"red\", \"TV -1\" = \"green\"))\n\n# 2. Forecast difference plot (shows the impact more clearly)\ndiff_data &lt;- data.frame(\n  Time = time(y_test),\n  Diff_A_vs_Baseline = res_A$mean - res_Baseline$mean,\n  Diff_B_vs_Baseline = res_B$mean - res_Baseline$mean,\n  Diff_A_vs_B = res_A$mean - res_B$mean\n) %&gt;%\n  pivot_longer(cols = -Time, names_to = \"Comparison\", values_to = \"Difference\")\n\nggplot(diff_data, aes(x = Time, y = Difference, color = Comparison)) +\n  geom_line(size = 1) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray50\") +\n  theme_minimal() +\n  labs(title = \"Forecast Differences: Impact of Counterfactual Scenarios\",\n       subtitle = \"How much do forecasts change under different scenario assumptions?\",\n       y = \"Difference in Forecasts\", x = \"Time\")\n\n# 3. Prediction interval comparison\ninterval_data &lt;- data.frame(\n  Time = rep(time(y_test), 2),\n  Actual = rep(y_test, 2),\n  Forecast = c(res_A$mean, res_B$mean),\n  Lower = c(res_A$lower, res_B$lower),\n  Upper = c(res_A$upper, res_B$upper),\n  Scenario = rep(c(\"TV +1\", \"TV -1\"), each = h_test)\n)\n\nggplot(interval_data, aes(x = Time)) +\n  geom_ribbon(aes(ymin = Lower, ymax = Upper, fill = Scenario), alpha = 0.3) +\n  geom_line(aes(y = Forecast, color = Scenario), size = 1) +\n  geom_point(aes(y = Actual), color = \"black\", size = 2) +\n  geom_line(aes(y = Actual), color = \"black\", linetype = \"dashed\") +\n  facet_wrap(~Scenario, ncol = 1) +\n  theme_minimal() +\n  labs(title = \"Prediction Intervals: Coverage Comparison\",\n       subtitle = \"Black points show actual values\",\n       y = \"Insurance Quotes\", x = \"Time\")\n</pre>\n<p><img alt=\"image-title-here\" class=\"img-responsive\" data-lazy-src=\"https://i2.wp.com/thierrymoudiki.github.io/images/2025-12-11/2025-12-11-Counterfactual-Scenario-Analysis-with-ridge2f_4_1.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"image-title-here\" class=\"img-responsive\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/thierrymoudiki.github.io/images/2025-12-11/2025-12-11-Counterfactual-Scenario-Analysis-with-ridge2f_4_1.png?w=578&amp;ssl=1\"/></noscript></p>\n<p><img alt=\"image-title-here\" class=\"img-responsive\" data-lazy-src=\"https://i2.wp.com/thierrymoudiki.github.io/images/2025-12-11/2025-12-11-Counterfactual-Scenario-Analysis-with-ridge2f_4_0.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"image-title-here\" class=\"img-responsive\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/thierrymoudiki.github.io/images/2025-12-11/2025-12-11-Counterfactual-Scenario-Analysis-with-ridge2f_4_0.png?w=578&amp;ssl=1\"/></noscript></p>\n<pre># Multiple comparison correction\ncat(\"\\n=== STATISTICAL SIGNIFICANCE (with Bonferroni correction) ===\\n\")\nn_tests &lt;- 5\nalpha_corrected &lt;- 0.05 / n_tests\ncat(sprintf(\"Adjusted alpha level: %.4f (Bonferroni correction for %d tests)\\n\\n\",\n            alpha_corrected, n_tests))\n\n# Focus on the most relevant contrasts\ncontrasts &lt;- list(\n  \"Scenario A vs B\" = comparison$Diff_A_B,\n  \"Scenario A vs Baseline\" = comparison$Diff_A_Baseline,\n  \"Scenario B vs Baseline\" = comparison$Diff_B_Baseline\n)\n\nresults &lt;- data.frame(\n  Contrast = names(contrasts),\n  Mean_Diff = sapply(contrasts, mean),\n  SE = sapply(contrasts, function(x) sd(x)/sqrt(length(x))),\n  t_stat = NA,\n  p_value = NA,\n  CI_lower = NA,\n  CI_upper = NA,\n  Significant_at_0.05 = NA,\n  Significant_corrected = NA\n)\n\nfor(i in 1:nrow(results)) {\n  test &lt;- t.test(contrasts[[i]])\n  results$t_stat[i] &lt;- test$statistic\n  results$p_value[i] &lt;- test$p.value\n  results$CI_lower[i] &lt;- test$conf.int[1]\n  results$CI_upper[i] &lt;- test$conf.int[2]\n  results$Significant_at_0.05[i] &lt;- test$p.value &lt; 0.05\n  results$Significant_corrected[i] &lt;- test$p.value &lt; alpha_corrected\n}\n\n# Only round numeric columns for printing\nnumeric_cols_results &lt;- sapply(results, is.numeric)\nresults_display &lt;- results\nresults_display[, numeric_cols_results] &lt;- round(results_display[, numeric_cols_results], 4)\nprint(results_display)\n\n# Effect sizes (Cohen's d)\ncat(\"\\n=== EFFECT SIZES (Cohen's d) ===\\n\")\ncohens_d &lt;- function(x) {\n  mean(x) / sd(x)\n}\n\neffect_sizes &lt;- data.frame(\n  Contrast = names(contrasts),\n  Cohens_d = sapply(contrasts, cohens_d),\n  Interpretation = sapply(sapply(contrasts, cohens_d), function(d) {\n    abs_d &lt;- abs(d)\n    if(abs_d &lt; 0.2) \"negligible\"\n    else if(abs_d &lt; 0.5) \"small\"\n    else if(abs_d &lt; 0.8) \"medium\"\n    else \"large\"\n  })\n)\nprint(effect_sizes)\n\n# Paired comparisons if more appropriate\ncat(\"\\n=== PAIRWISE COMPARISONS ===\\n\")\ncat(\"Testing if forecast differences are consistently non-zero:\\n\\n\")\n\n# Wilcoxon signed-rank test (non-parametric alternative)\nfor(i in 1:length(contrasts)) {\n  cat(names(contrasts)[i], \":\\n\")\n  wilcox_test &lt;- wilcox.test(contrasts[[i]], alternative = \"two.sided\")\n  cat(sprintf(\"  Wilcoxon p-value: %.4f\\n\", wilcox_test$p.value))\n  cat(sprintf(\"  Median difference: %.4f\\n\\n\", median(contrasts[[i]])))\n}\n\n\n=== STATISTICAL SIGNIFICANCE (with Bonferroni correction) ===\nAdjusted alpha level: 0.0100 (Bonferroni correction for 5 tests)\n\n                                     Contrast Mean_Diff     SE  t_stat p_value\nScenario A vs B               Scenario A vs B   -0.0802 0.6702 -0.1196  0.9082\nScenario A vs Baseline Scenario A vs Baseline    0.2740 0.5549  0.4938  0.6366\nScenario B vs Baseline Scenario B vs Baseline    0.3542 0.6379  0.5552  0.5961\n                       CI_lower CI_upper Significant_at_0.05\nScenario A vs B         -1.6650   1.5047               FALSE\nScenario A vs Baseline  -1.0381   1.5861               FALSE\nScenario B vs Baseline  -1.1543   1.8626               FALSE\n                       Significant_corrected\nScenario A vs B                        FALSE\nScenario A vs Baseline                 FALSE\nScenario B vs Baseline                 FALSE\n\n=== EFFECT SIZES (Cohen's d) ===\n                                     Contrast    Cohens_d Interpretation\nScenario A vs B               Scenario A vs B -0.04228715     negligible\nScenario A vs Baseline Scenario A vs Baseline  0.17458895     negligible\nScenario B vs Baseline Scenario B vs Baseline  0.19628662     negligible\n\n=== PAIRWISE COMPARISONS ===\nTesting if forecast differences are consistently non-zero:\n\nScenario A vs B :\n  Wilcoxon p-value: 0.7422\n  Median difference: -0.3001\n\nScenario A vs Baseline :\n  Wilcoxon p-value: 0.9453\n  Median difference: -0.0923\n\nScenario B vs Baseline :\n  Wilcoxon p-value: 0.6406\n  Median difference: 0.0457\n</pre>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://thierrymoudiki.github.io//blog/2025/12/11/r/Counterfactual-Scenario-Analysis-with-ridge2f\"> T. Moudiki's Webpage - R</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
    "main_text": "Counterfactual Scenario Analysis with ahead::ridge2f\nPosted on\nDecember 10, 2025\nby\nT. Moudiki\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nT. Moudiki's Webpage - R\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nIn this post, we will explore how to perform counterfactual scenario analysis using the\nridge2f\nfunction from the\nahead\npackage in R.\nCounterfactual scenario analysis is a powerful tool for understanding the impact of different scenarios on time series data. It allows us to evaluate the performance of different models under different scenarios, and to compare the performance of different models under different scenarios.\nWe will use the\ninsurance\ndataset from the\nahead\npackage, which contains monthly data on insurance quotes and TV advertising.\nThe data set is split into three parts:\ntrain\n: historical data to learn from\nscenario\n: period where we apply “what-if” scenarios\ntest\n: true future where we evaluate forecasts\nThe\ntrain\ndata is used to fit the model, the\nscenario\ndata is used to generate counterfactual scenarios, and the\ntest\ndata is used to evaluate the performance of the model under the counterfactual scenarios.\ninstall.packages(\"remotes\")\ninstall.packages(\"gridExtra\")\n\nremotes::install_github(\"Techtonique/ahead\")\n\nurl <- \"https://raw.githubusercontent.com/Techtonique/datasets/refs/heads/main/time_series/multivariate/insurance_quotes_advert.csv\"\ninsurance <- read.csv(url)\n\ninsurance <- ts(insurance, start=c(2002, 1), frequency = 12L)\n\nlibrary(ahead)\nlibrary(ggplot2)\nlibrary(gridExtra)\n\ny <- insurance[, \"Quotes\"]\nTV <- insurance[, \"TV.advert\"]\nt  <- as.numeric(time(insurance))\nT <- length(y)\n\n# ========== 3-PART SPLIT ==========\n# TRAIN: Historical data to learn from\n# SCENARIO: Period where we apply \"what-if\" scenarios\n# TEST: True future where we evaluate forecasts\n\ntrain_pct <- 0.50\nscenario_pct <- 0.30\n# test_pct <- 0.20 (remainder)\n\ntrain_end <- floor(train_pct * T)\nscenario_end <- floor((train_pct + scenario_pct) * T)\n\n# Split data\ny_train <- y[1:train_end]\ny_scenario <- y[(train_end + 1):scenario_end]\ny_test <- y[(scenario_end + 1):T]\n\nTV_train <- TV[1:train_end]\nTV_scenario <- TV[(train_end + 1):scenario_end]\nTV_test <- TV[(scenario_end + 1):T]\n\nt_train <- t[1:train_end]\nt_scenario <- t[(train_end + 1):scenario_end]\nt_test <- t[(scenario_end + 1):T]\n\nh_test <- length(y_test)\n\ncat(\"\\n=== 3-PART DATA SPLIT ===\\n\")\ncat(\"TRAIN:    periods\", 1, \"to\", train_end, \"(n =\", train_end, \")\\n\")\ncat(\"SCENARIO: periods\", train_end + 1, \"to\", scenario_end, \"(n =\", length(y_scenario), \")\\n\")\ncat(\"TEST:     periods\", scenario_end + 1, \"to\", T, \"(n =\", h_test, \")\\n\\n\")\n\n# ========== THE KEY INSIGHT ==========\ncat(\"=== THE APPROACH ===\\n\")\ncat(\"1. Train on: TRAIN data only\\n\")\ncat(\"2. Apply scenarios to: SCENARIO period (with actual y values)\\n\")\ncat(\"3. Forecast into: TEST period (what we're evaluating)\\n\")\ncat(\"4. Compare: How do different SCENARIO assumptions affect TEST forecasts?\\n\\n\")\n\n# ========== DEFINE SCENARIOS ==========\n# Baseline: TV advertising unchanged\n# Scenario A: TV advertising was +1 higher during scenario period\n# Scenario B: TV advertising was -1 lower during scenario period\n\nTV_scenario_A <- TV_scenario + 1\nTV_scenario_B <- TV_scenario - 1\n\ncat(\"=== SCENARIOS ===\\n\")\ncat(\"Scenario A: TV during scenario period = actual +1\\n\")\ncat(\"Scenario B: TV during scenario period = actual -1\\n\")\ncat(\"(We're asking: 'What if TV had been different in the recent past?')\\n\\n\")\n\n# ========== BUILD TRAINING DATA WITH SCENARIOS ==========\n\n# For Baseline scenario\ny_train_Baseline <- c(y_train, y_scenario)\nxreg_train_Baseline <- rbind(\n  cbind(TV = TV_train, trend = t_train),\n  cbind(TV = TV_scenario, trend = t_scenario)\n)\n\n# For Scenario A: combine TRAIN + SCENARIO (with modified TV)\ny_train_A <- y_train_Baseline\nxreg_train_A <- rbind(\n  cbind(TV = TV_train, trend = t_train),\n  cbind(TV = TV_scenario_A, trend = t_scenario)\n)\n\n# For Scenario B: combine TRAIN + SCENARIO (with different TV)\ny_train_B <- y_train_Baseline\nxreg_train_B <- rbind(\n  cbind(TV = TV_train, trend = t_train),\n  cbind(TV = TV_scenario_B, trend = t_scenario)\n)\n\n# ========== FIT MODELS ==========\n\ncat(\"Fitting Scenario A model...\\n\")\nset.seed(123)\nres_Baseline <- ridge2f(\n  y_train_Baseline,\n  h = h_test,\n  xreg = xreg_train_Baseline,\n  lags = 5,\n  type_pi = \"blockbootstrap\",\n  B = 200\n)\n\ncat(\"Fitting Scenario A model...\\n\")\nset.seed(123)\nres_A <- ridge2f(\n  y_train_A,\n  h = h_test,\n  xreg = xreg_train_A,\n  lags = 5,\n  type_pi = \"blockbootstrap\",\n  B = 200\n)\n\ncat(\"Fitting Scenario B model...\\n\")\nset.seed(123)\nres_B <- ridge2f(\n  y_train_B,\n  h = h_test,\n  xreg = xreg_train_B,\n  lags = 5,\n  type_pi = \"blockbootstrap\",\n  B = 200\n)\n\n# ========== COMPARISON TABLE ==========\ncomparison <- data.frame(\n  Period = time(y_test),\n  Actual = as.numeric(y_test),\n  Forecast_Baseline = as.numeric(res_Baseline$mean),\n  Forecast_A = as.numeric(res_A$mean),\n  Forecast_B = as.numeric(res_B$mean),\n  Diff_A_B = as.numeric(res_A$mean) - as.numeric(res_B$mean),\n  Diff_A_Baseline = as.numeric(res_A$mean) - as.numeric(res_Baseline$mean),\n  Diff_B_Baseline = as.numeric(res_B$mean) - as.numeric(res_Baseline$mean),\n  Impact_A = as.numeric(res_A$mean) - as.numeric(y_test),\n  Impact_B = as.numeric(res_B$mean) - as.numeric(y_test),\n  Lower_A = as.numeric(res_A$lower),\n  Upper_A = as.numeric(res_A$upper),\n  Lower_B = as.numeric(res_B$lower),\n  Upper_B = as.numeric(res_B$upper)\n)\n\ncat(\"\\n=== TEST PERIOD FORECASTS ===\\n\")\nprint(round(comparison, 2))\n\n# ========== SCENARIO IMPACT ==========\n\ncolnames_comparison <- colnames(comparison)\nprint(summary(comparison[, 6:10]))\nfor (i in 6:10)\n{\n  print(colnames_comparison[i])\n  print(t.test(comparison[, i]))\n}\n\n# ========== COVERAGE ANALYSIS ==========\nin_A <- sum(comparison$Actual >= comparison$Lower_A &\n              comparison$Actual <= comparison$Upper_A)\nin_B <- sum(comparison$Actual >= comparison$Lower_B &\n              comparison$Actual <= comparison$Upper_B)\ncoverage_A <- in_A / h_test * 100\ncoverage_B <- in_B / h_test * 100\n\ncat(\"\\n=== PREDICTION INTERVAL COVERAGE ===\\n\")\ncat(sprintf(\"Scenario A: %.1f%% (%d/%d)\\n\", coverage_A, in_A, h_test))\ncat(sprintf(\"Scenario B: %.1f%% (%d/%d)\\n\", coverage_B, in_B, h_test))\n\n# ========== PLOTS ==========\n\n=== 3-PART DATA SPLIT ===\nTRAIN:    periods 1 to 20 (n = 20 )\nSCENARIO: periods 21 to 32 (n = 12 )\nTEST:     periods 33 to 40 (n = 8 )\n\n=== THE APPROACH ===\n1. Train on: TRAIN data only\n2. Apply scenarios to: SCENARIO period (with actual y values)\n3. Forecast into: TEST period (what we're evaluating)\n4. Compare: How do different SCENARIO assumptions affect TEST forecasts?\n\n=== SCENARIOS ===\nScenario A: TV during scenario period = actual +1\nScenario B: TV during scenario period = actual -1\n(We're asking: 'What if TV had been different in the recent past?')\n\nFitting Scenario A model...\n  |======================================================================| 100%\nFitting Scenario A model...\n  |======================================================================| 100%\nFitting Scenario B model...\n  |======================================================================| 100%\n\n=== TEST PERIOD FORECASTS ===\n  Period Actual Forecast_Baseline Forecast_A Forecast_B Diff_A_B\n1      1  12.86             12.44      12.08      12.49    -0.42\n2      2  12.09             12.16      11.43      12.75    -1.33\n3      3  12.93             11.49      10.29      11.53    -1.24\n4      4  11.72             10.70       9.23       9.41    -0.19\n5      5  15.47             10.93      11.11       8.83     2.28\n6      6  18.44             11.47      14.21      11.22     2.99\n7      7  17.49             12.03      14.38      14.36     0.02\n8      8  14.49             12.59      13.28      16.04    -2.76\n  Diff_A_Baseline Diff_B_Baseline Impact_A Impact_B Lower_A Upper_A Lower_B\n1           -0.36            0.05    -0.78    -0.37   10.97   12.80   10.50\n2           -0.74            0.59    -0.66     0.66   10.51   12.12   10.58\n3           -1.20            0.04    -2.64    -1.40    7.65   12.97    9.90\n4           -1.47           -1.28    -2.50    -2.31    6.77   11.75    6.25\n5            0.18           -2.10    -4.36    -6.64    8.64   13.69    5.16\n6            2.74           -0.24    -4.23    -7.21   10.70   18.00    6.87\n7            2.35            2.33    -3.11    -3.13   11.35   19.12    9.14\n8            0.69            3.45    -1.21     1.54   10.56   17.72   12.62\n  Upper_B\n1   13.81\n2   15.34\n3   13.73\n4   12.89\n5   12.38\n6   15.08\n7   19.60\n8   20.18\n    Diff_A_B        Diff_A_Baseline    Diff_B_Baseline       Impact_A      \n Min.   :-2.75662   Min.   :-1.46811   Min.   :-2.10057   Min.   :-4.3592  \n 1st Qu.:-1.26217   1st Qu.:-0.85445   1st Qu.:-0.50317   1st Qu.:-3.3915  \n Median :-0.30014   Median :-0.09231   Median : 0.04573   Median :-2.5692  \n Mean   :-0.08017   Mean   : 0.27400   Mean   : 0.35417   Mean   :-2.4371  \n 3rd Qu.: 0.58402   3rd Qu.: 1.10542   3rd Qu.: 1.02461   3rd Qu.:-1.1051  \n Max.   : 2.98501   Max.   : 2.74174   Max.   : 3.44581   Max.   :-0.6627  \n    Impact_B      \n Min.   :-7.2143  \n 1st Qu.:-4.0080  \n Median :-1.8562  \n Mean   :-2.3569  \n 3rd Qu.:-0.1095  \n Max.   : 1.5440  \n[1] \"Diff_A_B\"\n\n\tOne Sample t-test\n\ndata:  comparison[, i]\nt = -0.11961, df = 7, p-value = 0.9082\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -1.665035  1.504705\nsample estimates:\n  mean of x \n-0.08016502 \n\n[1] \"Diff_A_Baseline\"\n\n\tOne Sample t-test\n\ndata:  comparison[, i]\nt = 0.49381, df = 7, p-value = 0.6366\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -1.038059  1.586063\nsample estimates:\nmean of x \n0.2740019 \n\n[1] \"Diff_B_Baseline\"\n\n\tOne Sample t-test\n\ndata:  comparison[, i]\nt = 0.55518, df = 7, p-value = 0.5961\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -1.154295  1.862629\nsample estimates:\nmean of x \n0.3541669 \n\n[1] \"Impact_A\"\n\n\tOne Sample t-test\n\ndata:  comparison[, i]\nt = -4.7416, df = 7, p-value = 0.002104\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -3.652457 -1.221723\nsample estimates:\nmean of x \n -2.43709 \n\n[1] \"Impact_B\"\n\n\tOne Sample t-test\n\ndata:  comparison[, i]\nt = -2.0825, df = 7, p-value = 0.07581\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -5.0332109  0.3193609\nsample estimates:\nmean of x \n-2.356925 \n\n=== PREDICTION INTERVAL COVERAGE ===\nScenario A: 62.5% (5/8)\nScenario B: 75.0% (6/8)\n\nlibrary(ggplot2)\nlibrary(tidyr)\n\ndf_long <- comparison[, 6:10] %>%\n  pivot_longer(cols = everything(),\n               names_to = \"Variable\",\n               values_to = \"Value\")\n\n# Create violin plot\nggplot(df_long, aes(x = Variable, y = Value, fill = Variable)) +\n  geom_violin(trim = FALSE) +\n  geom_jitter(width = 0.1, size = 1, alpha = 0.7) + # optional: show individual points\n  theme_minimal() +\n  labs(title = \"Violin Plot of Comparison Columns\",\n       y = \"Value\",\n       x = \"Variable\")\n\n# 1. Time series plot showing the full picture\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Combine all periods for context\nfull_data <- data.frame(\n  Time = c(t_train, t_scenario, time(y_test)),\n  Actual = c(y_train, y_scenario, y_test),\n  Period = c(rep(\"Train\", length(y_train)), \n             rep(\"Scenario\", length(y_scenario)),\n             rep(\"Test\", length(y_test)))\n)\n\nforecast_data <- data.frame(\n  Time = rep(time(y_test), 3),\n  Forecast = c(res_Baseline$mean, res_A$mean, res_B$mean),\n  Scenario = rep(c(\"Baseline\", \"TV +1\", \"TV -1\"), each = h_test)\n)\n\nggplot() +\n  geom_line(data = full_data, aes(x = Time, y = Actual), color = \"black\", size = 1) +\n  geom_vline(xintercept = t_scenario[1], linetype = \"dashed\", color = \"gray50\", alpha = 0.7) +\n  geom_vline(xintercept = time(y_test)[1], linetype = \"dashed\", color = \"gray50\", alpha = 0.7) +\n  geom_line(data = forecast_data, aes(x = Time, y = Forecast, color = Scenario), size = 1) +\n  annotate(\"text\", x = mean(t_train), y = max(full_data$Actual), label = \"TRAIN\") +\n  annotate(\"text\", x = mean(t_scenario), y = max(full_data$Actual), label = \"SCENARIO\") +\n  annotate(\"text\", x = mean(time(y_test)), y = max(full_data$Actual), label = \"TEST\") +\n  theme_minimal() +\n  labs(title = \"Counterfactual Forecasts: How Past TV Changes Affect Future Predictions\",\n       subtitle = \"Different scenario assumptions in the recent past lead to different test forecasts\",\n       y = \"Insurance Quotes\", x = \"Time\") +\n  scale_color_manual(values = c(\"Baseline\" = \"blue\", \"TV +1\" = \"red\", \"TV -1\" = \"green\"))\n\n# 2. Forecast difference plot (shows the impact more clearly)\ndiff_data <- data.frame(\n  Time = time(y_test),\n  Diff_A_vs_Baseline = res_A$mean - res_Baseline$mean,\n  Diff_B_vs_Baseline = res_B$mean - res_Baseline$mean,\n  Diff_A_vs_B = res_A$mean - res_B$mean\n) %>%\n  pivot_longer(cols = -Time, names_to = \"Comparison\", values_to = \"Difference\")\n\nggplot(diff_data, aes(x = Time, y = Difference, color = Comparison)) +\n  geom_line(size = 1) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray50\") +\n  theme_minimal() +\n  labs(title = \"Forecast Differences: Impact of Counterfactual Scenarios\",\n       subtitle = \"How much do forecasts change under different scenario assumptions?\",\n       y = \"Difference in Forecasts\", x = \"Time\")\n\n# 3. Prediction interval comparison\ninterval_data <- data.frame(\n  Time = rep(time(y_test), 2),\n  Actual = rep(y_test, 2),\n  Forecast = c(res_A$mean, res_B$mean),\n  Lower = c(res_A$lower, res_B$lower),\n  Upper = c(res_A$upper, res_B$upper),\n  Scenario = rep(c(\"TV +1\", \"TV -1\"), each = h_test)\n)\n\nggplot(interval_data, aes(x = Time)) +\n  geom_ribbon(aes(ymin = Lower, ymax = Upper, fill = Scenario), alpha = 0.3) +\n  geom_line(aes(y = Forecast, color = Scenario), size = 1) +\n  geom_point(aes(y = Actual), color = \"black\", size = 2) +\n  geom_line(aes(y = Actual), color = \"black\", linetype = \"dashed\") +\n  facet_wrap(~Scenario, ncol = 1) +\n  theme_minimal() +\n  labs(title = \"Prediction Intervals: Coverage Comparison\",\n       subtitle = \"Black points show actual values\",\n       y = \"Insurance Quotes\", x = \"Time\")\n# Multiple comparison correction\ncat(\"\\n=== STATISTICAL SIGNIFICANCE (with Bonferroni correction) ===\\n\")\nn_tests <- 5\nalpha_corrected <- 0.05 / n_tests\ncat(sprintf(\"Adjusted alpha level: %.4f (Bonferroni correction for %d tests)\\n\\n\",\n            alpha_corrected, n_tests))\n\n# Focus on the most relevant contrasts\ncontrasts <- list(\n  \"Scenario A vs B\" = comparison$Diff_A_B,\n  \"Scenario A vs Baseline\" = comparison$Diff_A_Baseline,\n  \"Scenario B vs Baseline\" = comparison$Diff_B_Baseline\n)\n\nresults <- data.frame(\n  Contrast = names(contrasts),\n  Mean_Diff = sapply(contrasts, mean),\n  SE = sapply(contrasts, function(x) sd(x)/sqrt(length(x))),\n  t_stat = NA,\n  p_value = NA,\n  CI_lower = NA,\n  CI_upper = NA,\n  Significant_at_0.05 = NA,\n  Significant_corrected = NA\n)\n\nfor(i in 1:nrow(results)) {\n  test <- t.test(contrasts[[i]])\n  results$t_stat[i] <- test$statistic\n  results$p_value[i] <- test$p.value\n  results$CI_lower[i] <- test$conf.int[1]\n  results$CI_upper[i] <- test$conf.int[2]\n  results$Significant_at_0.05[i] <- test$p.value < 0.05\n  results$Significant_corrected[i] <- test$p.value < alpha_corrected\n}\n\n# Only round numeric columns for printing\nnumeric_cols_results <- sapply(results, is.numeric)\nresults_display <- results\nresults_display[, numeric_cols_results] <- round(results_display[, numeric_cols_results], 4)\nprint(results_display)\n\n# Effect sizes (Cohen's d)\ncat(\"\\n=== EFFECT SIZES (Cohen's d) ===\\n\")\ncohens_d <- function(x) {\n  mean(x) / sd(x)\n}\n\neffect_sizes <- data.frame(\n  Contrast = names(contrasts),\n  Cohens_d = sapply(contrasts, cohens_d),\n  Interpretation = sapply(sapply(contrasts, cohens_d), function(d) {\n    abs_d <- abs(d)\n    if(abs_d < 0.2) \"negligible\"\n    else if(abs_d < 0.5) \"small\"\n    else if(abs_d < 0.8) \"medium\"\n    else \"large\"\n  })\n)\nprint(effect_sizes)\n\n# Paired comparisons if more appropriate\ncat(\"\\n=== PAIRWISE COMPARISONS ===\\n\")\ncat(\"Testing if forecast differences are consistently non-zero:\\n\\n\")\n\n# Wilcoxon signed-rank test (non-parametric alternative)\nfor(i in 1:length(contrasts)) {\n  cat(names(contrasts)[i], \":\\n\")\n  wilcox_test <- wilcox.test(contrasts[[i]], alternative = \"two.sided\")\n  cat(sprintf(\"  Wilcoxon p-value: %.4f\\n\", wilcox_test$p.value))\n  cat(sprintf(\"  Median difference: %.4f\\n\\n\", median(contrasts[[i]])))\n}\n\n=== STATISTICAL SIGNIFICANCE (with Bonferroni correction) ===\nAdjusted alpha level: 0.0100 (Bonferroni correction for 5 tests)\n\n                                     Contrast Mean_Diff     SE  t_stat p_value\nScenario A vs B               Scenario A vs B   -0.0802 0.6702 -0.1196  0.9082\nScenario A vs Baseline Scenario A vs Baseline    0.2740 0.5549  0.4938  0.6366\nScenario B vs Baseline Scenario B vs Baseline    0.3542 0.6379  0.5552  0.5961\n                       CI_lower CI_upper Significant_at_0.05\nScenario A vs B         -1.6650   1.5047               FALSE\nScenario A vs Baseline  -1.0381   1.5861               FALSE\nScenario B vs Baseline  -1.1543   1.8626               FALSE\n                       Significant_corrected\nScenario A vs B                        FALSE\nScenario A vs Baseline                 FALSE\nScenario B vs Baseline                 FALSE\n\n=== EFFECT SIZES (Cohen's d) ===\n                                     Contrast    Cohens_d Interpretation\nScenario A vs B               Scenario A vs B -0.04228715     negligible\nScenario A vs Baseline Scenario A vs Baseline  0.17458895     negligible\nScenario B vs Baseline Scenario B vs Baseline  0.19628662     negligible\n\n=== PAIRWISE COMPARISONS ===\nTesting if forecast differences are consistently non-zero:\n\nScenario A vs B :\n  Wilcoxon p-value: 0.7422\n  Median difference: -0.3001\n\nScenario A vs Baseline :\n  Wilcoxon p-value: 0.9453\n  Median difference: -0.0923\n\nScenario B vs Baseline :\n  Wilcoxon p-value: 0.6406\n  Median difference: 0.0457\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nT. Moudiki's Webpage - R\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "meta_description": "Counterfactual Scenario Analysis with ahead::ridge2f",
    "meta_keywords": null,
    "og_description": "Counterfactual Scenario Analysis with ahead::ridge2f",
    "og_image": "https://thierrymoudiki.github.io/images/2025-12-11/2025-12-11-Counterfactual-Scenario-Analysis-with-ridge2f_4_1.png",
    "og_title": "Counterfactual Scenario Analysis with ahead::ridge2f | R-bloggers",
    "raw_jsonld_article": null,
    "reading_time_min": 12.7,
    "sitemap_lastmod": null,
    "twitter_description": "Counterfactual Scenario Analysis with ahead::ridge2f",
    "twitter_title": "Counterfactual Scenario Analysis with ahead::ridge2f | R-bloggers",
    "url": "https://www.r-bloggers.com/2025/12/counterfactual-scenario-analysis-with-aheadridge2f/",
    "word_count": 2548
  }
}