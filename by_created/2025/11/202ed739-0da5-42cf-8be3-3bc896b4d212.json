{
  "uuid": "202ed739-0da5-42cf-8be3-3bc896b4d212",
  "created_at": "2025-11-22 19:59:08",
  "raw_json": {
    "article_author": null,
    "article_headline": null,
    "article_modified": null,
    "article_published": null,
    "article_section": null,
    "article_tags": null,
    "canonical_url": "https://www.r-bloggers.com/2025/03/bootstrap-vs-standard-error-confidence-intervals-2/",
    "crawled_at": "2025-11-22T10:53:00.805849",
    "external_links": [
      {
        "href": "https://bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error.html",
        "text": "Jason Bryer"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error.html",
        "text": "Jason Bryer"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "h1_title": "R-bloggers",
    "html_title": "Bootstrap vs Standard Error Confidence Intervals | R-bloggers",
    "images": [
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAE8AAAAmBAMAAAB34dsnAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMARIl2ZiJU75ndu6vNMhBVgMKNAAAACXBIWXMAAA7EAAAOxAGVKw4bAAABiUlEQVQ4EY2TPUjDUBSFv6RprC3ViovgYI0iiIMdxE3M4CIOKrg52MmpCAWR4lS6C90F7ewgFXEQl+LgpBhFEFRwcXKqu3+31rTVpi+5kNzzzvm4XB4J+NTc3JIPUY9NW7fryuetX/X4EL9xeH8rGEh4Mhh4QVcwsEx/MLBv3W6A2sjoCoznrIlcw/MUY2hZiJZgwDN3TS0PRehNQcj1PHvEhiQ8O2B6Aq4ZLcMSzGK4Toduvs/UkgNWOwAN++FrT/S2df7jRM5qlWykrULbhfAHN62e6K/WkrPslwGjikP6H/rnGE/AIMQqMlUJhiQ9gq4kRJDquKPcjpGCNRls1cC2uvtZtYquW8OgXxes0882qGYcerrtZjzf7nk6UbmVQPUYiBLoJCAYLmNOvSw4vnjEYfneNku+4Cuk5wmVleCTpDvyFIilVKC2aNNTEiJLr/qOYkX0hHwrVTKaaiLxN2RFjAoFn9/kkmkBQza3G8qJDDkVNeCm3cdpV6q78a7Om+lmU6qV04y/Af4IWIni275MAAAAAElFTkSuQmCC",
        "src": "https://latex.codecogs.com/png.latex?SE%20=%20%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i1.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-3-1.png?w=450&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i0.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-6-1.png?w=578&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i0.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-6-2.png?w=578&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i2.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-7-1.png?w=450&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i1.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-9-1.png?w=578&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i2.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-9-2.png?w=578&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAE8AAAAmBAMAAAB34dsnAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMARIl2ZiJU75ndu6vNMhBVgMKNAAAACXBIWXMAAA7EAAAOxAGVKw4bAAABiUlEQVQ4EY2TPUjDUBSFv7Tpjw21HQUFaxRBXDpIN7GrOKggODiYWYpQcCgOUroL3QUNuDlIRQTFpTgLRhEEFVx0caqTS7W+FNsUkr6+CyHnnfNxc3NJQF76UetbTvynlx/HSpxuM6YExhy2lMB1qCiB4rl7SmAMw1ICk7l5j9Mmp9ZgpmTOljwzSE2jFSFhw0hQ3PW0MlQhlYVw1wwS8Txk4M2BaFDe9RI1WIEF9K4VLKLN9oudsBGce+5z61Acds2bthW/divjxT1KO4DID/c9litbvSXOYr4C6A0cLDfvV8k0jIJRF12tfpDrhy04g1gG4ojqO6PYjp6FTdHYdEFfPbZHbRAKmRMQuquYV78+yDVOA12/mSz7vUAnIbaiVC9KlIAuFMFIjejc+5IzEI87rD7lo/ZA8BOsRcI1Kfgq0n1xVTCyMlBbzjNsC6JISr4jo0ooLb6VBgVN1pHkF2JE9DqVAb/JLTkBhvM8bEs7Mu7U5UAnHTq3OlJ+15vy3Et3PClXjhf/AWE6W/Yjp2QpAAAAAElFTkSuQmCC",
        "src": "https://latex.codecogs.com/png.latex?%20SE%20=%20%5Cfrac%7B%5Csigma%7D%7B%5Csqrt%7Bn%7D%7D%20"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i2.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-13-1.png?w=450&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i0.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-15-1.png?w=450&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i0.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-16-1.png?w=450&ssl=1"
      }
    ],
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/jason-bryer/",
        "text": "Jason Bryer"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "lang": "en-US",
    "main_html": "<article class=\"post-391404 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Bootstrap vs Standard Error Confidence Intervals</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">March 11, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/jason-bryer/\">Jason Bryer</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error.html\"> Jason Bryer</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<p>A student recently asked whether bootstrap confidence intervals were more robust than confidence intervals estimated using the standard error (i.e. <img data-lazy-src=\"https://latex.codecogs.com/png.latex?SE%20=%20%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?SE%20=%20%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D\"/></noscript>). In order to answer this question I wrote a function to simulate taking a bunch of random samples from a population, calculate the confidence interval for that sample using the standard error approach (the <em>t</em> distribution is used by default, see the <code>cv</code> parameter. To use the normal distribution, for example, set <code>cv = 1.96</code>.), and then also calculating a confidence interval using the boostrap.</p>\n<div class=\"cell\">\n<pre>library(dplyr)\nlibrary(ggplot2)\n\n#' Simulate random samples to estimate confidence intervals and bootstrap\n#' estimates.\n#'\n#' @param pop a numeric vector representing the population.\n#' @param n sample size for each random sample from the population.\n#' @param n_samples the number of random samples.\n#' @param n_boot number of bootstrap samples to take for each sample.\n#' @param seed a seed to use for the random process.\n#' @param cv critical value to use for calculating confidence intervals.\n#' @return a data.frame with the sample and bootstrap mean and confidence\n#'        intervals along with a logical variable indicating whether a Type I\n#'        error would have occurred with that sample.\nbootstrap_clt_simulation &lt;- function(\n        pop,\n        n = 30,\n        n_samples = 500,\n        n_boot = 500,\n        cv = abs(qt(0.025, df = n - 1)),\n        seed,\n        verbose = interactive()\n) {\n    if(missing(seed)) {\n        seed &lt;- sample(100000)\n    }\n    results &lt;- data.frame(\n        seed = 1:n_samples,\n        samp_mean = numeric(n_samples),\n        samp_se = numeric(n_samples),\n        samp_ci_low = numeric(n_samples),\n        samp_ci_high = numeric(n_samples),\n        samp_type1 = logical(n_samples),\n        boot_mean = numeric(n_samples),\n        boot_ci_low = numeric(n_samples),\n        boot_ci_high = numeric(n_samples),\n        boot_type1 = logical(n_samples)\n    )\n    if(verbose) {\n        pb &lt;- txtProgressBar(min = 0, max = n_samples, style = 3)\n    }\n    for(i in 1:n_samples) {\n        if(verbose) {\n            setTxtProgressBar(pb, i)\n        }\n        set.seed(seed + i)\n        samp &lt;- sample(pop, size = n)\n        boot_samp &lt;- numeric(n_boot)\n        for(j in 1:n_boot) {\n            boot_samp[j] &lt;- sample(samp, size = length(samp), replace = TRUE) |&gt;\n                mean()\n        }\n        results[i,]$seed &lt;- seed + i\n        results[i,]$samp_mean &lt;- mean(samp)\n        results[i,]$samp_se &lt;- sd(samp) / sqrt(length(samp))\n        results[i,]$samp_ci_low &lt;- mean(samp) - cv * results[i,]$samp_se\n        results[i,]$samp_ci_high &lt;- mean(samp) + cv * results[i,]$samp_se\n        results[i,]$samp_type1 &lt;- results[i,]$samp_ci_low &gt; mean(pop) |\n            mean(pop) &gt; results[i,]$samp_ci_high\n        results[i,]$boot_mean &lt;- mean(boot_samp)\n        results[i,]$boot_ci_low &lt;- mean(boot_samp) - cv * sd(boot_samp)\n        results[i,]$boot_ci_high &lt;- mean(boot_samp) + cv * sd(boot_samp)\n        results[i,]$boot_type1 &lt;- results[i,]$boot_ci_low &gt; mean(pop) |\n            mean(pop) &gt; results[i,]$boot_ci_high\n    }\n    if(verbose) {\n        close(pb)\n    }\n    return(results)\n}</pre>\n</div>\n<p><strong>Uniform distribution for the population</strong></p>\n<p>Let’s start with a uniform distribution for our population.</p>\n<div class=\"cell\">\n<pre>pop_unif &lt;- runif(1e5, 0, 1)\nggplot(data.frame(x = pop_unif), aes(x = x)) + geom_density()</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i1.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-3-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-3-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<p>The mean of the population is 0.5008915. We can now simulate samples and their corresponding bootstrap estimates.</p>\n<div class=\"cell\">\n<pre>results_unif &lt;- bootstrap_clt_simulation(pop = pop_unif, seed = 42, verbose = FALSE)</pre>\n</div>\n<p>5.8% of our samples did not contain the population mean in the confidence interval (i.e. Type I error rate) compared to <code>r</code>mean(results_unif$boot_type1) * 100`% of the bootstrap estimates. The following table compares the Type I errors for each sample compared to the bootstrap estiamted from that sample.</p>\n<div class=\"cell\">\n<pre>tab &lt;- table(results_unif$samp_type1, results_unif$boot_type1, useNA = 'ifany')\ntab</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>       \n        FALSE TRUE\n  FALSE   470    1\n  TRUE      1   28</pre>\n</div>\n</div>\n<p>In general committing a type I error is the same regardless of method, though there were 1 instances where the bootstrap would have led to a type I error rate where the standard error approach would not.</p>\n<p>The following plots show the relationship between the estimated mean (left) and condifence interval width (right) for each sample and its corresponding bootstrap.</p>\n<pre>results_unif |&gt;\n    ggplot(aes(x = samp_mean, y = boot_mean)) +\n    geom_vline(xintercept = mean(pop_unif), color = 'blue') +\n    geom_hline(yintercept = mean(pop_unif), color = 'blue') +\n    geom_abline() +\n    geom_point() +\n    ggtitle(\"Sample mean vs bootstrap mean\")\nresults_unif |&gt;\n    dplyr::mutate(samp_ci_width = samp_ci_high - samp_ci_low,\n                  boot_ci_width = boot_ci_high - boot_ci_low) |&gt;\n    ggplot(aes(x = samp_ci_width, y = boot_ci_width)) +\n    geom_abline() +\n    geom_point() +\n    ggtitle('Sample vs boostrap confidence interval width')</pre>\n<div class=\"cell quarto-layout-panel\" data-layout-ncol=\"2\">\n<div class=\"quarto-layout-row\">\n<div class=\"quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<p><img class=\"img-fluid\" data-lazy-src=\"https://i0.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-6-1.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-6-1.png?w=578&amp;ssl=1\"/></noscript></p>\n</div>\n<div class=\"quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<p><img class=\"img-fluid\" data-lazy-src=\"https://i0.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-6-2.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-6-2.png?w=578&amp;ssl=1\"/></noscript></p>\n</div>\n</div>\n</div>\n<p><strong>Skewed distribution for the population</strong></p>\n<p>We will repeat the same analysis using a positively skewed distribution.</p>\n<div class=\"cell\">\n<pre>pop_skewed &lt;- rnbinom(1e5, 3, .5)\nggplot(data.frame(x = pop_skewed), aes(x = x)) + geom_density(bw = 0.75)</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i2.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-7-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-7-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<p>The mean of the population for this distribution is 2.99792</p>\n<div class=\"cell\">\n<pre>results_skewed &lt;- bootstrap_clt_simulation(pop = pop_skewed, seed = 42, verbose = FALSE)\nmean(results_skewed$samp_type1) # Percent of samples with Type I error</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 0.05</pre>\n</div>\n<pre>mean(results_skewed$boot_type1) # Percent of bootstrap estimates with Type I error</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 0.052</pre>\n</div>\n<pre># CLT vs Bootstrap Type I error rate\ntable(results_skewed$samp_type1, results_skewed$boot_type1, useNA = 'ifany')</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>       \n        FALSE TRUE\n  FALSE   473    2\n  TRUE      1   24</pre>\n</div>\n</div>\n<pre>results_skewed |&gt;\n    ggplot(aes(x = samp_mean, y = boot_mean)) +\n    geom_vline(xintercept = mean(pop_skewed), color = 'blue') +\n    geom_hline(yintercept = mean(pop_skewed), color = 'blue') +\n    geom_abline() +\n    geom_point() +\n    ggtitle(\"Sample mean vs bootstrap mean\")\nresults_skewed |&gt;\n    dplyr::mutate(samp_ci_width = samp_ci_high - samp_ci_low,\n                  boot_ci_width = boot_ci_high - boot_ci_low) |&gt;\n    ggplot(aes(x = samp_ci_width, y = boot_ci_width)) +\n    geom_abline() +\n    geom_point() +\n    ggtitle('Sample vs boostrap confidence interval width')</pre>\n<div class=\"cell quarto-layout-panel\" data-layout-ncol=\"2\">\n<div class=\"quarto-layout-row\">\n<div class=\"quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<p><img class=\"img-fluid\" data-lazy-src=\"https://i1.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-9-1.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-9-1.png?w=578&amp;ssl=1\"/></noscript></p>\n</div>\n<div class=\"quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<p><img class=\"img-fluid\" data-lazy-src=\"https://i2.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-9-2.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-9-2.png?w=578&amp;ssl=1\"/></noscript></p>\n</div>\n</div>\n</div>\n<p>We can see the results are very similar to that of the uniform distirubtion. Exploring the one case where the bootstrap would have resulted in a Type I error where the standard error approach would not reveals that it is very close with the difference being less than 0.1.</p>\n<div class=\"cell\">\n<pre>results_differ &lt;- results_skewed |&gt;\n    dplyr::filter(!samp_type1 &amp; boot_type1)\nresults_differ</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>  seed samp_mean   samp_se samp_ci_low samp_ci_high samp_type1 boot_mean\n1  443  3.866667 0.4516466    2.942946     4.790388      FALSE  3.924733\n2  474  3.933333 0.4816956    2.948155     4.918511      FALSE  3.956800\n  boot_ci_low boot_ci_high boot_type1\n1    3.044802     4.804665       TRUE\n2    3.018549     4.895051       TRUE</pre>\n</div>\n</div>\n<div class=\"cell\">\n<pre>set.seed(results_differ[1,]$seed)\nsamp &lt;- sample(pop_skewed, size = 30)\nboot_samp &lt;- numeric(500)\nfor(j in 1:500) {\n    boot_samp[j] &lt;- sample(samp, size = length(samp), replace = TRUE) |&gt;\n        mean()\n}\ncv = abs(qt(0.025, df = 30 - 1))\nmean(pop_skewed)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 2.99792</pre>\n</div>\n<pre>ci &lt;- c(mean(samp) - cv * sd(samp) / sqrt(30), mean(samp) + cv * sd(samp) / sqrt(30))\nci</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 2.942946 4.790388</pre>\n</div>\n<pre>mean(pop_skewed) &lt; ci[1] | mean(pop_skewed) &gt; ci[2]</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] FALSE</pre>\n</div>\n<pre>ci_boot &lt;- c(mean(boot_samp) - cv * sd(boot_samp), mean(boot_samp) + cv * sd(boot_samp))\nci_boot</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 3.044802 4.804665</pre>\n</div>\n<pre>mean(pop_skewed) &lt; ci_boot[1] | mean(pop_skewed) &gt; ci_boot[2]</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] TRUE</pre>\n</div>\n</div>\n<section class=\"level3\" id=\"adding-an-outlier\">\n<h3 class=\"anchored\" data-anchor-id=\"adding-an-outlier\">Adding an outlier</h3>\n<p>Let’s consider a sample that forces the largest value from the population to be in the sample.</p>\n<div class=\"cell\">\n<pre>set.seed(2112)\nsamp_outlier &lt;- c(sample(pop_skewed, size = 29), max(pop_skewed))\nboot_samp &lt;- numeric(500)\nfor(j in 1:500) {\n    boot_samp[j] &lt;- sample(samp, size = length(samp), replace = TRUE) |&gt;\n        mean()\n}\n\nci &lt;- c(mean(samp_outlier) - cv * sd(samp_outlier) / sqrt(30), mean(samp_outlier) + cv * sd(samp_outlier) / sqrt(30))\nci</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 1.647006 4.952994</pre>\n</div>\n<pre>mean(pop_skewed) &lt; ci[1] | mean(pop_skewed) &gt; ci[2]</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] FALSE</pre>\n</div>\n<pre>ci_boot &lt;- c(mean(boot_samp) - cv * sd(boot_samp), mean(boot_samp) + cv * sd(boot_samp))\nci_boot</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 2.905153 4.781381</pre>\n</div>\n<pre>mean(pop_skewed) &lt; ci_boot[1] | mean(pop_skewed) &gt; ci_boot[2]</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] FALSE</pre>\n</div>\n</div>\n<p>In this example we do see that the presense of the outlier does have a bigger impact on the confidence interval with the bootstrap confidence interval being much smaller.</p>\n</section>\n<section class=\"level3\" id=\"sample-and-bootstrap-size-related-to-standard-error\">\n<h3 class=\"anchored\" data-anchor-id=\"sample-and-bootstrap-size-related-to-standard-error\">Sample and bootstrap size related to standard error</h3>\n<p>Let’s also explore the relationship of <em>n</em>, number of bootstrap samples, and standard error. Recall the formula for the standard error is:</p>\n<p><img data-lazy-src=\"https://latex.codecogs.com/png.latex?%20SE%20=%20%5Cfrac%7B%5Csigma%7D%7B%5Csqrt%7Bn%7D%7D%20\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?%20SE%20=%20%5Cfrac%7B%5Csigma%7D%7B%5Csqrt%7Bn%7D%7D%20\"/></noscript></p>\n<p>The figure below plots the standard error against the standard error assuming sigma (standard deviation) is one. As you can see, simply increasing the sample size will decrease the standard error (and therefore the confidence interval).</p>\n<div class=\"cell\">\n<pre>se &lt;- function(n, sigma = 1) {\n    sigma / sqrt(n)\n}\nggplot() + stat_function(fun = se) + xlim(c(0, 100)) +\n    ylab('Standard Error') + xlab('Sample Size (n)')</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i2.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-13-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-13-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<p>Considering again a population with a uniform distribution, the following code will draw random samples with <em>n</em> ranging from 30 to 50 in increments of 15. For each of those random samples, we will also estimate boostrap standard errors with the number of bootstrap samples ranging from 50 to 1,000 in increments of 50.</p>\n<div class=\"cell\">\n<pre>n &lt;- seq(30, 500, by = 15)\nn_boots &lt;- seq(50, 1000, by = 50)\n\nresults &lt;- expand.grid(n, n_boots)\nattributes(results) &lt;- NULL\nresults &lt;- as.data.frame(results)\nnames(results) &lt;- c('n', 'n_boots')\nresults$samp_mean &lt;- NA\nresults$samp_se &lt;- NA\nresults$boot_mean &lt;- NA\nresults$boot_se &lt;- NA\n\nfor(i in seq_len(nrow(results))) {\n    samp &lt;- sample(pop_unif, size = results[i,]$n)\n    results[i,]$samp_mean &lt;- mean(samp)\n    results[i,]$samp_se &lt;- sd(samp) / sqrt(length(samp))\n    boot_samp_dist &lt;- numeric(results[i,]$n_boots)\n    for(j in seq_len(results[i,]$n_boots)) {\n        boot_samp_dist[j] &lt;- sample(samp, size = length(samp), replace = TRUE) |&gt; mean()\n    }\n    results[i,]$boot_mean &lt;- mean(boot_samp_dist)\n    results[i,]$boot_se &lt;- sd(boot_samp_dist)\n}</pre>\n</div>\n<p>The figure to the left plots the sample size against the standard error which, like above, shows that as the sample size increases the standard error decreases. On the right is a plot of the number of bootstrap samples against the standard error where the point colors correspond to the sample size. Here we see the standard error is constant. That is, the number of bootstrap samples is not related to the standard error. The variability in standard error is accounted for by the sample size.</p>\n<div class=\"cell\">\n<pre>y_limits &lt;- c(0, 0.075)\np_samp_size_se &lt;- ggplot(results, aes(x = n, y = samp_se)) + \n    geom_point(fill = '#9ecae1', color = 'grey50', shape = 21) + \n    geom_smooth(color = 'darkgreen', se = FALSE, method = 'loess', formula = y ~ x) +\n    ylim(y_limits) +\n    ylab('Standard Error') +\n    xlab('Sample size (n)') +\n    ggtitle(latex2exp::TeX(\"Standard Error (SE = \\\\frac{\\\\sigma}{\\\\sqrt{n}})\")) +\n    scale_fill_gradient(low = '#deebf7', high = '#3182bd') +\n    theme(legend.position = 'bottom')\n\np_boot_size_se &lt;- \n    ggplot(results, aes(x = n_boots, y = boot_se)) + \n    geom_point(aes(fill = n), color = 'grey50', shape = 21) +\n    geom_smooth(color = 'darkgreen', se = FALSE, method = 'loess', formula = y ~ x) +\n    ylim(y_limits) +\n    ylab('Standard Error') +\n    xlab('Number of Bootstrap Samples') +\n    ggtitle('Bootstrap Standard Error',\n            subtitle = '(i.e. standard deviation of the bootstrap sample)') +\n    scale_fill_gradient(low = '#deebf7', high = '#3182bd') #+ theme(legend.position = 'none')\n\ncowplot::plot_grid(p_samp_size_se, p_boot_size_se)</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i0.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-15-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-15-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<p>Lastly we can plot the relationship between the two standard error estimates; the correlation of which is extremely high with r = 0.99.</p>\n<div class=\"cell\">\n<pre>ggplot(results, aes(x = samp_se, y = boot_se)) +\n    geom_abline() +\n    geom_point() +\n    xlab('Sample Standard Error') +\n    ylab('Boostrap Standard Error') +\n    ggtitle(paste0('Correlation between standard errors = ', round(cor(results$samp_se, results$boot_se), digits = 2))) +\n    coord_equal()</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i0.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-16-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error_files/figure-html/unnamed-chunk-16-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n</section>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://bryer.org/posts/2025-03-23-Bootstrap_vs_Standard_Error.html\"> Jason Bryer</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
    "main_text": "Bootstrap vs Standard Error Confidence Intervals\nPosted on\nMarch 11, 2025\nby\nJason Bryer\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nJason Bryer\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nA student recently asked whether bootstrap confidence intervals were more robust than confidence intervals estimated using the standard error (i.e.\n). In order to answer this question I wrote a function to simulate taking a bunch of random samples from a population, calculate the confidence interval for that sample using the standard error approach (the\nt\ndistribution is used by default, see the\ncv\nparameter. To use the normal distribution, for example, set\ncv = 1.96\n.), and then also calculating a confidence interval using the boostrap.\nlibrary(dplyr)\nlibrary(ggplot2)\n\n#' Simulate random samples to estimate confidence intervals and bootstrap\n#' estimates.\n#'\n#' @param pop a numeric vector representing the population.\n#' @param n sample size for each random sample from the population.\n#' @param n_samples the number of random samples.\n#' @param n_boot number of bootstrap samples to take for each sample.\n#' @param seed a seed to use for the random process.\n#' @param cv critical value to use for calculating confidence intervals.\n#' @return a data.frame with the sample and bootstrap mean and confidence\n#'        intervals along with a logical variable indicating whether a Type I\n#'        error would have occurred with that sample.\nbootstrap_clt_simulation <- function(\n        pop,\n        n = 30,\n        n_samples = 500,\n        n_boot = 500,\n        cv = abs(qt(0.025, df = n - 1)),\n        seed,\n        verbose = interactive()\n) {\n    if(missing(seed)) {\n        seed <- sample(100000)\n    }\n    results <- data.frame(\n        seed = 1:n_samples,\n        samp_mean = numeric(n_samples),\n        samp_se = numeric(n_samples),\n        samp_ci_low = numeric(n_samples),\n        samp_ci_high = numeric(n_samples),\n        samp_type1 = logical(n_samples),\n        boot_mean = numeric(n_samples),\n        boot_ci_low = numeric(n_samples),\n        boot_ci_high = numeric(n_samples),\n        boot_type1 = logical(n_samples)\n    )\n    if(verbose) {\n        pb <- txtProgressBar(min = 0, max = n_samples, style = 3)\n    }\n    for(i in 1:n_samples) {\n        if(verbose) {\n            setTxtProgressBar(pb, i)\n        }\n        set.seed(seed + i)\n        samp <- sample(pop, size = n)\n        boot_samp <- numeric(n_boot)\n        for(j in 1:n_boot) {\n            boot_samp[j] <- sample(samp, size = length(samp), replace = TRUE) |>\n                mean()\n        }\n        results[i,]$seed <- seed + i\n        results[i,]$samp_mean <- mean(samp)\n        results[i,]$samp_se <- sd(samp) / sqrt(length(samp))\n        results[i,]$samp_ci_low <- mean(samp) - cv * results[i,]$samp_se\n        results[i,]$samp_ci_high <- mean(samp) + cv * results[i,]$samp_se\n        results[i,]$samp_type1 <- results[i,]$samp_ci_low > mean(pop) |\n            mean(pop) > results[i,]$samp_ci_high\n        results[i,]$boot_mean <- mean(boot_samp)\n        results[i,]$boot_ci_low <- mean(boot_samp) - cv * sd(boot_samp)\n        results[i,]$boot_ci_high <- mean(boot_samp) + cv * sd(boot_samp)\n        results[i,]$boot_type1 <- results[i,]$boot_ci_low > mean(pop) |\n            mean(pop) > results[i,]$boot_ci_high\n    }\n    if(verbose) {\n        close(pb)\n    }\n    return(results)\n}\nUniform distribution for the population\nLet’s start with a uniform distribution for our population.\npop_unif <- runif(1e5, 0, 1)\nggplot(data.frame(x = pop_unif), aes(x = x)) + geom_density()\nThe mean of the population is 0.5008915. We can now simulate samples and their corresponding bootstrap estimates.\nresults_unif <- bootstrap_clt_simulation(pop = pop_unif, seed = 42, verbose = FALSE)\n5.8% of our samples did not contain the population mean in the confidence interval (i.e. Type I error rate) compared to\nr\nmean(results_unif$boot_type1) * 100`% of the bootstrap estimates. The following table compares the Type I errors for each sample compared to the bootstrap estiamted from that sample.\ntab <- table(results_unif$samp_type1, results_unif$boot_type1, useNA = 'ifany')\ntab\nFALSE TRUE\n  FALSE   470    1\n  TRUE      1   28\nIn general committing a type I error is the same regardless of method, though there were 1 instances where the bootstrap would have led to a type I error rate where the standard error approach would not.\nThe following plots show the relationship between the estimated mean (left) and condifence interval width (right) for each sample and its corresponding bootstrap.\nresults_unif |>\n    ggplot(aes(x = samp_mean, y = boot_mean)) +\n    geom_vline(xintercept = mean(pop_unif), color = 'blue') +\n    geom_hline(yintercept = mean(pop_unif), color = 'blue') +\n    geom_abline() +\n    geom_point() +\n    ggtitle(\"Sample mean vs bootstrap mean\")\nresults_unif |>\n    dplyr::mutate(samp_ci_width = samp_ci_high - samp_ci_low,\n                  boot_ci_width = boot_ci_high - boot_ci_low) |>\n    ggplot(aes(x = samp_ci_width, y = boot_ci_width)) +\n    geom_abline() +\n    geom_point() +\n    ggtitle('Sample vs boostrap confidence interval width')\nSkewed distribution for the population\nWe will repeat the same analysis using a positively skewed distribution.\npop_skewed <- rnbinom(1e5, 3, .5)\nggplot(data.frame(x = pop_skewed), aes(x = x)) + geom_density(bw = 0.75)\nThe mean of the population for this distribution is 2.99792\nresults_skewed <- bootstrap_clt_simulation(pop = pop_skewed, seed = 42, verbose = FALSE)\nmean(results_skewed$samp_type1) # Percent of samples with Type I error\n[1] 0.05\nmean(results_skewed$boot_type1) # Percent of bootstrap estimates with Type I error\n[1] 0.052\n# CLT vs Bootstrap Type I error rate\ntable(results_skewed$samp_type1, results_skewed$boot_type1, useNA = 'ifany')\nFALSE TRUE\n  FALSE   473    2\n  TRUE      1   24\nresults_skewed |>\n    ggplot(aes(x = samp_mean, y = boot_mean)) +\n    geom_vline(xintercept = mean(pop_skewed), color = 'blue') +\n    geom_hline(yintercept = mean(pop_skewed), color = 'blue') +\n    geom_abline() +\n    geom_point() +\n    ggtitle(\"Sample mean vs bootstrap mean\")\nresults_skewed |>\n    dplyr::mutate(samp_ci_width = samp_ci_high - samp_ci_low,\n                  boot_ci_width = boot_ci_high - boot_ci_low) |>\n    ggplot(aes(x = samp_ci_width, y = boot_ci_width)) +\n    geom_abline() +\n    geom_point() +\n    ggtitle('Sample vs boostrap confidence interval width')\nWe can see the results are very similar to that of the uniform distirubtion. Exploring the one case where the bootstrap would have resulted in a Type I error where the standard error approach would not reveals that it is very close with the difference being less than 0.1.\nresults_differ <- results_skewed |>\n    dplyr::filter(!samp_type1 & boot_type1)\nresults_differ\nseed samp_mean   samp_se samp_ci_low samp_ci_high samp_type1 boot_mean\n1  443  3.866667 0.4516466    2.942946     4.790388      FALSE  3.924733\n2  474  3.933333 0.4816956    2.948155     4.918511      FALSE  3.956800\n  boot_ci_low boot_ci_high boot_type1\n1    3.044802     4.804665       TRUE\n2    3.018549     4.895051       TRUE\nset.seed(results_differ[1,]$seed)\nsamp <- sample(pop_skewed, size = 30)\nboot_samp <- numeric(500)\nfor(j in 1:500) {\n    boot_samp[j] <- sample(samp, size = length(samp), replace = TRUE) |>\n        mean()\n}\ncv = abs(qt(0.025, df = 30 - 1))\nmean(pop_skewed)\n[1] 2.99792\nci <- c(mean(samp) - cv * sd(samp) / sqrt(30), mean(samp) + cv * sd(samp) / sqrt(30))\nci\n[1] 2.942946 4.790388\nmean(pop_skewed) < ci[1] | mean(pop_skewed) > ci[2]\n[1] FALSE\nci_boot <- c(mean(boot_samp) - cv * sd(boot_samp), mean(boot_samp) + cv * sd(boot_samp))\nci_boot\n[1] 3.044802 4.804665\nmean(pop_skewed) < ci_boot[1] | mean(pop_skewed) > ci_boot[2]\n[1] TRUE\nAdding an outlier\nLet’s consider a sample that forces the largest value from the population to be in the sample.\nset.seed(2112)\nsamp_outlier <- c(sample(pop_skewed, size = 29), max(pop_skewed))\nboot_samp <- numeric(500)\nfor(j in 1:500) {\n    boot_samp[j] <- sample(samp, size = length(samp), replace = TRUE) |>\n        mean()\n}\n\nci <- c(mean(samp_outlier) - cv * sd(samp_outlier) / sqrt(30), mean(samp_outlier) + cv * sd(samp_outlier) / sqrt(30))\nci\n[1] 1.647006 4.952994\nmean(pop_skewed) < ci[1] | mean(pop_skewed) > ci[2]\n[1] FALSE\nci_boot <- c(mean(boot_samp) - cv * sd(boot_samp), mean(boot_samp) + cv * sd(boot_samp))\nci_boot\n[1] 2.905153 4.781381\nmean(pop_skewed) < ci_boot[1] | mean(pop_skewed) > ci_boot[2]\n[1] FALSE\nIn this example we do see that the presense of the outlier does have a bigger impact on the confidence interval with the bootstrap confidence interval being much smaller.\nSample and bootstrap size related to standard error\nLet’s also explore the relationship of\nn\n, number of bootstrap samples, and standard error. Recall the formula for the standard error is:\nThe figure below plots the standard error against the standard error assuming sigma (standard deviation) is one. As you can see, simply increasing the sample size will decrease the standard error (and therefore the confidence interval).\nse <- function(n, sigma = 1) {\n    sigma / sqrt(n)\n}\nggplot() + stat_function(fun = se) + xlim(c(0, 100)) +\n    ylab('Standard Error') + xlab('Sample Size (n)')\nConsidering again a population with a uniform distribution, the following code will draw random samples with\nn\nranging from 30 to 50 in increments of 15. For each of those random samples, we will also estimate boostrap standard errors with the number of bootstrap samples ranging from 50 to 1,000 in increments of 50.\nn <- seq(30, 500, by = 15)\nn_boots <- seq(50, 1000, by = 50)\n\nresults <- expand.grid(n, n_boots)\nattributes(results) <- NULL\nresults <- as.data.frame(results)\nnames(results) <- c('n', 'n_boots')\nresults$samp_mean <- NA\nresults$samp_se <- NA\nresults$boot_mean <- NA\nresults$boot_se <- NA\n\nfor(i in seq_len(nrow(results))) {\n    samp <- sample(pop_unif, size = results[i,]$n)\n    results[i,]$samp_mean <- mean(samp)\n    results[i,]$samp_se <- sd(samp) / sqrt(length(samp))\n    boot_samp_dist <- numeric(results[i,]$n_boots)\n    for(j in seq_len(results[i,]$n_boots)) {\n        boot_samp_dist[j] <- sample(samp, size = length(samp), replace = TRUE) |> mean()\n    }\n    results[i,]$boot_mean <- mean(boot_samp_dist)\n    results[i,]$boot_se <- sd(boot_samp_dist)\n}\nThe figure to the left plots the sample size against the standard error which, like above, shows that as the sample size increases the standard error decreases. On the right is a plot of the number of bootstrap samples against the standard error where the point colors correspond to the sample size. Here we see the standard error is constant. That is, the number of bootstrap samples is not related to the standard error. The variability in standard error is accounted for by the sample size.\ny_limits <- c(0, 0.075)\np_samp_size_se <- ggplot(results, aes(x = n, y = samp_se)) + \n    geom_point(fill = '#9ecae1', color = 'grey50', shape = 21) + \n    geom_smooth(color = 'darkgreen', se = FALSE, method = 'loess', formula = y ~ x) +\n    ylim(y_limits) +\n    ylab('Standard Error') +\n    xlab('Sample size (n)') +\n    ggtitle(latex2exp::TeX(\"Standard Error (SE = \\\\frac{\\\\sigma}{\\\\sqrt{n}})\")) +\n    scale_fill_gradient(low = '#deebf7', high = '#3182bd') +\n    theme(legend.position = 'bottom')\n\np_boot_size_se <- \n    ggplot(results, aes(x = n_boots, y = boot_se)) + \n    geom_point(aes(fill = n), color = 'grey50', shape = 21) +\n    geom_smooth(color = 'darkgreen', se = FALSE, method = 'loess', formula = y ~ x) +\n    ylim(y_limits) +\n    ylab('Standard Error') +\n    xlab('Number of Bootstrap Samples') +\n    ggtitle('Bootstrap Standard Error',\n            subtitle = '(i.e. standard deviation of the bootstrap sample)') +\n    scale_fill_gradient(low = '#deebf7', high = '#3182bd') #+ theme(legend.position = 'none')\n\ncowplot::plot_grid(p_samp_size_se, p_boot_size_se)\nLastly we can plot the relationship between the two standard error estimates; the correlation of which is extremely high with r = 0.99.\nggplot(results, aes(x = samp_se, y = boot_se)) +\n    geom_abline() +\n    geom_point() +\n    xlab('Sample Standard Error') +\n    ylab('Boostrap Standard Error') +\n    ggtitle(paste0('Correlation between standard errors = ', round(cor(results$samp_se, results$boot_se), digits = 2))) +\n    coord_equal()\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nJason Bryer\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "meta_description": "A student recently asked whether bootstrap confidence intervals were more robust than confidence intervals estimated using the standard error (i.e. ). In order to answer this question I wrote a function to simulate taking a bunch of random s...",
    "meta_keywords": null,
    "og_description": "A student recently asked whether bootstrap confidence intervals were more robust than confidence intervals estimated using the standard error (i.e. ). In order to answer this question I wrote a function to simulate taking a bunch of random s...",
    "og_image": "https://latex.codecogs.com/png.latex?SE%20=%20%5Cfrac%7Bs%7D%7B%5Csqrt%7Bn%7D%7D",
    "og_title": "Bootstrap vs Standard Error Confidence Intervals | R-bloggers",
    "raw_jsonld_article": null,
    "reading_time_min": 8.8,
    "sitemap_lastmod": null,
    "twitter_description": "A student recently asked whether bootstrap confidence intervals were more robust than confidence intervals estimated using the standard error (i.e. ). In order to answer this question I wrote a function to simulate taking a bunch of random s...",
    "twitter_title": "Bootstrap vs Standard Error Confidence Intervals | R-bloggers",
    "url": "https://www.r-bloggers.com/2025/03/bootstrap-vs-standard-error-confidence-intervals-2/",
    "word_count": 1759
  }
}