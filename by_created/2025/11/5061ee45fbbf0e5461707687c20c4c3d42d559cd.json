{
  "id": "5061ee45fbbf0e5461707687c20c4c3d42d559cd",
  "url": "https://www.r-bloggers.com/2025/05/spatial-machine-learning-with-caret/",
  "created_at_utc": "2025-11-22T19:58:37Z",
  "data": null,
  "raw_original": {
    "uuid": "870adf36-ef30-4b92-9990-4422558101d0",
    "created_at": "2025-11-22 19:58:37",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2025/05/spatial-machine-learning-with-caret/",
      "crawled_at": "2025-11-22T10:49:01.715187",
      "external_links": [
        {
          "href": "https://geocompx.org/post/2025/sml-bp2/",
          "text": "geocompx"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://geocompx.org/post/2025/sml-bp1/",
          "text": "in part one"
        },
        {
          "href": "https://topepo.github.io/caret/",
          "text": "https://topepo.github.io/caret/"
        },
        {
          "href": "https://doi.org/10.18637/jss.v028.i05",
          "text": "https://doi.org/10.18637/jss.v028.i05"
        },
        {
          "href": "http://appliedpredictivemodeling.com/",
          "text": "http://appliedpredictivemodeling.com/"
        },
        {
          "href": "https://doi.org/10.5281/zenodo.15088973",
          "text": "https://doi.org/10.5281/zenodo.15088973"
        },
        {
          "href": "https://creativecommons.org/licenses/by/4.0/",
          "text": "CC BY 4.0"
        },
        {
          "href": "https://geocompx.org/post/2025/sml-bp2/",
          "text": "https://geocompx.org/post/2025/sml-bp2/"
        },
        {
          "href": "https://geocompx.org/post/2025/sml-bp2/",
          "text": "geocompx"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Spatial machine learning with caret | R-bloggers",
      "images": [
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/geocompx.org/post/2025/sml-bp2/index_files/figure-html/unnamed-chunk-3-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAANBAMAAACJLlk1AAAAKlBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmU0mKAAAADXRSTlMAMrsQRO+Jq81mdlTdgIQlWAAAAAlwSFlzAAAOxAAADsQBlSsOGwAAAEZJREFUCB1jYNQ1YAACVxDBkA4mO8HkRRDJcoFxFgMDm4KgKAMDR6KDNQMDrwpI3FdMAUgmMRxhZGDoZDjIzcBwmGHXBgYAM30KYRgI//EAAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?k"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAANBAMAAACJLlk1AAAAKlBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmU0mKAAAADXRSTlMAMrsQRO+Jq81mdlTdgIQlWAAAAAlwSFlzAAAOxAAADsQBlSsOGwAAAEZJREFUCB1jYNQ1YAACVxDBkA4mO8HkRRDJcoFxFgMDm4KgKAMDR6KDNQMDrwpI3FdMAUgmMRxhZGDoZDjIzcBwmGHXBgYAM30KYRgI//EAAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?k"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAANBAMAAACJLlk1AAAAKlBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmU0mKAAAADXRSTlMAMrsQRO+Jq81mdlTdgIQlWAAAAAlwSFlzAAAOxAAADsQBlSsOGwAAAEZJREFUCB1jYNQ1YAACVxDBkA4mO8HkRRDJcoFxFgMDm4KgKAMDR6KDNQMDrwpI3FdMAUgmMRxhZGDoZDjIzcBwmGHXBgYAM30KYRgI//EAAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?k"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAANBAMAAACJLlk1AAAAKlBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmU0mKAAAADXRSTlMAMrsQRO+Jq81mdlTdgIQlWAAAAAlwSFlzAAAOxAAADsQBlSsOGwAAAEZJREFUCB1jYNQ1YAACVxDBkA4mO8HkRRDJcoFxFgMDm4KgKAMDR6KDNQMDrwpI3FdMAUgmMRxhZGDoZDjIzcBwmGHXBgYAM30KYRgI//EAAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?k"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAANBAMAAACJLlk1AAAAKlBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmU0mKAAAADXRSTlMAMrsQRO+Jq81mdlTdgIQlWAAAAAlwSFlzAAAOxAAADsQBlSsOGwAAAEZJREFUCB1jYNQ1YAACVxDBkA4mO8HkRRDJcoFxFgMDm4KgKAMDR6KDNQMDrwpI3FdMAUgmMRxhZGDoZDjIzcBwmGHXBgYAM30KYRgI//EAAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?k"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/geocompx.org/post/2025/sml-bp2/index_files/figure-html/unnamed-chunk-5-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/geocompx.org/post/2025/sml-bp2/index_files/figure-html/unnamed-chunk-7-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/geocompx.org/post/2025/sml-bp2/index_files/figure-html/unnamed-chunk-9-1.png?w=450&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/jan-linnenbrink/",
          "text": "Jan Linnenbrink"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-392407 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Spatial machine learning with caret</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">May 13, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/jan-linnenbrink/\">Jan Linnenbrink</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://geocompx.org/post/2025/sml-bp2/\"> geocompx</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div class=\"callout callout-style-simple callout-note\">\n<div class=\"callout-body d-flex\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-body-container\">\n<p>This is the second part of a blog post series on spatial machine learning with R.</p>\n<p>You can find the list of other blog posts in this series <a href=\"https://geocompx.org/post/2025/sml-bp1/\" rel=\"nofollow\" target=\"_blank\">in part one</a>.</p>\n</div>\n</div>\n</div>\n<section class=\"level2\" id=\"introduction\">\n<h2 class=\"anchored\" data-anchor-id=\"introduction\">Introduction</h2>\n<p>This document shows the application of <strong>caret</strong> for spatial modelling at the example of predicting air temperature in Spain. Hereby, we use measurements of air temperature available only at specific locations in Spain to create a spatially continuous map of air temperature. Therefore, machine-learning models are trained to learn the relationship between spatially continuous predictors and air temperature.</p>\n<p>When using machine-learning methods with spatial data, we need to take care of, e.g., spatial autocorrelation, as well as extrapolation when predicting to regions that are far away from the training data. To deal with these issues, several methods have been developed. In this document, we will show how to combine the machine-learning workflow of <strong>caret</strong> with packages designed to deal with machine-learning with spatial data. Hereby, we use <code>blockCV::cv_spatial()</code> and <code>CAST::knndm()</code> for spatial cross-validation, and <code>CAST::aoa()</code> to mask areas of extrapolation. We use <strong>sf</strong> and <strong>terra</strong> for processing vector and raster data, respectively.</p>\n</section>\n<section class=\"level2\" id=\"the-caret-package\">\n<h2 class=\"anchored\" data-anchor-id=\"the-caret-package\">The caret package</h2>\n<p>The <strong>caret</strong> package contains functions to train machine-learning models, as well as for, e.g., model selection. Its main function is <code>caret::train()</code>, which provides a uniform interface to over 200 machine-learning algorithms. (User-specified-) Cross-Validation methods can be defined via <code>caret::trainControl()</code>. An extensive online tutorial is available at <a class=\"uri\" href=\"https://topepo.github.io/caret/\" rel=\"nofollow\" target=\"_blank\">https://topepo.github.io/caret/</a>. Furthermore, a paper (<a class=\"uri\" href=\"https://doi.org/10.18637/jss.v028.i05\" rel=\"nofollow\" target=\"_blank\">https://doi.org/10.18637/jss.v028.i05</a>), as well as a book (<a class=\"uri\" href=\"http://appliedpredictivemodeling.com/\" rel=\"nofollow\" target=\"_blank\">http://appliedpredictivemodeling.com/</a>), describing the use of <strong>caret</strong> are available.</p>\n</section>\n<section class=\"level2\" id=\"install-and-load-required-r-packages\">\n<h2 class=\"anchored\" data-anchor-id=\"install-and-load-required-r-packages\">Install and load required R-packages</h2>\n<div class=\"cell\">\n<pre># install.packages(\"caret\")\n# install.packages(\"CAST\")\n# install.packages(\"blockCV\")\n# install.packages(\"sf\")\n# install.packages(\"terra\")</pre>\n</div>\n<div class=\"cell\">\n<pre>library(caret)\nlibrary(CAST)\nlibrary(blockCV)\nlibrary(sf)\nlibrary(terra)</pre>\n</div>\n</section>\n<section class=\"level2\" id=\"case-study-data\">\n<h2 class=\"anchored\" data-anchor-id=\"case-study-data\">Case study data</h2>\n<p>Load data needed in this modelling example:</p>\n<ul>\n<li><strong>predictor stack</strong>: raster dataset of the environmental predictors used to predict air temperature</li>\n<li><strong>train points</strong>: vector dataset of ground measurements of air temperature</li>\n<li><strong>spain</strong>: region for which predictions are made</li>\n</ul>\n<div class=\"cell\">\n<pre>predictor_stack &lt;- terra::rast(\n    \"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/predictors.tif\"\n)\npredictor_names &lt;- names(predictor_stack)\nspain &lt;- sf::st_read(\n    \"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/spain.gpkg\"\n)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Reading layer `spain' from data source \n  `https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/spain.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1 feature and 0 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -13454.15 ymin: 3988025 xmax: 1020771 ymax: 4859816\nProjected CRS: ED50 / UTM zone 30N</pre>\n</div>\n<pre>train_points &lt;- sf::st_read(\n    \"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/temp_train.gpkg\"\n)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Reading layer `temp_train' from data source \n  `https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/temp_train.gpkg' \n  using driver `GPKG'\nSimple feature collection with 195 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 36026.79 ymin: 3988818 xmax: 978160.6 ymax: 4858999\nProjected CRS: ED50 / UTM zone 30N</pre>\n</div>\n<pre>train_data &lt;- terra::extract(\n    predictor_stack,\n    train_points,\n    bind = TRUE,\n    ID = FALSE\n) |&gt;\n    sf::st_as_sf()\n\nplot(sf::st_geometry(spain))\nplot(sf::st_geometry(train_points), col = \"blue4\", add = TRUE)</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i0.wp.com/geocompx.org/post/2025/sml-bp2/index_files/figure-html/unnamed-chunk-3-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/geocompx.org/post/2025/sml-bp2/index_files/figure-html/unnamed-chunk-3-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"standard-modelling-workflow\">\n<h2 class=\"anchored\" data-anchor-id=\"standard-modelling-workflow\">Standard modelling workflow</h2>\n<p>Firstly, a simple modelling workflow without feature selection and hyperparameter tuning is shown:</p>\n<ol type=\"1\">\n<li>split data into training and test data</li>\n<li>train model using the training data only</li>\n<li>predict on test data to obtain error metrics</li>\n<li>predict on predictor stack to obtain spatially continuous prediction of air temperature</li>\n</ol>\n<div class=\"callout callout-style-default callout-note callout-titled\">\n<div class=\"callout-header d-flex align-content-center\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nNote\n</div>\n</div>\n<div class=\"callout-body-container callout-body\">\n<p>Geometry column needs to be dropped before using <code>caret::train()</code>.</p>\n</div>\n</div>\n<div class=\"cell\">\n<pre># 1. train-test split\nset.seed(321)\ntrainIndex &lt;- caret::createDataPartition(\n    train_data$temp,\n    p = .8,\n    list = FALSE,\n    times = 1\n)\ntemperature_train &lt;- train_data[trainIndex, ]\ntemperature_test &lt;- train_data[-trainIndex, ]\n\n# 2. model training\nmodel &lt;- caret::train(\n    temp ~ .,\n    data = sf::st_drop_geometry(temperature_train),\n    method = \"ranger\",\n    tuneGrid = expand.grid(\n        \"mtry\" = 4,\n        \"splitrule\" = \"variance\",\n        \"min.node.size\" = 5\n    ),\n    num.trees = 100\n)\n\n# 3. predict on test data\ntest_df &lt;- temperature_test[, \"temp\", drop = FALSE]\ntest_df$prediction &lt;- predict(model, temperature_test)\n\ntest_metrics &lt;- caret::postResample(\n    pred = test_df$prediction,\n    obs = test_df$temp\n) |&gt;\n    round(3) |&gt;\n    t() |&gt;\n    as.data.frame()\n\nprint(test_metrics)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>   RMSE Rsquared   MAE\n1 0.913    0.901 0.741</pre>\n</div>\n<pre># 4. predict to raster stack\nprediction_spatial &lt;- terra::predict(predictor_stack, model, na.rm = TRUE)</pre>\n</div>\n</section>\n<section class=\"level2\" id=\"spatial-cross-validation-for-model-selection\">\n<h2 class=\"anchored\" data-anchor-id=\"spatial-cross-validation-for-model-selection\">Spatial Cross-Validation for model selection</h2>\n<p>Cross-validation (CV) methods are often employed to obtain optimal hyperparameter values. Therefore, the training data are split into <img data-lazy-src=\"https://latex.codecogs.com/png.latex?k\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?k\"/></noscript> folds, and a model is trained on <img data-lazy-src=\"https://latex.codecogs.com/png.latex?k\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?k\"/></noscript>-1 folds. The fold not used for model training is then used to obtain the test statistic. This is repeated over all folds, and the test metric is averaged over the <img data-lazy-src=\"https://latex.codecogs.com/png.latex?k\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?k\"/></noscript> folds.</p>\n<p>In spatial machine-learning, a spatial CV is often needed to prevent very similar data to be in the training and testing fold at the same time, which is often the case if training data are clustered and leads to overly optimistic CV error estimates. R packages that implement spatial CV include, e.g., <strong>blockCV</strong> and <strong>CAST</strong>. Here, we will explore the integration of those two with <strong>caret</strong>.</p>\n<section class=\"level3\" id=\"hyperparameter-tuning-using-spatial-block-cross-validation\">\n<h3 class=\"anchored\" data-anchor-id=\"hyperparameter-tuning-using-spatial-block-cross-validation\">Hyperparameter tuning using spatial block cross-validation</h3>\n<p>The <strong>blockCV</strong> package implements different blocking methods for spatial CV. The resulting object of the main function <code>blockCV::cv_spatial()</code> contains a nested list of the <img data-lazy-src=\"https://latex.codecogs.com/png.latex?k\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?k\"/></noscript> folds and the training data rows that belong to each fold, as well as a list of the test data left out in each of the <img data-lazy-src=\"https://latex.codecogs.com/png.latex?k\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?k\"/></noscript> iteration. These lists can be obtained using <code>lapply()</code> and then be used as an input to the <code>caret::trainControl()</code> function of caret that defines the CV strategy used in <code>caret::train()</code>. The grid of hyperparameter values tested during CV is defined using the <code>tune_grid</code> argument in <code>caret::train()</code>. Here, we test <code>mtry</code> values from 2 to 12 and <code>min.node.size</code> values between 5 and 15. The combination of <code>mtry</code> and <code>min.node.size</code> that minimizes the RMSE is then automatically used to re-train a final model with the complete training data set.</p>\n<div class=\"cell\">\n<pre>set.seed(333)\nspatial_blocks &lt;- blockCV::cv_spatial(\n    temperature_train,\n    k = 5,\n    progress = FALSE\n)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>\n  train test\n1   126   33\n2   126   33\n3   128   31\n4   128   31\n5   128   31</pre>\n</div>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i2.wp.com/geocompx.org/post/2025/sml-bp2/index_files/figure-html/unnamed-chunk-5-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/geocompx.org/post/2025/sml-bp2/index_files/figure-html/unnamed-chunk-5-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n<pre>train_ids &lt;- lapply(spatial_blocks$folds_list, function(x) x[[1]])\ntest_ids &lt;- lapply(spatial_blocks$folds_list, function(x) x[[2]])\n\ntr_control_block &lt;- caret::trainControl(\n    method = \"cv\",\n    index = train_ids,\n    indexOut = test_ids,\n    savePredictions = TRUE\n)\n\nhyperparameter_grid &lt;- expand.grid(\n    \"mtry\" = c(2, 4, 6, 10, 12),\n    \"min.node.size\" = c(5, 10, 15),\n    \"splitrule\" = \"variance\"\n)\n\nmodel_spatial &lt;- caret::train(\n    temp ~ .,\n    data = sf::st_drop_geometry(temperature_train),\n    method = \"ranger\",\n    trControl = tr_control_block,\n    tuneGrid = hyperparameter_grid,\n    num.trees = 100\n)\n\nmodel_spatial$finalModel</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Ranger result\n\nCall:\n ranger::ranger(dependent.variable.name = \".outcome\", data = x,      mtry = min(param$mtry, ncol(x)), min.node.size = param$min.node.size,      splitrule = as.character(param$splitrule), write.forest = TRUE,      probability = classProbs, ...) \n\nType:                             Regression \nNumber of trees:                  100 \nSample size:                      159 \nNumber of independent variables:  22 \nMtry:                             10 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       0.8557959 \nR squared (OOB):                  0.8952759 </pre>\n</div>\n</div>\n</section>\n<section class=\"level3\" id=\"hyperparameter-tuning-using-target-oriented-cv\">\n<h3 class=\"anchored\" data-anchor-id=\"hyperparameter-tuning-using-target-oriented-cv\">Hyperparameter tuning using target-oriented CV</h3>\n<p>Another spatial CV method is kNNDM, which is implemented in the <strong>CAST</strong> package and aims at emulating the prediction situation encountered by the model during CV. In this case, the prediction situation is to predict from the temperature measurement stations to the whole area of Spain. Since the temperature measurement stations are rather randomly distributed over the area of Spain, no spatial blocking is needed and kNNDM randomly assigns training points to CV folds. The output of kNNDM contains a list of row indices of training data points that are used in each CV-iteration (<code>indx_train</code>), as well as of indices that are left out in each iteration (<code>indx_test</code>). These lists can easily be used as input to the <code>caret::trainControl()</code> function of <strong>caret</strong> that defines the CV used in <code>caret::train()</code>.</p>\n<div class=\"cell\">\n<pre>knndm_folds &lt;- CAST::knndm(\n    tpoints = temperature_train,\n    modeldomain = spain,\n    space = \"geographical\",\n    clustering = \"kmeans\",\n    k = 5\n)\n\ntr_control_knndm &lt;- caret::trainControl(\n    method = \"cv\",\n    index = knndm_folds$indx_train,\n    indexOut = knndm_folds$indx_test,\n    savePredictions = TRUE\n)\n\nhyperparameter_grid &lt;- expand.grid(\n    \"mtry\" = c(2, 4, 6, 10, 12),\n    \"min.node.size\" = c(5, 10, 15),\n    \"splitrule\" = \"variance\"\n)\n\nmodel_knndm &lt;- caret::train(\n    temp ~ .,\n    data = sf::st_drop_geometry(temperature_train),\n    method = \"ranger\",\n    trControl = tr_control_knndm,\n    tuneGrid = hyperparameter_grid,\n    num.trees = 100\n)\n\nmodel_knndm$finalModel</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Ranger result\n\nCall:\n ranger::ranger(dependent.variable.name = \".outcome\", data = x,      mtry = min(param$mtry, ncol(x)), min.node.size = param$min.node.size,      splitrule = as.character(param$splitrule), write.forest = TRUE,      probability = classProbs, ...) \n\nType:                             Regression \nNumber of trees:                  100 \nSample size:                      159 \nNumber of independent variables:  22 \nMtry:                             12 \nTarget node size:                 10 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       0.8728343 \nR squared (OOB):                  0.8931909 </pre>\n</div>\n</div>\n</section>\n<section class=\"level3\" id=\"feature-selection-using-target-oriented-cv\">\n<h3 class=\"anchored\" data-anchor-id=\"feature-selection-using-target-oriented-cv\">Feature selection using target-oriented CV</h3>\n<p>To reduce the number of environmental predictors, and thus enhance the generalizability of the model, feature selection is commonly applied in machine-learning workflows. <strong>CAST</strong> implements Forward-Feature-Selection, that can be used with spatial CV. Here, we use the results of the hyperparameter tuning above and kNNDM CV to select the most relevant features. Plotting the results of <code>FFS()</code> shows that the variables <code>DEM</code>, <code>Y</code>, <code>EDF5</code> and <code>primaryroads</code> were selected.</p>\n<div class=\"cell\">\n<pre>selected_hyperparams &lt;- model_knndm$bestTune\n\nmodel_ffs &lt;- CAST::ffs(\n    predictors = sf::st_drop_geometry(temperature_train)[, predictor_names],\n    response = sf::st_drop_geometry(temperature_train)$temp,\n    method = \"ranger\",\n    num.trees = 100,\n    trControl = tr_control_knndm,\n    tuneGrid = selected_hyperparams,\n    verbose = FALSE\n)\n\nplot(model_ffs, plotType = \"selected\")</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i1.wp.com/geocompx.org/post/2025/sml-bp2/index_files/figure-html/unnamed-chunk-7-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/geocompx.org/post/2025/sml-bp2/index_files/figure-html/unnamed-chunk-7-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n<pre># obtain prediction\nprediction_ffs &lt;- terra::predict(predictor_stack, model_ffs, na.rm = TRUE)</pre>\n</div>\n</section>\n</section>\n<section class=\"level2\" id=\"aoa\">\n<h2 class=\"anchored\" data-anchor-id=\"aoa\">AOA</h2>\n<p>Lastly, the area which is too dissimilar from the training data for the models to make reliable predictions (area of applicability, AOA) is delineated using the function <code>CAST::aoa()</code>. The function <code>CAST::aoa()</code> takes as inputs the predictor stack, as well as the trained <strong>caret</strong> model. The resulting object contains the dissimilarity values, the threshold used to delineate the AOA (every dissimilarity value above this threshold is considered outside the AOA), as well as the final AOA raster. Since our training data are randomly distributed in the study area, most of the area falls within the AOA.</p>\n<div class=\"cell\">\n<pre>AOA_without_tuning &lt;- CAST::aoa(\n    newdata = predictor_stack,\n    model = model,\n    verbose = FALSE\n)\nAOA_with_tuning &lt;- CAST::aoa(\n    newdata = predictor_stack,\n    model = model_ffs,\n    verbose = FALSE\n)</pre>\n</div>\n</section>\n<section class=\"level2\" id=\"compare-predictions-obtained-by-the-un-tuned-model-vs-the-tuned-model\">\n<h2 class=\"anchored\" data-anchor-id=\"compare-predictions-obtained-by-the-un-tuned-model-vs-the-tuned-model\">Compare predictions obtained by the un-tuned model vs the tuned model</h2>\n<div class=\"cell\">\n<pre>par(mfrow = c(2, 2))\nplot(prediction_spatial, main = \"prediction without tuning\")\nplot(AOA_without_tuning$AOA, main = \"AOA without tuning\")\nplot(prediction_ffs, main = \"prediction with model selection\")\nplot(AOA_with_tuning$AOA, main = \"AOA with model selection\")</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i2.wp.com/geocompx.org/post/2025/sml-bp2/index_files/figure-html/unnamed-chunk-9-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/geocompx.org/post/2025/sml-bp2/index_files/figure-html/unnamed-chunk-9-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"conclusion\">\n<h2 class=\"anchored\" data-anchor-id=\"conclusion\">Conclusion</h2>\n<p><strong>caret</strong> has no functions that explicitly deal with spatial data. However, due to its rather flexible design, <strong>caret</strong> is compatible with several packages designed for spatial machine-learning. The <code>caret::trainControl()</code> takes a list of CV indices as input, which makes it quite flexible to work with the output of e.g. <code>CAST::knndm()</code> and <code>blockCV::cv_spatial()</code>. Furthermore, <strong>caret</strong> is easy to use due to its functional programming paradigm. The documentation is extensive, and it’s rather easy to find modelling algorithms and their hyperparameters. Lastly, it should be noted that <strong>caret</strong> is not actively developed, since its main developer moved to <strong>tidymodels</strong>.</p>\n<div class=\"callout callout-style-simple callout-note\">\n<div class=\"callout-body d-flex\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-body-container\">\n<p>This blog post was originally written as a supplement to the poster “An Inventory of Spatial Machine Learning Packages in R” presented at the FOSSGIS 2025 conference in Muenster, Germany. The poster is available at <a class=\"uri\" href=\"https://doi.org/10.5281/zenodo.15088973\" rel=\"nofollow\" target=\"_blank\">https://doi.org/10.5281/zenodo.15088973</a>.</p>\n</div>\n</div>\n</div>\n</section>\n<div class=\"default\" id=\"quarto-appendix\"><section class=\"quarto-appendix-contents\" id=\"quarto-reuse\"><h2 class=\"anchored quarto-appendix-heading\">Reuse</h2><div class=\"quarto-appendix-contents\"><div><a href=\"https://creativecommons.org/licenses/by/4.0/\" rel=\"nofollow\" target=\"_blank\">CC BY 4.0</a></div></div></section><section class=\"quarto-appendix-contents\" id=\"quarto-citation\"><h2 class=\"anchored quarto-appendix-heading\">Citation</h2><div><div class=\"quarto-appendix-secondary-label\">BibTeX citation:</div><pre>@online{linnenbrink2025,\n  author = {Linnenbrink, Jan},\n  title = {Spatial Machine Learning with Caret},\n  date = {2025-05-14},\n  url = {https://geocompx.org/post/2025/sml-bp2/},\n  langid = {en}\n}\n</pre><div class=\"quarto-appendix-secondary-label\">For attribution, please cite this work as:</div><div class=\"csl-entry quarto-appendix-citeas\" id=\"ref-linnenbrink2025\">\nLinnenbrink, Jan. 2025. <span>“Spatial Machine Learning with\nCaret.”</span> May 14, 2025. <a href=\"https://geocompx.org/post/2025/sml-bp2/\" rel=\"nofollow\" target=\"_blank\">https://geocompx.org/post/2025/sml-bp2/</a>.\n</div></div></section></div>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://geocompx.org/post/2025/sml-bp2/\"> geocompx</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
      "main_text": "Spatial machine learning with caret\nPosted on\nMay 13, 2025\nby\nJan Linnenbrink\nin\nR bloggers\n| 0 Comments\n[This article was first published on\ngeocompx\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nThis is the second part of a blog post series on spatial machine learning with R.\nYou can find the list of other blog posts in this series\nin part one\n.\nIntroduction\nThis document shows the application of\ncaret\nfor spatial modelling at the example of predicting air temperature in Spain. Hereby, we use measurements of air temperature available only at specific locations in Spain to create a spatially continuous map of air temperature. Therefore, machine-learning models are trained to learn the relationship between spatially continuous predictors and air temperature.\nWhen using machine-learning methods with spatial data, we need to take care of, e.g., spatial autocorrelation, as well as extrapolation when predicting to regions that are far away from the training data. To deal with these issues, several methods have been developed. In this document, we will show how to combine the machine-learning workflow of\ncaret\nwith packages designed to deal with machine-learning with spatial data. Hereby, we use\nblockCV::cv_spatial()\nand\nCAST::knndm()\nfor spatial cross-validation, and\nCAST::aoa()\nto mask areas of extrapolation. We use\nsf\nand\nterra\nfor processing vector and raster data, respectively.\nThe caret package\nThe\ncaret\npackage contains functions to train machine-learning models, as well as for, e.g., model selection. Its main function is\ncaret::train()\n, which provides a uniform interface to over 200 machine-learning algorithms. (User-specified-) Cross-Validation methods can be defined via\ncaret::trainControl()\n. An extensive online tutorial is available at\nhttps://topepo.github.io/caret/\n. Furthermore, a paper (\nhttps://doi.org/10.18637/jss.v028.i05\n), as well as a book (\nhttp://appliedpredictivemodeling.com/\n), describing the use of\ncaret\nare available.\nInstall and load required R-packages\n# install.packages(\"caret\")\n# install.packages(\"CAST\")\n# install.packages(\"blockCV\")\n# install.packages(\"sf\")\n# install.packages(\"terra\")\nlibrary(caret)\nlibrary(CAST)\nlibrary(blockCV)\nlibrary(sf)\nlibrary(terra)\nCase study data\nLoad data needed in this modelling example:\npredictor stack\n: raster dataset of the environmental predictors used to predict air temperature\ntrain points\n: vector dataset of ground measurements of air temperature\nspain\n: region for which predictions are made\npredictor_stack <- terra::rast(\n    \"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/predictors.tif\"\n)\npredictor_names <- names(predictor_stack)\nspain <- sf::st_read(\n    \"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/spain.gpkg\"\n)\nReading layer `spain' from data source \n  `https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/spain.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1 feature and 0 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -13454.15 ymin: 3988025 xmax: 1020771 ymax: 4859816\nProjected CRS: ED50 / UTM zone 30N\ntrain_points <- sf::st_read(\n    \"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/temp_train.gpkg\"\n)\nReading layer `temp_train' from data source \n  `https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/temp_train.gpkg' \n  using driver `GPKG'\nSimple feature collection with 195 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 36026.79 ymin: 3988818 xmax: 978160.6 ymax: 4858999\nProjected CRS: ED50 / UTM zone 30N\ntrain_data <- terra::extract(\n    predictor_stack,\n    train_points,\n    bind = TRUE,\n    ID = FALSE\n) |>\n    sf::st_as_sf()\n\nplot(sf::st_geometry(spain))\nplot(sf::st_geometry(train_points), col = \"blue4\", add = TRUE)\nStandard modelling workflow\nFirstly, a simple modelling workflow without feature selection and hyperparameter tuning is shown:\nsplit data into training and test data\ntrain model using the training data only\npredict on test data to obtain error metrics\npredict on predictor stack to obtain spatially continuous prediction of air temperature\nNote\nGeometry column needs to be dropped before using\ncaret::train()\n.\n# 1. train-test split\nset.seed(321)\ntrainIndex <- caret::createDataPartition(\n    train_data$temp,\n    p = .8,\n    list = FALSE,\n    times = 1\n)\ntemperature_train <- train_data[trainIndex, ]\ntemperature_test <- train_data[-trainIndex, ]\n\n# 2. model training\nmodel <- caret::train(\n    temp ~ .,\n    data = sf::st_drop_geometry(temperature_train),\n    method = \"ranger\",\n    tuneGrid = expand.grid(\n        \"mtry\" = 4,\n        \"splitrule\" = \"variance\",\n        \"min.node.size\" = 5\n    ),\n    num.trees = 100\n)\n\n# 3. predict on test data\ntest_df <- temperature_test[, \"temp\", drop = FALSE]\ntest_df$prediction <- predict(model, temperature_test)\n\ntest_metrics <- caret::postResample(\n    pred = test_df$prediction,\n    obs = test_df$temp\n) |>\n    round(3) |>\n    t() |>\n    as.data.frame()\n\nprint(test_metrics)\nRMSE Rsquared   MAE\n1 0.913    0.901 0.741\n# 4. predict to raster stack\nprediction_spatial <- terra::predict(predictor_stack, model, na.rm = TRUE)\nSpatial Cross-Validation for model selection\nCross-validation (CV) methods are often employed to obtain optimal hyperparameter values. Therefore, the training data are split into\nfolds, and a model is trained on\n-1 folds. The fold not used for model training is then used to obtain the test statistic. This is repeated over all folds, and the test metric is averaged over the\nfolds.\nIn spatial machine-learning, a spatial CV is often needed to prevent very similar data to be in the training and testing fold at the same time, which is often the case if training data are clustered and leads to overly optimistic CV error estimates. R packages that implement spatial CV include, e.g.,\nblockCV\nand\nCAST\n. Here, we will explore the integration of those two with\ncaret\n.\nHyperparameter tuning using spatial block cross-validation\nThe\nblockCV\npackage implements different blocking methods for spatial CV. The resulting object of the main function\nblockCV::cv_spatial()\ncontains a nested list of the\nfolds and the training data rows that belong to each fold, as well as a list of the test data left out in each of the\niteration. These lists can be obtained using\nlapply()\nand then be used as an input to the\ncaret::trainControl()\nfunction of caret that defines the CV strategy used in\ncaret::train()\n. The grid of hyperparameter values tested during CV is defined using the\ntune_grid\nargument in\ncaret::train()\n. Here, we test\nmtry\nvalues from 2 to 12 and\nmin.node.size\nvalues between 5 and 15. The combination of\nmtry\nand\nmin.node.size\nthat minimizes the RMSE is then automatically used to re-train a final model with the complete training data set.\nset.seed(333)\nspatial_blocks <- blockCV::cv_spatial(\n    temperature_train,\n    k = 5,\n    progress = FALSE\n)\ntrain test\n1   126   33\n2   126   33\n3   128   31\n4   128   31\n5   128   31\ntrain_ids <- lapply(spatial_blocks$folds_list, function(x) x[[1]])\ntest_ids <- lapply(spatial_blocks$folds_list, function(x) x[[2]])\n\ntr_control_block <- caret::trainControl(\n    method = \"cv\",\n    index = train_ids,\n    indexOut = test_ids,\n    savePredictions = TRUE\n)\n\nhyperparameter_grid <- expand.grid(\n    \"mtry\" = c(2, 4, 6, 10, 12),\n    \"min.node.size\" = c(5, 10, 15),\n    \"splitrule\" = \"variance\"\n)\n\nmodel_spatial <- caret::train(\n    temp ~ .,\n    data = sf::st_drop_geometry(temperature_train),\n    method = \"ranger\",\n    trControl = tr_control_block,\n    tuneGrid = hyperparameter_grid,\n    num.trees = 100\n)\n\nmodel_spatial$finalModel\nRanger result\n\nCall:\n ranger::ranger(dependent.variable.name = \".outcome\", data = x,      mtry = min(param$mtry, ncol(x)), min.node.size = param$min.node.size,      splitrule = as.character(param$splitrule), write.forest = TRUE,      probability = classProbs, ...) \n\nType:                             Regression \nNumber of trees:                  100 \nSample size:                      159 \nNumber of independent variables:  22 \nMtry:                             10 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       0.8557959 \nR squared (OOB):                  0.8952759\nHyperparameter tuning using target-oriented CV\nAnother spatial CV method is kNNDM, which is implemented in the\nCAST\npackage and aims at emulating the prediction situation encountered by the model during CV. In this case, the prediction situation is to predict from the temperature measurement stations to the whole area of Spain. Since the temperature measurement stations are rather randomly distributed over the area of Spain, no spatial blocking is needed and kNNDM randomly assigns training points to CV folds. The output of kNNDM contains a list of row indices of training data points that are used in each CV-iteration (\nindx_train\n), as well as of indices that are left out in each iteration (\nindx_test\n). These lists can easily be used as input to the\ncaret::trainControl()\nfunction of\ncaret\nthat defines the CV used in\ncaret::train()\n.\nknndm_folds <- CAST::knndm(\n    tpoints = temperature_train,\n    modeldomain = spain,\n    space = \"geographical\",\n    clustering = \"kmeans\",\n    k = 5\n)\n\ntr_control_knndm <- caret::trainControl(\n    method = \"cv\",\n    index = knndm_folds$indx_train,\n    indexOut = knndm_folds$indx_test,\n    savePredictions = TRUE\n)\n\nhyperparameter_grid <- expand.grid(\n    \"mtry\" = c(2, 4, 6, 10, 12),\n    \"min.node.size\" = c(5, 10, 15),\n    \"splitrule\" = \"variance\"\n)\n\nmodel_knndm <- caret::train(\n    temp ~ .,\n    data = sf::st_drop_geometry(temperature_train),\n    method = \"ranger\",\n    trControl = tr_control_knndm,\n    tuneGrid = hyperparameter_grid,\n    num.trees = 100\n)\n\nmodel_knndm$finalModel\nRanger result\n\nCall:\n ranger::ranger(dependent.variable.name = \".outcome\", data = x,      mtry = min(param$mtry, ncol(x)), min.node.size = param$min.node.size,      splitrule = as.character(param$splitrule), write.forest = TRUE,      probability = classProbs, ...) \n\nType:                             Regression \nNumber of trees:                  100 \nSample size:                      159 \nNumber of independent variables:  22 \nMtry:                             12 \nTarget node size:                 10 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       0.8728343 \nR squared (OOB):                  0.8931909\nFeature selection using target-oriented CV\nTo reduce the number of environmental predictors, and thus enhance the generalizability of the model, feature selection is commonly applied in machine-learning workflows.\nCAST\nimplements Forward-Feature-Selection, that can be used with spatial CV. Here, we use the results of the hyperparameter tuning above and kNNDM CV to select the most relevant features. Plotting the results of\nFFS()\nshows that the variables\nDEM\n,\nY\n,\nEDF5\nand\nprimaryroads\nwere selected.\nselected_hyperparams <- model_knndm$bestTune\n\nmodel_ffs <- CAST::ffs(\n    predictors = sf::st_drop_geometry(temperature_train)[, predictor_names],\n    response = sf::st_drop_geometry(temperature_train)$temp,\n    method = \"ranger\",\n    num.trees = 100,\n    trControl = tr_control_knndm,\n    tuneGrid = selected_hyperparams,\n    verbose = FALSE\n)\n\nplot(model_ffs, plotType = \"selected\")\n# obtain prediction\nprediction_ffs <- terra::predict(predictor_stack, model_ffs, na.rm = TRUE)\nAOA\nLastly, the area which is too dissimilar from the training data for the models to make reliable predictions (area of applicability, AOA) is delineated using the function\nCAST::aoa()\n. The function\nCAST::aoa()\ntakes as inputs the predictor stack, as well as the trained\ncaret\nmodel. The resulting object contains the dissimilarity values, the threshold used to delineate the AOA (every dissimilarity value above this threshold is considered outside the AOA), as well as the final AOA raster. Since our training data are randomly distributed in the study area, most of the area falls within the AOA.\nAOA_without_tuning <- CAST::aoa(\n    newdata = predictor_stack,\n    model = model,\n    verbose = FALSE\n)\nAOA_with_tuning <- CAST::aoa(\n    newdata = predictor_stack,\n    model = model_ffs,\n    verbose = FALSE\n)\nCompare predictions obtained by the un-tuned model vs the tuned model\npar(mfrow = c(2, 2))\nplot(prediction_spatial, main = \"prediction without tuning\")\nplot(AOA_without_tuning$AOA, main = \"AOA without tuning\")\nplot(prediction_ffs, main = \"prediction with model selection\")\nplot(AOA_with_tuning$AOA, main = \"AOA with model selection\")\nConclusion\ncaret\nhas no functions that explicitly deal with spatial data. However, due to its rather flexible design,\ncaret\nis compatible with several packages designed for spatial machine-learning. The\ncaret::trainControl()\ntakes a list of CV indices as input, which makes it quite flexible to work with the output of e.g.\nCAST::knndm()\nand\nblockCV::cv_spatial()\n. Furthermore,\ncaret\nis easy to use due to its functional programming paradigm. The documentation is extensive, and it’s rather easy to find modelling algorithms and their hyperparameters. Lastly, it should be noted that\ncaret\nis not actively developed, since its main developer moved to\ntidymodels\n.\nThis blog post was originally written as a supplement to the poster “An Inventory of Spatial Machine Learning Packages in R” presented at the FOSSGIS 2025 conference in Muenster, Germany. The poster is available at\nhttps://doi.org/10.5281/zenodo.15088973\n.\nReuse\nCC BY 4.0\nCitation\nBibTeX citation:\n@online{linnenbrink2025,\n  author = {Linnenbrink, Jan},\n  title = {Spatial Machine Learning with Caret},\n  date = {2025-05-14},\n  url = {https://geocompx.org/post/2025/sml-bp2/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLinnenbrink, Jan. 2025.\n“Spatial Machine Learning with\nCaret.”\nMay 14, 2025.\nhttps://geocompx.org/post/2025/sml-bp2/\n.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\ngeocompx\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "This is the second part of a blog post series on spatial machine learning with R. You can find the list of other blog posts in this series in part one. Introduction This document shows the application of caret for spatial modelling at t...",
      "meta_keywords": null,
      "og_description": "This is the second part of a blog post series on spatial machine learning with R. You can find the list of other blog posts in this series in part one. Introduction This document shows the application of caret for spatial modelling at t...",
      "og_image": "https://geocompx.org/post/2025/sml-bp2/index_files/figure-html/unnamed-chunk-3-1.png",
      "og_title": "Spatial machine learning with caret | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 10.2,
      "sitemap_lastmod": null,
      "twitter_description": "This is the second part of a blog post series on spatial machine learning with R. You can find the list of other blog posts in this series in part one. Introduction This document shows the application of caret for spatial modelling at t...",
      "twitter_title": "Spatial machine learning with caret | R-bloggers",
      "url": "https://www.r-bloggers.com/2025/05/spatial-machine-learning-with-caret/",
      "word_count": 2045
    }
  }
}