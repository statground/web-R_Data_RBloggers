{
  "id": "687eb252bd176c98119c460e0b3a8fc2bbbd524f",
  "url": "https://www.r-bloggers.com/2025/06/spatial-machine-learning-with-mlr3/",
  "created_at_utc": "2025-11-22T19:58:23Z",
  "data": null,
  "raw_original": {
    "uuid": "db3b4f27-5aea-469a-b913-8edd42f01169",
    "created_at": "2025-11-22 19:58:23",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2025/06/spatial-machine-learning-with-mlr3/",
      "crawled_at": "2025-11-22T10:47:32.004424",
      "external_links": [
        {
          "href": "https://geocompx.org/post/2025/sml-bp4/",
          "text": "geocompx"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://geocompx.org/post/2025/sml-bp1/",
          "text": "in part one"
        },
        {
          "href": "https://mlr3book.mlr-org.com/",
          "text": "https://mlr3book.mlr-org.com/"
        },
        {
          "href": "https://mlr-org.com/",
          "text": "https://mlr-org.com/"
        },
        {
          "href": "https://mlr3spatial.mlr-org.com/",
          "text": "https://mlr3spatial.mlr-org.com/"
        },
        {
          "href": "https://mlr3spatiotempcv.mlr-org.com/articles/mlr3spatiotempcv.html",
          "text": "https://mlr3spatiotempcv.mlr-org.com/articles/mlr3spatiotempcv.html"
        },
        {
          "href": "https://doi.org/10.5281/zenodo.15088973",
          "text": "https://doi.org/10.5281/zenodo.15088973"
        },
        {
          "href": "https://creativecommons.org/licenses/by/4.0/",
          "text": "CC BY 4.0"
        },
        {
          "href": "https://geocompx.org/post/2025/sml-bp4/",
          "text": "https://geocompx.org/post/2025/sml-bp4/"
        },
        {
          "href": "https://geocompx.org/post/2025/sml-bp4/",
          "text": "geocompx"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Spatial machine learning with mlr3 | R-bloggers",
      "images": [
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/geocompx.org/post/2025/sml-bp4/index_files/figure-html/mlr3-prediction-tabular-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/geocompx.org/post/2025/sml-bp4/index_files/figure-html/mlr3-prediction-spatial-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/geocompx.org/post/2025/sml-bp4/index_files/figure-html/spatial-cv-results-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/geocompx.org/post/2025/sml-bp4/index_files/figure-html/mlr3-finalmodel-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/geocompx.org/post/2025/sml-bp4/index_files/figure-html/unnamed-chunk-1-1.png?w=450&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/marvin-ludwig/",
          "text": "Marvin Ludwig"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-392986 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Spatial machine learning with mlr3</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">June 10, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/marvin-ludwig/\">Marvin Ludwig</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://geocompx.org/post/2025/sml-bp4/\"> geocompx</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div class=\"callout callout-style-simple callout-note\">\n<div class=\"callout-body d-flex\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-body-container\">\n<p>This is the fourth part of a blog post series on spatial machine learning with R.</p>\n<p>You can find the list of other blog posts in this series <a href=\"https://geocompx.org/post/2025/sml-bp1/\" rel=\"nofollow\" target=\"_blank\">in part one</a>.</p>\n</div>\n</div>\n</div>\n<section class=\"level2\" id=\"aims-of-this-post\">\n<h2 class=\"anchored\" data-anchor-id=\"aims-of-this-post\">Aims of this post</h2>\n<p>This post aims to give a minimal example on how to use <strong>mlr3</strong> for a spatial prediction task. We want to get from measurements of temperature at specific locations in Spain to a spatially continuous map of temperature for all of Spain.</p>\n<p>Such a spatial prediction task is often done by applying machine learning algorithms that are not necessarily developed for spatial tasks specifically and hence do not consider problems we might encounter in the spatial world, e.g., spatial autocorrelation or map extrapolation. In the last decade, a lot of methodological developments were made by various research groups to consider and deal with such specialties of spatial mapping. Many of which found their way in software packages such as <strong>mlr3</strong>.</p>\n</section>\n<section class=\"level2\" id=\"setup\">\n<h2 class=\"anchored\" data-anchor-id=\"setup\">Setup</h2>\n<div class=\"cell\">\n<pre>install.packages(\"mlr3verse\")\ninstall.packages(\"mlr3spatiotempcv\")\ninstall.packages(\"sf\")\ninstall.packages(\"terra\")</pre>\n</div>\n<div class=\"cell\">\n<pre>library(sf)\nlibrary(terra)</pre>\n</div>\n<section class=\"level3\" id=\"casestudy-data\">\n<h3 class=\"anchored\" data-anchor-id=\"casestudy-data\">Casestudy data</h3>\n<div class=\"cell\">\n<pre>covariates &lt;- terra::rast(\"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/predictors.tif\")\ntemperature &lt;- sf::read_sf(\"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/temp_train.gpkg\")\n\nspain &lt;- sf::read_sf(\"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/spain.gpkg\") |&gt;\n    st_cast(\"POLYGON\") |&gt;\n    st_transform(st_crs(temperature))\n\ntemperature &lt;- terra::extract(covariates, temperature, bind = TRUE) |&gt;\n    sf::st_as_sf()\n\n# the sf object cannot contain a column named \"X\" or \"Y\". Otherwise the task creation will fail because \"Assertion on 'data' failed: Must have unique colnames\"\ntemperature$X &lt;- NULL\ntemperature$Y &lt;- NULL</pre>\n</div>\n<p>Some words about the terminology that is specific to the example data:</p>\n<ul>\n<li><code>spain</code> is the region outline - for visualization purposes and kNNDM setup</li>\n<li><code>covariates</code> are the spatially explicit data data to predict on (to prevent wording confusions with the predict function or the prediction)</li>\n<li><code>temperature</code> are the measured temperature data (i.e. the response variable, i.e., the ground truth) along with the covariates at the measurement location</li>\n</ul>\n</section>\n<section class=\"level3\" id=\"official-documentation\">\n<h3 class=\"anchored\" data-anchor-id=\"official-documentation\">Official Documentation</h3>\n<p>The best general introduction to <strong>mlr3</strong> is probably the official <strong>mlr3</strong> book which you can access for free here: <a class=\"uri\" href=\"https://mlr3book.mlr-org.com/\" rel=\"nofollow\" target=\"_blank\">https://mlr3book.mlr-org.com/</a>. The homepage <a class=\"uri\" href=\"https://mlr-org.com/\" rel=\"nofollow\" target=\"_blank\">https://mlr-org.com/</a> also gives a very detailed overview of all the associated packages an current developments.<br/>\nThe individual packages also have their own documentation pages, where you will find more specific topics. The “spatial” packages are the following:</p>\n<ul>\n<li><code>mlr3spatial</code> implements support for spatial data types in R – <a class=\"uri\" href=\"https://mlr3spatial.mlr-org.com/\" rel=\"nofollow\" target=\"_blank\">https://mlr3spatial.mlr-org.com/</a></li>\n<li><code>mlr3spatiotemporalcv</code> implements spatial cross-validation methods in the workflow – <a class=\"uri\" href=\"https://mlr3spatiotempcv.mlr-org.com/articles/mlr3spatiotempcv.html\" rel=\"nofollow\" target=\"_blank\">https://mlr3spatiotempcv.mlr-org.com/articles/mlr3spatiotempcv.html</a> – and also uses the <code>mlr3spatial</code> package for the spatial data types handling</li>\n</ul>\n<div class=\"cell\">\n<pre>library(mlr3verse)\nlibrary(mlr3spatiotempcv)\nlibrary(mlr3viz)</pre>\n</div>\n<div class=\"callout-hint\">\n<p><strong>mlr3</strong> functions can be very verbose. For this blog post, I turned off messages for a less overwhelming tutorial.</p>\n</div>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Code</summary>\n<pre>lgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\nlgr::get_logger(\"bbotk\")$set_threshold(\"warn\")</pre>\n</details>\n</div>\n</section>\n</section>\n<section class=\"level2\" id=\"getting-started-with-mlr3\">\n<h2 class=\"anchored\" data-anchor-id=\"getting-started-with-mlr3\">Getting started with mlr3</h2>\n<p>First of all, <strong>mlr3</strong> uses <code>R6</code> classes and therefor an object-oriented design paradigm. This might be not intuitive for a lot of R users and more in line with something like scikit-learn of Python. In general, with <code>R6</code> classes you define an object first, and this object contains all the methods and parameters you can access.</p>\n<p>The <code>R6</code> class in R has a significant drawback when it comes to RStudio’s convenience features. For example, it does not provide in-line popup help for available parameters in a model. This means you must manually look up the parameters, e.g., needed for the <code>ranger()</code> function.”</p>\n<p>Let’s define a minimum spatial prediction task example with <strong>mlr3</strong> classes:</p>\n<div class=\"callout-hint\">\n<p><strong>mlr3</strong> uses its own terminology. You have to know a lot of specific terms in order to comfortably use the functions. I try to use the <strong>mlr3</strong> terminology here and give some alternative terms in parenthesis.</p>\n</div>\n<section class=\"level3\" id=\"task\">\n<h3 class=\"anchored\" data-anchor-id=\"task\">Task</h3>\n<p>The <code>task</code> defines general information about the data we have at hand. From our point observations we create the task and define what column the target (response / dependent) variable is, what column the geometry (coordinates) is and whether we want to use the coordinates as features (predictors). In this example, we also split the data in our task into a training and a test partition.</p>\n<div class=\"cell\">\n<pre>task_spain &lt;- mlr3spatial::as_task_regr_st(\n    temperature,\n    target = \"temp\",\n    coordinate_names = \"geometry\",\n    coords_as_features = TRUE,\n    crs = st_crs(temperature)\n)\n\ntrain_test_split &lt;- mlr3::partition(task_spain, ratio = 0.7)</pre>\n</div>\n<div class=\"callout callout-style-default callout-tip callout-titled\">\n<div class=\"callout-header d-flex align-content-center\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\n<code>st_drop_geometry()</code>\n</div>\n</div>\n<div class=\"callout-body-container callout-body\">\n<p>In <strong>caret</strong>, if we want to use spatial data, we have to specifically exclude the geometry column of the <code>sf</code> object. We lose the spatial information in the process of model training and prediction. However, this information can be critical, e.g., if we want to use <code>CAST::errorprofiles()</code> or <code>CAST::knncv()</code>. In <strong>mlr3</strong> we can keep the geometry and can also directly define whether we want to use the coordinates as predictors.</p>\n</div>\n</div>\n</section>\n<section class=\"level3\" id=\"learner\">\n<h3 class=\"anchored\" data-anchor-id=\"learner\">Learner</h3>\n<p>The <code>learner</code> is the model type or algorithm we want to use with all its necessary or optional parameters. Here I define a Random Forest regression method from the <strong>ranger</strong> package with 100 decision trees and an <code>mtry</code> of 4.</p>\n<div class=\"cell\">\n<pre>rfmodel &lt;- mlr3::lrn(\"regr.ranger\", num.trees = 100, mtry = 4)</pre>\n</div>\n</section>\n<section class=\"level3\" id=\"measure\">\n<h3 class=\"anchored\" data-anchor-id=\"measure\">Measure</h3>\n<p>In order to evaluate the a score (model performance), e.g., from the previously defined test data partition, we need to define a <code>measure</code>. Here I use the Root Mean Squared Error (RMSE).</p>\n<div class=\"cell\">\n<pre>measure_rmse &lt;- mlr3::msr(\"regr.rmse\")</pre>\n</div>\n</section>\n</section>\n<section class=\"level2\" id=\"training-validation-and-prediction\">\n<h2 class=\"anchored\" data-anchor-id=\"training-validation-and-prediction\">Training, Validation and Prediction</h2>\n<p>We now have everything defined to actually do something. To train the model we can use the <code>train</code> method from out defined learner. And we have to tell the <code>train</code> method on what to actually fit the model – in this case the data in <code>task_spain</code>, but only the subset we sampled as training data.</p>\n<div class=\"cell\">\n<pre>rfmodel$train(task_spain, row_ids = train_test_split$train)\nrfmodel$model</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Ranger result\n\nCall:\n ranger::ranger(dependent.variable.name = task$target_names, data = task$data(),      case.weights = task$weights$weight, mtry = 4L, num.threads = 1L,      num.trees = 100L) \n\nType:                             Regression \nNumber of trees:                  100 \nSample size:                      136 \nNumber of independent variables:  22 \nMtry:                             4 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       0.8517061 \nR squared (OOB):                  0.8846182 </pre>\n</div>\n</div>\n<p>To test how well out model performs now on unseen data, we use the <code>predict</code> method of our fitted learner. Again, we tell the <code>predict</code> method on what data to predict. We can then calculate the <code>score</code> of this test prediction, i.e., the RMSE we defined earlier as out measure.</p>\n<div class=\"cell\">\n<pre>test_prediction &lt;- rfmodel$predict(task_spain, row_ids = train_test_split$test)\ntest_prediction$score(measure_rmse)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>regr.rmse \n 1.169592 </pre>\n</div>\n<pre>plot(test_prediction)</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i0.wp.com/geocompx.org/post/2025/sml-bp4/index_files/figure-html/mlr3-prediction-tabular-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/geocompx.org/post/2025/sml-bp4/index_files/figure-html/mlr3-prediction-tabular-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<p>Finally, we can also use the model to predict temperatures for the whole raster by using the <code>predict()</code> function from <strong>terra</strong>. Alternatively, we could use <code>predict_spatial()</code> for the <strong>mlr3spatial</strong> package.</p>\n<div class=\"cell\">\n<pre>prediction &lt;- terra::predict(covariates, rfmodel)\nplot(prediction)</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i0.wp.com/geocompx.org/post/2025/sml-bp4/index_files/figure-html/mlr3-prediction-spatial-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/geocompx.org/post/2025/sml-bp4/index_files/figure-html/mlr3-prediction-spatial-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"spatial-cross-validation-hyperparameter-tuning\">\n<h2 class=\"anchored\" data-anchor-id=\"spatial-cross-validation-hyperparameter-tuning\">Spatial cross-validation hyperparameter tuning</h2>\n<p>In many cases, the ideal model hyperparameters are not obvious and we have the possibility to tune them based on the data we have.</p>\n<section class=\"level3\" id=\"define-the-c-v-strategy-and-hyperparameters\">\n<h3 class=\"anchored\" data-anchor-id=\"define-the-c-v-strategy-and-hyperparameters\">Define the c-v strategy and hyperparameters</h3>\n<p>Again, we first define the necessary <strong>mlr3</strong> objects for our tuning process. With <code>rsmp</code> we decide on a resampling strategy, i.e., the data partitions we use as cross-validation folds. The package <strong>mlr3spatiotemporalcv</strong> contains the popular spatial resampling strategies such as block CV (<code>spcv_block</code> used in the example below) or kNNDM.</p>\n<p>For the <code>learner</code> instead of predefined hyperparameters, we use the function <code>to_tune()</code> where we can specify different values for the hyperparameters we want to test.</p>\n<div class=\"cell\">\n<pre>library(mlr3spatiotempcv)\n\nresampling_blockcv &lt;- rsmp(\"spcv_block\", folds = 5, range = 5000)\n\nrfmodel &lt;- lrn(\n    \"regr.ranger\",\n    num.trees = 100,\n    mtry = to_tune(c(2, 4, 6, 10, 12)),\n    min.node.size = to_tune(c(5, 10, 15)),\n    importance = \"impurity\"\n)</pre>\n</div>\n<p>Now we can assemble everything together in a <code>tuning instance</code> object with the <code>ti()</code> function. The first four arguments should be self explanatory: <code>terminator</code> means, if we want to stop with our search for the best hyperparameter combination after some criteria is met. <code>store_benchmark_results</code> and <code>store_models</code> regulates whether we want to keep the measures and models for all the hyperparameter combinations we test.</p>\n<p>Finally, we have to decide on a strategy on how to search with the <code>tuner</code> object. Here I use <code>grid_search</code> which is the brute force method that tests every possible combination once. We then execute the cross-validation with the <code>optimize</code> method from the <code>tuner</code> object.</p>\n<div class=\"cell\">\n<pre>tuning_blockcv &lt;- ti(\n    task = task_spain, # the data\n    resampling = resampling_blockcv, # the folds\n    learner = rfmodel, # the rfmodel with mtry and min.node.size to tune\n    measures = measure_rmse, # how to measure performance\n    terminator = trm(\"none\"),\n    store_benchmark_result = TRUE,\n    store_models = TRUE\n)\n\ntuner_grid_search &lt;- mlr3tuning::tnr(\"grid_search\")\n\ntuner_grid_search$optimize(tuning_blockcv)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>   min.node.size   mtry learner_param_vals  x_domain regr.rmse\n          &lt;char&gt; &lt;char&gt;             &lt;list&gt;    &lt;list&gt;     &lt;num&gt;\n1:             5     10          &lt;list[5]&gt; &lt;list[2]&gt; 0.8371396</pre>\n</div>\n</div>\n<p>The results are stored in the defined <code>tuning instance</code> object. We also have some nice plotting options with the <strong>mlr3viz</strong> package.</p>\n<div class=\"cell\">\n<pre>tuning_blockcv$result_learner_param_vals</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>$importance\n[1] \"impurity\"\n\n$num.threads\n[1] 1\n\n$num.trees\n[1] 100\n\n$min.node.size\n[1] 5\n\n$mtry\n[1] 10</pre>\n</div>\n<pre>tuning_blockcv$result_y</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>regr.rmse \n0.8371396 </pre>\n</div>\n<pre>autoplot(tuning_blockcv, type = \"parallel\")</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i0.wp.com/geocompx.org/post/2025/sml-bp4/index_files/figure-html/spatial-cv-results-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/geocompx.org/post/2025/sml-bp4/index_files/figure-html/spatial-cv-results-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<p>Because we set <code>store_benchmark_result = TRUE</code> and <code>store_models = TRUE</code>, we also have a <code>archive</code> where all the other results are stored.</p>\n<div class=\"callout callout-style-default callout-tip callout-titled\">\n<div aria-controls=\"callout-2\" aria-expanded=\"false\" aria-label=\"Toggle callout\" class=\"callout-header d-flex align-content-center\" data-bs-=\"\" data-bs-toggle=\"collapse\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nTuning Archive\n</div>\n<div class=\"callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end\"><i class=\"callout-toggle\"></i></div>\n</div>\n<div class=\"callout-2-contents callout-collapse collapse\" id=\"callout-2\">\n<div class=\"callout-body-container callout-body\">\n<div class=\"cell\">\n<pre>tuning_blockcv$archive$data</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>    min.node.size   mtry regr.rmse warnings errors runtime_learners\n           &lt;char&gt; &lt;char&gt;     &lt;num&gt;    &lt;int&gt;  &lt;int&gt;            &lt;num&gt;\n 1:            10      2 1.0967280        0      0            0.088\n 2:             5     12 0.8445786        0      0            0.194\n 3:             5      2 1.0611523        0      0            0.100\n 4:            10     10 0.8664100        0      0            0.143\n 5:            15      2 1.1328312        0      0            0.076\n 6:            15      6 0.8977785        0      0            0.115\n 7:            15     12 0.8584339        0      0            0.130\n 8:             5     10 0.8371396        0      0            0.173\n 9:             5      6 0.8751873        0      0            0.135\n10:            15      4 0.9558697        0      0            0.096\n11:            10     12 0.8686075        0      0            0.150\n12:            15     10 0.8482450        0      0            0.124\n13:            10      4 0.9337196        0      0            0.098\n14:            10      6 0.9080175        0      0            0.112\n15:             5      4 0.9093173        0      0            0.120\n                                   uhash  x_domain           timestamp batch_nr\n                                  &lt;char&gt;    &lt;list&gt;              &lt;POSc&gt;    &lt;int&gt;\n 1: ea0ec2ec-61ea-491b-89d6-0199f7911c86 &lt;list[2]&gt; 2025-06-10 15:23:25        1\n 2: c6e3dafc-d8f8-45de-8e33-e697bf03043c &lt;list[2]&gt; 2025-06-10 15:23:25        2\n 3: 6cee1b95-a51e-424d-a83c-1803a0129bd3 &lt;list[2]&gt; 2025-06-10 15:23:26        3\n 4: d5158623-9d5a-4364-8892-44f5d35474c1 &lt;list[2]&gt; 2025-06-10 15:23:26        4\n 5: e0b4d893-6eb7-4296-9cef-d7581b8a67e4 &lt;list[2]&gt; 2025-06-10 15:23:26        5\n 6: fad242aa-4690-49a5-8441-839497e051de &lt;list[2]&gt; 2025-06-10 15:23:26        6\n 7: 623348f6-dcc2-44e6-b1fa-3dd6c3275e31 &lt;list[2]&gt; 2025-06-10 15:23:27        7\n 8: 58234e7f-0886-47ca-9c03-ba2aa25ef475 &lt;list[2]&gt; 2025-06-10 15:23:27        8\n 9: 9ff77763-ca89-4d9d-9d29-68e8e4209483 &lt;list[2]&gt; 2025-06-10 15:23:27        9\n10: 5b63b98f-536c-47ac-bbc5-09a968005885 &lt;list[2]&gt; 2025-06-10 15:23:27       10\n11: f89ed101-fa0f-4050-813b-66c1ee24bcc7 &lt;list[2]&gt; 2025-06-10 15:23:28       11\n12: 5ab5bad0-126a-466c-8980-c0531ff01fdd &lt;list[2]&gt; 2025-06-10 15:23:28       12\n13: b953b8fd-26b2-4b05-8d45-f522bac498e4 &lt;list[2]&gt; 2025-06-10 15:23:28       13\n14: ad5f6183-d75f-41de-8b24-891a9c9f26cb &lt;list[2]&gt; 2025-06-10 15:23:28       14\n15: 8d6ef31e-8c86-40fc-9a2a-02a533025c62 &lt;list[2]&gt; 2025-06-10 15:23:29       15</pre>\n</div>\n</div>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level3\" id=\"final-model-with-optimized-hyperparameter\">\n<h3 class=\"anchored\" data-anchor-id=\"final-model-with-optimized-hyperparameter\">Final model with optimized hyperparameter</h3>\n<p>Once we found the optimal hyperparameter combination we can use them to train a final model on all the data. We define a new <code>learner</code> and assign the parameters from our <code>tuning instance</code> to it. Then we can train and predict again.</p>\n<div class=\"cell\">\n<pre>tuned_rfmodel &lt;- lrn(\"regr.ranger\")\ntuned_rfmodel$param_set$values &lt;- tuning_blockcv$result_learner_param_vals\n\ntuned_rfmodel$train(task_spain)\ntuned_prediction &lt;- terra::predict(covariates, tuned_rfmodel)\nplot(tuned_prediction)</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i1.wp.com/geocompx.org/post/2025/sml-bp4/index_files/figure-html/mlr3-finalmodel-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/geocompx.org/post/2025/sml-bp4/index_files/figure-html/mlr3-finalmodel-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n</section>\n</section>\n<section class=\"level2\" id=\"feature-selection\">\n<h2 class=\"anchored\" data-anchor-id=\"feature-selection\">Feature Selection</h2>\n<section class=\"level3\" id=\"define-the-feature-selection-strategy\">\n<h3 class=\"anchored\" data-anchor-id=\"define-the-feature-selection-strategy\">Define the feature selection strategy</h3>\n<p>Similar to the hyperparameter tuning, we can use the cross-validation strategy to test whether we can build a model with reduces predictors / covariates / features / variable. Here I demonstrate a forward variable selection, that starts out with the best performing pair of variables and appends additional variables, if there is still an increase in our cross-validation performance estimation.</p>\n<p>First we have to define the feature selection strategy with <code>fs()</code>. I use a learner here with fixed hyperparameters. Everything is put together in the <code>fselect()</code> function that creates a feature selection <code>instance</code> in which all the information, methods and results are stored.</p>\n<div class=\"cell\">\n<pre>library(mlr3fselect)\nlibrary(mlr3filters)\n\nselect_mode &lt;- fs(\"sequential\", min_features = 2)\n\nfs_rfmodel &lt;- lrn(\n    \"regr.ranger\",\n    num.trees = 50,\n    mtry = 2,\n    min.node.size = 5,\n    importance = \"impurity\"\n)\n\nset.seed(20)\nfeature_selection &lt;- fselect(\n    fselector = select_mode,\n    task = task_spain,\n    learner = fs_rfmodel,\n    resampling = resampling_blockcv,\n    measure = measure_rmse\n)</pre>\n</div>\n<div class=\"cell\">\n<pre># selected variables\nfeature_selection$result_feature_set</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] \"Y\"         \"dem\"       \"lst_day\"   \"lst_night\" \"ntl\"       \"popdens\"  </pre>\n</div>\n<pre># CV RMSE with the selected variables\nfeature_selection$result$regr.rmse</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 0.7795219</pre>\n</div>\n</div>\n</section>\n<section class=\"level3\" id=\"final-model-with-selected-features\">\n<h3 class=\"anchored\" data-anchor-id=\"final-model-with-selected-features\">Final model with selected features</h3>\n<p>Once we found the ideal combination of variables, we can reduce our task to those predictors, train a model and predict.</p>\n<div class=\"cell\">\n<pre>fs_task &lt;- task_spain$select(feature_selection$result_feature_set)\n\nfs_rfmodel$train(fs_task)\n\nfs_prediction &lt;- terra::predict(covariates, fs_rfmodel)\nplot(fs_prediction)</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i1.wp.com/geocompx.org/post/2025/sml-bp4/index_files/figure-html/unnamed-chunk-1-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/geocompx.org/post/2025/sml-bp4/index_files/figure-html/unnamed-chunk-1-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n</section>\n</section>\n<section class=\"level2\" id=\"conclusions\">\n<h2 class=\"anchored\" data-anchor-id=\"conclusions\">Conclusions</h2>\n<ul>\n<li>Utilizes an <strong>object-oriented approach</strong> with <code>R6</code> classes, offering flexibility but requiring familiarity with this system in R.</li>\n<li>Possible target audience: <strong>machine learning experts</strong> and <strong>Python users</strong> transitioning to R, especially those familiar with object-oriented programming.</li>\n</ul>\n<section class=\"level3\" id=\"strengths\">\n<h3 class=\"anchored\" data-anchor-id=\"strengths\">Strengths</h3>\n<ul>\n<li><strong>Spatially explicit methods are directly implemented</strong>: there is no need to exclude the geometry column of the <code>sf</code> object, allowing for the retention of spatial information.</li>\n<li><strong>Active development</strong>: continuously updated with improvements and bug fixes.</li>\n<li><strong>Very good introduction to the framework through the book</strong>: The book offers a well-structured guide for learning the <strong>mlr3</strong> framework.</li>\n<li><strong>Well-documented functions</strong>: Clear and comprehensive documentation helps users understand the functions easily.</li>\n</ul>\n</section>\n<section class=\"level3\" id=\"weaknesses\">\n<h3 class=\"anchored\" data-anchor-id=\"weaknesses\">Weaknesses</h3>\n<ul>\n<li><strong>Steep learning curve</strong>: The framework’s complexity can be challenging for beginners.</li>\n<li><strong>Overwhelming number of methods and options</strong>: The extensive methods can be difficult to navigate for new users.</li>\n<li><strong>Confusing help pages due to <code>R6</code> logic</strong>: Understanding the <code>R6</code> logic in help files can be tough for those unfamiliar with the system.</li>\n<li><strong>No in-line help in RStudio</strong>: Lack of in-line help for <code>R6</code> methods in RStudio makes it harder to access function details quickly.</li>\n</ul>\n<div class=\"callout callout-style-simple callout-note\">\n<div class=\"callout-body d-flex\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-body-container\">\n<p>This blog post was originally written as a supplement to the poster “An Inventory of Spatial Machine Learning Packages in R” presented at the FOSSGIS 2025 conference in Muenster, Germany. The poster is available at <a class=\"uri\" href=\"https://doi.org/10.5281/zenodo.15088973\" rel=\"nofollow\" target=\"_blank\">https://doi.org/10.5281/zenodo.15088973</a>.</p>\n</div>\n</div>\n</div>\n</section>\n</section>\n<div class=\"default\" id=\"quarto-appendix\"><section class=\"quarto-appendix-contents\" id=\"quarto-reuse\"><h2 class=\"anchored quarto-appendix-heading\">Reuse</h2><div class=\"quarto-appendix-contents\"><div><a href=\"https://creativecommons.org/licenses/by/4.0/\" rel=\"nofollow\" target=\"_blank\">CC BY 4.0</a></div></div></section><section class=\"quarto-appendix-contents\" id=\"quarto-citation\"><h2 class=\"anchored quarto-appendix-heading\">Citation</h2><div><div class=\"quarto-appendix-secondary-label\">BibTeX citation:</div><pre>@online{ludwig2025,\n  author = {Ludwig, Marvin},\n  title = {Spatial Machine Learning with Mlr3},\n  date = {2025-06-11},\n  url = {https://geocompx.org/post/2025/sml-bp4/},\n  langid = {en}\n}\n</pre><div class=\"quarto-appendix-secondary-label\">For attribution, please cite this work as:</div><div class=\"csl-entry quarto-appendix-citeas\" id=\"ref-ludwig2025\">\nLudwig, Marvin. 2025. <span>“Spatial Machine Learning with Mlr3.”</span>\nJune 11, 2025. <a href=\"https://geocompx.org/post/2025/sml-bp4/\" rel=\"nofollow\" target=\"_blank\">https://geocompx.org/post/2025/sml-bp4/</a>.\n</div></div></section></div>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://geocompx.org/post/2025/sml-bp4/\"> geocompx</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
      "main_text": "Spatial machine learning with mlr3\nPosted on\nJune 10, 2025\nby\nMarvin Ludwig\nin\nR bloggers\n| 0 Comments\n[This article was first published on\ngeocompx\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nThis is the fourth part of a blog post series on spatial machine learning with R.\nYou can find the list of other blog posts in this series\nin part one\n.\nAims of this post\nThis post aims to give a minimal example on how to use\nmlr3\nfor a spatial prediction task. We want to get from measurements of temperature at specific locations in Spain to a spatially continuous map of temperature for all of Spain.\nSuch a spatial prediction task is often done by applying machine learning algorithms that are not necessarily developed for spatial tasks specifically and hence do not consider problems we might encounter in the spatial world, e.g., spatial autocorrelation or map extrapolation. In the last decade, a lot of methodological developments were made by various research groups to consider and deal with such specialties of spatial mapping. Many of which found their way in software packages such as\nmlr3\n.\nSetup\ninstall.packages(\"mlr3verse\")\ninstall.packages(\"mlr3spatiotempcv\")\ninstall.packages(\"sf\")\ninstall.packages(\"terra\")\nlibrary(sf)\nlibrary(terra)\nCasestudy data\ncovariates <- terra::rast(\"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/predictors.tif\")\ntemperature <- sf::read_sf(\"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/temp_train.gpkg\")\n\nspain <- sf::read_sf(\"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/spain.gpkg\") |>\n    st_cast(\"POLYGON\") |>\n    st_transform(st_crs(temperature))\n\ntemperature <- terra::extract(covariates, temperature, bind = TRUE) |>\n    sf::st_as_sf()\n\n# the sf object cannot contain a column named \"X\" or \"Y\". Otherwise the task creation will fail because \"Assertion on 'data' failed: Must have unique colnames\"\ntemperature$X <- NULL\ntemperature$Y <- NULL\nSome words about the terminology that is specific to the example data:\nspain\nis the region outline - for visualization purposes and kNNDM setup\ncovariates\nare the spatially explicit data data to predict on (to prevent wording confusions with the predict function or the prediction)\ntemperature\nare the measured temperature data (i.e. the response variable, i.e., the ground truth) along with the covariates at the measurement location\nOfficial Documentation\nThe best general introduction to\nmlr3\nis probably the official\nmlr3\nbook which you can access for free here:\nhttps://mlr3book.mlr-org.com/\n. The homepage\nhttps://mlr-org.com/\nalso gives a very detailed overview of all the associated packages an current developments.\nThe individual packages also have their own documentation pages, where you will find more specific topics. The “spatial” packages are the following:\nmlr3spatial\nimplements support for spatial data types in R –\nhttps://mlr3spatial.mlr-org.com/\nmlr3spatiotemporalcv\nimplements spatial cross-validation methods in the workflow –\nhttps://mlr3spatiotempcv.mlr-org.com/articles/mlr3spatiotempcv.html\n– and also uses the\nmlr3spatial\npackage for the spatial data types handling\nlibrary(mlr3verse)\nlibrary(mlr3spatiotempcv)\nlibrary(mlr3viz)\nmlr3\nfunctions can be very verbose. For this blog post, I turned off messages for a less overwhelming tutorial.\nCode\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\nlgr::get_logger(\"bbotk\")$set_threshold(\"warn\")\nGetting started with mlr3\nFirst of all,\nmlr3\nuses\nR6\nclasses and therefor an object-oriented design paradigm. This might be not intuitive for a lot of R users and more in line with something like scikit-learn of Python. In general, with\nR6\nclasses you define an object first, and this object contains all the methods and parameters you can access.\nThe\nR6\nclass in R has a significant drawback when it comes to RStudio’s convenience features. For example, it does not provide in-line popup help for available parameters in a model. This means you must manually look up the parameters, e.g., needed for the\nranger()\nfunction.”\nLet’s define a minimum spatial prediction task example with\nmlr3\nclasses:\nmlr3\nuses its own terminology. You have to know a lot of specific terms in order to comfortably use the functions. I try to use the\nmlr3\nterminology here and give some alternative terms in parenthesis.\nTask\nThe\ntask\ndefines general information about the data we have at hand. From our point observations we create the task and define what column the target (response / dependent) variable is, what column the geometry (coordinates) is and whether we want to use the coordinates as features (predictors). In this example, we also split the data in our task into a training and a test partition.\ntask_spain <- mlr3spatial::as_task_regr_st(\n    temperature,\n    target = \"temp\",\n    coordinate_names = \"geometry\",\n    coords_as_features = TRUE,\n    crs = st_crs(temperature)\n)\n\ntrain_test_split <- mlr3::partition(task_spain, ratio = 0.7)\nst_drop_geometry()\nIn\ncaret\n, if we want to use spatial data, we have to specifically exclude the geometry column of the\nsf\nobject. We lose the spatial information in the process of model training and prediction. However, this information can be critical, e.g., if we want to use\nCAST::errorprofiles()\nor\nCAST::knncv()\n. In\nmlr3\nwe can keep the geometry and can also directly define whether we want to use the coordinates as predictors.\nLearner\nThe\nlearner\nis the model type or algorithm we want to use with all its necessary or optional parameters. Here I define a Random Forest regression method from the\nranger\npackage with 100 decision trees and an\nmtry\nof 4.\nrfmodel <- mlr3::lrn(\"regr.ranger\", num.trees = 100, mtry = 4)\nMeasure\nIn order to evaluate the a score (model performance), e.g., from the previously defined test data partition, we need to define a\nmeasure\n. Here I use the Root Mean Squared Error (RMSE).\nmeasure_rmse <- mlr3::msr(\"regr.rmse\")\nTraining, Validation and Prediction\nWe now have everything defined to actually do something. To train the model we can use the\ntrain\nmethod from out defined learner. And we have to tell the\ntrain\nmethod on what to actually fit the model – in this case the data in\ntask_spain\n, but only the subset we sampled as training data.\nrfmodel$train(task_spain, row_ids = train_test_split$train)\nrfmodel$model\nRanger result\n\nCall:\n ranger::ranger(dependent.variable.name = task$target_names, data = task$data(),      case.weights = task$weights$weight, mtry = 4L, num.threads = 1L,      num.trees = 100L) \n\nType:                             Regression \nNumber of trees:                  100 \nSample size:                      136 \nNumber of independent variables:  22 \nMtry:                             4 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       0.8517061 \nR squared (OOB):                  0.8846182\nTo test how well out model performs now on unseen data, we use the\npredict\nmethod of our fitted learner. Again, we tell the\npredict\nmethod on what data to predict. We can then calculate the\nscore\nof this test prediction, i.e., the RMSE we defined earlier as out measure.\ntest_prediction <- rfmodel$predict(task_spain, row_ids = train_test_split$test)\ntest_prediction$score(measure_rmse)\nregr.rmse \n 1.169592\nplot(test_prediction)\nFinally, we can also use the model to predict temperatures for the whole raster by using the\npredict()\nfunction from\nterra\n. Alternatively, we could use\npredict_spatial()\nfor the\nmlr3spatial\npackage.\nprediction <- terra::predict(covariates, rfmodel)\nplot(prediction)\nSpatial cross-validation hyperparameter tuning\nIn many cases, the ideal model hyperparameters are not obvious and we have the possibility to tune them based on the data we have.\nDefine the c-v strategy and hyperparameters\nAgain, we first define the necessary\nmlr3\nobjects for our tuning process. With\nrsmp\nwe decide on a resampling strategy, i.e., the data partitions we use as cross-validation folds. The package\nmlr3spatiotemporalcv\ncontains the popular spatial resampling strategies such as block CV (\nspcv_block\nused in the example below) or kNNDM.\nFor the\nlearner\ninstead of predefined hyperparameters, we use the function\nto_tune()\nwhere we can specify different values for the hyperparameters we want to test.\nlibrary(mlr3spatiotempcv)\n\nresampling_blockcv <- rsmp(\"spcv_block\", folds = 5, range = 5000)\n\nrfmodel <- lrn(\n    \"regr.ranger\",\n    num.trees = 100,\n    mtry = to_tune(c(2, 4, 6, 10, 12)),\n    min.node.size = to_tune(c(5, 10, 15)),\n    importance = \"impurity\"\n)\nNow we can assemble everything together in a\ntuning instance\nobject with the\nti()\nfunction. The first four arguments should be self explanatory:\nterminator\nmeans, if we want to stop with our search for the best hyperparameter combination after some criteria is met.\nstore_benchmark_results\nand\nstore_models\nregulates whether we want to keep the measures and models for all the hyperparameter combinations we test.\nFinally, we have to decide on a strategy on how to search with the\ntuner\nobject. Here I use\ngrid_search\nwhich is the brute force method that tests every possible combination once. We then execute the cross-validation with the\noptimize\nmethod from the\ntuner\nobject.\ntuning_blockcv <- ti(\n    task = task_spain, # the data\n    resampling = resampling_blockcv, # the folds\n    learner = rfmodel, # the rfmodel with mtry and min.node.size to tune\n    measures = measure_rmse, # how to measure performance\n    terminator = trm(\"none\"),\n    store_benchmark_result = TRUE,\n    store_models = TRUE\n)\n\ntuner_grid_search <- mlr3tuning::tnr(\"grid_search\")\n\ntuner_grid_search$optimize(tuning_blockcv)\nmin.node.size   mtry learner_param_vals  x_domain regr.rmse\n          <char> <char>             <list>    <list>     <num>\n1:             5     10          <list[5]> <list[2]> 0.8371396\nThe results are stored in the defined\ntuning instance\nobject. We also have some nice plotting options with the\nmlr3viz\npackage.\ntuning_blockcv$result_learner_param_vals\n$importance\n[1] \"impurity\"\n\n$num.threads\n[1] 1\n\n$num.trees\n[1] 100\n\n$min.node.size\n[1] 5\n\n$mtry\n[1] 10\ntuning_blockcv$result_y\nregr.rmse \n0.8371396\nautoplot(tuning_blockcv, type = \"parallel\")\nBecause we set\nstore_benchmark_result = TRUE\nand\nstore_models = TRUE\n, we also have a\narchive\nwhere all the other results are stored.\nTuning Archive\ntuning_blockcv$archive$data\nmin.node.size   mtry regr.rmse warnings errors runtime_learners\n           <char> <char>     <num>    <int>  <int>            <num>\n 1:            10      2 1.0967280        0      0            0.088\n 2:             5     12 0.8445786        0      0            0.194\n 3:             5      2 1.0611523        0      0            0.100\n 4:            10     10 0.8664100        0      0            0.143\n 5:            15      2 1.1328312        0      0            0.076\n 6:            15      6 0.8977785        0      0            0.115\n 7:            15     12 0.8584339        0      0            0.130\n 8:             5     10 0.8371396        0      0            0.173\n 9:             5      6 0.8751873        0      0            0.135\n10:            15      4 0.9558697        0      0            0.096\n11:            10     12 0.8686075        0      0            0.150\n12:            15     10 0.8482450        0      0            0.124\n13:            10      4 0.9337196        0      0            0.098\n14:            10      6 0.9080175        0      0            0.112\n15:             5      4 0.9093173        0      0            0.120\n                                   uhash  x_domain           timestamp batch_nr\n                                  <char>    <list>              <POSc>    <int>\n 1: ea0ec2ec-61ea-491b-89d6-0199f7911c86 <list[2]> 2025-06-10 15:23:25        1\n 2: c6e3dafc-d8f8-45de-8e33-e697bf03043c <list[2]> 2025-06-10 15:23:25        2\n 3: 6cee1b95-a51e-424d-a83c-1803a0129bd3 <list[2]> 2025-06-10 15:23:26        3\n 4: d5158623-9d5a-4364-8892-44f5d35474c1 <list[2]> 2025-06-10 15:23:26        4\n 5: e0b4d893-6eb7-4296-9cef-d7581b8a67e4 <list[2]> 2025-06-10 15:23:26        5\n 6: fad242aa-4690-49a5-8441-839497e051de <list[2]> 2025-06-10 15:23:26        6\n 7: 623348f6-dcc2-44e6-b1fa-3dd6c3275e31 <list[2]> 2025-06-10 15:23:27        7\n 8: 58234e7f-0886-47ca-9c03-ba2aa25ef475 <list[2]> 2025-06-10 15:23:27        8\n 9: 9ff77763-ca89-4d9d-9d29-68e8e4209483 <list[2]> 2025-06-10 15:23:27        9\n10: 5b63b98f-536c-47ac-bbc5-09a968005885 <list[2]> 2025-06-10 15:23:27       10\n11: f89ed101-fa0f-4050-813b-66c1ee24bcc7 <list[2]> 2025-06-10 15:23:28       11\n12: 5ab5bad0-126a-466c-8980-c0531ff01fdd <list[2]> 2025-06-10 15:23:28       12\n13: b953b8fd-26b2-4b05-8d45-f522bac498e4 <list[2]> 2025-06-10 15:23:28       13\n14: ad5f6183-d75f-41de-8b24-891a9c9f26cb <list[2]> 2025-06-10 15:23:28       14\n15: 8d6ef31e-8c86-40fc-9a2a-02a533025c62 <list[2]> 2025-06-10 15:23:29       15\nFinal model with optimized hyperparameter\nOnce we found the optimal hyperparameter combination we can use them to train a final model on all the data. We define a new\nlearner\nand assign the parameters from our\ntuning instance\nto it. Then we can train and predict again.\ntuned_rfmodel <- lrn(\"regr.ranger\")\ntuned_rfmodel$param_set$values <- tuning_blockcv$result_learner_param_vals\n\ntuned_rfmodel$train(task_spain)\ntuned_prediction <- terra::predict(covariates, tuned_rfmodel)\nplot(tuned_prediction)\nFeature Selection\nDefine the feature selection strategy\nSimilar to the hyperparameter tuning, we can use the cross-validation strategy to test whether we can build a model with reduces predictors / covariates / features / variable. Here I demonstrate a forward variable selection, that starts out with the best performing pair of variables and appends additional variables, if there is still an increase in our cross-validation performance estimation.\nFirst we have to define the feature selection strategy with\nfs()\n. I use a learner here with fixed hyperparameters. Everything is put together in the\nfselect()\nfunction that creates a feature selection\ninstance\nin which all the information, methods and results are stored.\nlibrary(mlr3fselect)\nlibrary(mlr3filters)\n\nselect_mode <- fs(\"sequential\", min_features = 2)\n\nfs_rfmodel <- lrn(\n    \"regr.ranger\",\n    num.trees = 50,\n    mtry = 2,\n    min.node.size = 5,\n    importance = \"impurity\"\n)\n\nset.seed(20)\nfeature_selection <- fselect(\n    fselector = select_mode,\n    task = task_spain,\n    learner = fs_rfmodel,\n    resampling = resampling_blockcv,\n    measure = measure_rmse\n)\n# selected variables\nfeature_selection$result_feature_set\n[1] \"Y\"         \"dem\"       \"lst_day\"   \"lst_night\" \"ntl\"       \"popdens\"\n# CV RMSE with the selected variables\nfeature_selection$result$regr.rmse\n[1] 0.7795219\nFinal model with selected features\nOnce we found the ideal combination of variables, we can reduce our task to those predictors, train a model and predict.\nfs_task <- task_spain$select(feature_selection$result_feature_set)\n\nfs_rfmodel$train(fs_task)\n\nfs_prediction <- terra::predict(covariates, fs_rfmodel)\nplot(fs_prediction)\nConclusions\nUtilizes an\nobject-oriented approach\nwith\nR6\nclasses, offering flexibility but requiring familiarity with this system in R.\nPossible target audience:\nmachine learning experts\nand\nPython users\ntransitioning to R, especially those familiar with object-oriented programming.\nStrengths\nSpatially explicit methods are directly implemented\n: there is no need to exclude the geometry column of the\nsf\nobject, allowing for the retention of spatial information.\nActive development\n: continuously updated with improvements and bug fixes.\nVery good introduction to the framework through the book\n: The book offers a well-structured guide for learning the\nmlr3\nframework.\nWell-documented functions\n: Clear and comprehensive documentation helps users understand the functions easily.\nWeaknesses\nSteep learning curve\n: The framework’s complexity can be challenging for beginners.\nOverwhelming number of methods and options\n: The extensive methods can be difficult to navigate for new users.\nConfusing help pages due to\nR6\nlogic\n: Understanding the\nR6\nlogic in help files can be tough for those unfamiliar with the system.\nNo in-line help in RStudio\n: Lack of in-line help for\nR6\nmethods in RStudio makes it harder to access function details quickly.\nThis blog post was originally written as a supplement to the poster “An Inventory of Spatial Machine Learning Packages in R” presented at the FOSSGIS 2025 conference in Muenster, Germany. The poster is available at\nhttps://doi.org/10.5281/zenodo.15088973\n.\nReuse\nCC BY 4.0\nCitation\nBibTeX citation:\n@online{ludwig2025,\n  author = {Ludwig, Marvin},\n  title = {Spatial Machine Learning with Mlr3},\n  date = {2025-06-11},\n  url = {https://geocompx.org/post/2025/sml-bp4/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLudwig, Marvin. 2025.\n“Spatial Machine Learning with Mlr3.”\nJune 11, 2025.\nhttps://geocompx.org/post/2025/sml-bp4/\n.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\ngeocompx\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "This is the fourth part of a blog post series on spatial machine learning with R. You can find the list of other blog posts in this series in part one. Aims of this post This post aims to give a minimal example on how to use mlr3 for a ...",
      "meta_keywords": null,
      "og_description": "This is the fourth part of a blog post series on spatial machine learning with R. You can find the list of other blog posts in this series in part one. Aims of this post This post aims to give a minimal example on how to use mlr3 for a ...",
      "og_image": "https://geocompx.org/post/2025/sml-bp4/index_files/figure-html/mlr3-prediction-tabular-1.png",
      "og_title": "Spatial machine learning with mlr3 | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 13.1,
      "sitemap_lastmod": null,
      "twitter_description": "This is the fourth part of a blog post series on spatial machine learning with R. You can find the list of other blog posts in this series in part one. Aims of this post This post aims to give a minimal example on how to use mlr3 for a ...",
      "twitter_title": "Spatial machine learning with mlr3 | R-bloggers",
      "url": "https://www.r-bloggers.com/2025/06/spatial-machine-learning-with-mlr3/",
      "word_count": 2610
    }
  }
}