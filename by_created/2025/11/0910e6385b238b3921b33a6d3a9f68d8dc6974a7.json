{
  "id": "0910e6385b238b3921b33a6d3a9f68d8dc6974a7",
  "url": "https://www.r-bloggers.com/2023/10/survival-modeling-in-mlr3-using-bayesian-additive-regression-trees-bart/",
  "created_at_utc": "2025-11-17T20:39:30Z",
  "data": null,
  "raw_original": {
    "uuid": "6e3f4a42-6260-4bde-9a3e-8476ccce70fc",
    "created_at": "2025-11-17 20:39:30",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2023/10/survival-modeling-in-mlr3-using-bayesian-additive-regression-trees-bart/",
      "crawled_at": "2025-11-17T10:04:50.031021",
      "external_links": [
        {
          "href": "https://mlr-org.com/gallery/technical/2023-19-25-bart-survival/",
          "text": "mlr-org"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://mlr3extralearners.mlr-org.com/reference/mlr_learners_surv.bart.html",
          "text": "documentation"
        },
        {
          "href": "https://r6.r-lib.org/index.html",
          "text": "R6"
        },
        {
          "href": "https://doi.org/10.1093/BIOINFORMATICS/BTQ660",
          "text": "https://doi.org/10.1093/BIOINFORMATICS/BTQ660"
        },
        {
          "href": "http://www.jstor.org/stable/27801587",
          "text": "http://www.jstor.org/stable/27801587"
        },
        {
          "href": "https://doi.org/10.1214/aos/1013203451",
          "text": "https://doi.org/10.1214/aos/1013203451"
        },
        {
          "href": "https://doi.org/10.1093/BIOINFORMATICS/BTAC451",
          "text": "https://doi.org/10.1093/BIOINFORMATICS/BTAC451"
        },
        {
          "href": "https://doi.org/10.48550/arxiv.2206.03256",
          "text": "https://doi.org/10.48550/arxiv.2206.03256"
        },
        {
          "href": "https://doi.org/10.1002/SIM.6893",
          "text": "https://doi.org/10.1002/SIM.6893"
        },
        {
          "href": "https://doi.org/10.18637/JSS.V097.I01",
          "text": "https://doi.org/10.18637/JSS.V097.I01"
        },
        {
          "href": "https://mlr-org.com/gallery/technical/2023-19-25-bart-survival/",
          "text": "mlr-org"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Survival modeling in mlr3 using Bayesian Additive Regression Trees (BART) | R-bloggers",
      "images": [
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:application/octet-stream;base64,iVBORw0KGgoAAAANSUhEUgAAAKcAAAAMBAMAAAD147DyAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAdomZu1QiEGbdMu/NRKugN9EaAAAACXBIWXMAAA7EAAAOxAGVKw4bAAACLklEQVQoFV2TPWgUURSFv5nszs7+ZdeNSkRdVxRME0xwFSyM2/hTWIzaCBZOCBaCuKttCmc3grGzsbFxwE6EXRvLsKRIJ4yglYqroKCFiYhRIhLvezszjLnw7jtz7uHw7n1voFJ3sNsfSMZitQxv/SRlLbdPUxyfTHKghNcntrvY23YOwctOAKab+c0EJXGJw/T4zmzXjwkB1qMll6cU3CSphdf+fIajzKBArs8KZH2Oc5D8ICE2GyxByU9QWI58ncKYSpKmEl4VptjgiQYphzHIexwW9rYnaU7WXlkgpw9NI06bblDs6XqcRKhMs54kBeQkb2SDc7L2KJAeYNRkB6MfmUacNd4Jcuvkful6nEQ4uzhJ6VLH0aDr0m1J1dqAhWFXC1S03D4iW9h+yGXKPCyK6bpUZr5JfFRKJbwpI2xOyWgUeC+mrhQKnqQ7yh57emiOfSY2jTnq4ii+/4USMtLoetwbAhfxRa5eItVXmS86S5KRRBcVc7ulp/SW9vXsjF4z4IocS4Cvge3BV0a02J6uKddRn5OtyDTksg77+Eu6pwRRaOEDjLWSI14aBFyW6mts6yeja0oYzq/psBqfNOQKLnXOYgxEFs9UC1ek/VSZXfJABXhUIXfi3UUOMV8Wsdy0WZPdbGWeiWkgMObsVuY5r7Y+fiW8y7ybu88LDYoN9fjzm5s/MPZ/UgY3ZOn/sFJ1uLW67Ce59gGX9I4tv6kS2pVj8HgsGILzFwL+AcvOndgZ4Kh+AAAAAElFTkSuQmCC",
          "src": "https://latex.codecogs.com/png.latex?23%20%5Ctimes%2031%20%5Ctimes%2050%20=%2035650"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:application/octet-stream;base64,iVBORw0KGgoAAAANSUhEUgAAAHkAAAATBAMAAABGu79GAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMARIl2ZiJU75ndu6vNMhBVgMKNAAAACXBIWXMAAA7EAAAOxAGVKw4bAAABd0lEQVQ4EY2RPywDURjAf9f22jqqnRj8SZU0ESSdbOIGq6QJE4Mm2Ay1GQydTXYhErEYKCuJS5mls8WFxSQkRsL3epq+u0tzvuF9733f7/f+3MFfvKhcaq8isgYb4xPLUFfCa4TF5E5h79MHFzG2iefgjaQd0Ieb/oJ1DEUdNmqwT59QJ+BI0mLpKWBnSzCiw2kb8myI86329Uc2YKvdRnXYqkOZU8hUYcgvE7TnMfxw8mtOlCrGdMMmFWHfEAvAjz9H6uVYNmSVnb5WkVfT4Nm7hTup6jDGAaYjZBlSLr4I2OYHM/hgcbbIODAoXo/rk72zjTMVtnQS70jS4ExOfat+ucyUtCPe3esIo8PxClyqr8Z9f8Wzu787lRdZh+WHJUrwAIdxWGl1O0NWbqbFmrfswLFYYUz6s7C+CQsaKtPn20ZTq8QurlqrELzqQeca230agi1XwWa9u6J1QrBZU920q8bICMMDylmMFD0gBJuqXv6n3YZ/AWEvYmxWS2TXAAAAAElFTkSuQmCC",
          "src": "https://latex.codecogs.com/png.latex?S(t)%20=%201%20-%20F(t)"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:application/octet-stream;base64,iVBORw0KGgoAAAANSUhEUgAAAB8AAAATBAMAAACaQstxAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMARIl2ZiJU75ndu6vNMhBVgMKNAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA3klEQVQYGT2NPU4CURSFv8c4/EwYoNLCRtHQQEFlRzIFLckUVtCQqJ3FsINZAr3RhtgS2AEh1C7AahIbKleAgXMZ5Bb3nPPl3fPgND+m3WNwd/ePsDC/PYIWboLXgF+KkYhLYUpVbgYrSTmCG57l/qAlCXQd8wlhAtcCxV1PO8F11hElWb73H9ZCEEHdAO4Nf6UQQymze14JBa6ASkbYsKqaTtoC6vDGsLRSNrWxAf160YUvePdgCIVC81ZvH+DpBfqy+Yxymf9ngsysvzgDPzVbzmznc2kyOAUT31YMB2d6JCPwz5NuAAAAAElFTkSuQmCC",
          "src": "https://latex.codecogs.com/png.latex?S(t)"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:application/octet-stream;base64,iVBORw0KGgoAAAANSUhEUgAAACEAAAATBAMAAADseHn6AAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAid3vmbtmVHZEMhAiq833cN8pAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA5ElEQVQYGUWOPUtCYRiGLzud/DpqtgSB4dzk4Cwu7Y1BQmdqcGqKhga3RoWGoAj6Bzo4CC5ncZTsD4QtEbQ0BTp1P4+Kz3B/XO/L876wmZGFjreDevn0D2ZWhk7CMzgk04Mx6dhQqQNPFJXOYS6j/wrP3Cgt7bKmS5aEFuRq8GLkg5S0Rvb4MyYw0ih/S6sQxlqqGC04ks7VEggGsPeLznIiD8COSEEZ8lWoyG1PsC+xzXzlr5289Zz8wEkGJpC6fHdyD7d3cOXFZbqKF1sS6hF9YrYlUdPyrvM1fTRvr4tbZJrAP0yhKO+F498AAAAAAElFTkSuQmCC",
          "src": "https://latex.codecogs.com/png.latex?F(t)"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:application/octet-stream;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAMBAMAAACzedEdAAAALVBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAOrOgAAAADnRSTlMAELt2Mu9Eic1mIqtU3XZzvlQAAAAJcEhZcwAADsQAAA7EAZUrDhsAAAA4SURBVAgdY2BgFGBgYDJgYOBzYGBwZWBI76hkYNBkYGB4xcDAFsDAwL6BgYFjggwDr4MBA4/NAgB9KgZ4TDfkbAAAAABJRU5ErkJggg==",
          "src": "https://latex.codecogs.com/png.latex?t"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:application/octet-stream;base64,iVBORw0KGgoAAAANSUhEUgAAABcAAAAMBAMAAAB7FTvLAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMARHZmiTLNIrtUme8Qq91+bSRLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAgklEQVQIHWNgEDIRYGBgYE8xamdgYE1gSAdx3u8tYGDgmMCgBeJMABIM/AEM0nBOfAFD/AGgjDJIqzyQA1TNo8DwlAHEAvJBYAUDQ30Aw3ygMiDQBhogwDAbyOKbwKAPNNqAQRfIYSsAKWNsAFpae4D5AM92oNikKQIM0QUMRl4FDAAtYhmg9ED8pgAAAABJRU5ErkJggg==",
          "src": "https://latex.codecogs.com/png.latex?0.5"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:application/octet-stream;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAMBAMAAADxOqKKAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMARHZmiTLNIrtUme8Qq91+bSRLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAsUlEQVQIHWNgEDIRYAAClRUTGMqcNQoYWBMY0oF8lgKezwx1v68zMHBMYNACCvAFMKxjqAQp5Q9gkAZS3AYM/hCB+AKG+AMgGYY2hiJjRwYGeaBAAYjP/pXhEEgnkAcUAwI2AyDB1cBQH8Aw/wBIwBlEMG1g4BdgmA1iMgMVvGRg+sDAYcCgCxKQZGAGOgiohbEBSNceYF0oOIvBhuE00LhJUwQYogu4////xcCsspwBAB4IJmXk3vceAAAAAElFTkSuQmCC",
          "src": "https://latex.codecogs.com/png.latex?0.25"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/mlr-org.com/gallery/technical/2023-19-25-bart-survival/index_files/figure-html/diag-mcmc-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:application/octet-stream;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAMBAMAAABCcoqQAAAALVBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAOrOgAAAADnRSTlMARHZmiTLNIrtUme8Qq9MyhvYAAAAJcEhZcwAADsQAAA7EAZUrDhsAAABHSURBVAgdY2AQMhFgYGBNYEhnYOCYwKDFwMAXwCDNwBBXwBB3gEEOSIIRkFEXwDDvAAOfAMNsoEoDBl0GBsYGkC6GSVMEGACgDQxqAEhSYQAAAABJRU5ErkJggg==",
          "src": "https://latex.codecogs.com/png.latex?0"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:application/octet-stream;base64,iVBORw0KGgoAAAANSUhEUgAAAAcAAAAMBAMAAABcu7ojAAAAHlBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACGjDitAAAACXRSTlMARM0yInYQiat4/XZtAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAHElEQVQIHWNgEDJgYHC1BBIMnMQSAgwM6Z3qBgBsXAQZn03r+gAAAABJRU5ErkJggg==",
          "src": "https://latex.codecogs.com/png.latex?1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/mlr-org.com/gallery/technical/2023-19-25-bart-survival/index_files/figure-html/surv-with-uq-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:application/octet-stream;base64,iVBORw0KGgoAAAANSUhEUgAAAJMAAAATBAMAAABmeyL+AAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAid2ZzVQQRGYi76sydrteOEbCAAAACXBIWXMAAA7EAAAOxAGVKw4bAAACYklEQVQ4EZWSP2gTURzHP0lzl7vLv6KEKh3MIAgiGhcnkQhGHBwqNRqwyokUXKSnokVFOFpsI2pJHQxFsF2kIg5Z3Kwc+Aft0luKBVFclDoImSrZ/L2zekkGG39w977f3+/z3u+9dwetcaHV/Jf2Fb0pH86pK7kyECa6VucUGQtnphzxxnJOpYPQ7XWx4aC5gmTsv1xMqeh7teDvSPt/1IZjQYhLIVVWcjb0ZLwW82+ZlfLmEPmu5PHQs9iiN5A3pH4EY+X8nbelFzAn9uz2Piifhk9D1YuHtiQH0fLxvulJ0G51HLdSqSoyPlgbt7FkbpPaoqsVOQM5saxCwo87aTdRED1seQlfu9/bDwuMSlnb2SsvWyk34iryTXI16pCB+BwDYxg5PmIWBOAZjBGpTpHolTbOEpZ34rp9TSFbpfx65iVEFBg5qgekn1wzwLKJ1GGv7IMfJAsC6A3YXf7AEyxH2tAv38FW9xn9es+RYR89X0iLwNzzOCBJyRJEbWIuzEtnvYmeQ3aZQyRmk6WgzQ6moCiFkaq8IA8HHjwPpLlNket/ptxVZsYzG9LZKDjBtUsLtbFkg8/xmDvMGguaviYTRoLpuJB66itdxFIkzqydkgMKYcgq0rnHdzksBTkqu9C8Of2gEfV8Gvp8TStIIeoxJEMYdW4q8l1uzL4Nj+TyJkm5ZInLP7YsnOXBdGmCy6VXE9pylfGTx9yU2oWZLdsyhDFachVpZmtZDyphQamH8qyfo73QhfvWzqRtrp5qT3XrzHo7aeb5ub891a3rsTvIK1TcjlSX9m4nZ3YmuvZV+AVCipFwuEWstAAAAABJRU5ErkJggg==",
          "src": "https://latex.codecogs.com/png.latex?lm(feature%20%5Csim%20sex)"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:application/octet-stream;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAARBAMAAADNtor0AAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAid2ZuxCrzWZUMiJ270Sf5u5eAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAiUlEQVQIHWNggIAZwlAGA/cBNgEom6uAwwEmzMAIEhX6LOwYwBAUAGSyJDAwFzBkgeT5Gxg4f/Es2ABkrt/AwPP1HcMBIPMsA0Ns9///IG1uDJF+QAoEPs8wAekGAq7fDDwFECbPBQaODxAmyNgLECbQWKYCVjD7/QIGdod9ICajsSUDV0YDkAUAzUEdLLdbUkMAAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?R%5E2"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/mlr-org.com/gallery/technical/2023-19-25-bart-survival/index_files/figure-html/surv-pdp-1.png?w=450&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/john-zobolas/",
          "text": "John Zobolas"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-379493 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Survival modeling in mlr3 using Bayesian Additive Regression Trees (BART)</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">October 24, 2023</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/john-zobolas/\">John Zobolas</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://mlr-org.com/gallery/technical/2023-19-25-bart-survival/\"> mlr-org</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<section class=\"level2\" id=\"intro\">\n<h2 class=\"anchored\" data-anchor-id=\"intro\">Intro</h2>\n<p>Here are some interesting reads regarding BART:</p>\n<ul>\n<li>The first BART paper <span class=\"citation\" data-cites=\"Chipman2010\">(Chipman, George, and McCulloch 2010)</span>.</li>\n<li>The first implementation of BART for survival data <span class=\"citation\" data-cites=\"Bonato2011\">(Bonato et al. 2011)</span>. This includes fully parametric AFT and Weibull models and the semi-parametric CoxPH regression model.</li>\n<li>The first non-parametric implementation of BART for survival data <span class=\"citation\" data-cites=\"Sparapani2016\">(R. A. Sparapani et al. 2016)</span></li>\n<li><code>BART</code> R package tutorial <span class=\"citation\" data-cites=\"Sparapani2021\">(R. Sparapani, Spanbauer, and McCulloch 2021)</span></li>\n</ul>\n<p>We incorporated the survival <code>BART</code> model in <code>mlr3extralearners</code> and in this tutorial we will demonstrate how we can use packages like <code>mlr3</code>, <code>mlr3proba</code> and <code>distr6</code> to more easily manipulate the output predictions, evaluate the learner’s performance and graphically display them.</p>\n</section>\n<section class=\"level2\" id=\"libraries\">\n<h2 class=\"anchored\" data-anchor-id=\"libraries\">Libraries</h2>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>library(mlr3extralearners)\nlibrary(mlr3pipelines)\nlibrary(mlr3proba)\nlibrary(distr6)\nlibrary(BART) # 2.9.4\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(ggplot2)</pre>\n</div>\n</section>\n<section class=\"level2\" id=\"data\">\n<h2 class=\"anchored\" data-anchor-id=\"data\">Data</h2>\n<p>We will use the Lung Cancer Dataset. We convert the <code>time</code> variable from days to months to ease the computational burden:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>task_lung = tsk('lung')\n\nd = task_lung$data()\n# in case we want to select specific columns to keep\n# d = d[ ,colnames(d) %in% c(\"time\", \"status\", \"age\", \"sex\", \"ph.karno\"), with = FALSE]\nd$time = ceiling(d$time/30.44)\ntask_lung = as_task_surv(d, time = 'time', event = 'status', id = 'lung')\ntask_lung$label = \"Lung Cancer\"</pre>\n</div>\n<div class=\"callout callout-style-default callout-note callout-titled\">\n<div class=\"callout-header d-flex align-content-center\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nNote\n</div>\n</div>\n<div class=\"callout-body-container callout-body\">\n<ol type=\"1\">\n<li>The original <code>BART</code> implementation supports categorical features (factors). This results in different importance scores per each dummy level which doesn’t work well with <code>mlr3</code>. So features of type <code>factor</code> or <code>character</code> are not allowed and we leave it to the user to encode them as they please.</li>\n<li>The original <code>BART</code> implementation supports features with missing values. This is totally fine with <code>mlr3</code> as well! In this example, we impute the features to show good ML practice.</li>\n</ol>\n</div>\n</div>\n<p>In our lung dataset, we encode the <code>sex</code> feature and perform model-based imputation with the <code>rpart</code> regression learner:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>po_encode = po('encode', method = 'treatment')\npo_impute = po('imputelearner', lrn('regr.rpart'))\npre = po_encode %&gt;&gt;% po_impute\ntask = pre$train(task_lung)[[1]]\ntask</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>&lt;TaskSurv:lung&gt; (228 x 10): Lung Cancer\n* Target: time, status\n* Properties: -\n* Features (8):\n  - int (7): age, inst, meal.cal, pat.karno, ph.ecog, ph.karno, wt.loss\n  - dbl (1): sex</pre>\n</div>\n</div>\n<p>No missing values in our data:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>task$missings()</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>     time    status       age       sex      inst  meal.cal pat.karno   ph.ecog  ph.karno   wt.loss \n        0         0         0         0         0         0         0         0         0         0 </pre>\n</div>\n</div>\n<p>We partition the data to train and test sets:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>set.seed(42)\npart = partition(task, ratio = 0.9)</pre>\n</div>\n</section>\n<section class=\"level2\" id=\"train-and-test\">\n<h2 class=\"anchored\" data-anchor-id=\"train-and-test\">Train and Test</h2>\n<p>We train the <code>BART</code> model and predict on the test set:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre># default `ndpost` value: 1000. We reduce it to 50 to speed up calculations in this tutorial\nlearner = lrn(\"surv.bart\", nskip = 250, ndpost = 50, keepevery = 10, mc.cores = 10)\nlearner$train(task, row_ids = part$train)\np = learner$predict(task, row_ids = part$test)\np</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>&lt;PredictionSurv&gt; for 23 observations:\n    row_ids time status    crank     distr\n          9    8   TRUE 66.19326 &lt;list[1]&gt;\n         10    6   TRUE 98.43005 &lt;list[1]&gt;\n         21   10   TRUE 54.82313 &lt;list[1]&gt;\n---                                       \n        160   13  FALSE 37.82089 &lt;list[1]&gt;\n        163   10  FALSE 69.63534 &lt;list[1]&gt;\n        194    8  FALSE 81.13678 &lt;list[1]&gt;</pre>\n</div>\n</div>\n<p>See more details about <code>BART</code>’s parameters on the online <a href=\"https://mlr3extralearners.mlr-org.com/reference/mlr_learners_surv.bart.html\" rel=\"nofollow\" target=\"_blank\">documentation</a>.</p>\n<section class=\"level3\" id=\"distr\">\n<h3 class=\"anchored\" data-anchor-id=\"distr\">distr</h3>\n<p>What kind of object is the predicted <code>distr</code>?</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>p$distr</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Arrdist(23x31x50) </pre>\n</div>\n</div>\n<div class=\"callout callout-style-default callout-tip callout-titled\">\n<div class=\"callout-header d-flex align-content-center\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nArrdist dimensions:\n</div>\n</div>\n<div class=\"callout-body-container callout-body\">\n<ol type=\"1\">\n<li>Patients (observations)</li>\n<li>Time points (months)</li>\n<li>Number of posterior draws</li>\n</ol>\n</div>\n</div>\n<p>Actually the <code>$distr</code> is an active <a href=\"https://r6.r-lib.org/index.html\" rel=\"nofollow\" target=\"_blank\">R6</a> field – this means that some computation is required to create it. What the prediction object actually stores internally is a 3d survival array (can be used directly with no performance overhead):</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>dim(p$data$distr)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 23 31 50</pre>\n</div>\n</div>\n<p>This is a more easy-to-understand and manipulate form of the full posterior survival matrix prediction from the <code>BART</code> package (<span class=\"citation\" data-cites=\"Sparapani2021\">(R. Sparapani, Spanbauer, and McCulloch 2021)</span>, pages 34-35).</p>\n<div class=\"callout callout-style-default callout-warning callout-titled\">\n<div class=\"callout-header d-flex align-content-center\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nWarning\n</div>\n</div>\n<div class=\"callout-body-container callout-body\">\n<p>Though we have optimized with C++ code the way the <code>Arrdist</code> object is constructed, calling the <code>$distr</code> field can be computationally taxing if the product of the sizes of the 3 dimensions above <strong>exceeds ~1 million</strong>. In our case, <img data-lazy-src=\"https://latex.codecogs.com/png.latex?23%20%5Ctimes%2031%20%5Ctimes%2050%20=%2035650\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?23%20%5Ctimes%2031%20%5Ctimes%2050%20=%2035650\"/></noscript> so the conversion to an <code>Arrdist</code> via <code>$distr</code> will certainly not create performance issues.</p>\n</div>\n</div>\n<p>An example using the internal prediction data: get all the posterior probabilities of the 3rd patient in the test set, at 12 months (1 year):</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>p$data$distr[3, 12, ]</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre> [1] 0.26546909 0.27505937 0.21151435 0.46700513 0.26178380 0.24040003 0.29946469 0.52357780 0.40833108 0.40367780\n[11] 0.27027392 0.31781286 0.54151844 0.34460027 0.41826554 0.41866367 0.33694401 0.34511270 0.47244492 0.49423660\n[21] 0.42069678 0.20095489 0.48696980 0.48409357 0.35649439 0.47969355 0.16355660 0.33728105 0.40245228 0.42418033\n[31] 0.36336145 0.48181667 0.51858238 0.49635078 0.37238179 0.26694030 0.52219952 0.48992897 0.08572207 0.30306005\n[41] 0.33881682 0.33463870 0.29102074 0.43176131 0.38554545 0.38053756 0.36808776 0.13772665 0.21898264 0.14552514</pre>\n</div>\n</div>\n<p>Working with the <code>$distr</code> interface and <code>Arrdist</code> objects is very efficient as we will see later for predicting survival estimates.</p>\n<div class=\"callout callout-style-default callout-tip callout-titled\">\n<div class=\"callout-header d-flex align-content-center\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nTip\n</div>\n</div>\n<div class=\"callout-body-container callout-body\">\n<p>In survival analysis, <img data-lazy-src=\"https://latex.codecogs.com/png.latex?S(t)%20=%201%20-%20F(t)\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?S(t)%20=%201%20-%20F(t)\"/></noscript>, where <img data-lazy-src=\"https://latex.codecogs.com/png.latex?S(t)\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?S(t)\"/></noscript> the survival function and <img data-lazy-src=\"https://latex.codecogs.com/png.latex?F(t)\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?F(t)\"/></noscript> the cumulative distribution function (cdf). The latter can be interpreted as <code>risk</code> or probability of death up to time <img data-lazy-src=\"https://latex.codecogs.com/png.latex?t\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?t\"/></noscript>.</p>\n<p>We can verify the above from the prediction object:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>surv_array = 1 - distr6::gprm(p$distr, \"cdf\") # 3d array\ntestthat::expect_equal(p$data$distr, surv_array)</pre>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level3\" id=\"crank\">\n<h3 class=\"anchored\" data-anchor-id=\"crank\">crank</h3>\n<p><code>crank</code> is the <strong>expected mortality</strong> <span class=\"citation\" data-cites=\"Sonabend2022\">(Sonabend, Bender, and Vollmer 2022)</span> which is the sum of the predicted cumulative hazard function (as is done in random survival forest models). Higher values denote larger risk. To calculate <code>crank</code>, we need a survival matrix. So we have to choose which 3rd dimension we should use from the predicted survival array. This is what the <code>which.curve</code> parameter of the <code>learner</code> does:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>learner$param_set$get_values()$which.curve</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 0.5</pre>\n</div>\n</div>\n<p>The default value (<img data-lazy-src=\"https://latex.codecogs.com/png.latex?0.5\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?0.5\"/></noscript> quantile) is the <strong>median survival probability</strong>. It could be any other quantile (e.g. <img data-lazy-src=\"https://latex.codecogs.com/png.latex?0.25\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?0.25\"/></noscript>). Other possible values for <code>which.curve</code> are <code>mean</code> or a number denoting the exact posterior draw to extract (e.g. the last one, <code>which.curve = 50</code>).</p>\n</section>\n</section>\n<section class=\"level2\" id=\"feature-importance\">\n<h2 class=\"anchored\" data-anchor-id=\"feature-importance\">Feature importance</h2>\n<p>Default score is the <strong>observed count of each feature</strong> in the trees (so the higher the score, the more important the feature):</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>learner$param_set$values$importance</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] \"count\"</pre>\n</div>\n<pre>learner$importance()</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>      sex  meal.cal      inst pat.karno  ph.karno   wt.loss       age   ph.ecog \n     7.84      7.46      7.08      6.76      6.60      6.46      5.48      5.42 </pre>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"mcmc-diagnostics\">\n<h2 class=\"anchored\" data-anchor-id=\"mcmc-diagnostics\">MCMC Diagnostics</h2>\n<p><code>BART</code> uses internally MCMC (Markov Chain Monte Carlo) to sample from the posterior survival distribution. We need to check that MCMC has converged, meaning that the chains have reached a stationary distribution that approximates the true posterior survival distribution (otherwise the predictions may be inaccurate, misleading and unreliable).</p>\n<p>We use Geweke’s convergence diagnostic test as it is implemented in the <code>BART</code> R package. We choose 10 random patients from the train set to evaluate the MCMC convergence.</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre># predictions on the train set\np_train = learner$predict(task, row_ids = part$train)\n\nz_list = list()\n# choose 10 patients from the train set randomly\nfor (patient_id in sample(length(part$train), 10)) {\n  # matrix with columns =&gt; time points and rows =&gt; posterior draws\n  post_surv = 1 - t(distr6::gprm(p_train$distr[patient_id], \"cdf\")[1,,])\n  z_list[[patient_id]] = BART::gewekediag(post_surv)$z # get the z-scores\n}\n\n# plot the z scores vs time for all patients\ndplyr::bind_rows(z_list) %&gt;%\n  tidyr::pivot_longer(cols = everything()) %&gt;%\n  mutate(name = as.numeric(name)) %&gt;%\n  ggplot(aes(x = name, y = value)) +\n  geom_point() +\n  labs(x = \"Time (months)\", y = \"Z-scores\") +\n  # add critical values for a = 0.05\n  geom_hline(yintercept = 1.96, linetype = 'dashed', color = \"red\") +\n  geom_hline(yintercept = -1.96, linetype = 'dashed', color = \"red\") +\n  theme_bw(base_size = 14)</pre>\n<div class=\"cell-output-display\">\n<div class=\"quarto-figure quarto-figure-center\">\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i0.wp.com/mlr-org.com/gallery/technical/2023-19-25-bart-survival/index_files/figure-html/diag-mcmc-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/mlr-org.com/gallery/technical/2023-19-25-bart-survival/index_files/figure-html/diag-mcmc-1.png?w=450&amp;ssl=1\"/></noscript></p>\n<figcaption>Geweke plot for MCMC diagnostics. Z-scores for the difference in the mean survival prediction between the first 10% and last 50% part of a Markov chain. The predictions are taken from 10 random patients in the train set. Red lines indicate the a = 0.05 critical line. Only a few z-scores exceed the 95% limits so we conclude that convergence has been attained.</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"performance-test-set\">\n<h2 class=\"anchored\" data-anchor-id=\"performance-test-set\">Performance (test set)</h2>\n<p>We will use the following survival metrics:</p>\n<ol type=\"1\">\n<li>Integrated Brier Score (requires a survival distribution prediction – <code>distr</code>)</li>\n<li>Right-Censored Log loss (requires a survival distribution prediction – <code>distr</code>)</li>\n<li>Uno’s C-index (requires a continuous ranking score prediction – <code>crank</code>)</li>\n</ol>\n<p>For the first two measures we will use the ERV (<strong>Explained Residual Variation</strong>) version, which standardizes the scores against a Kaplan-Meier (KM) baseline <span class=\"citation\" data-cites=\"Sonabend2022a\">(Sonabend et al. 2022)</span>. This means that values close to <img data-lazy-src=\"https://latex.codecogs.com/png.latex?0\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?0\"/></noscript> represent performance similar to a KM model, negative values denote worse performance than KM and <img data-lazy-src=\"https://latex.codecogs.com/png.latex?1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?1\"/></noscript> is the absolute best possible score.</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>measures = list(\n  msr(\"surv.graf\", ERV = TRUE),\n  msr(\"surv.rcll\", ERV = TRUE),\n  msr(\"surv.cindex\", weight_meth = \"G2\", id = \"surv.cindex.uno\")\n)\n\nfor (measure in measures) {\n  print(p$score(measure, task = task, train_set = part$train))\n}</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>  surv.graf \n-0.09950096 \n  surv.rcll \n-0.02622117 \nsurv.cindex.uno \n       0.551951 </pre>\n</div>\n</div>\n<div class=\"callout callout-style-default callout-note callout-titled\">\n<div class=\"callout-header d-flex align-content-center\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nNote\n</div>\n</div>\n<div class=\"callout-body-container callout-body\">\n<p>All metrics use by default the <strong>median survival distribution</strong> from the 3d array, no matter what is the <code>which.curve</code> argument during the learner’s construction.</p>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"resampling\">\n<h2 class=\"anchored\" data-anchor-id=\"resampling\">Resampling</h2>\n<p>Performing resampling with the <code>BART</code> learner is very easy using <code>mlr3</code>.</p>\n<p>We first stratify the data by <code>status</code>, so that in each resampling the proportion of censored vs un-censored patients remains the same:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>task$col_roles$stratum = 'status'\ntask$strata</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>     N                row_id\n1: 165       1,2,4,5,7,8,...\n2:  63  3, 6,38,68,71,83,...</pre>\n</div>\n</div>\n<div class=\"cell\" data-hash=\"index_cache/html/unnamed-chunk-16_c842465294e8cacdd194b2d077fa21df\" data-layout-align=\"center\">\n<pre>rr = resample(task, learner, resampling = rsmp(\"cv\", folds = 5), store_backends = TRUE)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>INFO  [11:41:53.078] [mlr3] Applying learner 'surv.bart' on task 'lung' (iter 1/5)\nINFO  [11:41:55.545] [mlr3] Applying learner 'surv.bart' on task 'lung' (iter 2/5)\nINFO  [11:41:57.937] [mlr3] Applying learner 'surv.bart' on task 'lung' (iter 3/5)\nINFO  [11:42:00.417] [mlr3] Applying learner 'surv.bart' on task 'lung' (iter 4/5)\nINFO  [11:42:03.357] [mlr3] Applying learner 'surv.bart' on task 'lung' (iter 5/5)</pre>\n</div>\n</div>\n<p>No errors or warnings:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>rr$errors</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Empty data.table (0 rows and 2 cols): iteration,msg</pre>\n</div>\n<pre>rr$warnings</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Empty data.table (0 rows and 2 cols): iteration,msg</pre>\n</div>\n</div>\n<p>Performance in each fold:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>rr$score(measures)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>             task task_id                          learner learner_id         resampling resampling_id iteration\n1: &lt;TaskSurv[55]&gt;    lung &lt;LearnerSurvLearnerSurvBART[37]&gt;  surv.bart &lt;ResamplingCV[20]&gt;            cv         1\n2: &lt;TaskSurv[55]&gt;    lung &lt;LearnerSurvLearnerSurvBART[37]&gt;  surv.bart &lt;ResamplingCV[20]&gt;            cv         2\n3: &lt;TaskSurv[55]&gt;    lung &lt;LearnerSurvLearnerSurvBART[37]&gt;  surv.bart &lt;ResamplingCV[20]&gt;            cv         3\n4: &lt;TaskSurv[55]&gt;    lung &lt;LearnerSurvLearnerSurvBART[37]&gt;  surv.bart &lt;ResamplingCV[20]&gt;            cv         4\n5: &lt;TaskSurv[55]&gt;    lung &lt;LearnerSurvLearnerSurvBART[37]&gt;  surv.bart &lt;ResamplingCV[20]&gt;            cv         5\n             prediction    surv.graf    surv.rcll surv.cindex.uno\n1: &lt;PredictionSurv[20]&gt; -0.312614598 -0.102013166       0.5869665\n2: &lt;PredictionSurv[20]&gt; -0.103181391 -0.009579343       0.5502903\n3: &lt;PredictionSurv[20]&gt;  0.001448263  0.338851363       0.6178001\n4: &lt;PredictionSurv[20]&gt; -0.044161171  0.003691073       0.6157215\n5: &lt;PredictionSurv[20]&gt; -0.043129352  0.157902047       0.5688389</pre>\n</div>\n</div>\n<p>Mean cross-validation performance:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>rr$aggregate(measures)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>      surv.graf       surv.rcll surv.cindex.uno \n     -0.1003276       0.0777704       0.5879235 </pre>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"uncertainty-quantification-in-survival-prediction\">\n<h2 class=\"anchored\" data-anchor-id=\"uncertainty-quantification-in-survival-prediction\">Uncertainty Quantification in Survival Prediction</h2>\n<p>We will choose two patients from the test set and plot their survival prediction posterior estimates.</p>\n<p>Let’s choose the patients with the worst and the best survival time:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>death_times = p$truth[,1]\nsort(death_times)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre> [1]  3  5  5  6  6  6  7  8  8  8  8 10 10 10 12 12 12 13 15 16 17 18 27</pre>\n</div>\n<pre>worst_indx = which(death_times == min(death_times))[1] # died first\nbest_indx  = which(death_times == max(death_times))[1] # died last\n\npatient_ids = c(worst_indx, best_indx)\npatient_ids # which patient IDs</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1]  5 18</pre>\n</div>\n<pre>death_times = death_times[patient_ids]\ndeath_times # 1st is worst, 2nd is best</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1]  3 27</pre>\n</div>\n</div>\n<p>Subset <code>Arrdist</code> to only the above 2 patients:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>arrd = p$distr[patient_ids]\narrd</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Arrdist(2x31x50) </pre>\n</div>\n</div>\n<p>We choose time points (in months) for the survival estimates:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>months = seq(1, 36) # 1 month - 3 years</pre>\n</div>\n<p>We use the <code>$distr</code> interface and the <code>$survival</code> property to get survival probabilities from an <code>Arrdist</code> object as well as the <strong>quantile credible intervals</strong> (CIs). The median survival probabilities can be extracted as follows:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>med = arrd$survival(months) # 'med' for median\n\ncolnames(med) = paste0(patient_ids, \"_med\")\nmed = as_tibble(med) %&gt;% add_column(month = months)\nhead(med)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre># A tibble: 6 × 3\n  `5_med` `18_med` month\n    &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;\n1   0.874    0.981     1\n2   0.767    0.962     2\n3   0.670    0.945     3\n4   0.569    0.927     4\n5   0.465    0.901     5\n6   0.366    0.869     6</pre>\n</div>\n</div>\n<p>We can briefly verify model’s predictions: 1st patient survival probabilities on any month are lower (worst) compared to the 2nd patient.</p>\n<p>Note that subsetting an <code>Arrdist</code> (3d array) creates a <code>Matdist</code> (2d matrix), for example we can explicitly get the median survival probabilities:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>matd_median = arrd[, 0.5] # median\nhead(matd_median$survival(months)) # same as with `arrd`</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>       [,1]      [,2]\n1 0.8741127 0.9808363\n2 0.7670382 0.9621618\n3 0.6701276 0.9450867\n4 0.5688809 0.9272284\n5 0.4647686 0.9007042\n6 0.3660939 0.8687270</pre>\n</div>\n</div>\n<p>Using the <code>mean</code> posterior survival probabilities or the ones from the last posterior draw is also possible and can be done as follows:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>matd_mean = arrd[, \"mean\"] # mean (if needed)\nhead(matd_mean$survival(months))</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>       [,1]      [,2]\n1 0.8652006 0.9748463\n2 0.7533538 0.9521817\n3 0.6560050 0.9293229\n4 0.5623555 0.9051549\n5 0.4750038 0.8758896\n6 0.3815333 0.8360373</pre>\n</div>\n<pre>matd_50draw = arrd[, 50] # the 50th posterior draw\nhead(matd_50draw$survival(months))</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>       [,1]      [,2]\n1 0.9178342 0.9920982\n2 0.8424195 0.9842589\n3 0.7732014 0.9764815\n4 0.7096707 0.9687656\n5 0.6029119 0.9495583\n6 0.5122132 0.9307318</pre>\n</div>\n</div>\n<p>To get the CIs we will subset the <code>Arrdist</code> using a quantile number (0-1), which extracts a <code>Matdist</code> based on the cdf. The survival function is 1 – cdf, so low and upper bounds are reversed:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>low  = arrd[, 0.975]$survival(months) # 2.5% bound\nhigh = arrd[, 0.025]$survival(months) # 97.5% bound\ncolnames(low)  = paste0(patient_ids, \"_low\")\ncolnames(high) = paste0(patient_ids, \"_high\")\nlow  = as_tibble(low)\nhigh = as_tibble(high)</pre>\n</div>\n<p>The median posterior survival probabilities for the two patient of interest and the corresponding CI bounds in a tidy format are:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>surv_tbl =\n  bind_cols(low, med, high) %&gt;%\n  pivot_longer(cols = !month, values_to = \"surv\",\n    names_to = c(\"patient_id\", \".value\"), names_sep = \"_\") %&gt;%\n  relocate(patient_id)\nsurv_tbl</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre># A tibble: 72 × 5\n   patient_id month   low   med  high\n   &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 5              1 0.713 0.874 0.953\n 2 18             1 0.929 0.981 0.996\n 3 5              2 0.508 0.767 0.903\n 4 18             2 0.863 0.962 0.991\n 5 5              3 0.362 0.670 0.855\n 6 18             3 0.801 0.945 0.985\n 7 5              4 0.244 0.569 0.804\n 8 18             4 0.734 0.927 0.977\n 9 5              5 0.146 0.465 0.748\n10 18             5 0.654 0.901 0.969\n# … with 62 more rows</pre>\n</div>\n</div>\n<p>We draw survival curves with the uncertainty for the survival probability quantified:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>my_colors = c(\"#E41A1C\", \"#4DAF4A\")\nnames(my_colors) = patient_ids\n\nsurv_tbl %&gt;%\n  ggplot(aes(x = month, y = med)) +\n  geom_step(aes(color = patient_id), linewidth = 1) +\n  xlab('Time (Months)') +\n  ylab('Survival Probability') +\n  geom_ribbon(aes(ymin = low, ymax = high, fill = patient_id),\n    alpha = 0.3, show.legend = F) +\n  geom_vline(xintercept = death_times[1], linetype = 'dashed', color = my_colors[1]) +\n  geom_vline(xintercept = death_times[2], linetype = 'dashed', color = my_colors[2]) +\n  theme_bw(base_size = 14) +\n  scale_color_manual(values = my_colors) +\n  scale_fill_manual(values = my_colors) +\n  guides(color = guide_legend(title = \"Patient ID\"))</pre>\n<div class=\"cell-output-display\">\n<div class=\"quarto-figure quarto-figure-center\">\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i1.wp.com/mlr-org.com/gallery/technical/2023-19-25-bart-survival/index_files/figure-html/surv-with-uq-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/mlr-org.com/gallery/technical/2023-19-25-bart-survival/index_files/figure-html/surv-with-uq-1.png?w=450&amp;ssl=1\"/></noscript></p>\n<figcaption>Uncertainty quantification for the survival prediction of two patients in the test set using 95% credible intervals. The two vertical lines correspond to the reported time of death (in months) for the two patients.</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"partial-dependence-plot\">\n<h2 class=\"anchored\" data-anchor-id=\"partial-dependence-plot\">Partial Dependence Plot</h2>\n<p>We will use a Partial Dependence Plot (PDP) <span class=\"citation\" data-cites=\"Friedman2001\">(Friedman 2001)</span> to visualize how much different are males vs females in terms of their average survival predictions across time.</p>\n<div class=\"callout callout-style-default callout-note callout-titled\">\n<div class=\"callout-header d-flex align-content-center\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nNote\n</div>\n</div>\n<div class=\"callout-body-container callout-body\">\n<p>PDPs assume that features are independent. In our case we need to check that <code>sex</code> doesn’t correlate with any of the other features used for training the <code>BART</code> learner. Since <code>sex</code> is a categorical feature, we fit a linear model using as target variable every other feature in the data (<img data-lazy-src=\"https://latex.codecogs.com/png.latex?lm(feature%20%5Csim%20sex)\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?lm(feature%20%5Csim%20sex)\"/></noscript>) and conduct an ANOVA (ANalysis Of VAriance) to get the variance explained or <img data-lazy-src=\"https://latex.codecogs.com/png.latex?R%5E2\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?R%5E2\"/></noscript>. The square root of that value is the correlation measure we want.</p>\n</div>\n</div>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre># code from https://christophm.github.io/interpretable-ml-book/ale.html\nmycor = function(cnames, data) {\n  x.num = data[, cnames[1], with = FALSE][[1]]\n  x.cat = data[, cnames[2], with = FALSE][[1]]\n  # R^2 = Cor(X, Y)^2 in simple linear regression\n  sqrt(summary(lm(x.num ~ x.cat))$r.squared)\n}\n\ncnames = c(\"sex\")\ncombs = expand.grid(y = setdiff(colnames(d), \"sex\"), x = cnames)\ncombs$cor = apply(combs, 1, mycor, data = task$data()) # use the train set\ncombs</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>          y   x        cor\n1      time sex 0.12941337\n2    status sex 0.24343282\n3       age sex 0.12216709\n4      inst sex 0.07826337\n5  meal.cal sex 0.18389545\n6 pat.karno sex 0.04132443\n7   ph.ecog sex 0.02564987\n8  ph.karno sex 0.01702471\n9   wt.loss sex 0.13431983</pre>\n</div>\n</div>\n<p><code>sex</code> doesn’t correlate strongly with any other feature, so we can compute the PDP:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre># create two datasets: one with males and one with females\n# all other features remain the same (use train data, 205 patients)\nd = task$data(rows = part$train) # `rows = part$test` to use the test set\n\nd$sex = 1\ntask_males = as_task_surv(d, time = 'time', event = 'status', id = 'lung-males')\nd$sex = 0\ntask_females = as_task_surv(d, time = 'time', event = 'status', id = 'lung-females')\n\n# make predictions\np_males   = learner$predict(task_males)\np_females = learner$predict(task_females)\n\n# take the median posterior survival probability\nsurv_males   = p_males$distr$survival(months) # patients x times\nsurv_females = p_females$distr$survival(months) # patients x times\n\n# tidy up data: average and quantiles across patients\ndata_males =\n  apply(surv_males, 1, function(row) {\n    tibble(\n      low = quantile(row, probs = 0.025),\n      avg = mean(row),\n      high = quantile(row, probs = 0.975)\n    )\n  }) %&gt;%\n  bind_rows() %&gt;%\n  add_column(sex = 'male', month = months, .before = 1)\n\ndata_females =\n  apply(surv_females, 1, function(row) {\n    tibble(\n      low = quantile(row, probs = 0.025),\n      avg = mean(row),\n      high = quantile(row, probs = 0.975)\n    )\n  }) %&gt;%\n  bind_rows() %&gt;%\n  add_column(sex = 'female', month = months, .before = 1)\n\npdp_tbl = bind_rows(data_males, data_females)\npdp_tbl</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre># A tibble: 72 × 5\n   sex   month    low   avg  high\n   &lt;chr&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 male      1 0.836  0.942 0.981\n 2 male      2 0.704  0.889 0.963\n 3 male      3 0.587  0.839 0.943\n 4 male      4 0.488  0.788 0.924\n 5 male      5 0.392  0.732 0.897\n 6 male      6 0.304  0.663 0.860\n 7 male      7 0.234  0.601 0.829\n 8 male      8 0.172  0.550 0.799\n 9 male      9 0.130  0.503 0.766\n10 male     10 0.0945 0.455 0.733\n# … with 62 more rows</pre>\n</div>\n</div>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>my_colors = c(\"#E41A1C\", \"#4DAF4A\")\nnames(my_colors) = c('male', 'female')\n\npdp_tbl %&gt;%\n  ggplot(aes(x = month, y = avg)) +\n  geom_step(aes(color = sex), linewidth = 1) +\n  xlab('Time (Months)') +\n  ylab('Survival Probability') +\n  geom_ribbon(aes(ymin = low, ymax = high, fill = sex), alpha = 0.2, show.legend = F) +\n  theme_bw(base_size = 14) +\n  scale_color_manual(values = my_colors) +\n  scale_fill_manual(values = my_colors)</pre>\n<div class=\"cell-output-display\">\n<div class=\"quarto-figure quarto-figure-center\">\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i1.wp.com/mlr-org.com/gallery/technical/2023-19-25-bart-survival/index_files/figure-html/surv-pdp-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/mlr-org.com/gallery/technical/2023-19-25-bart-survival/index_files/figure-html/surv-pdp-1.png?w=450&amp;ssl=1\"/></noscript></p>\n<figcaption>Friedman’s partial dependence function with 95% prediction intervals: males vs females. Females show on average larger survival estimates compared to men, across all time points. Overlapping shaded area represents men and women that have similar survival characteristics.</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"references\">\n</section>\n<div class=\"default\" id=\"quarto-appendix\"><section class=\"quarto-appendix-contents\"><h2 class=\"anchored quarto-appendix-heading\">References</h2><div class=\"references csl-bib-body hanging-indent\" data-entry-spacing=\"0\" id=\"refs\">\n<div class=\"csl-entry\" id=\"ref-Bonato2011\">\nBonato, Vinicius, Veerabhadran Baladandayuthapani, Bradley M. Broom, Erik P. Sulman, Kenneth D. Aldape, and Kim Anh Do. 2011. <span>“<span class=\"nocase\">Bayesian ensemble methods for survival prediction in gene expression data</span>.”</span> <em>Bioinformatics</em> 27 (3): 359–67. <a href=\"https://doi.org/10.1093/BIOINFORMATICS/BTQ660\" rel=\"nofollow\" target=\"_blank\">https://doi.org/10.1093/BIOINFORMATICS/BTQ660</a>.\n</div>\n<div class=\"csl-entry\" id=\"ref-Chipman2010\">\nChipman, Hugh A, Edward I George, and Robert E McCulloch. 2010. <span>“<span>BART: BAYESIAN ADDITIVE REGRESSION TREES</span>.”</span> <em>The Annals of Applied Statistics</em> 4 (1): 266–98. <a href=\"http://www.jstor.org/stable/27801587\" rel=\"nofollow\" target=\"_blank\">http://www.jstor.org/stable/27801587</a>.\n</div>\n<div class=\"csl-entry\" id=\"ref-Friedman2001\">\nFriedman, Jerome H. 2001. <span>“<span class=\"nocase\">Greedy function approximation: a gradient boosting machine</span>.”</span> <em>Annals of Statistics</em>, 1189–1232. <a href=\"https://doi.org/10.1214/aos/1013203451\" rel=\"nofollow\" target=\"_blank\">https://doi.org/10.1214/aos/1013203451</a>.\n</div>\n<div class=\"csl-entry\" id=\"ref-Sonabend2022\">\nSonabend, Raphael, Andreas Bender, and Sebastian Vollmer. 2022. <span>“<span class=\"nocase\">Avoiding C-hacking when evaluating survival distribution predictions with discrimination measures</span>.”</span> Edited by Zhiyong Lu. <em>Bioinformatics</em>, July. <a href=\"https://doi.org/10.1093/BIOINFORMATICS/BTAC451\" rel=\"nofollow\" target=\"_blank\">https://doi.org/10.1093/BIOINFORMATICS/BTAC451</a>.\n</div>\n<div class=\"csl-entry\" id=\"ref-Sonabend2022a\">\nSonabend, Raphael, Florian Pfisterer, Alan Mishler, Moritz Schauer, Lukas Burk, Sumantrak Mukherjee, and Sebastian Vollmer. 2022. <span>“<span class=\"nocase\">Flexible Group Fairness Metrics for Survival Analysis</span>,”</span> May. <a href=\"https://doi.org/10.48550/arxiv.2206.03256\" rel=\"nofollow\" target=\"_blank\">https://doi.org/10.48550/arxiv.2206.03256</a>.\n</div>\n<div class=\"csl-entry\" id=\"ref-Sparapani2016\">\nSparapani, Rodney A., Brent R. Logan, Robert E. McCulloch, and Purushottam W. Laud. 2016. <span>“<span class=\"nocase\">Nonparametric survival analysis using Bayesian Additive Regression Trees (BART)</span>.”</span> <em>Statistics in Medicine</em> 35 (16): 2741–53. <a href=\"https://doi.org/10.1002/SIM.6893\" rel=\"nofollow\" target=\"_blank\">https://doi.org/10.1002/SIM.6893</a>.\n</div>\n<div class=\"csl-entry\" id=\"ref-Sparapani2021\">\nSparapani, Rodney, Charles Spanbauer, and Robert McCulloch. 2021. <span>“<span class=\"nocase\">Nonparametric Machine Learning and Efficient Computation with Bayesian Additive Regression Trees: The BART R Package</span>.”</span> <em>Journal of Statistical Software</em> 97 (1): 1–66. <a href=\"https://doi.org/10.18637/JSS.V097.I01\" rel=\"nofollow\" target=\"_blank\">https://doi.org/10.18637/JSS.V097.I01</a>.\n</div>\n</div></section></div>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://mlr-org.com/gallery/technical/2023-19-25-bart-survival/\"> mlr-org</a></strong>.</div>\n<hr>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</hr></div> </div>\n</article>",
      "main_text": "Survival modeling in mlr3 using Bayesian Additive Regression Trees (BART)\nPosted on\nOctober 24, 2023\nby\nJohn Zobolas\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nmlr-org\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nIntro\nHere are some interesting reads regarding BART:\nThe first BART paper\n(Chipman, George, and McCulloch 2010)\n.\nThe first implementation of BART for survival data\n(Bonato et al. 2011)\n. This includes fully parametric AFT and Weibull models and the semi-parametric CoxPH regression model.\nThe first non-parametric implementation of BART for survival data\n(R. A. Sparapani et al. 2016)\nBART\nR package tutorial\n(R. Sparapani, Spanbauer, and McCulloch 2021)\nWe incorporated the survival\nBART\nmodel in\nmlr3extralearners\nand in this tutorial we will demonstrate how we can use packages like\nmlr3\n,\nmlr3proba\nand\ndistr6\nto more easily manipulate the output predictions, evaluate the learner’s performance and graphically display them.\nLibraries\nlibrary(mlr3extralearners)\nlibrary(mlr3pipelines)\nlibrary(mlr3proba)\nlibrary(distr6)\nlibrary(BART) # 2.9.4\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(ggplot2)\nData\nWe will use the Lung Cancer Dataset. We convert the\ntime\nvariable from days to months to ease the computational burden:\ntask_lung = tsk('lung')\n\nd = task_lung$data()\n# in case we want to select specific columns to keep\n# d = d[ ,colnames(d) %in% c(\"time\", \"status\", \"age\", \"sex\", \"ph.karno\"), with = FALSE]\nd$time = ceiling(d$time/30.44)\ntask_lung = as_task_surv(d, time = 'time', event = 'status', id = 'lung')\ntask_lung$label = \"Lung Cancer\"\nNote\nThe original\nBART\nimplementation supports categorical features (factors). This results in different importance scores per each dummy level which doesn’t work well with\nmlr3\n. So features of type\nfactor\nor\ncharacter\nare not allowed and we leave it to the user to encode them as they please.\nThe original\nBART\nimplementation supports features with missing values. This is totally fine with\nmlr3\nas well! In this example, we impute the features to show good ML practice.\nIn our lung dataset, we encode the\nsex\nfeature and perform model-based imputation with the\nrpart\nregression learner:\npo_encode = po('encode', method = 'treatment')\npo_impute = po('imputelearner', lrn('regr.rpart'))\npre = po_encode %>>% po_impute\ntask = pre$train(task_lung)[[1]]\ntask\n<TaskSurv:lung> (228 x 10): Lung Cancer\n* Target: time, status\n* Properties: -\n* Features (8):\n  - int (7): age, inst, meal.cal, pat.karno, ph.ecog, ph.karno, wt.loss\n  - dbl (1): sex\nNo missing values in our data:\ntask$missings()\ntime    status       age       sex      inst  meal.cal pat.karno   ph.ecog  ph.karno   wt.loss \n        0         0         0         0         0         0         0         0         0         0\nWe partition the data to train and test sets:\nset.seed(42)\npart = partition(task, ratio = 0.9)\nTrain and Test\nWe train the\nBART\nmodel and predict on the test set:\n# default `ndpost` value: 1000. We reduce it to 50 to speed up calculations in this tutorial\nlearner = lrn(\"surv.bart\", nskip = 250, ndpost = 50, keepevery = 10, mc.cores = 10)\nlearner$train(task, row_ids = part$train)\np = learner$predict(task, row_ids = part$test)\np\n<PredictionSurv> for 23 observations:\n    row_ids time status    crank     distr\n          9    8   TRUE 66.19326 <list[1]>\n         10    6   TRUE 98.43005 <list[1]>\n         21   10   TRUE 54.82313 <list[1]>\n---                                       \n        160   13  FALSE 37.82089 <list[1]>\n        163   10  FALSE 69.63534 <list[1]>\n        194    8  FALSE 81.13678 <list[1]>\nSee more details about\nBART\n’s parameters on the online\ndocumentation\n.\ndistr\nWhat kind of object is the predicted\ndistr\n?\np$distr\nArrdist(23x31x50)\nArrdist dimensions:\nPatients (observations)\nTime points (months)\nNumber of posterior draws\nActually the\n$distr\nis an active\nR6\nfield – this means that some computation is required to create it. What the prediction object actually stores internally is a 3d survival array (can be used directly with no performance overhead):\ndim(p$data$distr)\n[1] 23 31 50\nThis is a more easy-to-understand and manipulate form of the full posterior survival matrix prediction from the\nBART\npackage (\n(R. Sparapani, Spanbauer, and McCulloch 2021)\n, pages 34-35).\nWarning\nThough we have optimized with C++ code the way the\nArrdist\nobject is constructed, calling the\n$distr\nfield can be computationally taxing if the product of the sizes of the 3 dimensions above\nexceeds ~1 million\n. In our case,\nso the conversion to an\nArrdist\nvia\n$distr\nwill certainly not create performance issues.\nAn example using the internal prediction data: get all the posterior probabilities of the 3rd patient in the test set, at 12 months (1 year):\np$data$distr[3, 12, ]\n[1] 0.26546909 0.27505937 0.21151435 0.46700513 0.26178380 0.24040003 0.29946469 0.52357780 0.40833108 0.40367780\n[11] 0.27027392 0.31781286 0.54151844 0.34460027 0.41826554 0.41866367 0.33694401 0.34511270 0.47244492 0.49423660\n[21] 0.42069678 0.20095489 0.48696980 0.48409357 0.35649439 0.47969355 0.16355660 0.33728105 0.40245228 0.42418033\n[31] 0.36336145 0.48181667 0.51858238 0.49635078 0.37238179 0.26694030 0.52219952 0.48992897 0.08572207 0.30306005\n[41] 0.33881682 0.33463870 0.29102074 0.43176131 0.38554545 0.38053756 0.36808776 0.13772665 0.21898264 0.14552514\nWorking with the\n$distr\ninterface and\nArrdist\nobjects is very efficient as we will see later for predicting survival estimates.\nTip\nIn survival analysis,\n, where\nthe survival function and\nthe cumulative distribution function (cdf). The latter can be interpreted as\nrisk\nor probability of death up to time\n.\nWe can verify the above from the prediction object:\nsurv_array = 1 - distr6::gprm(p$distr, \"cdf\") # 3d array\ntestthat::expect_equal(p$data$distr, surv_array)\ncrank\ncrank\nis the\nexpected mortality\n(Sonabend, Bender, and Vollmer 2022)\nwhich is the sum of the predicted cumulative hazard function (as is done in random survival forest models). Higher values denote larger risk. To calculate\ncrank\n, we need a survival matrix. So we have to choose which 3rd dimension we should use from the predicted survival array. This is what the\nwhich.curve\nparameter of the\nlearner\ndoes:\nlearner$param_set$get_values()$which.curve\n[1] 0.5\nThe default value (\nquantile) is the\nmedian survival probability\n. It could be any other quantile (e.g.\n). Other possible values for\nwhich.curve\nare\nmean\nor a number denoting the exact posterior draw to extract (e.g. the last one,\nwhich.curve = 50\n).\nFeature importance\nDefault score is the\nobserved count of each feature\nin the trees (so the higher the score, the more important the feature):\nlearner$param_set$values$importance\n[1] \"count\"\nlearner$importance()\nsex  meal.cal      inst pat.karno  ph.karno   wt.loss       age   ph.ecog \n     7.84      7.46      7.08      6.76      6.60      6.46      5.48      5.42\nMCMC Diagnostics\nBART\nuses internally MCMC (Markov Chain Monte Carlo) to sample from the posterior survival distribution. We need to check that MCMC has converged, meaning that the chains have reached a stationary distribution that approximates the true posterior survival distribution (otherwise the predictions may be inaccurate, misleading and unreliable).\nWe use Geweke’s convergence diagnostic test as it is implemented in the\nBART\nR package. We choose 10 random patients from the train set to evaluate the MCMC convergence.\n# predictions on the train set\np_train = learner$predict(task, row_ids = part$train)\n\nz_list = list()\n# choose 10 patients from the train set randomly\nfor (patient_id in sample(length(part$train), 10)) {\n  # matrix with columns => time points and rows => posterior draws\n  post_surv = 1 - t(distr6::gprm(p_train$distr[patient_id], \"cdf\")[1,,])\n  z_list[[patient_id]] = BART::gewekediag(post_surv)$z # get the z-scores\n}\n\n# plot the z scores vs time for all patients\ndplyr::bind_rows(z_list) %>%\n  tidyr::pivot_longer(cols = everything()) %>%\n  mutate(name = as.numeric(name)) %>%\n  ggplot(aes(x = name, y = value)) +\n  geom_point() +\n  labs(x = \"Time (months)\", y = \"Z-scores\") +\n  # add critical values for a = 0.05\n  geom_hline(yintercept = 1.96, linetype = 'dashed', color = \"red\") +\n  geom_hline(yintercept = -1.96, linetype = 'dashed', color = \"red\") +\n  theme_bw(base_size = 14)\nGeweke plot for MCMC diagnostics. Z-scores for the difference in the mean survival prediction between the first 10% and last 50% part of a Markov chain. The predictions are taken from 10 random patients in the train set. Red lines indicate the a = 0.05 critical line. Only a few z-scores exceed the 95% limits so we conclude that convergence has been attained.\nPerformance (test set)\nWe will use the following survival metrics:\nIntegrated Brier Score (requires a survival distribution prediction –\ndistr\n)\nRight-Censored Log loss (requires a survival distribution prediction –\ndistr\n)\nUno’s C-index (requires a continuous ranking score prediction –\ncrank\n)\nFor the first two measures we will use the ERV (\nExplained Residual Variation\n) version, which standardizes the scores against a Kaplan-Meier (KM) baseline\n(Sonabend et al. 2022)\n. This means that values close to\nrepresent performance similar to a KM model, negative values denote worse performance than KM and\nis the absolute best possible score.\nmeasures = list(\n  msr(\"surv.graf\", ERV = TRUE),\n  msr(\"surv.rcll\", ERV = TRUE),\n  msr(\"surv.cindex\", weight_meth = \"G2\", id = \"surv.cindex.uno\")\n)\n\nfor (measure in measures) {\n  print(p$score(measure, task = task, train_set = part$train))\n}\nsurv.graf \n-0.09950096 \n  surv.rcll \n-0.02622117 \nsurv.cindex.uno \n       0.551951\nNote\nAll metrics use by default the\nmedian survival distribution\nfrom the 3d array, no matter what is the\nwhich.curve\nargument during the learner’s construction.\nResampling\nPerforming resampling with the\nBART\nlearner is very easy using\nmlr3\n.\nWe first stratify the data by\nstatus\n, so that in each resampling the proportion of censored vs un-censored patients remains the same:\ntask$col_roles$stratum = 'status'\ntask$strata\nN                row_id\n1: 165       1,2,4,5,7,8,...\n2:  63  3, 6,38,68,71,83,...\nrr = resample(task, learner, resampling = rsmp(\"cv\", folds = 5), store_backends = TRUE)\nINFO  [11:41:53.078] [mlr3] Applying learner 'surv.bart' on task 'lung' (iter 1/5)\nINFO  [11:41:55.545] [mlr3] Applying learner 'surv.bart' on task 'lung' (iter 2/5)\nINFO  [11:41:57.937] [mlr3] Applying learner 'surv.bart' on task 'lung' (iter 3/5)\nINFO  [11:42:00.417] [mlr3] Applying learner 'surv.bart' on task 'lung' (iter 4/5)\nINFO  [11:42:03.357] [mlr3] Applying learner 'surv.bart' on task 'lung' (iter 5/5)\nNo errors or warnings:\nrr$errors\nEmpty data.table (0 rows and 2 cols): iteration,msg\nrr$warnings\nEmpty data.table (0 rows and 2 cols): iteration,msg\nPerformance in each fold:\nrr$score(measures)\ntask task_id                          learner learner_id         resampling resampling_id iteration\n1: <TaskSurv[55]>    lung <LearnerSurvLearnerSurvBART[37]>  surv.bart <ResamplingCV[20]>            cv         1\n2: <TaskSurv[55]>    lung <LearnerSurvLearnerSurvBART[37]>  surv.bart <ResamplingCV[20]>            cv         2\n3: <TaskSurv[55]>    lung <LearnerSurvLearnerSurvBART[37]>  surv.bart <ResamplingCV[20]>            cv         3\n4: <TaskSurv[55]>    lung <LearnerSurvLearnerSurvBART[37]>  surv.bart <ResamplingCV[20]>            cv         4\n5: <TaskSurv[55]>    lung <LearnerSurvLearnerSurvBART[37]>  surv.bart <ResamplingCV[20]>            cv         5\n             prediction    surv.graf    surv.rcll surv.cindex.uno\n1: <PredictionSurv[20]> -0.312614598 -0.102013166       0.5869665\n2: <PredictionSurv[20]> -0.103181391 -0.009579343       0.5502903\n3: <PredictionSurv[20]>  0.001448263  0.338851363       0.6178001\n4: <PredictionSurv[20]> -0.044161171  0.003691073       0.6157215\n5: <PredictionSurv[20]> -0.043129352  0.157902047       0.5688389\nMean cross-validation performance:\nrr$aggregate(measures)\nsurv.graf       surv.rcll surv.cindex.uno \n     -0.1003276       0.0777704       0.5879235\nUncertainty Quantification in Survival Prediction\nWe will choose two patients from the test set and plot their survival prediction posterior estimates.\nLet’s choose the patients with the worst and the best survival time:\ndeath_times = p$truth[,1]\nsort(death_times)\n[1]  3  5  5  6  6  6  7  8  8  8  8 10 10 10 12 12 12 13 15 16 17 18 27\nworst_indx = which(death_times == min(death_times))[1] # died first\nbest_indx  = which(death_times == max(death_times))[1] # died last\n\npatient_ids = c(worst_indx, best_indx)\npatient_ids # which patient IDs\n[1]  5 18\ndeath_times = death_times[patient_ids]\ndeath_times # 1st is worst, 2nd is best\n[1]  3 27\nSubset\nArrdist\nto only the above 2 patients:\narrd = p$distr[patient_ids]\narrd\nArrdist(2x31x50)\nWe choose time points (in months) for the survival estimates:\nmonths = seq(1, 36) # 1 month - 3 years\nWe use the\n$distr\ninterface and the\n$survival\nproperty to get survival probabilities from an\nArrdist\nobject as well as the\nquantile credible intervals\n(CIs). The median survival probabilities can be extracted as follows:\nmed = arrd$survival(months) # 'med' for median\n\ncolnames(med) = paste0(patient_ids, \"_med\")\nmed = as_tibble(med) %>% add_column(month = months)\nhead(med)\n# A tibble: 6 × 3\n  `5_med` `18_med` month\n    <dbl>    <dbl> <int>\n1   0.874    0.981     1\n2   0.767    0.962     2\n3   0.670    0.945     3\n4   0.569    0.927     4\n5   0.465    0.901     5\n6   0.366    0.869     6\nWe can briefly verify model’s predictions: 1st patient survival probabilities on any month are lower (worst) compared to the 2nd patient.\nNote that subsetting an\nArrdist\n(3d array) creates a\nMatdist\n(2d matrix), for example we can explicitly get the median survival probabilities:\nmatd_median = arrd[, 0.5] # median\nhead(matd_median$survival(months)) # same as with `arrd`\n[,1]      [,2]\n1 0.8741127 0.9808363\n2 0.7670382 0.9621618\n3 0.6701276 0.9450867\n4 0.5688809 0.9272284\n5 0.4647686 0.9007042\n6 0.3660939 0.8687270\nUsing the\nmean\nposterior survival probabilities or the ones from the last posterior draw is also possible and can be done as follows:\nmatd_mean = arrd[, \"mean\"] # mean (if needed)\nhead(matd_mean$survival(months))\n[,1]      [,2]\n1 0.8652006 0.9748463\n2 0.7533538 0.9521817\n3 0.6560050 0.9293229\n4 0.5623555 0.9051549\n5 0.4750038 0.8758896\n6 0.3815333 0.8360373\nmatd_50draw = arrd[, 50] # the 50th posterior draw\nhead(matd_50draw$survival(months))\n[,1]      [,2]\n1 0.9178342 0.9920982\n2 0.8424195 0.9842589\n3 0.7732014 0.9764815\n4 0.7096707 0.9687656\n5 0.6029119 0.9495583\n6 0.5122132 0.9307318\nTo get the CIs we will subset the\nArrdist\nusing a quantile number (0-1), which extracts a\nMatdist\nbased on the cdf. The survival function is 1 – cdf, so low and upper bounds are reversed:\nlow  = arrd[, 0.975]$survival(months) # 2.5% bound\nhigh = arrd[, 0.025]$survival(months) # 97.5% bound\ncolnames(low)  = paste0(patient_ids, \"_low\")\ncolnames(high) = paste0(patient_ids, \"_high\")\nlow  = as_tibble(low)\nhigh = as_tibble(high)\nThe median posterior survival probabilities for the two patient of interest and the corresponding CI bounds in a tidy format are:\nsurv_tbl =\n  bind_cols(low, med, high) %>%\n  pivot_longer(cols = !month, values_to = \"surv\",\n    names_to = c(\"patient_id\", \".value\"), names_sep = \"_\") %>%\n  relocate(patient_id)\nsurv_tbl\n# A tibble: 72 × 5\n   patient_id month   low   med  high\n   <chr>      <int> <dbl> <dbl> <dbl>\n 1 5              1 0.713 0.874 0.953\n 2 18             1 0.929 0.981 0.996\n 3 5              2 0.508 0.767 0.903\n 4 18             2 0.863 0.962 0.991\n 5 5              3 0.362 0.670 0.855\n 6 18             3 0.801 0.945 0.985\n 7 5              4 0.244 0.569 0.804\n 8 18             4 0.734 0.927 0.977\n 9 5              5 0.146 0.465 0.748\n10 18             5 0.654 0.901 0.969\n# … with 62 more rows\nWe draw survival curves with the uncertainty for the survival probability quantified:\nmy_colors = c(\"#E41A1C\", \"#4DAF4A\")\nnames(my_colors) = patient_ids\n\nsurv_tbl %>%\n  ggplot(aes(x = month, y = med)) +\n  geom_step(aes(color = patient_id), linewidth = 1) +\n  xlab('Time (Months)') +\n  ylab('Survival Probability') +\n  geom_ribbon(aes(ymin = low, ymax = high, fill = patient_id),\n    alpha = 0.3, show.legend = F) +\n  geom_vline(xintercept = death_times[1], linetype = 'dashed', color = my_colors[1]) +\n  geom_vline(xintercept = death_times[2], linetype = 'dashed', color = my_colors[2]) +\n  theme_bw(base_size = 14) +\n  scale_color_manual(values = my_colors) +\n  scale_fill_manual(values = my_colors) +\n  guides(color = guide_legend(title = \"Patient ID\"))\nUncertainty quantification for the survival prediction of two patients in the test set using 95% credible intervals. The two vertical lines correspond to the reported time of death (in months) for the two patients.\nPartial Dependence Plot\nWe will use a Partial Dependence Plot (PDP)\n(Friedman 2001)\nto visualize how much different are males vs females in terms of their average survival predictions across time.\nNote\nPDPs assume that features are independent. In our case we need to check that\nsex\ndoesn’t correlate with any of the other features used for training the\nBART\nlearner. Since\nsex\nis a categorical feature, we fit a linear model using as target variable every other feature in the data (\n) and conduct an ANOVA (ANalysis Of VAriance) to get the variance explained or\n. The square root of that value is the correlation measure we want.\n# code from https://christophm.github.io/interpretable-ml-book/ale.html\nmycor = function(cnames, data) {\n  x.num = data[, cnames[1], with = FALSE][[1]]\n  x.cat = data[, cnames[2], with = FALSE][[1]]\n  # R^2 = Cor(X, Y)^2 in simple linear regression\n  sqrt(summary(lm(x.num ~ x.cat))$r.squared)\n}\n\ncnames = c(\"sex\")\ncombs = expand.grid(y = setdiff(colnames(d), \"sex\"), x = cnames)\ncombs$cor = apply(combs, 1, mycor, data = task$data()) # use the train set\ncombs\ny   x        cor\n1      time sex 0.12941337\n2    status sex 0.24343282\n3       age sex 0.12216709\n4      inst sex 0.07826337\n5  meal.cal sex 0.18389545\n6 pat.karno sex 0.04132443\n7   ph.ecog sex 0.02564987\n8  ph.karno sex 0.01702471\n9   wt.loss sex 0.13431983\nsex\ndoesn’t correlate strongly with any other feature, so we can compute the PDP:\n# create two datasets: one with males and one with females\n# all other features remain the same (use train data, 205 patients)\nd = task$data(rows = part$train) # `rows = part$test` to use the test set\n\nd$sex = 1\ntask_males = as_task_surv(d, time = 'time', event = 'status', id = 'lung-males')\nd$sex = 0\ntask_females = as_task_surv(d, time = 'time', event = 'status', id = 'lung-females')\n\n# make predictions\np_males   = learner$predict(task_males)\np_females = learner$predict(task_females)\n\n# take the median posterior survival probability\nsurv_males   = p_males$distr$survival(months) # patients x times\nsurv_females = p_females$distr$survival(months) # patients x times\n\n# tidy up data: average and quantiles across patients\ndata_males =\n  apply(surv_males, 1, function(row) {\n    tibble(\n      low = quantile(row, probs = 0.025),\n      avg = mean(row),\n      high = quantile(row, probs = 0.975)\n    )\n  }) %>%\n  bind_rows() %>%\n  add_column(sex = 'male', month = months, .before = 1)\n\ndata_females =\n  apply(surv_females, 1, function(row) {\n    tibble(\n      low = quantile(row, probs = 0.025),\n      avg = mean(row),\n      high = quantile(row, probs = 0.975)\n    )\n  }) %>%\n  bind_rows() %>%\n  add_column(sex = 'female', month = months, .before = 1)\n\npdp_tbl = bind_rows(data_males, data_females)\npdp_tbl\n# A tibble: 72 × 5\n   sex   month    low   avg  high\n   <chr> <int>  <dbl> <dbl> <dbl>\n 1 male      1 0.836  0.942 0.981\n 2 male      2 0.704  0.889 0.963\n 3 male      3 0.587  0.839 0.943\n 4 male      4 0.488  0.788 0.924\n 5 male      5 0.392  0.732 0.897\n 6 male      6 0.304  0.663 0.860\n 7 male      7 0.234  0.601 0.829\n 8 male      8 0.172  0.550 0.799\n 9 male      9 0.130  0.503 0.766\n10 male     10 0.0945 0.455 0.733\n# … with 62 more rows\nmy_colors = c(\"#E41A1C\", \"#4DAF4A\")\nnames(my_colors) = c('male', 'female')\n\npdp_tbl %>%\n  ggplot(aes(x = month, y = avg)) +\n  geom_step(aes(color = sex), linewidth = 1) +\n  xlab('Time (Months)') +\n  ylab('Survival Probability') +\n  geom_ribbon(aes(ymin = low, ymax = high, fill = sex), alpha = 0.2, show.legend = F) +\n  theme_bw(base_size = 14) +\n  scale_color_manual(values = my_colors) +\n  scale_fill_manual(values = my_colors)\nFriedman’s partial dependence function with 95% prediction intervals: males vs females. Females show on average larger survival estimates compared to men, across all time points. Overlapping shaded area represents men and women that have similar survival characteristics.\nReferences\nBonato, Vinicius, Veerabhadran Baladandayuthapani, Bradley M. Broom, Erik P. Sulman, Kenneth D. Aldape, and Kim Anh Do. 2011.\n“\nBayesian ensemble methods for survival prediction in gene expression data\n.”\nBioinformatics\n27 (3): 359–67.\nhttps://doi.org/10.1093/BIOINFORMATICS/BTQ660\n.\nChipman, Hugh A, Edward I George, and Robert E McCulloch. 2010.\n“\nBART: BAYESIAN ADDITIVE REGRESSION TREES\n.”\nThe Annals of Applied Statistics\n4 (1): 266–98.\nhttp://www.jstor.org/stable/27801587\n.\nFriedman, Jerome H. 2001.\n“\nGreedy function approximation: a gradient boosting machine\n.”\nAnnals of Statistics\n, 1189–1232.\nhttps://doi.org/10.1214/aos/1013203451\n.\nSonabend, Raphael, Andreas Bender, and Sebastian Vollmer. 2022.\n“\nAvoiding C-hacking when evaluating survival distribution predictions with discrimination measures\n.”\nEdited by Zhiyong Lu.\nBioinformatics\n, July.\nhttps://doi.org/10.1093/BIOINFORMATICS/BTAC451\n.\nSonabend, Raphael, Florian Pfisterer, Alan Mishler, Moritz Schauer, Lukas Burk, Sumantrak Mukherjee, and Sebastian Vollmer. 2022.\n“\nFlexible Group Fairness Metrics for Survival Analysis\n,”\nMay.\nhttps://doi.org/10.48550/arxiv.2206.03256\n.\nSparapani, Rodney A., Brent R. Logan, Robert E. McCulloch, and Purushottam W. Laud. 2016.\n“\nNonparametric survival analysis using Bayesian Additive Regression Trees (BART)\n.”\nStatistics in Medicine\n35 (16): 2741–53.\nhttps://doi.org/10.1002/SIM.6893\n.\nSparapani, Rodney, Charles Spanbauer, and Robert McCulloch. 2021.\n“\nNonparametric Machine Learning and Efficient Computation with Bayesian Additive Regression Trees: The BART R Package\n.”\nJournal of Statistical Software\n97 (1): 1–66.\nhttps://doi.org/10.18637/JSS.V097.I01\n.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nmlr-org\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "Intro Here are some interesting reads regarding BART: The first BART paper (Chipman, George, and McCulloch 2010). The first implementation of BART for survival data (Bonato et al. 2011). This includes fully parametric AFT and Weibull models an...",
      "meta_keywords": null,
      "og_description": "Intro Here are some interesting reads regarding BART: The first BART paper (Chipman, George, and McCulloch 2010). The first implementation of BART for survival data (Bonato et al. 2011). This includes fully parametric AFT and Weibull models an...",
      "og_image": "https://latex.codecogs.com/png.latex?23%20%5Ctimes%2031%20%5Ctimes%2050%20=%2035650",
      "og_title": "Survival modeling in mlr3 using Bayesian Additive Regression Trees (BART) | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 17.9,
      "sitemap_lastmod": "2023-10-25T00:00:00+00:00",
      "twitter_description": "Intro Here are some interesting reads regarding BART: The first BART paper (Chipman, George, and McCulloch 2010). The first implementation of BART for survival data (Bonato et al. 2011). This includes fully parametric AFT and Weibull models an...",
      "twitter_title": "Survival modeling in mlr3 using Bayesian Additive Regression Trees (BART) | R-bloggers",
      "url": "https://www.r-bloggers.com/2023/10/survival-modeling-in-mlr3-using-bayesian-additive-regression-trees-bart/",
      "word_count": 3589
    }
  }
}