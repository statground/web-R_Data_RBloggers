{
  "id": "9c82449a4379808bd58b8848c10959890bb54643",
  "url": "https://www.r-bloggers.com/2024/01/benchmarking-the-speed-of-cumulative-functions-in-tidydensity/",
  "created_at_utc": "2025-11-17T20:38:37Z",
  "data": null,
  "raw_original": {
    "uuid": "8f4dd3d2-1e17-40f0-babf-4e9702c4737c",
    "created_at": "2025-11-17 20:38:37",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2024/01/benchmarking-the-speed-of-cumulative-functions-in-tidydensity/",
      "crawled_at": "2025-11-17T09:18:50.869503",
      "external_links": [
        {
          "href": "https://www.spsanderson.com/steveondata/posts/2023-01-11/index.html",
          "text": "Steve's Data Tips and Tricks"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://cran.r-project.org/web/packages/TidyDensity/index.html",
          "text": "TidyDensity"
        },
        {
          "href": "https://cran.r-project.org/web/packages/rbenchmark/index.html",
          "text": "rbenchmark"
        },
        {
          "href": "https://www.spsanderson.com/steveondata/posts/2023-01-11/index.html",
          "text": "Steve's Data Tips and Tricks"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Benchmarking the Speed of Cumulative Functions in TidyDensity | R-bloggers",
      "images": [
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/www.spsanderson.com/steveondata/posts/2023-01-11/index_files/figure-html/unnamed-chunk-1-1.png?w=450&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/steven-p-sanderson-ii-mph/",
          "text": "Steven P. Sanderson II, MPH"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-381452 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Benchmarking the Speed of Cumulative Functions in TidyDensity</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">January 10, 2024</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/steven-p-sanderson-ii-mph/\">Steven P. Sanderson II, MPH</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://www.spsanderson.com/steveondata/posts/2023-01-11/index.html\"> Steve's Data Tips and Tricks</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<section class=\"level1\" id=\"introduction\">\n<h1>Introduction</h1>\n<p>Statistical analysis often involves calculating various measures on large datasets. Speed and efficiency are crucial, especially when dealing with real-time analytics or massive data volumes. The <a href=\"https://cran.r-project.org/web/packages/TidyDensity/index.html\" rel=\"nofollow\" target=\"_blank\">TidyDensity</a> package in R provides a set of fast cumulative functions for common statistical measures like mean, standard deviation, skewness, and kurtosis. But just how fast are these cumulative functions compared to doing the computations directly? In this post, I benchmark the cumulative functions against the base R implementations using the <a href=\"https://cran.r-project.org/web/packages/rbenchmark/index.html\" rel=\"nofollow\" target=\"_blank\">rbenchmark</a> package.</p>\n</section>\n<section class=\"level1\" id=\"setting-the-bench\">\n<h1>Setting the bench</h1>\n<p>To assess the performance of TidyDensity’s cumulative functions, we’ll employ the rbenchmark package for benchmarking and the ggplot2 package for visualization. I’ll benchmark the following cumulative functions on random samples of increasing size:</p>\n<ul>\n<li><code>cgmean()</code> – Cumulative geometric mean</li>\n<li><code>chmean()</code> – Cumulative harmonic mean</li>\n<li><code>ckurtosis()</code> – Cumulative kurtosis</li>\n<li><code>cskewness()</code> – Cumulative skewness</li>\n<li><code>cmean()</code> – Cumulative mean</li>\n<li><code>csd()</code> – Cumulative standard deviation</li>\n<li><code>cvar()</code> – Cumulative variance</li>\n</ul>\n<div class=\"cell\">\n<pre>library(TidyDensity)\nlibrary(rbenchmark)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nset.seed(123)\n\nx1 &lt;- sample(1e2) + 1e2\nx2 &lt;- sample(1e3) + 1e3 \nx3 &lt;- sample(1e4) + 1e4\nx4 &lt;- sample(1e5) + 1e5\nx5 &lt;- sample(1e6) + 1e6\n\ncg_bench &lt;- benchmark(\n  \"100\" = cgmean(x1),\n  \"1000\" = cgmean(x2),\n  \"10000\" = cgmean(x3),\n  \"100000\" = cgmean(x4),\n  \"1000000\" = cgmean(x5),\n  replications = 100L,\n  columns = c(\"test\",\"replications\",\"elapsed\", \"relative\",\"user.self\",\"sys.self\")\n)\n\n# Run benchmarks for other functions\nch_bench &lt;- benchmark(\n  \"100\" = chmean(x1),\n  \"1000\" = chmean(x2),\n  \"10000\" = chmean(x3),\n  \"100000\" = chmean(x4),\n  \"1000000\" = chmean(x5),\n  replications = 100L,\n  columns = c(\"test\",\"replications\",\"elapsed\", \"relative\",\"user.self\",\"sys.self\")\n)\n\nck_bench &lt;- benchmark(\n  \"100\" = ckurtosis(x1),\n  \"1000\" = ckurtosis(x2),\n  \"10000\" = ckurtosis(x3),\n  \"100000\" = ckurtosis(x4),\n  \"1000000\" = ckurtosis(x5),\n  replications = 100L,\n  columns = c(\"test\",\"replications\",\"elapsed\", \"relative\",\"user.self\",\"sys.self\")  \n)\n\ncs_bench &lt;- benchmark(\n  \"100\" = cskewness(x1),\n  \"1000\" = cskewness(x2), \n  \"10000\" = cskewness(x3),\n  \"100000\" = cskewness(x4),\n  \"1000000\" = cskewness(x5),\n  replications = 100L,\n  columns = c(\"test\",\"replications\",\"elapsed\", \"relative\",\"user.self\",\"sys.self\")\n)\n\ncm_bench &lt;- benchmark(\n  \"100\" = cmean(x1),\n  \"1000\" = cmean(x2),\n  \"10000\" = cmean(x3),\n  \"100000\" = cmean(x4),\n  \"1000000\" = cmean(x5),\n  replications = 100L,\n  columns = c(\"test\",\"replications\",\"elapsed\", \"relative\",\"user.self\",\"sys.self\")\n)\n\ncsd_bench &lt;- benchmark(\n  \"100\" = csd(x1),\n  \"1000\" = csd(x2),\n  \"10000\" = csd(x3),\n  \"100000\" = csd(x4),\n  \"1000000\" = csd(x5),\n  replications = 100L,\n  columns = c(\"test\",\"replications\",\"elapsed\", \"relative\",\"user.self\",\"sys.self\")  \n)\n\ncv_bench &lt;- benchmark(\n  \"100\" = cvar(x1),\n  \"1000\" = cvar(x2),\n  \"10000\" = cvar(x3),\n  \"100000\" = cvar(x4), \n  \"1000000\" = cvar(x5),\n  replications = 100L,\n  columns = c(\"test\",\"replications\",\"elapsed\", \"relative\",\"user.self\",\"sys.self\")\n)\n\nbenchmarks &lt;- rbind(cg_bench, ch_bench, ck_bench, cs_bench, cm_bench, csd_bench, cv_bench)\n\n# Arrange benchmarks and plot\nbench_tbl &lt;- benchmarks |&gt; \n  mutate(func = c(\n    rep(\"cgmean\", 5), \n    rep(\"chmean\", 5),\n    rep(\"ckurtosis\", 5),\n    rep(\"cskewness\", 5),\n    rep(\"cmean\", 5),\n    rep(\"csd\", 5),\n    rep(\"cvar\", 5)\n    )\n  ) |&gt;\n  arrange(func, test) |&gt;\n  select(func, test, everything())\n\nbench_tbl |&gt;\n  ggplot(aes(x=test, y=elapsed, group = func, color = func)) +\n    geom_line() +\n    facet_wrap(~func, scales=\"free_y\") +\n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n    labs(title=\"Cumulative Function Speed Comparison\",\n       x=\"Sample Size\",\n       y=\"Elapsed Time (sec)\",\n       color = \"Function\")</pre>\n<div class=\"cell-output-display\">\n<p><img class=\"img-fluid\" data-lazy-src=\"https://i0.wp.com/www.spsanderson.com/steveondata/posts/2023-01-11/index_files/figure-html/unnamed-chunk-1-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.spsanderson.com/steveondata/posts/2023-01-11/index_files/figure-html/unnamed-chunk-1-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</div>\n</div>\n<p>The results show that the TidyDensity cumulative functions scale extremely well as the sample size increases. The elapsed time remains very low even at 1 million observations. The base R implementations like <code>var()</code> and <code>sd()</code> perform significantly worse when used inside of an <code>sapply</code> at large sample sizes. What was not tested however is <code>cmedian()</code> and this is because the performance is very slow once we reach 1e4 compared to the other functions as such that it would take too long to run the benchmark if it ran at all.</p>\n<p>So if you need fast statistical functions that can scale to big datasets, the TidyDensity cumulative functions are a great option! They provide massive speedups over base R while returning the same final result.</p>\n<p>Let me know in the comments if you have any other benchmark ideas for comparing R packages! I’m always looking for interesting performance comparisons to test out.</p>\n</section>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://www.spsanderson.com/steveondata/posts/2023-01-11/index.html\"> Steve's Data Tips and Tricks</a></strong>.</div>\n<hr>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</hr></div> </div>\n</article>",
      "main_text": "Benchmarking the Speed of Cumulative Functions in TidyDensity\nPosted on\nJanuary 10, 2024\nby\nSteven P. Sanderson II, MPH\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nSteve's Data Tips and Tricks\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nIntroduction\nStatistical analysis often involves calculating various measures on large datasets. Speed and efficiency are crucial, especially when dealing with real-time analytics or massive data volumes. The\nTidyDensity\npackage in R provides a set of fast cumulative functions for common statistical measures like mean, standard deviation, skewness, and kurtosis. But just how fast are these cumulative functions compared to doing the computations directly? In this post, I benchmark the cumulative functions against the base R implementations using the\nrbenchmark\npackage.\nSetting the bench\nTo assess the performance of TidyDensity’s cumulative functions, we’ll employ the rbenchmark package for benchmarking and the ggplot2 package for visualization. I’ll benchmark the following cumulative functions on random samples of increasing size:\ncgmean()\n– Cumulative geometric mean\nchmean()\n– Cumulative harmonic mean\nckurtosis()\n– Cumulative kurtosis\ncskewness()\n– Cumulative skewness\ncmean()\n– Cumulative mean\ncsd()\n– Cumulative standard deviation\ncvar()\n– Cumulative variance\nlibrary(TidyDensity)\nlibrary(rbenchmark)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nset.seed(123)\n\nx1 <- sample(1e2) + 1e2\nx2 <- sample(1e3) + 1e3 \nx3 <- sample(1e4) + 1e4\nx4 <- sample(1e5) + 1e5\nx5 <- sample(1e6) + 1e6\n\ncg_bench <- benchmark(\n  \"100\" = cgmean(x1),\n  \"1000\" = cgmean(x2),\n  \"10000\" = cgmean(x3),\n  \"100000\" = cgmean(x4),\n  \"1000000\" = cgmean(x5),\n  replications = 100L,\n  columns = c(\"test\",\"replications\",\"elapsed\", \"relative\",\"user.self\",\"sys.self\")\n)\n\n# Run benchmarks for other functions\nch_bench <- benchmark(\n  \"100\" = chmean(x1),\n  \"1000\" = chmean(x2),\n  \"10000\" = chmean(x3),\n  \"100000\" = chmean(x4),\n  \"1000000\" = chmean(x5),\n  replications = 100L,\n  columns = c(\"test\",\"replications\",\"elapsed\", \"relative\",\"user.self\",\"sys.self\")\n)\n\nck_bench <- benchmark(\n  \"100\" = ckurtosis(x1),\n  \"1000\" = ckurtosis(x2),\n  \"10000\" = ckurtosis(x3),\n  \"100000\" = ckurtosis(x4),\n  \"1000000\" = ckurtosis(x5),\n  replications = 100L,\n  columns = c(\"test\",\"replications\",\"elapsed\", \"relative\",\"user.self\",\"sys.self\")  \n)\n\ncs_bench <- benchmark(\n  \"100\" = cskewness(x1),\n  \"1000\" = cskewness(x2), \n  \"10000\" = cskewness(x3),\n  \"100000\" = cskewness(x4),\n  \"1000000\" = cskewness(x5),\n  replications = 100L,\n  columns = c(\"test\",\"replications\",\"elapsed\", \"relative\",\"user.self\",\"sys.self\")\n)\n\ncm_bench <- benchmark(\n  \"100\" = cmean(x1),\n  \"1000\" = cmean(x2),\n  \"10000\" = cmean(x3),\n  \"100000\" = cmean(x4),\n  \"1000000\" = cmean(x5),\n  replications = 100L,\n  columns = c(\"test\",\"replications\",\"elapsed\", \"relative\",\"user.self\",\"sys.self\")\n)\n\ncsd_bench <- benchmark(\n  \"100\" = csd(x1),\n  \"1000\" = csd(x2),\n  \"10000\" = csd(x3),\n  \"100000\" = csd(x4),\n  \"1000000\" = csd(x5),\n  replications = 100L,\n  columns = c(\"test\",\"replications\",\"elapsed\", \"relative\",\"user.self\",\"sys.self\")  \n)\n\ncv_bench <- benchmark(\n  \"100\" = cvar(x1),\n  \"1000\" = cvar(x2),\n  \"10000\" = cvar(x3),\n  \"100000\" = cvar(x4), \n  \"1000000\" = cvar(x5),\n  replications = 100L,\n  columns = c(\"test\",\"replications\",\"elapsed\", \"relative\",\"user.self\",\"sys.self\")\n)\n\nbenchmarks <- rbind(cg_bench, ch_bench, ck_bench, cs_bench, cm_bench, csd_bench, cv_bench)\n\n# Arrange benchmarks and plot\nbench_tbl <- benchmarks |> \n  mutate(func = c(\n    rep(\"cgmean\", 5), \n    rep(\"chmean\", 5),\n    rep(\"ckurtosis\", 5),\n    rep(\"cskewness\", 5),\n    rep(\"cmean\", 5),\n    rep(\"csd\", 5),\n    rep(\"cvar\", 5)\n    )\n  ) |>\n  arrange(func, test) |>\n  select(func, test, everything())\n\nbench_tbl |>\n  ggplot(aes(x=test, y=elapsed, group = func, color = func)) +\n    geom_line() +\n    facet_wrap(~func, scales=\"free_y\") +\n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n    labs(title=\"Cumulative Function Speed Comparison\",\n       x=\"Sample Size\",\n       y=\"Elapsed Time (sec)\",\n       color = \"Function\")\nThe results show that the TidyDensity cumulative functions scale extremely well as the sample size increases. The elapsed time remains very low even at 1 million observations. The base R implementations like\nvar()\nand\nsd()\nperform significantly worse when used inside of an\nsapply\nat large sample sizes. What was not tested however is\ncmedian()\nand this is because the performance is very slow once we reach 1e4 compared to the other functions as such that it would take too long to run the benchmark if it ran at all.\nSo if you need fast statistical functions that can scale to big datasets, the TidyDensity cumulative functions are a great option! They provide massive speedups over base R while returning the same final result.\nLet me know in the comments if you have any other benchmark ideas for comparing R packages! I’m always looking for interesting performance comparisons to test out.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nSteve's Data Tips and Tricks\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "Introduction Statistical analysis often involves calculating various measures on large datasets. Speed and efficiency are crucial, especially when dealing with real-time analytics or massive data volumes. The TidyDensity package in R provides a ...",
      "meta_keywords": null,
      "og_description": "Introduction Statistical analysis often involves calculating various measures on large datasets. Speed and efficiency are crucial, especially when dealing with real-time analytics or massive data volumes. The TidyDensity package in R provides a ...",
      "og_image": "https://www.spsanderson.com/steveondata/posts/2023-01-11/index_files/figure-html/unnamed-chunk-1-1.png",
      "og_title": "Benchmarking the Speed of Cumulative Functions in TidyDensity | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 3.9,
      "sitemap_lastmod": "2024-01-11T05:00:00+00:00",
      "twitter_description": "Introduction Statistical analysis often involves calculating various measures on large datasets. Speed and efficiency are crucial, especially when dealing with real-time analytics or massive data volumes. The TidyDensity package in R provides a ...",
      "twitter_title": "Benchmarking the Speed of Cumulative Functions in TidyDensity | R-bloggers",
      "url": "https://www.r-bloggers.com/2024/01/benchmarking-the-speed-of-cumulative-functions-in-tidydensity/",
      "word_count": 775
    }
  }
}