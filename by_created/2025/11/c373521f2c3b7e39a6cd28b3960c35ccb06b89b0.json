{
  "id": "c373521f2c3b7e39a6cd28b3960c35ccb06b89b0",
  "url": "https://www.r-bloggers.com/2025/01/amateur-urbanist-critique-of-work-live-ride-using-360k-fairfield-county-parcels/",
  "created_at_utc": "2025-11-22T19:59:29Z",
  "data": null,
  "raw_original": {
    "uuid": "bf504d09-57bf-414f-a34d-c6cebd71ccd2",
    "created_at": "2025-11-22 19:59:29",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2025/01/amateur-urbanist-critique-of-work-live-ride-using-360k-fairfield-county-parcels/",
      "crawled_at": "2025-11-22T10:55:49.181519",
      "external_links": [
        {
          "href": "https://www.redwallanalytics.com/2025/01/16/thoughts-on-work-live-ride-using-greenwich-ct-parcel-data/",
          "text": "R on Redwall Analytics"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://ontheline.trincoll.edu/index.html",
          "text": "On The Line: How Schooling, Housing, and Civil Rights Shaped Hartford and its Suburbs"
        },
        {
          "href": "https://www.desegregatect.org/work-live-ride",
          "text": "Desegregate CT Work-Live-Ride"
        },
        {
          "href": "https://cga.ct.gov/2025/TOB/H/PDF/2025HB-06831-R00-HB.PDF?mc_cid=91e1b53e90&mc_eid=27bb054ad1",
          "text": "Bill #6831"
        },
        {
          "href": "https://geodata.ct.gov/pages/parcels",
          "text": "CT Geodata Portal"
        },
        {
          "href": "https://www.zoningatlas.org/atlas",
          "text": "National Zoning Atlas"
        },
        {
          "href": "https://www.redwallanalytics.com/2025/01/16/thoughts-on-work-live-ride-using-greenwich-ct-parcel-data/",
          "text": "R on Redwall Analytics"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Amateur Urbanist Critique of Work-Live-Ride using 360k Fairfield County Parcels | R-bloggers",
      "images": [
        {
          "alt": "MetroNorth New Haven Line Stations",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "MetroNorth New Haven Line Stations",
          "base64": null,
          "src": "https://i0.wp.com/www.redwallanalytics.com/2025/01/16/thoughts-on-work-live-ride-using-greenwich-ct-parcel-data/images/mnr.png?w=578&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/r-on-redwall-analytics/",
          "text": "R on Redwall Analytics"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-390362 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Amateur Urbanist Critique of Work-Live-Ride using 360k Fairfield County Parcels</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">January 15, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/r-on-redwall-analytics/\">R on Redwall Analytics</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://www.redwallanalytics.com/2025/01/16/thoughts-on-work-live-ride-using-greenwich-ct-parcel-data/\"> R on Redwall Analytics</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<link href=\"https://www.redwallanalytics.com/2025/01/16/thoughts-on-work-live-ride-using-greenwich-ct-parcel-data/index_files/htmltools-fill/fill.css\" rel=\"stylesheet\"/>\n\n<link href=\"https://www.redwallanalytics.com/2025/01/16/thoughts-on-work-live-ride-using-greenwich-ct-parcel-data/index_files/datatables-css/datatables-crosstalk.css\" rel=\"stylesheet\"/>\n\n\n<link href=\"https://www.redwallanalytics.com/2025/01/16/thoughts-on-work-live-ride-using-greenwich-ct-parcel-data/index_files/dt-core/css/jquery.dataTables.min.css\" rel=\"stylesheet\"/>\n<link href=\"https://www.redwallanalytics.com/2025/01/16/thoughts-on-work-live-ride-using-greenwich-ct-parcel-data/index_files/dt-core/css/jquery.dataTables.extra.css\" rel=\"stylesheet\"/>\n\n<link href=\"https://www.redwallanalytics.com/2025/01/16/thoughts-on-work-live-ride-using-greenwich-ct-parcel-data/index_files/crosstalk/css/crosstalk.min.css\" rel=\"stylesheet\"/>\n\n\n\n<link href=\"https://www.redwallanalytics.com/2025/01/16/thoughts-on-work-live-ride-using-greenwich-ct-parcel-data/index_files/plotly-htmlwidgets-css/plotly-htmlwidgets.css\" rel=\"stylesheet\"/>\n\n<div class=\"float\">\n<img alt=\"MetroNorth New Haven Line Stations\" data-lazy-src=\"https://i0.wp.com/www.redwallanalytics.com/2025/01/16/thoughts-on-work-live-ride-using-greenwich-ct-parcel-data/images/mnr.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"MetroNorth New Haven Line Stations\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.redwallanalytics.com/2025/01/16/thoughts-on-work-live-ride-using-greenwich-ct-parcel-data/images/mnr.png?w=578&amp;ssl=1\"/></noscript>\n<div class=\"figcaption\">MetroNorth New Haven Line Stations</div>\n</div>\n<div class=\"section level1\" id=\"introduction\">\n<h1>Introduction</h1>\n<p>Connecticut has long had some of the highest income and home prices in the US. Although home prices have trailed national rate of appreciation in recent decades, from a high starting point, housing has gotten a lot more expensive in absolute terms and is still out of reach for too many. High housing costs have constrained population growth in many towns, likely slowed income growth by impeding business formation, and contributed to the State’s high costs and taxes. Starting in the 1920’s, many CT Towns started requiring large minimum parcel sizes in zoning, among other regulations, often with exclusionary intent, well documented in <a href=\"https://ontheline.trincoll.edu/index.html\" rel=\"nofollow\" target=\"_blank\">On The Line: How Schooling, Housing, and Civil Rights Shaped Hartford and its Suburbs</a>. The effects of these policies have become acute due to the demand surge caused by the COVID-19 pandemic, which gobbled up residual excess supply left by the Global Financial Crisis. In 2021, a group called <a href=\"https://www.desegregatect.org/work-live-ride\" rel=\"nofollow\" target=\"_blank\">Desegregate CT Work-Live-Ride</a> began making a series of reform proposals, a central one being <a href=\"https://cga.ct.gov/2025/TOB/H/PDF/2025HB-06831-R00-HB.PDF?mc_cid=91e1b53e90&amp;mc_eid=27bb054ad1\" rel=\"nofollow\" target=\"_blank\">Bill #6831</a> (<code>WLR</code>), to allow towns to opt into “Transit Oriented Development” allowing “by right” development of minimum densities and mixed use development near transit stations. This group consists of dozens of housing advocacy groups with backing from the Regional Plan Association (<code>RPA</code>), also non-profit whose largest contributors Board Members and often Executive leadership have often come from the New York real estate development industry.</p>\n<p>One of the <code>Desegregate</code> group’s main points has been that only single family homes are allowed as of right on 90% of parcels in the State, while much less commonly for two family housing (and almost not at all more than that). Also, 80% of those single family parcels have been zoned 1+ acres, constraining housing supply growth increasingly over decades and driving up home ownership costs and sprawl. Finally, many towns have allowed only single family residential zoning around vital transit hubs. These points all are unfortunately true, but in my opinion, there is a bait and switch using the valid large lot issue as the reason we need the inflexible <code>WLR</code>, when densities near MNR have much lower percentages of residential housing and very few large nearby parcels.</p>\n<p>The Connecticut Parcel and Cama data was first added to the Portal after laws requiring it passed in 2021, and offering the opportunity to look at the exact Polygon location data for almost 1.3 million parcels. This made me curious to investigate the lot sizes and housing density in those locations using the <a href=\"https://geodata.ct.gov/pages/parcels\" rel=\"nofollow\" target=\"_blank\">CT Geodata Portal</a> and to explore what it all would mean for my Town of Greenwich. There are surely a lot of experts with more knowledge of these issues and stronger views on either side mine. I agree with most of the sentiments of the pro-housing reform coalition, but hope on the eve of the legislative session, this post injects what has seemed absent from the contentious discussions thus far. For full disclosure, I grew up in Stamford and live near a station in Greenwich (but not within a potential transit zone), and probably carry some of those biases against what might be done in a suburban location, but also have yet to see a multi-family residential project in my town which I opposed (likely putting me among the most pro-housing residents in my community). There is a lot of data cleaning and coding in this post, so please feel free to skip ahead to <code>Results and Analysis</code> to the tables and charts of findings and parting thoughts.</p>\n</div>\n<div class=\"section level1\" id=\"collecting-loading-and-cleaning-data\">\n<h1>Collecting, Loading and Cleaning Data</h1>\n<p>I downloaded the Parcel File Geodatabase and 2024 CAMA property assessment data for each city. There are also separate files for county layers, but used the 2024 Basic Parcel Layers (including all counties) and filtered for Fairfield County and the last few Towns up the MNR line into New Haven County, the economic engine of the State. I get “unexpected geometry” warnings about interior rings, but discovered that changing to type = 3 while importing, converting the 3-dimensional XYZ Multi-Polygons to 2-dimensional XY Polygons for each parcel, which seems to work for my purposes. In the future, I would like to see if I can also look at the building footprints within the parcels, but this was enough for the purposes of this post. This was my first attempt at using GIS data on this scale, and so my knowledge is superficial, and suggestions are welcome.</p>\n<details>\n<summary>\nLoad and Clean FF Parcels\n</summary>\n<pre># Basic Parcel Geodatabase \nfolder &lt;- \"~/Documents/Data/ct_state_data/\"\nfile &lt;- paste0(folder, \"2024 Basic Parcel Layer.gdb\")\n\n# Reading and filtering for Fairfield County towns\nff_parcels &lt;- read_sf(\n  dsn = file, \n  query =\n    \"SELECT * FROM \\\"Basic_Parcels_2024\\\" where Town_Name in ('Greenwich', 'Stamford', 'Darien', 'New Canaan', 'Westport', 'Norwalk', 'Bridgeport', 'Shelton', 'West Haven', 'New Haven', 'East Haven', 'Trumbull', 'Easton', 'Redding', 'Bethel', 'Brookfield', 'Danbury', 'Newtown', 'New Fairfield', 'Ridgefield', 'Wilton', 'Weston', 'Stratford', 'Fairfield', 'Monroe', 'Ridgefield', 'Orange', 'Milford', 'Derby')\", \n  type = 3)\n\n# Clean parcels\nff_parcels &lt;- ff_parcels[sf::st_is_valid(ff_parcels),]\n\n# Fix Danbury links\nff_parcels[ff_parcels$Town_Name == \"Danbury\", ]$CAMA_Link &lt;- \n  paste0(\"18500-\", ff_parcels[ff_parcels$Town_Name ==\"Danbury\", ]$Parcel_ID)</pre>\n</details>\n<p>There were several thousand parcels which were invalid, and the only way I could manipulate the data with the <code>{sf}</code> package, was by removing them with <code>sf::st_is_valid()</code>. Also, Danbury’s disclosure was missing all property links, but I was fortunately able to extract and parse from other fields. The polygon shapes can be seen inside the NAD83 Connecticut boundaries. I spent some time trying to convert this to a lon-lat Coordinate Reference System (CRS), but in the end, discovered could do everything I needed with the original CRS distances. Below is the Shape of the parcels, which are I believe are called State Plane Coordinates.</p>\n<pre># Towns along the MRN property Polygons\nprint(ff_parcels$Shape)\n## Geometry set for 359565 features  (with 10 geometries empty)\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 730512.2 ymin: 554931.1 xmax: 1002166 ymax: 756258.3\n## Projected CRS: NAD83 / Connecticut (ftUS)\n## First 5 geometries:\n## POLYGON ((868586.9 613438.8, 868509.1 613356.3,...\n## POLYGON ((868361.3 613493.1, 868247.5 613380, 8...\n## POLYGON ((868662.6 613522.2, 868586.9 613438.8,...\n## POLYGON ((867755.4 613622.7, 867744.1 613443.5,...\n## POLYGON ((867505.7 613668.3, 867622.2 613647, 8...</pre>\n<p>The Geodatabase unfortunately does not currently have the property assessment data, including the “state use” codes (ie: Commercial, Residential (Single Family, Multi-family), Industrial), which are the only way I could sort residential properties, and within those, if more than one family would be allowed in a location. The problem with the CAMA data is that was not contributed by Towns with consistent standards (as I have often found with data submitted by 169 often small towns probably lacking data infrastructure). While the data could be a lot cleaner and more uniform, my first recommendation would be to clean up the state use codes, and include them in this GIS database, which would streamline things for those working with the raw data instead of the online Parcel Viewer.</p>\n<details>\n<summary>\nLoad and Clean CAMA Data\n</summary>\n<pre>file &lt;- paste0(folder, \"/2024_Connecticut_Parcel_and_CAMA_Data_20250111.csv\")\ncama_data &lt;- data.table::fread(file)\ncama_data[, link := re2::re2_replace_all(link, \" \", \"\")]\ncama_data &lt;- janitor::clean_names(cama_data)\n\n# Fix some Darien links not matching ff_parcels data\ncama_data[\n    property_city == \"Darien\"\n    , link := data.table::fifelse(\n      re2::re2_detect(link, \".*\\\\-\\\\d$\"), \n      re2::re2_extract_replace(link, \"^(.*)\\\\-(\\\\d)$\", \"\\\\1-0\\\\2\"),\n      link\n    )]\n\n# Fix missing Bridgeport links\ncama_data[\n  property_city==\"Bridgeport\", \n  cama_site_link := paste(\"0\", cama_site_link)]\n\n# Clean up any whitepace to make sure of joins\ncama_data[, cama_site_link := trimws(cama_site_link)]</pre>\n</details>\n<p>The full extent of the work in progress nature of this data can be seen in the <code>{skimR}</code> summary below. Some places where the state might clean up this dataset are: eight towns haven’t populated the <code>town_id</code> field, and various other fields are incomplete. There are two zoning fields (<code>zone</code> and <code>zone description</code>), but no uniform structure to these. An academic from Connecticut was Founder of the <a href=\"https://www.zoningatlas.org/atlas\" rel=\"nofollow\" target=\"_blank\">National Zoning Atlas</a>, an impressive data-oriented project, which led to the initial recognition of the extent of the large lot zoning problem in the State. It doesn’t appear that this data can be downloaded and combined with other data, but tying the parcel data to to minimum zoned lot sizes would be big opportunity. The Zoning Atlas data also doesn’t include Coastal Overlay or other flood plane data, which seems like a significant factor to zoning for many parcels along the MNR line (if you look at the train map above).</p>\n<p>For now, the most important field for the purposes of this exercise is <code>state_use</code> which is never NA, but in four towns had an empty string for all properties and overall has over 1600 unique categories just in this subset of Towns. <code>state_use</code> for a single family in most towns is “101”, but there are many others coded as simply “100” or starting with “1” followed by other formats. If I had more time, I might be able to do a better job predicting <code>state_use</code> with <code>state_use_description</code>, but leave that for another time. For this reason, all data summaries below had to be looked at as approximate and by no means the final word on density or mix of land use near stations.</p>\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-1\" style=\"width:100%;height:auto;\"></div>\n\n<p>In order to get train station coordinates, I found the USDOT Intermodal Passenger Connectivity Dataset (IPCD) with 15,000 transportation hubs around the US. This offers the option to conduct future analyses around other transport hubs, like bus routes. It took a few tries to get the MNR lines, for example, Cos Cob is mistakenly listed in NY state, and some locations came up more than once if there was both an Amtrak, MNR or bus stop at that location. I generally prefer data.table, but this doesn’t work for data manipulation with sf objects. I was able to get away with it here using only the X, Y coordinates, and then convert back to sf further downstream.</p>\n<details>\n<summary>\nLoad Train Station coordinates\n</summary>\n<pre>file &lt;- \n  paste0(folder, \n  \"NTAD_Intermodal_Passenger_Connectivity_Database/Intermodal_Passenger_Connectivity_Database_(IPCD).shp\"\n  )\ntrains &lt;- st_read(\n  dsn = file, \n  query = \"select * from \\\"Intermodal_Passenger_Connectivity_Database_(IPCD)\\\" \n    where METRO_AREA LIKE 'Bridgeport-Stamford-Norwalk CT' AND MODE_RAIL = 1\")\n## Reading query `select * from \"Intermodal_Passenger_Connectivity_Database_(IPCD)\" \n##     where METRO_AREA LIKE 'Bridgeport-Stamford-Norwalk CT' AND MODE_RAIL = 1'\n## from data source `/Users/davidlucey/Documents/Data/ct_state_data/NTAD_Intermodal_Passenger_Connectivity_Database/Intermodal_Passenger_Connectivity_Database_(IPCD).shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 31 features and 52 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -73.62515 ymin: 41.02125 xmax: -73.13083 ymax: 41.3981\n## Geodetic CRS:  WGS 84\ndata.table::setDT(trains)\n\n# Filter unique stations by point_id and select columns\ntrains &lt;- unique(trains, by=\"POINT_ID\")\ntrains &lt;- \n  trains[, .(X, Y, POINT_ID, ADDRESS, METRO_AREA, FAC_NAME, CITY, STATE, ZIPCODE)]</pre>\n</details>\n<pre>DT::datatable(trains)</pre>\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-2\" style=\"width:100%;height:auto;\"></div>\n\n</div>\n<div class=\"section level1\" id=\"code-for-filtering-and-aggregating-parcels-within-ranges\">\n<h1>Code for Filtering and Aggregating Parcels within Ranges</h1>\n<p>This section has the code to load and find lots within progressively expanding radiuses for each station. My custom function, <code>get_parcels_in_geo_range()</code>, loads data from an IPCD point and filter CAMA points within a specified parameter distance. Again, I’m relatively new to GIS data, so it took me a long time to figure out how to create the station <code>{sf}</code> data.frame in a long-lat point XY dimension and with a CRS which could properly filter the ff_parcels for distance with <code>st::st_is_within_distance()</code>. First I had to load as CRS 4326, then transform to 2234 for distance calculations in accordance with my ff_parcels sf formatting. This took a long time to figure out, and I still don’t completely understand how it is working.</p>\n<details>\n<summary>\nGet Parcels in GEO Range\n</summary>\n<pre>get_parcels_in_geo_range &lt;- function(point_id, dist_range) {\n  \n  # Using trains, cama_data, and ff_parcels from the global env\n  \n  # Get train station\n  train_station &lt;- trains[trains$POINT_ID == point_id]\n  train_station &lt;- data.frame(lon=train_station$X, lat=train_station$Y)\n  \n  # Convert to sf\n  station &lt;- \n    sf::st_as_sf(train_station, coords = c(\"lon\", \"lat\"), crs = 4326) %&gt;% \n    st_transform(crs = 2234) \n  \n  # Find lots with components within dist_range\n  wd &lt;- \n    st_is_within_distance(ff_parcels, station, dist = units::set_units(dist_range, \"mile\"))\n\n  # Drop any lots where none of the components are within dist_range\n  parcels &lt;- ff_parcels %&gt;% filter(lengths(wd) &gt; 0)\n  \n  # Convert to data.table\n  data.table::setDT(parcels)\n  \n  # Clean names\n  parcels &lt;- janitor::clean_names(parcels)\n  \n  # Keep lots &gt;=0\n  parcels &lt;- parcels[shape_area &gt;= 0]\n  \n  # Copy cama_data to leave in place\n  cama_data &lt;- copy(cama_data)\n  \n  # Clean up any extra spaces in Cama link\n  parcels[, cama_link := re2::re2_replace_all(cama_link, \" \", \"\")]\n  \n  # Join data on \"link\" = \"cama_link\"\n  parcels &lt;- cama_data[parcels, on = c(\"link\" = \"cama_link\")]\n  \n  # Return\n  return(parcels)\n}</pre>\n</details>\n<p>In <code>prepare_town_data_frame()</code>, I had to use trial and error to figure out towns where the standard codes were not picking up residential properties. There were varying codes for single family home, condominium or apartment building, so I did my best to capture them all as shown in the <code>resi_codes</code> vector below. Unfortunately, I had to leave the job of separating single- and multi-family properties for a later time. I went with number of dwellings, which doesn’t distinguish between single and multi-family, but does give an overall sense of density in those zones.</p>\n<details>\n<summary>\nPrepare Town data.frame\n</summary>\n<pre>prepare_town_data_frame &lt;- function(towns) {\n  \n  # Remove towns outside FF county without parcels\n  towns &lt;- towns[sapply(towns, nrow) &gt; 20]\n  \n  # Convert list of towns to a single data.table\n  towns_df &lt;- rbindlist(towns, fill = TRUE, use.names = TRUE, idcol = \"station_name\")\n  \n  # Add an indicator and filter keeping properties thought to be residential derived by trial and error\n  resi_codes &lt;- \n    c(800, 801, 802, 803, 805, 899, 100, 101, 102, 103, 122, 104, 105, 108, 109, 172, 1010, 1040, 1110, 1012, 1015, 1050, 1111)\n  towns_df[, resi := state_use %in% as.character(resi_codes)]\n  towns_df[, resi := fifelse((resi == FALSE &amp; state_use_description == \"Residential\"), TRUE, resi)]\n  towns_df[, resi := fifelse((resi == FALSE &amp; state_use_description == \"Commericial\"), FALSE, resi)]\n  towns_df[is.na(resi), resi := FALSE]\n  \n  # Drop empty links\n  towns_df &lt;- \n    towns_df[!link %in% c(\"48620-\", \"77200-\", \"57600-\", \"68170-\", \"86370-\", \"52980-\") ]\n\n  return(towns_df)\n}</pre>\n</details>\n<p><code>prepare_station_summary()</code> summarizes all towns based on properties which were not identified, total residential properties, mean acres of residential dwellings, total number of properties above 1/2 acre and 1 acre, and the total acres of residential land within the specified distance. I also calculated the percentage of residential land within the total area in the half mile radius, which for most stations was more than half.</p>\n<details>\n<summary>\nPrepare Station Summary\n</summary>\n<pre>prepare_station_summary &lt;- function(towns_df) {\n  \n  # Find unmatched links\n  missing &lt;- towns_df[is.na(pid), .(unmatched = .N), station_name]\n  \n  # Count total resi properties near specified station_name\n  total_resi &lt;- towns_df[resi == TRUE, .(total_dwellings = .N), by = station_name]\n  \n  # Calc mean acres and counts of 1/2 and 1 acre parcels\n  ff_summary &lt;- dplyr::distinct(towns_df[resi == TRUE], shape, .keep_all = TRUE)[\n    , .(\n      avg_acres_dwelling = round(mean(shape_area)/43560, 2), \n      `total_half_ac+` = sum(shape_area&gt;0.5*43560), \n      `total_1_ac+` = sum(shape_area &gt;43560))\n    ,  station_name]\n  \n  # Count total acres and resi acres near specified station_name and dist_range\n  resi_land &lt;- dplyr::distinct(towns_df[resi==TRUE], shape, .keep_all = TRUE)[\n    , .(resi_ac = sum(shape_area)/43560), station_name]\n  total_land &lt;- dplyr::distinct(towns_df, shape, .keep_all = TRUE)[\n    , .(total_ac = round(sum(shape_area)/43560, 1)), station_name]\n  \n  # Aggregate components into final table by station_name\n  ff_summary &lt;- merge(ff_summary, total_land, by = \"station_name\")\n  ff_summary &lt;- merge(ff_summary, resi_land, by = \"station_name\")\n  ff_summary &lt;- merge(ff_summary, total_resi, by = \"station_name\")\n  ff_summary &lt;- merge(ff_summary, missing, by = \"station_name\")\n  \n  # Round digits\n  ff_summary &lt;- ff_summary[\n    , pct_resi := round(resi_ac/total_ac, 1)][\n      , resi_ac := NULL]\n  \n  # Return\n  return(ff_summary)\n}</pre>\n</details>\n<p>I wrote <code>get_stations_summary()</code> to iterate over all the train stations at a given <code>dist_range</code> in the select trains data.frame.</p>\n<details>\n<summary>\nGet Stations Summary\n</summary>\n</details>\n</div>\n<div class=\"section level1\" id=\"results-and-analysis\">\n<h1>Results and Analysis</h1>\n<p>Below is a summary table of stations within 1/2 mile of stations with several showing more or less than the 500 acres (expected in 1/2 mile radius). This is probably because some stations may be close to the water or include significant portions that are highway, so has a smaller area of land which may be developed for any purpose. Others may have a large property (ie: cemeteries, golf clubs, parks and schools) with an address within, but extending outside the radius. Bethel’s numbers look off, but it is missing most “state use” codes, so it is difficult to accurately account for what parcel usage. For a sense of the overall accuracy for a particular station, the “Unmatched Properties” column shows how many of the parcels were not classified by a “state use” code and were left out of the calculations. For example, I still have a lot of properties near Darien’s 33 West Ave station which are not classified. The proposed legislation has specified 15 to 30 units per acre minimum density as of right within these zones, so demonstrating how significant the change for adopting <code>WLR</code> could be for residents of those neighborhoods. Overall, there are no stations with average residential lots greater than 1 acre at any of the 26 stations.</p>\n<div class=\"figure\">\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-3\" style=\"width:100%;height:auto;\"></div>\n\n<p class=\"caption\">\n(#fig:0.5_miles)Summary of Properties within 1/2 mile of stations\n</p>\n</div>\n<p>Looking at density per acre for the portion of the zone including residential <code>state_use</code> codes, seven out of 26 stations have averages of more than 1 acre per dwelling in the first mile with more after 1.5 miles, much smaller numbers than the 80% average in the state, but still a lot. All of the lower density stations were much further from Grand Central. I don’t know the circumstances at those stations, but it does support the claim that some towns may have allowed sparse density at these valuable locations. Two stations have average lot size well above 1 acre in the first 0.5 miles, but then drop below 1 acre further out. Please hover over the lines to more better discern the station and the density at a given point, or select labels on the right to drill down on any location.</p>\n<div class=\"figure\">\n<div class=\"plotly html-widget html-fill-item\" id=\"htmlwidget-4\" style=\"width:672px;height:480px;\"></div>\n\n<p class=\"caption\">\n(#fig:average_acres)Average acres per dwelling is low around many stations\n</p>\n</div>\n<p>The next chart shows the number of 1+ acre lots by mile from stations, showing there are few within 1/2 mile at stations closest to NYC in Greenwich, Stamford and Norwalk for example, but there are lower densities much further up the line. While there are approximately 1,000 1+ acre lots near the 26 MNR stations, there are 10x that at 1.5 miles, and 25x 3 miles further away. Once you get a few miles away from stations, there is a lot more land in some locations, so this is my point that the remedy seems to miss the opportunity to address the concern.</p>\n<div class=\"figure\">\n<div class=\"plotly html-widget html-fill-item\" id=\"htmlwidget-5\" style=\"width:672px;height:480px;\"></div>\n</div></div>\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://www.redwallanalytics.com/2025/01/16/thoughts-on-work-live-ride-using-greenwich-ct-parcel-data/\"> R on Redwall Analytics</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
      "main_text": "Amateur Urbanist Critique of Work-Live-Ride using 360k Fairfield County Parcels\nPosted on\nJanuary 15, 2025\nby\nR on Redwall Analytics\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nR on Redwall Analytics\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nMetroNorth New Haven Line Stations\nIntroduction\nConnecticut has long had some of the highest income and home prices in the US. Although home prices have trailed national rate of appreciation in recent decades, from a high starting point, housing has gotten a lot more expensive in absolute terms and is still out of reach for too many. High housing costs have constrained population growth in many towns, likely slowed income growth by impeding business formation, and contributed to the State’s high costs and taxes. Starting in the 1920’s, many CT Towns started requiring large minimum parcel sizes in zoning, among other regulations, often with exclusionary intent, well documented in\nOn The Line: How Schooling, Housing, and Civil Rights Shaped Hartford and its Suburbs\n. The effects of these policies have become acute due to the demand surge caused by the COVID-19 pandemic, which gobbled up residual excess supply left by the Global Financial Crisis. In 2021, a group called\nDesegregate CT Work-Live-Ride\nbegan making a series of reform proposals, a central one being\nBill #6831\n(\nWLR\n), to allow towns to opt into “Transit Oriented Development” allowing “by right” development of minimum densities and mixed use development near transit stations. This group consists of dozens of housing advocacy groups with backing from the Regional Plan Association (\nRPA\n), also non-profit whose largest contributors Board Members and often Executive leadership have often come from the New York real estate development industry.\nOne of the\nDesegregate\ngroup’s main points has been that only single family homes are allowed as of right on 90% of parcels in the State, while much less commonly for two family housing (and almost not at all more than that). Also, 80% of those single family parcels have been zoned 1+ acres, constraining housing supply growth increasingly over decades and driving up home ownership costs and sprawl. Finally, many towns have allowed only single family residential zoning around vital transit hubs. These points all are unfortunately true, but in my opinion, there is a bait and switch using the valid large lot issue as the reason we need the inflexible\nWLR\n, when densities near MNR have much lower percentages of residential housing and very few large nearby parcels.\nThe Connecticut Parcel and Cama data was first added to the Portal after laws requiring it passed in 2021, and offering the opportunity to look at the exact Polygon location data for almost 1.3 million parcels. This made me curious to investigate the lot sizes and housing density in those locations using the\nCT Geodata Portal\nand to explore what it all would mean for my Town of Greenwich. There are surely a lot of experts with more knowledge of these issues and stronger views on either side mine. I agree with most of the sentiments of the pro-housing reform coalition, but hope on the eve of the legislative session, this post injects what has seemed absent from the contentious discussions thus far. For full disclosure, I grew up in Stamford and live near a station in Greenwich (but not within a potential transit zone), and probably carry some of those biases against what might be done in a suburban location, but also have yet to see a multi-family residential project in my town which I opposed (likely putting me among the most pro-housing residents in my community). There is a lot of data cleaning and coding in this post, so please feel free to skip ahead to\nResults and Analysis\nto the tables and charts of findings and parting thoughts.\nCollecting, Loading and Cleaning Data\nI downloaded the Parcel File Geodatabase and 2024 CAMA property assessment data for each city. There are also separate files for county layers, but used the 2024 Basic Parcel Layers (including all counties) and filtered for Fairfield County and the last few Towns up the MNR line into New Haven County, the economic engine of the State. I get “unexpected geometry” warnings about interior rings, but discovered that changing to type = 3 while importing, converting the 3-dimensional XYZ Multi-Polygons to 2-dimensional XY Polygons for each parcel, which seems to work for my purposes. In the future, I would like to see if I can also look at the building footprints within the parcels, but this was enough for the purposes of this post. This was my first attempt at using GIS data on this scale, and so my knowledge is superficial, and suggestions are welcome.\nLoad and Clean FF Parcels\n# Basic Parcel Geodatabase \nfolder <- \"~/Documents/Data/ct_state_data/\"\nfile <- paste0(folder, \"2024 Basic Parcel Layer.gdb\")\n\n# Reading and filtering for Fairfield County towns\nff_parcels <- read_sf(\n  dsn = file, \n  query =\n    \"SELECT * FROM \\\"Basic_Parcels_2024\\\" where Town_Name in ('Greenwich', 'Stamford', 'Darien', 'New Canaan', 'Westport', 'Norwalk', 'Bridgeport', 'Shelton', 'West Haven', 'New Haven', 'East Haven', 'Trumbull', 'Easton', 'Redding', 'Bethel', 'Brookfield', 'Danbury', 'Newtown', 'New Fairfield', 'Ridgefield', 'Wilton', 'Weston', 'Stratford', 'Fairfield', 'Monroe', 'Ridgefield', 'Orange', 'Milford', 'Derby')\", \n  type = 3)\n\n# Clean parcels\nff_parcels <- ff_parcels[sf::st_is_valid(ff_parcels),]\n\n# Fix Danbury links\nff_parcels[ff_parcels$Town_Name == \"Danbury\", ]$CAMA_Link <- \n  paste0(\"18500-\", ff_parcels[ff_parcels$Town_Name ==\"Danbury\", ]$Parcel_ID)\nThere were several thousand parcels which were invalid, and the only way I could manipulate the data with the\n{sf}\npackage, was by removing them with\nsf::st_is_valid()\n. Also, Danbury’s disclosure was missing all property links, but I was fortunately able to extract and parse from other fields. The polygon shapes can be seen inside the NAD83 Connecticut boundaries. I spent some time trying to convert this to a lon-lat Coordinate Reference System (CRS), but in the end, discovered could do everything I needed with the original CRS distances. Below is the Shape of the parcels, which are I believe are called State Plane Coordinates.\n# Towns along the MRN property Polygons\nprint(ff_parcels$Shape)\n## Geometry set for 359565 features  (with 10 geometries empty)\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 730512.2 ymin: 554931.1 xmax: 1002166 ymax: 756258.3\n## Projected CRS: NAD83 / Connecticut (ftUS)\n## First 5 geometries:\n## POLYGON ((868586.9 613438.8, 868509.1 613356.3,...\n## POLYGON ((868361.3 613493.1, 868247.5 613380, 8...\n## POLYGON ((868662.6 613522.2, 868586.9 613438.8,...\n## POLYGON ((867755.4 613622.7, 867744.1 613443.5,...\n## POLYGON ((867505.7 613668.3, 867622.2 613647, 8...\nThe Geodatabase unfortunately does not currently have the property assessment data, including the “state use” codes (ie: Commercial, Residential (Single Family, Multi-family), Industrial), which are the only way I could sort residential properties, and within those, if more than one family would be allowed in a location. The problem with the CAMA data is that was not contributed by Towns with consistent standards (as I have often found with data submitted by 169 often small towns probably lacking data infrastructure). While the data could be a lot cleaner and more uniform, my first recommendation would be to clean up the state use codes, and include them in this GIS database, which would streamline things for those working with the raw data instead of the online Parcel Viewer.\nLoad and Clean CAMA Data\nfile <- paste0(folder, \"/2024_Connecticut_Parcel_and_CAMA_Data_20250111.csv\")\ncama_data <- data.table::fread(file)\ncama_data[, link := re2::re2_replace_all(link, \" \", \"\")]\ncama_data <- janitor::clean_names(cama_data)\n\n# Fix some Darien links not matching ff_parcels data\ncama_data[\n    property_city == \"Darien\"\n    , link := data.table::fifelse(\n      re2::re2_detect(link, \".*\\\\-\\\\d$\"), \n      re2::re2_extract_replace(link, \"^(.*)\\\\-(\\\\d)$\", \"\\\\1-0\\\\2\"),\n      link\n    )]\n\n# Fix missing Bridgeport links\ncama_data[\n  property_city==\"Bridgeport\", \n  cama_site_link := paste(\"0\", cama_site_link)]\n\n# Clean up any whitepace to make sure of joins\ncama_data[, cama_site_link := trimws(cama_site_link)]\nThe full extent of the work in progress nature of this data can be seen in the\n{skimR}\nsummary below. Some places where the state might clean up this dataset are: eight towns haven’t populated the\ntown_id\nfield, and various other fields are incomplete. There are two zoning fields (\nzone\nand\nzone description\n), but no uniform structure to these. An academic from Connecticut was Founder of the\nNational Zoning Atlas\n, an impressive data-oriented project, which led to the initial recognition of the extent of the large lot zoning problem in the State. It doesn’t appear that this data can be downloaded and combined with other data, but tying the parcel data to to minimum zoned lot sizes would be big opportunity. The Zoning Atlas data also doesn’t include Coastal Overlay or other flood plane data, which seems like a significant factor to zoning for many parcels along the MNR line (if you look at the train map above).\nFor now, the most important field for the purposes of this exercise is\nstate_use\nwhich is never NA, but in four towns had an empty string for all properties and overall has over 1600 unique categories just in this subset of Towns.\nstate_use\nfor a single family in most towns is “101”, but there are many others coded as simply “100” or starting with “1” followed by other formats. If I had more time, I might be able to do a better job predicting\nstate_use\nwith\nstate_use_description\n, but leave that for another time. For this reason, all data summaries below had to be looked at as approximate and by no means the final word on density or mix of land use near stations.\nIn order to get train station coordinates, I found the USDOT Intermodal Passenger Connectivity Dataset (IPCD) with 15,000 transportation hubs around the US. This offers the option to conduct future analyses around other transport hubs, like bus routes. It took a few tries to get the MNR lines, for example, Cos Cob is mistakenly listed in NY state, and some locations came up more than once if there was both an Amtrak, MNR or bus stop at that location. I generally prefer data.table, but this doesn’t work for data manipulation with sf objects. I was able to get away with it here using only the X, Y coordinates, and then convert back to sf further downstream.\nLoad Train Station coordinates\nfile <- \n  paste0(folder, \n  \"NTAD_Intermodal_Passenger_Connectivity_Database/Intermodal_Passenger_Connectivity_Database_(IPCD).shp\"\n  )\ntrains <- st_read(\n  dsn = file, \n  query = \"select * from \\\"Intermodal_Passenger_Connectivity_Database_(IPCD)\\\" \n    where METRO_AREA LIKE 'Bridgeport-Stamford-Norwalk CT' AND MODE_RAIL = 1\")\n## Reading query `select * from \"Intermodal_Passenger_Connectivity_Database_(IPCD)\" \n##     where METRO_AREA LIKE 'Bridgeport-Stamford-Norwalk CT' AND MODE_RAIL = 1'\n## from data source `/Users/davidlucey/Documents/Data/ct_state_data/NTAD_Intermodal_Passenger_Connectivity_Database/Intermodal_Passenger_Connectivity_Database_(IPCD).shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 31 features and 52 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -73.62515 ymin: 41.02125 xmax: -73.13083 ymax: 41.3981\n## Geodetic CRS:  WGS 84\ndata.table::setDT(trains)\n\n# Filter unique stations by point_id and select columns\ntrains <- unique(trains, by=\"POINT_ID\")\ntrains <- \n  trains[, .(X, Y, POINT_ID, ADDRESS, METRO_AREA, FAC_NAME, CITY, STATE, ZIPCODE)]\nDT::datatable(trains)\nCode for Filtering and Aggregating Parcels within Ranges\nThis section has the code to load and find lots within progressively expanding radiuses for each station. My custom function,\nget_parcels_in_geo_range()\n, loads data from an IPCD point and filter CAMA points within a specified parameter distance. Again, I’m relatively new to GIS data, so it took me a long time to figure out how to create the station\n{sf}\ndata.frame in a long-lat point XY dimension and with a CRS which could properly filter the ff_parcels for distance with\nst::st_is_within_distance()\n. First I had to load as CRS 4326, then transform to 2234 for distance calculations in accordance with my ff_parcels sf formatting. This took a long time to figure out, and I still don’t completely understand how it is working.\nGet Parcels in GEO Range\nget_parcels_in_geo_range <- function(point_id, dist_range) {\n  \n  # Using trains, cama_data, and ff_parcels from the global env\n  \n  # Get train station\n  train_station <- trains[trains$POINT_ID == point_id]\n  train_station <- data.frame(lon=train_station$X, lat=train_station$Y)\n  \n  # Convert to sf\n  station <- \n    sf::st_as_sf(train_station, coords = c(\"lon\", \"lat\"), crs = 4326) %>% \n    st_transform(crs = 2234) \n  \n  # Find lots with components within dist_range\n  wd <- \n    st_is_within_distance(ff_parcels, station, dist = units::set_units(dist_range, \"mile\"))\n\n  # Drop any lots where none of the components are within dist_range\n  parcels <- ff_parcels %>% filter(lengths(wd) > 0)\n  \n  # Convert to data.table\n  data.table::setDT(parcels)\n  \n  # Clean names\n  parcels <- janitor::clean_names(parcels)\n  \n  # Keep lots >=0\n  parcels <- parcels[shape_area >= 0]\n  \n  # Copy cama_data to leave in place\n  cama_data <- copy(cama_data)\n  \n  # Clean up any extra spaces in Cama link\n  parcels[, cama_link := re2::re2_replace_all(cama_link, \" \", \"\")]\n  \n  # Join data on \"link\" = \"cama_link\"\n  parcels <- cama_data[parcels, on = c(\"link\" = \"cama_link\")]\n  \n  # Return\n  return(parcels)\n}\nIn\nprepare_town_data_frame()\n, I had to use trial and error to figure out towns where the standard codes were not picking up residential properties. There were varying codes for single family home, condominium or apartment building, so I did my best to capture them all as shown in the\nresi_codes\nvector below. Unfortunately, I had to leave the job of separating single- and multi-family properties for a later time. I went with number of dwellings, which doesn’t distinguish between single and multi-family, but does give an overall sense of density in those zones.\nPrepare Town data.frame\nprepare_town_data_frame <- function(towns) {\n  \n  # Remove towns outside FF county without parcels\n  towns <- towns[sapply(towns, nrow) > 20]\n  \n  # Convert list of towns to a single data.table\n  towns_df <- rbindlist(towns, fill = TRUE, use.names = TRUE, idcol = \"station_name\")\n  \n  # Add an indicator and filter keeping properties thought to be residential derived by trial and error\n  resi_codes <- \n    c(800, 801, 802, 803, 805, 899, 100, 101, 102, 103, 122, 104, 105, 108, 109, 172, 1010, 1040, 1110, 1012, 1015, 1050, 1111)\n  towns_df[, resi := state_use %in% as.character(resi_codes)]\n  towns_df[, resi := fifelse((resi == FALSE & state_use_description == \"Residential\"), TRUE, resi)]\n  towns_df[, resi := fifelse((resi == FALSE & state_use_description == \"Commericial\"), FALSE, resi)]\n  towns_df[is.na(resi), resi := FALSE]\n  \n  # Drop empty links\n  towns_df <- \n    towns_df[!link %in% c(\"48620-\", \"77200-\", \"57600-\", \"68170-\", \"86370-\", \"52980-\") ]\n\n  return(towns_df)\n}\nprepare_station_summary()\nsummarizes all towns based on properties which were not identified, total residential properties, mean acres of residential dwellings, total number of properties above 1/2 acre and 1 acre, and the total acres of residential land within the specified distance. I also calculated the percentage of residential land within the total area in the half mile radius, which for most stations was more than half.\nPrepare Station Summary\nprepare_station_summary <- function(towns_df) {\n  \n  # Find unmatched links\n  missing <- towns_df[is.na(pid), .(unmatched = .N), station_name]\n  \n  # Count total resi properties near specified station_name\n  total_resi <- towns_df[resi == TRUE, .(total_dwellings = .N), by = station_name]\n  \n  # Calc mean acres and counts of 1/2 and 1 acre parcels\n  ff_summary <- dplyr::distinct(towns_df[resi == TRUE], shape, .keep_all = TRUE)[\n    , .(\n      avg_acres_dwelling = round(mean(shape_area)/43560, 2), \n      `total_half_ac+` = sum(shape_area>0.5*43560), \n      `total_1_ac+` = sum(shape_area >43560))\n    ,  station_name]\n  \n  # Count total acres and resi acres near specified station_name and dist_range\n  resi_land <- dplyr::distinct(towns_df[resi==TRUE], shape, .keep_all = TRUE)[\n    , .(resi_ac = sum(shape_area)/43560), station_name]\n  total_land <- dplyr::distinct(towns_df, shape, .keep_all = TRUE)[\n    , .(total_ac = round(sum(shape_area)/43560, 1)), station_name]\n  \n  # Aggregate components into final table by station_name\n  ff_summary <- merge(ff_summary, total_land, by = \"station_name\")\n  ff_summary <- merge(ff_summary, resi_land, by = \"station_name\")\n  ff_summary <- merge(ff_summary, total_resi, by = \"station_name\")\n  ff_summary <- merge(ff_summary, missing, by = \"station_name\")\n  \n  # Round digits\n  ff_summary <- ff_summary[\n    , pct_resi := round(resi_ac/total_ac, 1)][\n      , resi_ac := NULL]\n  \n  # Return\n  return(ff_summary)\n}\nI wrote\nget_stations_summary()\nto iterate over all the train stations at a given\ndist_range\nin the select trains data.frame.\nGet Stations Summary\nResults and Analysis\nBelow is a summary table of stations within 1/2 mile of stations with several showing more or less than the 500 acres (expected in 1/2 mile radius). This is probably because some stations may be close to the water or include significant portions that are highway, so has a smaller area of land which may be developed for any purpose. Others may have a large property (ie: cemeteries, golf clubs, parks and schools) with an address within, but extending outside the radius. Bethel’s numbers look off, but it is missing most “state use” codes, so it is difficult to accurately account for what parcel usage. For a sense of the overall accuracy for a particular station, the “Unmatched Properties” column shows how many of the parcels were not classified by a “state use” code and were left out of the calculations. For example, I still have a lot of properties near Darien’s 33 West Ave station which are not classified. The proposed legislation has specified 15 to 30 units per acre minimum density as of right within these zones, so demonstrating how significant the change for adopting\nWLR\ncould be for residents of those neighborhoods. Overall, there are no stations with average residential lots greater than 1 acre at any of the 26 stations.\n(#fig:0.5_miles)Summary of Properties within 1/2 mile of stations\nLooking at density per acre for the portion of the zone including residential\nstate_use\ncodes, seven out of 26 stations have averages of more than 1 acre per dwelling in the first mile with more after 1.5 miles, much smaller numbers than the 80% average in the state, but still a lot. All of the lower density stations were much further from Grand Central. I don’t know the circumstances at those stations, but it does support the claim that some towns may have allowed sparse density at these valuable locations. Two stations have average lot size well above 1 acre in the first 0.5 miles, but then drop below 1 acre further out. Please hover over the lines to more better discern the station and the density at a given point, or select labels on the right to drill down on any location.\n(#fig:average_acres)Average acres per dwelling is low around many stations\nThe next chart shows the number of 1+ acre lots by mile from stations, showing there are few within 1/2 mile at stations closest to NYC in Greenwich, Stamford and Norwalk for example, but there are lower densities much further up the line. While there are approximately 1,000 1+ acre lots near the 26 MNR stations, there are 10x that at 1.5 miles, and 25x 3 miles further away. Once you get a few miles away from stations, there is a lot more land in some locations, so this is my point that the remedy seems to miss the opportunity to address the concern.\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nR on Redwall Analytics\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "MetroNorth New Haven Line Stations Introduction Connecticut has long had some of the highest income and home prices in the US. Although home prices have trailed national rate of appreciation in recent decades, from a high starting ...",
      "meta_keywords": null,
      "og_description": "MetroNorth New Haven Line Stations Introduction Connecticut has long had some of the highest income and home prices in the US. Although home prices have trailed national rate of appreciation in recent decades, from a high starting ...",
      "og_image": "https://www.redwallanalytics.com/2025/01/16/thoughts-on-work-live-ride-using-greenwich-ct-parcel-data/images/mnr.png",
      "og_title": "Amateur Urbanist Critique of Work-Live-Ride using 360k Fairfield County Parcels | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 15.8,
      "sitemap_lastmod": null,
      "twitter_description": "MetroNorth New Haven Line Stations Introduction Connecticut has long had some of the highest income and home prices in the US. Although home prices have trailed national rate of appreciation in recent decades, from a high starting ...",
      "twitter_title": "Amateur Urbanist Critique of Work-Live-Ride using 360k Fairfield County Parcels | R-bloggers",
      "url": "https://www.r-bloggers.com/2025/01/amateur-urbanist-critique-of-work-live-ride-using-360k-fairfield-county-parcels/",
      "word_count": 3163
    }
  }
}