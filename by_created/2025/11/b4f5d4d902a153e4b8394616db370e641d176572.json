{
  "id": "b4f5d4d902a153e4b8394616db370e641d176572",
  "url": "https://www.r-bloggers.com/2023/12/data-engineering-in-r-how-to-build-your-first-data-pipeline-with-r-mage-and-google-cloud-platform-in-under-45-minutes/",
  "created_at_utc": "2025-11-17T20:39:02Z",
  "data": null,
  "raw_original": {
    "uuid": "a9d12d85-4c9a-4916-bed0-a5a00d13aa39",
    "created_at": "2025-11-17 20:39:02",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2023/12/data-engineering-in-r-how-to-build-your-first-data-pipeline-with-r-mage-and-google-cloud-platform-in-under-45-minutes/",
      "crawled_at": "2025-11-17T09:42:35.942992",
      "external_links": [
        {
          "href": "https://www.business-science.io/code-tools/2023/12/02/how-to-use-r-in-production-mage-ai-google-cloud.html",
          "text": "business-science.io"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://learn.business-science.io/r-tips-newsletter",
          "text": "R-tips newsletter"
        },
        {
          "href": "https://www.linkedin.com/in/arben-kqiku-301457117/",
          "text": "Arben Kqiku"
        },
        {
          "href": "https://www.linkedin.com/in/arben-kqiku-301457117/",
          "text": "Arben"
        },
        {
          "href": "https://www.simoahava.com/analytics/join-ga4-google-ads-data-in-google-bigquery/",
          "text": "Simo Ahavaâ€™s website"
        },
        {
          "href": "https://learn.business-science.io/registration-chatgpt-2?el=website",
          "text": "Inside the workshop"
        },
        {
          "href": "https://learn.business-science.io/registration-chatgpt-2?el=website",
          "text": "my free chatgpt for data scientists workshop"
        },
        {
          "href": "https://learn.business-science.io/registration-chatgpt-2?el=website",
          "text": "ðŸ‘‰ Register Here"
        },
        {
          "href": "https://learn.business-science.io/r-tips-newsletter?el=website",
          "text": "weekly tutorial"
        },
        {
          "href": "https://learn.business-science.io/r-tips-newsletter?el=website",
          "text": "Get the Code"
        },
        {
          "href": "https://learn.business-science.io/r-tips-newsletter?el=website",
          "text": "Register for R-Tips Newsletter Here"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "https://www.r-project.org/"
        },
        {
          "href": "https://cran.r-project.org/",
          "text": "https://cran.r-project.org/"
        },
        {
          "href": "https://www.linkedin.com/in/dangtommy/",
          "text": "Tommy Dang"
        },
        {
          "href": "https://mage.ai/",
          "text": "https://mage.ai/"
        },
        {
          "href": "https://learn.business-science.io/r-tips-newsletter?el=website",
          "text": "Register for R-Tips Newsletter Here"
        },
        {
          "href": "https://cloud.google.com/",
          "text": "https://cloud.google.com/"
        },
        {
          "href": "https://console.cloud.google.com/welcome",
          "text": "https://console.cloud.google.com/welcome"
        },
        {
          "href": "https://code.visualstudio.com/",
          "text": "https://code.visualstudio.com/"
        },
        {
          "href": "https://code.visualstudio.com/download",
          "text": "https://code.visualstudio.com/download"
        },
        {
          "href": "https://www.youtube.com/watch?v=C0fNc8ZOpSI&t=696s&ab_channel=DataSlinger",
          "text": "this tutorial"
        },
        {
          "href": "https://console.cloud.google.com/apis/credentials",
          "text": "Credentials"
        },
        {
          "href": "https://console.cloud.google.com/apis/credentials",
          "text": "Credentials"
        },
        {
          "href": "https://ga-dev-tools.google/ga4/dimensions-metrics-explorer/",
          "text": "this website"
        },
        {
          "href": "https://console.cloud.google.com/marketplace/product/google/googleads.googleapis.com",
          "text": "Google Ads API"
        },
        {
          "href": "https://console.cloud.google.com/apis/credentials/consent",
          "text": "OAuth consent screen"
        },
        {
          "href": "https://console.cloud.google.com/apis/credentials",
          "text": "Credentials"
        },
        {
          "href": "https://developers.google.com/google-ads/api/fields/v13/overview#list-of-all-resources",
          "text": "here"
        },
        {
          "href": "https://developers.google.com/google-ads/api/fields/v13/customer_query_builder",
          "text": "Google Ads query builder"
        },
        {
          "href": "https://console.cloud.google.com/bigquery/",
          "text": "BigQuery console"
        },
        {
          "href": "https://www.linkedin.com/in/arben-kqiku-301457117/",
          "text": "here is my LinkedIn"
        },
        {
          "href": "https://university.business-science.io/p/5-course-bundle-machine-learning-web-apps-time-series/",
          "text": "see my testimonials here"
        },
        {
          "href": "https://university.business-science.io/p/5-course-bundle-machine-learning-web-apps-time-series",
          "text": "Hereâ€™s the system"
        },
        {
          "href": "https://university.business-science.io/p/5-course-bundle-machine-learning-web-apps-time-series",
          "text": "Join My 5-Course R-Track Program Now!(And Become The Data Scientist You Were Meant To Be...)"
        },
        {
          "href": "https://university.business-science.io/p/5-course-bundle-machine-learning-web-apps-time-series",
          "text": "This could be you."
        },
        {
          "href": "https://www.business-science.io/code-tools/2023/12/02/how-to-use-r-in-production-mage-ai-google-cloud.html",
          "text": "business-science.io"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Data Engineering in R: How to Build Your First Data Pipeline with R, Mage, and Google Cloud Platform (in under 45 Minutes) | R-bloggers",
      "images": [
        {
          "alt": "Data Engineering Workflow",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Data Engineering Workflow",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_workflow.jpg?w=578&ssl=1"
        },
        {
          "alt": "8-Step Framework",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "8-Step Framework",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_8_step_framework.jpg?w=578&ssl=1"
        },
        {
          "alt": "ChatGPT for Data Scientists",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "ChatGPT for Data Scientists",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/lab_82_chatgpt_rcode.jpg?w=578&ssl=1"
        },
        {
          "alt": "How the Tools Integrate",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "How the Tools Integrate",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_tool_integration.jpg?w=578&ssl=1"
        },
        {
          "alt": "Rstudio",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Rstudio",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/069_r_logo_board.png?w=578&ssl=1"
        },
        {
          "alt": "Mage AI",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Mage AI",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_mage_ai.jpg?w=578&ssl=1"
        },
        {
          "alt": "Mage.ai",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Mage.ai",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_mage-ai-example.jpg?w=578&ssl=1"
        },
        {
          "alt": "Mage Schedule",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Mage Schedule",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_mage-schedule.jpg?w=578&ssl=1"
        },
        {
          "alt": "Google Cloud Platform",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Google Cloud Platform",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_google_cloud_platform.jpg?w=578&ssl=1"
        },
        {
          "alt": "$300 Credits",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "$300 Credits",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_google-cloud-credits.jpg?w=578&ssl=1"
        },
        {
          "alt": "Billing",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Billing",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_billing.jpg?w=578&ssl=1"
        },
        {
          "alt": "VSCode",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "VSCode",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_vscode_ide.jpg?w=578&ssl=1"
        },
        {
          "alt": "8-Step Framework",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "8-Step Framework",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_8_step_framework.jpg?w=578&ssl=1"
        },
        {
          "alt": "Project Selector",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Project Selector",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_project-selector.jpg?w=578&ssl=1"
        },
        {
          "alt": "New Project",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "New Project",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_new-project.jpg?w=578&ssl=1"
        },
        {
          "alt": "Project Name",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Project Name",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_new-cloud-project.jpg?w=578&ssl=1"
        },
        {
          "alt": "VM Instances",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "VM Instances",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_vm-instances.jpg?w=578&ssl=1"
        },
        {
          "alt": "Compute Engine",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Compute Engine",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_gcp_mage_compute-engine-api.jpg?w=578&ssl=1"
        },
        {
          "alt": "VM Instance",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "VM Instance",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_create-vm-instance.jpg?w=578&ssl=1"
        },
        {
          "alt": "SSH Keys",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "SSH Keys",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_create-ssh-key.jpg?w=578&ssl=1"
        },
        {
          "alt": "Public SSH Key",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Public SSH Key",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_public-key.jpg?w=578&ssl=1"
        },
        {
          "alt": "Create Instance",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Create Instance",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_create-new-vm-instance.jpg?w=578&ssl=1"
        },
        {
          "alt": "VM Instance Name",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "VM Instance Name",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_name-and-region-of-vm-instance.jpg?w=578&ssl=1"
        },
        {
          "alt": "Boot Disk",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Boot Disk",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_change-boot-disk.jpg?w=578&ssl=1"
        },
        {
          "alt": "Boot Disk Options",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Boot Disk Options",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_gcp_mage_advanced-boot-disk-options.jpg?w=578&ssl=1"
        },
        {
          "alt": "Firewall Options",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Firewall Options",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_gcp_mage_firewall-options.jpg?w=578&ssl=1"
        },
        {
          "alt": "Add SSH Key",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Add SSH Key",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_gcp_mage_add-public-key-to-vm.jpg?w=578&ssl=1"
        },
        {
          "alt": "Paste SSH Key",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Paste SSH Key",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_gcp_mage_paste-ssh-key.jpg?w=578&ssl=1"
        },
        {
          "alt": "External IP",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "External IP",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_gcp_mage_vm-external-ip.jpg?w=578&ssl=1"
        },
        {
          "alt": "SSH Connection",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "SSH Connection",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_ubuntu-vm-remote.jpg?w=578&ssl=1"
        },
        {
          "alt": "Remote SSH",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Remote SSH",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_remote-ssh-code-extension.jpg?w=578&ssl=1"
        },
        {
          "alt": "Remote SSH Config",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Remote SSH Config",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_open-ssh-config.jpg?w=578&ssl=1"
        },
        {
          "alt": "SSH Agent",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "SSH Agent",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_ssh-add-command.jpg?w=578&ssl=1"
        },
        {
          "alt": "Remote SSH Connect",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Remote SSH Connect",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_code-connect-to-ssh-host.jpg?w=578&ssl=1"
        },
        {
          "alt": "Choose Host",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Choose Host",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_gcp_mage_choose-ssh-host.jpg?w=578&ssl=1"
        },
        {
          "alt": "Password",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Password",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_ssh-passphrase.jpg?w=578&ssl=1"
        },
        {
          "alt": "Remote Explorer",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Remote Explorer",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_remote-explorer-vm.jpg?w=578&ssl=1"
        },
        {
          "alt": "Terminal Below",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Terminal Below",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_display-terminal-icon.jpg?w=578&ssl=1"
        },
        {
          "alt": "Terminal",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Terminal",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_access-terminal-success.jpg?w=578&ssl=1"
        },
        {
          "alt": "Docker Hello World",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Docker Hello World",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_hello-docker.jpg?w=578&ssl=1"
        },
        {
          "alt": "Create Firewall Rule",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Create Firewall Rule",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_create-firewall-rule.jpg?w=578&ssl=1"
        },
        {
          "alt": "Firewall Rule Options",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Firewall Rule Options",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_firewall-options.jpg?w=578&ssl=1"
        },
        {
          "alt": "Mage IP Test",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Mage IP Test",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_mage-test.jpg?w=578&ssl=1"
        },
        {
          "alt": "New Pipeline",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "New Pipeline",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_new-batch-pipeline.jpg?w=578&ssl=1"
        },
        {
          "alt": "Mage Files",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Mage Files",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_files-in-pipeline.jpg?w=578&ssl=1"
        },
        {
          "alt": "Mage Blocks",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Mage Blocks",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_mage-blocks.jpg?w=578&ssl=1"
        },
        {
          "alt": "Data Loader",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Data Loader",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_use-r.jpg?w=578&ssl=1"
        },
        {
          "alt": "Data Loader R",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Data Loader R",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_sample-r-code.jpg?w=578&ssl=1"
        },
        {
          "alt": "GA Auth",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "GA Auth",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_select-google-account.jpg?w=578&ssl=1"
        },
        {
          "alt": "GA Auth Error",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "GA Auth Error",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_ga-auth-error.jpg?w=578&ssl=1"
        },
        {
          "alt": "Enable APIs",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Enable APIs",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_enable-apis-services.jpg?w=578&ssl=1"
        },
        {
          "alt": "Enable GA API",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Enable GA API",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_enable-ga-api.jpg?w=578&ssl=1"
        },
        {
          "alt": "Service Account",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Service Account",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_create-service-account.jpg?w=578&ssl=1"
        },
        {
          "alt": "Service Account Name",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Service Account Name",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_create-and-continue-service-account.jpg?w=578&ssl=1"
        },
        {
          "alt": "Set Editor Role",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Set Editor Role",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_set-editor-role.jpg?w=578&ssl=1"
        },
        {
          "alt": "Service Account Credentials",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Service Account Credentials",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_click-service-account-edit.jpg?w=578&ssl=1"
        },
        {
          "alt": "Create New Key",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Create New Key",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_create-new-key.jpg?w=578&ssl=1"
        },
        {
          "alt": "Service Account Email",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Service Account Email",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_copy-service-account-email.jpg?w=578&ssl=1"
        },
        {
          "alt": "Property Access Management",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Property Access Management",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_property-access-management.jpg?w=578&ssl=1"
        },
        {
          "alt": "GA Auth Success",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "GA Auth Success",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_ga-auth-test-worked.jpg?w=578&ssl=1"
        },
        {
          "alt": "GA4 Data",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "GA4 Data",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_ga-table-results.jpg?w=578&ssl=1"
        },
        {
          "alt": "GA4 API Fields",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "GA4 API Fields",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_ga-explorer-dims.jpg?w=578&ssl=1"
        },
        {
          "alt": "GA4 Goals and Sessions",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "GA4 Goals and Sessions",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_sessions-by-goals.jpg?w=578&ssl=1"
        },
        {
          "alt": "Open VSCode",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Open VSCode",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_visual-studio-code-open.jpg?w=578&ssl=1"
        },
        {
          "alt": "Copy JSON Path",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Copy JSON Path",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_vs-code-json-path.jpg?w=578&ssl=1"
        },
        {
          "alt": "Connect to VM",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Connect to VM",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_connect-to-vm.jpg?w=578&ssl=1"
        },
        {
          "alt": "Open Mage Folder",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Open Mage Folder",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_open-file-folder.jpg?w=578&ssl=1"
        },
        {
          "alt": "Paste JSON",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Paste JSON",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_service-account-in-vm.jpg?w=578&ssl=1"
        },
        {
          "alt": "List Files",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "List Files",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_service-account-key-available.jpg?w=578&ssl=1"
        },
        {
          "alt": "Preview Data",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Preview Data",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_image-preview.jpg?w=578&ssl=1"
        },
        {
          "alt": "Data Loader Success",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Data Loader Success",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_data-loader-worked.jpg?w=578&ssl=1"
        },
        {
          "alt": "Configure Consent Screen",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Configure Consent Screen",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_configure-consent-screen.jpg?w=578&ssl=1"
        },
        {
          "alt": "App Name",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "App Name",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_name-and-email-consent.jpg?w=578&ssl=1"
        },
        {
          "alt": "Google Ads API",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Google Ads API",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_add-google-ads-scope.jpg?w=578&ssl=1"
        },
        {
          "alt": "Test Users",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Test Users",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_add-test-user.jpg?w=578&ssl=1"
        },
        {
          "alt": "OAuth Client ID",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "OAuth Client ID",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_oauth-client-id.jpg?w=578&ssl=1"
        },
        {
          "alt": "OAuth Client ID Name",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "OAuth Client ID Name",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_create-oauth-id.jpg?w=578&ssl=1"
        },
        {
          "alt": "Download JSON",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Download JSON",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_download-oauth-json.jpg?w=578&ssl=1"
        },
        {
          "alt": "Select Email",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Select Email",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_authorize-app.jpg?w=578&ssl=1"
        },
        {
          "alt": "Authorize App",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Authorize App",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_authorize-google-ads-access.jpg?w=578&ssl=1"
        },
        {
          "alt": "Token Info",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Token Info",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_review-token.jpg?w=578&ssl=1"
        },
        {
          "alt": "Accessible Accounts",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Accessible Accounts",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_ads-accounts-listed.jpg?w=578&ssl=1"
        },
        {
          "alt": "Data Loader",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Data Loader",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_new-data-loader-with-r.jpg?w=578&ssl=1"
        },
        {
          "alt": "Google Ads Query Builder",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Google Ads Query Builder",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_build-customer-query.jpg?w=578&ssl=1"
        },
        {
          "alt": "Google Ads Query Builder",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Google Ads Query Builder",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_select-attributes-segments-metrics.jpg?w=578&ssl=1"
        },
        {
          "alt": "Google Ads Data",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Google Ads Data",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_ads-data-table.jpg?w=578&ssl=1"
        },
        {
          "alt": "Join Data",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Join Data",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_join-ga4-transformer.jpg?w=578&ssl=1"
        },
        {
          "alt": "Add Variables",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Add Variables",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_transform-data-loader-functions.jpg?w=578&ssl=1"
        },
        {
          "alt": "Merged Data",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Merged Data",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_joined-data-after-transformation.jpg?w=578&ssl=1"
        },
        {
          "alt": "Create Dataset",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Create Dataset",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_create-bq-dataset.jpg?w=578&ssl=1"
        },
        {
          "alt": "Dataset Name",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Dataset Name",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_configure-bq-dataset.jpg?w=578&ssl=1"
        },
        {
          "alt": "Data Tree",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Data Tree",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_mage-data-tree.jpg?w=578&ssl=1"
        },
        {
          "alt": "Data Set ID",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Data Set ID",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_dataset-info.jpg?w=578&ssl=1"
        },
        {
          "alt": "BigQuery Table",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "BigQuery Table",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_bigquery-preview.jpg?w=578&ssl=1"
        },
        {
          "alt": "Pipeline Complete",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Pipeline Complete",
          "base64": null,
          "src": "https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_mage-pipeline-complete.jpg?w=578&ssl=1"
        },
        {
          "alt": "Triggers",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Triggers",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_mage-triggers.jpg?w=578&ssl=1"
        },
        {
          "alt": "Trigger Running",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Trigger Running",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_trigger-running.jpg?w=578&ssl=1"
        },
        {
          "alt": "BigQuery Table",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "BigQuery Table",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_date-time-bigquery-updated.jpg?w=578&ssl=1"
        },
        {
          "alt": "Schedule Trigger",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Schedule Trigger",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_mage-new-schedule-trigger.jpg?w=578&ssl=1"
        },
        {
          "alt": "Cron Expression",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Cron Expression",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_every-five-minutes.jpg?w=578&ssl=1"
        },
        {
          "alt": "Save Changes",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Save Changes",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_save-schedule-trigger.jpg?w=578&ssl=1"
        },
        {
          "alt": "Start Trigger",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Start Trigger",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_start-schedule-trigger.jpg?w=578&ssl=1"
        },
        {
          "alt": "Next Trigger",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Next Trigger",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_trigger-next-run-date.jpg?w=578&ssl=1"
        },
        {
          "alt": "BigQuery Table",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "BigQuery Table",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_bigquery-schedule-updated.jpg?w=578&ssl=1"
        },
        {
          "alt": "What They're Doing - 5 Course R-Track",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "What They're Doing - 5 Course R-Track",
          "base64": null,
          "src": "https://i2.wp.com/www.business-science.io/assets/rtrack_what_theyre_doing_2.jpg?w=578&ssl=1"
        },
        {
          "alt": "Success Samantha Got The Job",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Success Samantha Got The Job",
          "base64": null,
          "src": "https://i0.wp.com/www.business-science.io/img/success_samantha_got_job.jpg?w=578&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/business-science/",
          "text": "Business Science"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/cdn-cgi/l/email-protection",
          "text": "[emailÂ protected]"
        },
        {
          "href": "https://www.r-bloggers.com/cdn-cgi/l/email-protection",
          "text": "[emailÂ protected]"
        },
        {
          "href": "https://www.r-bloggers.com/cdn-cgi/l/email-protection",
          "text": "[emailÂ protected]"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-380454 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Data Engineering in R: How to Build Your First Data Pipeline with R, Mage, and Google Cloud Platform (in under 45 Minutes)</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">December 2, 2023</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/business-science/\">Business Science</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://www.business-science.io/code-tools/2023/12/02/how-to-use-r-in-production-mage-ai-google-cloud.html\"> business-science.io</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 3.8.9--><p>Hey guys, welcome back to my <a href=\"https://learn.business-science.io/r-tips-newsletter\" rel=\"nofollow\" target=\"_blank\">R-tips newsletter</a>. In todayâ€™s R-Tip, <a href=\"https://www.linkedin.com/in/arben-kqiku-301457117/\" rel=\"nofollow\" target=\"_blank\">Arben Kqiku</a> is sharing his <strong>exact 8-step framework</strong> for taking R into production for Digital Analytics projects. Youâ€™ll learn how to use R, Mage.ai, and Google Cloud Platform (GCP) to build your first data engineering pipeline <strong>in under 45 minutes.</strong></p>\n<h3 id=\"about-the-author\">About the Author</h3>\n<p><a href=\"https://www.linkedin.com/in/arben-kqiku-301457117/\" rel=\"nofollow\" target=\"_blank\">Arben</a> is a digital analytics and Google Cloud Platform (GCP) expert. Heâ€™s also a Business Science University student. In this post, Arben shares how to use R in production, with Mage.ai and Google Cloud.</p>\n<p>This article was originally published on <a href=\"https://www.simoahava.com/analytics/join-ga4-google-ads-data-in-google-bigquery/\" rel=\"nofollow\" target=\"_blank\">Simo Ahavaâ€™s website</a>, which is focused on aspiring Digital Analytics Professionals. Weâ€™ve republished it here with permission to help spread the word of R in production with new tools including Mage.ai and Google Cloud Platform.</p>\n<p>Letâ€™s dive in!</p>\n<h3 id=\"table-of-contents\">Table of Contents</h3>\n<p>Hereâ€™s what youâ€™re learning today:</p>\n<ul>\n<li>\n<p><strong><em>The Problem:</em></strong> Weâ€™ll cover a case study from a recent problem Arben had in Multi-Touch Campaign Attribution.</p>\n</li>\n<li>\n<p><strong><em>The Solution: Arbenâ€™s 8-Step Framework:</em></strong> Arbenâ€™s sharing his exact process for how he sets up production R data engineering pipelines on GCP with R and Mage.ai (perfect if itâ€™s your first time).</p>\n</li>\n<li>\n<p><strong><em>Full Code Demo:</em> EXACTLY HOW TO BUILD YOUR FIRST DATA SCIENCE PIPELINE (IN UNDER 45 minutes).</strong></p>\n</li>\n</ul>\n<h3 id=\"what-you-make-today\">What You Make Today:</h3>\n<p>Below you can see an architectural overview of what weâ€™ll build today.</p>\n<p><img alt=\"Data Engineering Workflow\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_workflow.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Data Engineering Workflow\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_workflow.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p class=\"date text-center\">What You Make Today!</p>\n<h3 id=\"the-8-step-framework-to-accomplish-this\">The 8-Step Framework to Accomplish This:</h3>\n<p>Hereâ€™s the 8-step framework that Arben will walk you through today:</p>\n<p><img alt=\"8-Step Framework\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_8_step_framework.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"8-Step Framework\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_8_step_framework.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p class=\"date text-center\">The 8 steps you follow</p>\n<h3 id=\"the-8-things-youll-learn-in-this-tutorial\">The 8 Things Youâ€™ll learn in this tutorial:</h3>\n<ol>\n<li>\n<p><strong>How to create a Google Cloud project.</strong></p>\n</li>\n<li>\n<p>How to set up a virtual machine.</p>\n</li>\n<li>\n<p><strong>How to access your virtual machine remotely.</strong></p>\n</li>\n<li>\n<p>How to install Mage.ai on the virtual machine to handle the automation.</p>\n</li>\n<li>\n<p><strong>How to retrieve data from the GA4 API in a production environment.</strong></p>\n</li>\n<li>\n<p>How to retrieve data from the Google Ads API in a production environment.</p>\n</li>\n<li>\n<p><strong>How to export data to Google BigQuery in a production environment.</strong></p>\n</li>\n<li>\n<p>How to schedule a data pipeline that automatically updates every 5 minutes.</p>\n</li>\n</ol>\n<hr>\n<!--\n# SPECIAL ANNOUNCEMENT: How To Become A <u>6-Figure Business Scientist</u> (Even In A Recession) on August 30th\n\n![Business Scientist](/assets/business-science-cube-2.jpg)\n\n**What:** How To Become A 6-Figure Business Scientist (Even In A Recession)\n\n**When:** Wednesday August 30th, 2pm EST\n\n**How It Will Help You:** Data science in 2023 has changed. *The 10+ person data science team is out.* And the one-person Business Scientist is in. I'll show you how to become a 1-person data science team inside [my LIVE 6-figure business scientist masterclass](https://learn.business-science.io/registration-2-page?el=website). \n\n**Price:** Does **Free** sound good?\n\n**How To Join:** [**ðŸ‘‰ Register Here**](https://learn.business-science.io/registration-2-page?el=website)\n-->\n<h1 id=\"special-announcement-chatgpt-for-data-scientists-workshop-on-december-13th\">SPECIAL ANNOUNCEMENT: ChatGPT for Data Scientists Workshop on December 13th</h1>\n<p><a href=\"https://learn.business-science.io/registration-chatgpt-2?el=website\" rel=\"nofollow\" target=\"_blank\">Inside the workshop</a> Iâ€™ll share how I built a Machine Learning Powered Production Shiny App with <code>ChatGPT</code> (extends this data analysis to an <em>insane</em> production app):</p>\n<p><img alt=\"ChatGPT for Data Scientists\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/lab_82_chatgpt_rcode.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"ChatGPT for Data Scientists\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/lab_82_chatgpt_rcode.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p><strong>What:</strong> ChatGPT for Data Scientists</p>\n<p><strong>When:</strong> Wednesday December 13th, 2pm EST</p>\n<p><strong>How It Will Help You:</strong> Whether you are new to data science or are an expert, ChatGPT is changing the game. Thereâ€™s a ton of hype. But how can ChatGPT actually help you become a better data scientist and help you stand out in your career? Iâ€™ll show you inside <a href=\"https://learn.business-science.io/registration-chatgpt-2?el=website\" rel=\"nofollow\" target=\"_blank\">my free chatgpt for data scientists workshop</a>.</p>\n<p><strong>Price:</strong> Does <strong>Free</strong> sound good?</p>\n<p><strong>How To Join:</strong> <a href=\"https://learn.business-science.io/registration-chatgpt-2?el=website\" rel=\"nofollow\" target=\"_blank\"><strong>ðŸ‘‰ Register Here</strong></a></p>\n<hr/>\n<h1 id=\"r-tips-weekly\">R-Tips Weekly</h1>\n<p>This article is part of R-Tips Weekly, a <a href=\"https://learn.business-science.io/r-tips-newsletter?el=website\" rel=\"nofollow\" target=\"_blank\">weekly tutorial</a> that shows you step-by-step how to do common R coding tasks. Pretty cool, right?</p>\n<p>Here are the links to get set up. ðŸ‘‡</p>\n<ul>\n<li><a href=\"https://learn.business-science.io/r-tips-newsletter?el=website\" rel=\"nofollow\" target=\"_blank\">Get the Code</a></li>\n<!-- <li><a href=\"https://youtu.be/fkwKQi7skAw\" rel=\"nofollow\" target=\"_blank\">YouTube Tutorial</a></li>-->\n</ul>\n<h1 id=\"the-problem-multi-touch-campaign-attribution-in-digital-analytics\">The Problem: Multi-Touch Campaign Attribution in Digital Analytics</h1>\n<p>As a digital analyst, I often need to combine data from different sources and display it in a dashboard. This is especially true when Iâ€™m working with Google Analytics 4 (GA4) and Google Ads for Campaign Attribution.</p>\n<h2 id=\"case-study-digital-analytics-and-multi-touch-campaign-attribution\">Case Study: Digital Analytics and Multi-Touch Campaign Attribution</h2>\n<p>For instance, clients run campaigns on platforms like Google Ads and Meta Ads, and <strong>they want to understand the impact of each channel or even individual campaigns.</strong></p>\n<p>To address this, we usually:</p>\n<ol>\n<li>Use <strong>conversion data</strong> from a third-party source, like Google Analytics, and</li>\n<li>Combine it with other data such as impressions, clicks, and cost from the advertising channels.</li>\n</ol>\n<p>This helps us <strong>calculate the cost per conversion</strong> for each channel more accurately.</p>\n<h2 id=\"building-the-multi-touch-attribution-data-engineering-pipeline\">Building the Multi-Touch Attribution Data Engineering Pipeline</h2>\n<p>To build a data engineering pipeline, we need to factor in:</p>\n<ol>\n<li>\n<p><strong>Accessibility:</strong> Make sure we can easily get data from different sources, such as Google Ads, Meta Ads, and GA4.</p>\n</li>\n<li>\n<p><strong>Data integration:</strong> Combine data from different sources accurately.</p>\n</li>\n<li>\n<p><strong>Storage:</strong> Create a data warehouse in Google BigQuery for the joined data and make it accessible to data visualization tools.</p>\n</li>\n<li>\n<p><strong>Maintenance:</strong> Find a way to automate these steps without needing manual intervention. That way stakeholders will have access to almost real-time data.</p>\n</li>\n</ol>\n<h2 id=\"our-tech-stack-r-mageai-google-cloud-platform-and-vscode-ide\">Our Tech Stack: R, Mage.ai, Google Cloud Platform, and VSCode IDE</h2>\n<p><img alt=\"How the Tools Integrate\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_tool_integration.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"How the Tools Integrate\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_tool_integration.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p class=\"text-center date\"><a href=\"https://learn.business-science.io/r-tips-newsletter?el=website\" rel=\"nofollow\" target=\"_blank\">Register for R-Tips Newsletter Here</a></p>\n<p>To build this pipeline, weâ€™ll use:</p>\n<ol>\n<li>R: To retrieve data from the APIs and combine it.</li>\n<li>Mage.ai: To automate the Extract Transform Load (ETL) process.</li>\n<li>Google Cloud Platform (GCP): To store the data and make it accessible to data visualization tools.</li>\n<li>VSCode IDE: To access the virtual machine remotely.</li>\n</ol>\n<h3 id=\"1-r-to-retrieve-data-from-the-apis-and-combine-it\">1. R: To retrieve data from the APIs and combine it</h3>\n<p><img alt=\"Rstudio\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/069_r_logo_board.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Rstudio\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/069_r_logo_board.png?w=578&amp;ssl=1\"/></noscript></p>\n<p>If you are new to R:</p>\n<ul>\n<li>Install R here: <a href=\"https://www.r-project.org/\" rel=\"nofollow\" target=\"_blank\">https://www.r-project.org/</a></li>\n<li>Access to 20,000+ of open source R packages here: <a href=\"https://cran.r-project.org/\" rel=\"nofollow\" target=\"_blank\">https://cran.r-project.org/</a></li>\n</ul>\n<p>Packages weâ€™ll use today:</p>\n<ul>\n<li><code>tidyverse</code>: To work with data and make the data pipeline.</li>\n<li><code>googleAnalyticsR</code>: To retrieve data from the GA4 API.</li>\n<li><code>rgoogleads</code>: To retrieve data from the Google Ads API.</li>\n<li><code>bigrquery</code>: To export data to Google BigQuery.</li>\n<li><code>gargle</code>: For Google authentication.</li>\n</ul>\n<h3 id=\"2-mageai-to-automate-the-extract-transform-load-etl-process\">2. Mage.ai: To automate the Extract Transform Load (ETL) process</h3>\n<p>I love R and I am so thankful that <a href=\"https://www.linkedin.com/in/dangtommy/\" rel=\"nofollow\" target=\"_blank\">Tommy Dang</a> and his team included it in Mage.</p>\n<p><img alt=\"Mage AI\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_mage_ai.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Mage AI\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_mage_ai.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p class=\"text-center date\">Mage AI</p>\n<p>If you are new to Mage:</p>\n<ul>\n<li>Mage.ai is a tool that helps you automate the ETL process. Itâ€™s a great tool for data scientists who want to automate their data engineering pipelines.</li>\n<li>Mage.ai: <a href=\"https://mage.ai/\" rel=\"nofollow\" target=\"_blank\">https://mage.ai/</a></li>\n</ul>\n<p>The screenshot below comes from Mage. Mage is a data engineering tool that allows you to build your ETL (extract, transform, and load) pipelines. What I love about Mage is that it is easy to use, you can visualize your data pipelines and it supports multiple programming languages: SQL, Python.. and R!</p>\n<p><img alt=\"Mage.ai\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_mage-ai-example.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Mage.ai\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_mage-ai-example.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>In addition to building our pipeline, weâ€™ll use Mage to <strong>schedule your pipelines</strong>, as you can see in the example below.</p>\n<p><img alt=\"Mage Schedule\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_mage-schedule.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Mage Schedule\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_mage-schedule.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p class=\"text-center date\"><a href=\"https://learn.business-science.io/r-tips-newsletter?el=website\" rel=\"nofollow\" target=\"_blank\">Register for R-Tips Newsletter Here</a></p>\n<h3 id=\"3-google-cloud-platform-gcp-to-store-the-data-and-make-it-accessible-to-data-visualization-tools\">3. Google Cloud Platform (GCP): To store the data and make it accessible to data visualization tools.</h3>\n<p>You can run Mage on your local machine or in the cloud.</p>\n<p>Obviously, if you run it locally, your computer needs to be on all the time, which is not ideal. Therefore, weâ€™ll create a virtual machine (VM) on the Google Cloud Platform and run Mage from there.</p>\n<p>A virtual machine (VM) on GCP is like a computer in the cloud. Itâ€™s not a physical machine you can touch; instead, itâ€™s a powerful, remote computer that you can use to run your software and store your data.</p>\n<p><img alt=\"Google Cloud Platform\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_google_cloud_platform.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Google Cloud Platform\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_google_cloud_platform.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p class=\"text-center date\">Google Cloud Platform (GCP)</p>\n<p>If you are new to Google Cloud Platform (GCP):</p>\n<ul>\n<li>Google Cloud Platform (GCP) is a cloud computing platform that allows you to store data and make it accessible to data visualization tools.</li>\n<li>Youâ€™ll need to create a Google Cloud account to use GCP.</li>\n<li>Google Cloud Platform: <a href=\"https://cloud.google.com/\" rel=\"nofollow\" target=\"_blank\">https://cloud.google.com/</a></li>\n</ul>\n<p>To use GCP, you need a payment method. But worry not, as of today, If you have never used GCP, <strong>you get a credit of $300</strong>. So, go to the Google Cloud Console and create an account: <a href=\"https://console.cloud.google.com/welcome\" rel=\"nofollow\" target=\"_blank\">https://console.cloud.google.com/welcome</a>.</p>\n<p><img alt=\"$300 Credits\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_google-cloud-credits.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"$300 Credits\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_google-cloud-credits.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Once you have used your free credits, you need to add a credit card to your account, by going under â€œBILLINGâ€:</p>\n<p><img alt=\"Billing\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_billing.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Billing\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_billing.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<h3 id=\"4-vscode-ide-to-access-the-virtual-machine-remotely\">4. VSCode IDE: To access the virtual machine remotely</h3>\n<p>To access the virtual machine from our computer, weâ€™ll use Visual Studio Code, which is a lovely, free code editor that supports many programming languages.</p>\n<p><img alt=\"VSCode\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_vscode_ide.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"VSCode\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_vscode_ide.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p class=\"text-center date\">VSCode IDE</p>\n<p>If you are new to VSCode IDE:</p>\n<ul>\n<li>VSCode IDE is a free code editor that supports many programming languages including R, Python, C++ and has extensions for tools like Remote SSH (covered in this tutorial).</li>\n<li>Install the VSCode IDE here: <a href=\"https://code.visualstudio.com/\" rel=\"nofollow\" target=\"_blank\">https://code.visualstudio.com/</a></li>\n</ul>\n<h1 id=\"the-solution-arbens-8-step-framework-for-data-engineering-in-r-with-mage-and-gcp-in-under-45-minutes\">The Solution: Arbenâ€™s 8-Step Framework for Data Engineering in R with Mage and GCP (in under 45 minutes)</h1>\n<p><img alt=\"8-Step Framework\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_8_step_framework.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"8-Step Framework\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_8_step_framework.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p class=\"date text-center\">The 8 steps you follow</p>\n<p>Now for my <strong>8-step framework</strong> for building a data engineering pipeline in R with Mage.ai and GCP.</p>\n<ul>\n<li>These are the steps I follow when Iâ€™m building a data engineering pipeline for a client.</li>\n<li>Once you are familiar with my framework, you can build your own data engineering pipelines <strong>in under 45 minutes.</strong></li>\n</ul>\n<p><strong>Heads up, this is a comprehensive tutorial.</strong> This is because I wanted to build the training I wish I had when I solved this problem for the first time. I hope you enjoy it!</p>\n<h2 id=\"step-1-how-to-create-a-google-cloud-project\">Step 1: How to create a Google Cloud project</h2>\n<p>In order to use GCP, we need a project. Later, everything that weâ€™ll do will be within this project.</p>\n<p>So, go back to https://console.cloud.google.com/welcome and create a new project by first clicking on the project selector in the top left.</p>\n<p><img alt=\"Project Selector\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_project-selector.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Project Selector\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_project-selector.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Then click on â€œNEW PROJECTâ€:</p>\n<p><img alt=\"New Project\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_new-project.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"New Project\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_new-project.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Next, name your project. I called my project <code>mage-ai-test</code>.</p>\n<p><img alt=\"Project Name\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_new-cloud-project.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Project Name\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_new-cloud-project.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Finally, click on â€œCREATEâ€. Then simply wait until your project is created. Once you have selected your project, type â€œvm instancesâ€ in the search bar, and select â€œVM instancesâ€.</p>\n<p><img alt=\"VM Instances\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_vm-instances.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"VM Instances\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_vm-instances.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>This will lead to the following screen:</p>\n<p><img alt=\"Compute Engine\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_gcp_mage_compute-engine-api.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Compute Engine\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_gcp_mage_compute-engine-api.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<h2 id=\"step-2-how-to-set-up-a-virtual-machine\">Step 2: How to set up a virtual machine</h2>\n<p>There are 4 sub-steps:</p>\n<ol>\n<li>Activate the Compute Engine APIâ€™s features</li>\n<li>Set up SSH keys</li>\n<li>Create a virtual machine</li>\n<li>Connect to the virtual machine via SSH</li>\n</ol>\n<h3 id=\"step-21-activate-the-compute-engine-apis-features\">Step 2.1: Activate the Compute Engine APIâ€™s features</h3>\n<p>On GCP, to use specific features, you must activate the corresponding APIs:</p>\n<ul>\n<li>For example, weâ€™ll enable the Google Analytics API later to get data from GA4.</li>\n<li>To make a virtual machine, we need to enable the Compute Engine API.</li>\n<li>Afterward, youâ€™ll see this screen, but we wonâ€™t create a VM instance just yetâ€¦</li>\n</ul>\n<p><img alt=\"VM Instance\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_create-vm-instance.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"VM Instance\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_create-vm-instance.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<h3 id=\"step-22-set-up-ssh-keys\">Step 2.2: Set up SSH keys</h3>\n<p>Next, we need to create SSH keys that will allow us to access our virtual machine from our computer.</p>\n<p>SSH keys are like special keys that help your computer talk securely to another computer, such as a virtual machine.</p>\n<p>Itâ€™s a way for your computer to prove itâ€™s really you when connecting to the virtual machine. Itâ€™s like having a secret handshake between your computer and the virtual machine, making sure they can trust each other without needing to type in a password every time.</p>\n<h4 id=\"create-ssh-and-public-keys\">Create SSH and Public Keys</h4>\n<p>We need to create two SSH keys, a private and a public key. Think of SSH keys like a pair of magic keys for your online accounts. You have one key that you keep secret (the private key) and another key that you share with others (the public key).</p>\n<ol>\n<li><strong>Private Key (Secret Key):</strong> This is like the key to your front door that only you have. You keep it safe on your computer, and itâ€™s a secret. Itâ€™s used to unlock and access your accounts securely.</li>\n<li><strong>Public Key (Shared Key):</strong> This is like a lock that matches your private key.</li>\n</ol>\n<p>When you connect to a server or service, you use your private key to prove you are who you say you are. The server then checks this with your public key to make sure itâ€™s really you. This way, even if someone gets your public key, they canâ€™t do anything without the private key, which stays safe on your computer. Itâ€™s a bit like having a special lock and key where only your key can open it.</p>\n<p>To create your keys, hop to the terminal in your local machine and type the following code:</p>\n<pre>ssh-keygen -t rsa -f ~/.ssh/mage-ai-test -C arbenkqiku\n</pre>\n<p>The end of the code should be your username, in my case <code>arbenkqiku</code>. If you donâ€™t know your user name, type <code>whoami</code> in the terminal and press enter. This will output your username.</p>\n<p>Once you enter the code mentioned above, youâ€™ll be prompted to insert your computerâ€™s password, if you have any. Once you add your password, your SSH keys will be created.</p>\n<p><img alt=\"SSH Keys\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_create-ssh-key.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"SSH Keys\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_create-ssh-key.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Now, go to the directory where your SSH keys can be found. <code>cd</code> stands for â€œchange directoryâ€:</p>\n<pre>cd ~/.ssh\n</pre>\n<p>This is where your public private and public SSH keys are located.</p>\n<p>Now, type the following code to display the content of your public SSH key in the terminal.</p>\n<pre>cat mage-ai-test.pub\n</pre>\n<p>This will show the content of your public SSH key that we will later paste into our VM.</p>\n<p><img alt=\"Public SSH Key\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_public-key.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Public SSH Key\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_public-key.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<h3 id=\"step-23-create-a-virtual-machine\">Step 2.3: Create a virtual machine</h3>\n<p>Now, letâ€™s go back to Google Cloud Platform and click on â€œCREATE INSTANCEâ€ in the VM instances overview.</p>\n<p><img alt=\"Create Instance\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_create-new-vm-instance.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Create Instance\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_create-new-vm-instance.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Give a name to the VM instance and select the region closest to you:</p>\n<p><img alt=\"VM Instance Name\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_name-and-region-of-vm-instance.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"VM Instance Name\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_name-and-region-of-vm-instance.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Go to the â€œBoot diskâ€ section and click on â€œCHANGEâ€:</p>\n<p><img alt=\"Boot Disk\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_change-boot-disk.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Boot Disk\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_change-boot-disk.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Select the following options:</p>\n<p><img alt=\"Boot Disk Options\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_gcp_mage_advanced-boot-disk-options.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Boot Disk Options\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_gcp_mage_advanced-boot-disk-options.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Under Firewall, select the following options:</p>\n<p><img alt=\"Firewall Options\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_gcp_mage_firewall-options.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Firewall Options\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_gcp_mage_firewall-options.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>This is important, as otherwise we wonâ€™t be able to access Mage by using the IP address of our VM, youâ€™ll understand later what I mean by this.</p>\n<p>Under Advanced Options &gt; Security, click on â€œADD ITEMâ€. Here is where weâ€™ll add our <strong>public SSH key</strong>.</p>\n<p><img alt=\"Add SSH Key\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_gcp_mage_add-public-key-to-vm.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Add SSH Key\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_gcp_mage_add-public-key-to-vm.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Copy the entire SSH public key and paste it.</p>\n<p><img alt=\"Paste SSH Key\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_gcp_mage_paste-ssh-key.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Paste SSH Key\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_gcp_mage_paste-ssh-key.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Finally, click on â€œCREATEâ€. It may take some time to create the VM.</p>\n<p>Once done, your new VM will appear here. Also, youâ€™ll see that your VM will have an â€œExternal IPâ€.</p>\n<p><img alt=\"External IP\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_gcp_mage_vm-external-ip.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"External IP\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_gcp_mage_vm-external-ip.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>You can use this â€œExternal IPâ€ and your SSH private key to connect to this VM. Letâ€™s do this!</p>\n<h2 id=\"step-3-how-to-access-your-virtual-machine-remotely\">Step 3: How to access your virtual machine remotely</h2>\n<p>Step 3 has 2 sub-steps:</p>\n<ol>\n<li>How to connect to your VM via SSH</li>\n<li>How to connect via VSCode IDE (using Remote â€“ SSH extension)</li>\n</ol>\n<h3 id=\"step-31-how-to-connect-to-your-vm-via-ssh\">Step 3.1: How to connect to your VM via SSH</h3>\n<p>Go back to the terminal in your local machine and go to the directory where the SSH keys are located:</p>\n<pre>cd ~/.ssh\n</pre>\n<p>Next, type this command:</p>\n<pre>ssh -i mage-ai-test <a class=\"__cf_email__\" data-cfemail=\"3756455552595c465e5c427704031901021905040619060f07\" href=\"/cdn-cgi/l/email-protection\">[emailÂ protected]</a>\n</pre>\n<p>Iâ€™ll break it down to you so you know what to replace:</p>\n<pre>ssh -i name_of_private_key user_name@gcp_vm_instance_external_ip\n</pre>\n<p>Youâ€™ll likely will be prompted to enter your password again, and also to add the â€œExternal IPâ€ as a host. Just follow the instructions and you should be able to connect to your VM.</p>\n<p>As you can see from the image below, we connected to the VM named <code>mage-demo-test</code>. And if you recall, in â€œBoot diskâ€ options, we selected Ubuntu as our operating system.</p>\n<p><img alt=\"SSH Connection\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_ubuntu-vm-remote.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"SSH Connection\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_ubuntu-vm-remote.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<h3 id=\"step-32-how-to-connect-via-vscode-ide-using-remote---ssh-extension\">Step 3.2: How to connect via VSCode IDE (using Remote â€“ SSH extension)</h3>\n<p>We could do this whole process through the terminal, but it is much more user-friendly to do it through Visual Studio Code.</p>\n<p>Visual Studio Code is a very powerful code editor. Go to this link: <a href=\"https://code.visualstudio.com/download\" rel=\"nofollow\" target=\"_blank\">https://code.visualstudio.com/download</a>, and download Visual Studio Code.</p>\n<p>Once you have installed it, go to â€œExtensionsâ€ and install â€œRemote â€“ SSHâ€.</p>\n<p><img alt=\"Remote SSH\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_remote-ssh-code-extension.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Remote SSH\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_remote-ssh-code-extension.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>In Visual Studio Code, go the the search bar and type &gt;, and then select the following option:</p>\n<p><img alt=\"Remote SSH Config\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_open-ssh-config.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Remote SSH Config\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_open-ssh-config.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>In the configuration file that will open, you need to enter your details. Essentially, weâ€™re providing the details to connect to our VM.</p>\n<pre>Host mage-demo-test # Give a name to your host\n  HostName 34.65.231.180 # Replace with the External IP address in GCP\n  User arbenkqiku # Replace this with your user name\n  IdentityFile /Users/arbenkqiku/.ssh/mage-ai-test # Path to private SSH key\n</pre>\n<p>Now, we still have to go back to the terminal one last time and type this:</p>\n<pre>eval $(ssh-agent)\nssh-add /Users/arbenkqiku/.ssh/mage-ai-test # Path to private SSH key\n</pre>\n<p>Then, type your password when prompted. This basically means that you can use your password when you try to access the VM through Visual Studio Code.</p>\n<p><img alt=\"SSH Agent\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_ssh-add-command.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"SSH Agent\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_ssh-add-command.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Now, go back to the search bar of Visual Studio Code, type &gt; and select the following option:</p>\n<p><img alt=\"Remote SSH Connect\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_code-connect-to-ssh-host.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Remote SSH Connect\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_code-connect-to-ssh-host.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>It should suggest the host that you just created, click on that host:</p>\n<p><img alt=\"Choose Host\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_gcp_mage_choose-ssh-host.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Choose Host\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_gcp_mage_choose-ssh-host.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Then, youâ€™ll be prompted to enter your password. Once you enter your password, youâ€™ll be connected to your VM.</p>\n<p><img alt=\"Password\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_ssh-passphrase.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Password\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_ssh-passphrase.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Now, click on the â€œRemote Explorerâ€ icon, and it should show that you connected to your VM:</p>\n<p><img alt=\"Remote Explorer\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_remote-explorer-vm.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Remote Explorer\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_remote-explorer-vm.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>On the top right, click this icon to display the terminal below:</p>\n<p><img alt=\"Terminal Below\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_display-terminal-icon.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Terminal Below\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_display-terminal-icon.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Now click on â€œTERMINALâ€. Congratulations, you have accessed your VM through Visual Studio Code!</p>\n<p><img alt=\"Terminal\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_access-terminal-success.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Terminal\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_access-terminal-success.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<h2 id=\"step-4-how-to-install-mageai-on-the-virtual-machine-to-handle-the-automation\">Step 4: How to install Mage.ai on the virtual machine to handle the automation</h2>\n<p>To install mage on GCP, I largely followed <a href=\"https://www.youtube.com/watch?v=C0fNc8ZOpSI&amp;t=696s&amp;ab_channel=DataSlinger\" rel=\"nofollow\" target=\"_blank\">this tutorial</a>, but I will also explain every step here.</p>\n<p>Ther are mainly 3 sub-steps:</p>\n<ol>\n<li>Create the folder for Mage</li>\n<li>Install <code>Docker</code></li>\n<li>Install <code>Mage</code></li>\n<li>Access <code>Mage</code> through the External IP from GCP</li>\n</ol>\n<h3 id=\"step-41-create-the-folder-for-mage\">Step 4.1: Create the folder for Mage</h3>\n<p>First of all, letâ€™s create a directory in our VM for mage:</p>\n<pre>mkdir mage-demo\n</pre>\n<p>Now, if you type the following code, you should be able to see the newly created folder:</p>\n<pre>ls\n</pre>\n<p>Then, letâ€™s access the folder:</p>\n<pre>cd mage-demo\n</pre>\n<h3 id=\"step-42-install-docker\">Step 4.2: Install <code>Docker</code></h3>\n<p>Now, to install mage, we need to first install <code>Docker</code>.</p>\n<p>Docker is a platform for developing, shipping, and running applications. It uses containerization technology to package an application and its dependencies together into a single unit called a â€œcontainerâ€.</p>\n<p>In the <code>mage-demo</code> folder, letâ€™s download a GitHub repo that contains the installation for Docker:</p>\n<pre>git clone https://github.com/MichaelShoemaker/DockerComposeInstall.git\n</pre>\n<p>Letâ€™s access the folder that contains the Docker installation:</p>\n<pre>cd DockerComposeInstall\n</pre>\n<p>Letâ€™s modify the file to make it executable:</p>\n<pre>chmod +x InstallDocker\n</pre>\n<p>Then, letâ€™s run it:</p>\n<pre>./InstallDocker\n</pre>\n<p>Type this to verify that Docker has been installed correctly:</p>\n<pre>docker run hello-world\n</pre>\n<p>This should show the following message:</p>\n<p><img alt=\"Docker Hello World\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_hello-docker.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Docker Hello World\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_hello-docker.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<h3 id=\"step-43-install-mage\">Step 4.3: Install <code>Mage</code></h3>\n<p>Now, letâ€™s go back to the initial directory:</p>\n<pre>cd mage-demo\n</pre>\n<p>Now, we can finally install mage with this command:</p>\n<pre>docker run -it -p 6789:6789 -v $(pwd):/home/src --restart always mageai/mageai /app/run_app.sh mage start mage-ai-test\n</pre>\n<p>With the command <code>--restart always</code>, weâ€™re asking the VM to always restart mage whenever the VM is shut down and later restarted.</p>\n<p>At the end, <code>mage-ai-test</code> represents the name of our project.</p>\n<h3 id=\"step-44-access-mage-through-the-external-ip-from-gcp\">Step 4.4: Access <code>Mage</code> through the External IP from GCP</h3>\n<p>Now, to access mage through our External IP from GCP, we need to hop back on GCP first, as we need to create a <strong>firewall rule</strong>.</p>\n<p>This is necessary to control and regulate incoming and outgoing traffic to and from your VM on Google Cloud Platform. When you want to access mage through your External IP from GCP, a firewall rule is needed to explicitly allow the traffic to reach your VM.</p>\n<p>Browse to Firewall in the Google Cloud Platform.</p>\n<p>Click on â€œCREATE FIREWALL RULEâ€:</p>\n<p><img alt=\"Create Firewall Rule\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_create-firewall-rule.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Create Firewall Rule\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_create-firewall-rule.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Select the following options and click on â€œCREATEâ€:</p>\n<p><img alt=\"Firewall Rule Options\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_firewall-options.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Firewall Rule Options\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_firewall-options.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Basically, with this firewall rule in place, it means we can access mage via the external IP address by using port number 6789.</p>\n<p>Now, if you type <strong>your VM external IP</strong> followed by <code>:6789</code> in your web browser you should be able to access mage.</p>\n<p>For example, this is the URL I would use with my configuration: <code>http://34.65.231.180:6789</code>.</p>\n<p><img alt=\"Mage IP Test\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_mage-test.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Mage IP Test\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_mage-test.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>As you can see, <code>mage-ai-test</code> was the name of our project in a previous command.</p>\n<p>Congrats, now you can create data pipelines that will run in the cloud!</p>\n<h2 id=\"step-5-how-to-retrieve-data-from-the-ga4-api-in-a-production-environment\">Step 5: How to retrieve data from the GA4 API in a production environment</h2>\n<p><strong>Now, we can finally create the pipeline.</strong> Weâ€™ll first focus on retrieving data from the Google Analytics 4 (GA4) API. We will accomplish this inside of <code>Mage</code>.</p>\n<p>We have the following sub-steps:</p>\n<ol>\n<li>Create a new pipeline</li>\n<li>Select a Mage block tyoe (Data Loader)</li>\n<li>Use R packages and code to retrieve data from the GA4 API</li>\n<li>GA4 API: How to get an access token</li>\n<li>How to run GA Authentication in a production environment</li>\n<li>Create a Google Analytics token</li>\n<li>Test <code>R</code> Code on Your Local Machine</li>\n<li>Create the full <code>R</code> Script</li>\n<li>Make JSON service account key accessible to Mage</li>\n<li>Add the <code>R</code> Script to Mage</li>\n</ol>\n<h3 id=\"step-51-create-a-new-pipeline\">Step 5.1: Create a new pipeline</h3>\n<p>To start, click on <strong>New pipeline &gt; Standard (batch)</strong>:</p>\n<p><img alt=\"New Pipeline\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_new-batch-pipeline.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"New Pipeline\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_new-batch-pipeline.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>On the left side, you can see all your files inside of <code>Mage</code>`, even the pipeline that we have just created.</p>\n<p><img alt=\"Mage Files\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_files-in-pipeline.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Mage Files\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_files-in-pipeline.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>In the middle, you can see the blocks that you can use to build your pipelines. In this guide, weâ€™ll use <strong>Data loader</strong>, <strong>Transformer</strong>, and <strong>Data exporter</strong> blocks:</p>\n<p><img alt=\"Mage Blocks\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_mage-blocks.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Mage Blocks\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_mage-blocks.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<h3 id=\"step-52-select-a-mage-block-type-data-loader\">Step 5.2: Select a Mage block type (Data Loader)</h3>\n<p><strong>The Data loader block:</strong> As mentioned previously, you can use Python, SQL, and R in each block. In our case, weâ€™ll use <code>R</code>. So, click on Data Loader and select R:</p>\n<p><img alt=\"Data Loader\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_use-r.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Data Loader\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_use-r.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Name the block <code>ga4</code>, then click Save and add block. You should now see the block on the right, together with a sample R code.</p>\n<p><img alt=\"Data Loader R\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_sample-r-code.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Data Loader R\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_sample-r-code.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<h3 id=\"step-53-use-r-packages-and-code-to-retrieve-data-from-the-ga4-api\">Step 5.3: Use R packages and code to retrieve data from the GA4 API</h3>\n<p>To install and load packages, mage uses the pacman package. Once you load <code>pacman</code>, you can install packages by using:</p>\n<pre>pacman::p_load(package1, package2, package3)\n</pre>\n<p>â€‹The first time you run the <code>p_load()</code> function, it will install a package, and then it will simply load it. For this block, weâ€™ll install three packages:</p>\n<pre>library(\"pacman\")\npacman::p_load(dplyr, purrr, googleAnalyticsR)\n\nload_data &lt;- function() {\n\n}\n</pre>\n<h3 id=\"step-54-how-to-get-an-access-token\">Step 5.4: How to get an access token</h3>\n<p>In order to access GA4 data by using the <code>googleAnalyticsR</code> package, developed by Mark Edmondson, you need an access token.</p>\n<p>An access token is like your digital ID card; it confirms your identity and verifies that you truly have permission to access the GA4 properties youâ€™re attempting to retrieve data from.</p>\n<p>To get an access token, you can run the following function in the RStudio console in your local machine: <code>ga_auth()</code>.</p>\n<p>Once you run this function, youâ€™ll be redirected to a browser window where youâ€™ll select your account:</p>\n<p><img alt=\"GA Auth\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_select-google-account.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"GA Auth\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_select-google-account.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>With this, you are basically giving permission to the googleAnalyticsR package to access your GA4 properties.</p>\n<p><strong>However, the problem is that weâ€™ll run our data pipeline in a production environment where you cannot interact with the browser.</strong></p>\n<p>So, we need to find another way to solve this problem.</p>\n<p>In fact, if I try to run the function <code>ga_auth()</code> on Mage, <strong>it throws an error</strong>:</p>\n<p><img alt=\"GA Auth Error\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_ga-auth-error.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"GA Auth Error\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_ga-auth-error.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>So, we need to generate a Google Analytics token that we can use in a production environment.</p>\n<h3 id=\"step-55-how-to-run-ga-authentication-in-a-production-environment-without-a-browser\">Step 5.5: How to run GA Authentication in a production environment (without a browser)</h3>\n<h4 id=\"enable-google-analytics-reporting-api\">Enable Google Analytics Reporting API</h4>\n<p>First, letâ€™s go back to GCP and browse to Enabled APIs &amp; services.</p>\n<p>Click on â€œENABLE APIS AND SERVICESâ€.</p>\n<p><img alt=\"Enable APIs\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_enable-apis-services.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Enable APIs\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_enable-apis-services.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Search for <code>Google Analytics</code>, click the <strong>Google Analytics Reporting API</strong> result, and then choose <strong>ENABLE</strong>.</p>\n<p><img alt=\"Enable GA API\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_enable-ga-api.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Enable GA API\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_enable-ga-api.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>This means that our project is now eligible to use the Google Analytics Reporting API.</p>\n<h4 id=\"repeat-steps-to-enable-google-analytics-data-api\">Repeat steps to Enable Google Analytics Data API</h4>\n<p>Next, repeat these API-enabling steps for the <strong>Google Analytics Data API.</strong></p>\n<p>Once done, we have the APIs enabled but we still havenâ€™t created the required token.</p>\n<h3 id=\"step-56-how-to-create-a-google-analytics-token\">Step 5.6: How to create a Google Analytics token</h3>\n<p>Browse to <a href=\"https://console.cloud.google.com/apis/credentials\" rel=\"nofollow\" target=\"_blank\">Credentials</a> in the Google Cloud console.</p>\n<p>Hover over â€œCREATE CREDENTIALSâ€ and click on Service account.</p>\n<p><img alt=\"Service Account\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_create-service-account.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Service Account\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_create-service-account.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Give the service account a name and then click CREATE AND CONTINUE.</p>\n<p><img alt=\"Service Account Name\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_create-and-continue-service-account.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Service Account Name\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_create-and-continue-service-account.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Give the service account the Editor role and then click on Continue.</p>\n<p><img alt=\"Set Editor Role\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_set-editor-role.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Set Editor Role\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_set-editor-role.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Finally, click on <strong>DONE</strong>.</p>\n<p>Now that the service account has been created, go back to the Credentials view and youâ€™ll see the account that you just created. Click on it.</p>\n<p><img alt=\"Service Account Credentials\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_click-service-account-edit.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Service Account Credentials\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_click-service-account-edit.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Then, click the <strong>KEYS</strong> tab and choose to <strong>Create new key</strong>.</p>\n<p><img alt=\"Create New Key\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_create-new-key.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Create New Key\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_create-new-key.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Select <strong>JSON</strong> as the key type and click <strong>Create</strong>.</p>\n<p>This should download your key as a JSON file.</p>\n<p><strong>Important: Store it in a safe place.</strong> Basically, the service account is like an account that has permission to act on your behalf. When you want your application or service to communicate with the GA4 API, it needs to prove its identity. Instead of using a userâ€™s personal Google account, which may not be appropriate for server-to-server communication, you can use a service account.</p>\n<p>Now, as if it were a real user, we need to go to the GA4 property and add our service account email. So, go back to <a href=\"https://console.cloud.google.com/apis/credentials\" rel=\"nofollow\" target=\"_blank\">Credentials</a> and copy your service accountâ€™s <strong>email address</strong>:</p>\n<p><img alt=\"Service Account Email\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_copy-service-account-email.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Service Account Email\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_copy-service-account-email.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Next, open Google Analytics 4, go to your property, and click on <strong>Property access management</strong> in Admin:</p>\n<p><img alt=\"Property Access Management\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_property-access-management.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Property Access Management\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_property-access-management.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Add your service account email address to the list of users, give it Viewer permissions, and click on Add to add the service account as a user to the GA4 property.</p>\n<h3 id=\"step-57-test-r-code-on-your-local-machine\">Step 5.7: Test R Code on Your Local Machine</h3>\n<p>Now, before adding code to Mage, I like to test it on my local machine to make sure that everything works properly.</p>\n<p>So, on your local machine, open a new R script and try the following code:</p>\n<pre># Packages ----\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(googleAnalyticsR)\n\n# Authenticate ----  \n\n# path to your JSON service account that we saved earlier\nga_auth(json_file = \"/Users/arbenkqiku/Desktop/mage-ai/mage-ai-test-405614-2e1e1c865c18.json\")  \n</pre>\n<p>â€‹If everything works correctly, you should see the following message:</p>\n<p><img alt=\"GA Auth Success\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_ga-auth-test-worked.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"GA Auth Success\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_ga-auth-test-worked.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>That means that your pipeline can now communicate with the GA4 Reporting API without any extra authentication flows.</p>\n<h3 id=\"step-58-create-the-r-script\">Step 5.8: Create the R Script</h3>\n<p>Now, what I want to retrieve from GA4 are the sessions where a lead generation conversion event happened.</p>\n<p>In the case of this client of mine, either someone submitted a form, clicked on the WhatsApp icon to talk to them privately, or clicked on the phone icon to call them.</p>\n<p>So, in the the next piece of code I want to create a filter with all the event names I am interested in, namely the event names equal to <code>form_submit_lead</code> or <code>whatsapp_click</code> or <code>phone_click</code>.</p>\n<pre># GA4 property ID\nproperty_id = \"1234567\"\n\n# Create filter\ngoals_filter = ga_data_filter(\"eventName\" == \"form_submit_lead\" | \"eventName\" == \"whatsapp_click\" | \"eventName\" == \"phone_click\")\n</pre>\n<p>In the next piece of code, we have the actual query to GA4:</p>\n<pre># Get conversions from GA4\ngoals_data = ga_data(propertyId = property_id,         \n                     date_range = c(\"2023-10-01\", \"2023-11-08\"),        \n                     dimensions = c(\"date\"),        \n                     metrics = c(\"sessions\"),        \n                     dim_filter = goals_filter) %&gt;%     \n\n# rename sessions to goals\nset_names(c(\"date\", \"goals\"))\n</pre>\n<p>Basically, weâ€™re getting the sessions from 1st October 2023 until 8th November 2023, segmented by date, and only when one of the events mentioned earlier occurred.</p>\n<p>This is what the final table looks like in my case:</p>\n<p><img alt=\"GA4 Data\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_ga-table-results.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"GA4 Data\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_ga-table-results.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>It is not always easy to know what certain fields are called in the GA4 API. You can go to <a href=\"https://ga-dev-tools.google/ga4/dimensions-metrics-explorer/\" rel=\"nofollow\" target=\"_blank\">this website</a> and look for a specific field. For example, if we look for â€œchannelâ€, you can see all the different fields that contain â€œchannelâ€ and what they are called in the GA4 API.</p>\n<p><img alt=\"GA4 API Fields\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_ga-explorer-dims.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"GA4 API Fields\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_ga-explorer-dims.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Now, in addition to retrieving the sessions where a conversion event occurred, I also want to retrieve the sessions segmented by day, so Iâ€™ll use this query:</p>\n<pre># Get sessions from GA4\nsessions_data = ga_data(\n    propertyId = property_id,                      \n    date_range = c(\"2023-10-01\", \"2023-11-08\"),        \n    dimensions = c(\"date\"),                     \n    metrics = c(\"sessions\")\n)\n</pre>\n<p>This returns a table of sessions segmented by date.</p>\n<p>Now, to join the sessions with the conversions:</p>\n<pre># Merge GA4 goals and sessions\nsessions_goals_ga4 = sessions_data %&gt;%   \n\t# join sessions with goals  \n    full_join(goals_data) %&gt;%   \n\t# replace all NAs with 0  \n    replace(is.na(.), 0)\n</pre>\n<p>This is the final result:</p>\n<p><img alt=\"GA4 Goals and Sessions\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_sessions-by-goals.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"GA4 Goals and Sessions\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_sessions-by-goals.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p><strong>Here is the complete code.</strong> At the end of the script, I added the <code>sessions_goals_ga4</code> dataframe. This is because in Mage, weâ€™re using this code within a Data Loader block. We need to return a dataframe for the next block, otherwise the next block doesnâ€™t have any data to play with.</p>\n<pre># Packages ----\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(googleAnalyticsR)\n\n# Authenticate ----  \n\t# path to your JSON service account that we save earlier\nga_auth(json_file = \"/Users/arbenkqiku/Desktop/mage-ai/mage-ai-test-405614-2e1e1c865c18.json\")  \n\n# GA4 property ID\nproperty_id = \"1234567\"\n\n# Create filter\ngoals_filter = ga_data_filter(\"eventName\" == \"form_submit_lead\" | \"eventName\" == \"whatsapp_click\" | \"eventName\" == \"phone_click\")\n\n# Get conversions from GA4\ngoals_data = ga_data(propertyId = property_id,         \n                     date_range = c(\"2023-10-01\", \"2023-11-08\"),        \n                     dimensions = c(\"date\"),        \n                     metrics = c(\"sessions\"),        \n                     dim_filter = goals_filter) %&gt;%     \n\n\t# rename sessions to goals\nset_names(c(\"date\", \"goals\"))\n\n# Get sessions from GA4\nsessions_data = ga_data(propertyId = property_id,                      \n                        date_range = c(\"2023-10-01\", \"2023-11-08\"),        \n                        dimensions = c(\"date\"),                     \n                        metrics = c(\"sessions\"))\n\n# Merge GA4 goals and sessions\nsessions_goals_ga4 = sessions_data %&gt;%   \n\t# join sessions with goals  \nfull_join(goals_data) %&gt;%   \n\t# replace all NAs with 0  \nreplace(is.na(.), 0)\n\n# Final data frame for next block in mage.ai\nsessions_goals_ga4\n</pre>\n<h3 id=\"step-59-make-json-service-account-key-accessible-to-mage\">Step 5.9: Make JSON service account key accessible to Mage</h3>\n<p>Now, before we copy this code to Mage, we need to make our JSON service account key accessible to Mage, as for now it is only available on our local machine.</p>\n<p>Remember, Mage is installed on our virtual machine. We need to paste the JSON service account key there.</p>\n<p>Open Visual Studio Code and click on â€œOpenâ€.</p>\n<p><img alt=\"Open VSCode\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_visual-studio-code-open.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Open VSCode\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_visual-studio-code-open.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Go to the path where your JSON service account key is located in your local machine. You should be able to see your service account key in the left panel.</p>\n<p><img alt=\"Copy JSON Path\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_vs-code-json-path.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Copy JSON Path\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_vs-code-json-path.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Right-click and copy it.</p>\n<p>Next, go to the search bar, type &gt; and connect to your virtual machine.</p>\n<p><img alt=\"Connect to VM\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_connect-to-vm.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Connect to VM\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_connect-to-vm.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Once you are in the VM, click on â€œOpenâ€¦â€ and access the folder where Mage is installed. Click on â€œOKâ€.</p>\n<p><img alt=\"Open Mage Folder\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_open-file-folder.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Open Mage Folder\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_open-file-folder.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>On the left side you should now see the files contained in that folder.</p>\n<p>Right-click in that area and choose <strong>Paste</strong> to paste your service account JSON file into the project.</p>\n<p>You should see your service account file now successfully added to the files in your VM.</p>\n<p><img alt=\"Paste JSON\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_service-account-in-vm.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Paste JSON\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_service-account-in-vm.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>In Mage, you can use the function <code>list.files()</code> to see that the service account key is available.</p>\n<p><img alt=\"List Files\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_service-account-key-available.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"List Files\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_service-account-key-available.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<h3 id=\"step-510-add-the-r-script-to-mage\">Step 5.10: Add the R Script to Mage</h3>\n<p>Now, take the code that we previously played with in RStudio and paste it into Mage. You need to make some adjustments, though.</p>\n<p>The main change is that the bulk of the code is now within the <code>load_data()</code> function. The only code thatâ€™s run outside that function are the library loads.</p>\n<p>Another thing that changes is the path to the service account key. This now needs to reference the path to the file in your VM. As it should be in the root of your project, you just need to add the filename.</p>\n<pre>library(\"pacman\")\npacman::p_load(dplyr, purrr, googleAnalyticsR)\n\nload_data &lt;- function() {\n    # Specify your data loading logic here\n    # Return value: loaded dataframe\n\n    # Retrieve data ----\n    # path to your JSON service account\n    ga_auth(json_file = \"mage-ai-test-405614-2e1e1c865c18.json\")\n\n    # GA4 property ID\n    property_id = \"1234567\"\n\n    # Create filter\n    goals_filter = ga_data_filter(\"eventName\" == \"form_submit_lead\" | \"eventName\" == \"whatsapp_click\" | \"eventName\" == \"phone_click\")\n\n    # Get conversions from GA4\n    goals_data = ga_data(propertyId = property_id, \n                         date_range = c(\"2023-10-01\", \"2023-11-08\"),\n                         dimensions = c(\"date\"),\n                         metrics = c(\"sessions\"),\n                         dim_filter = goals_filter,\n    ) %&gt;% \n    \n    set_names(c(\"date\", \"goals\"))\n\n    # Get sessions from GA4\n    sessions_data = ga_data(propertyId = property_id, \n                            date_range = c(\"2023-10-01\", \"2023-11-08\"),\n                            dimensions = c(\"date\"),\n                            metrics = c(\"sessions\"))\n\n    # Merge GA4 goals and sessions\n    sessions_goals_ga4 = sessions_data %&gt;% \n    # join sessions with goals\n    full_join(goals_data) %&gt;% \n    # replace all NAs with 0\n    replace(is.na(.), 0)\n\n    # Final data frame\n    sessions_goals_ga4\n}\n</pre>\n<p>If everything worked properly, Mage will provide a preview of the data retrieved:</p>\n<p><img alt=\"Preview Data\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_image-preview.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Preview Data\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_image-preview.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>As you can see, our Data loader block has a green tick next to it, which means that it was able to run successfully.</p>\n<p><img alt=\"Data Loader Success\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_data-loader-worked.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Data Loader Success\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_data-loader-worked.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Later, we can use this data that we retrieved from GA4 for whatever purpose we want. However, before playing around with it, letâ€™s download some data from Google Ads!</p>\n<h2 id=\"step-6-how-to-retrieve-data-from-the-google-ads-api-in-a-production-environment\">Step 6: How to retrieve data from the Google Ads API in a production environment</h2>\n<p>To retrieve data from the Google Ads API, weâ€™ll use the R package <code>rgoogleads</code>, developed by Alexey Seleznev. Unfortunately, with this package it is not possible to use a service account key.</p>\n<p>Instead, weâ€™ll have to generate an access token by using the <code>gargle</code> package. The goal of <code>gargle</code>, as explained on their website, is to â€œtake some of the agonizing pain out of working with Google APIsâ€.</p>\n<p>This step has 4 sub-steps:</p>\n<ol>\n<li>Get an access token</li>\n<li>Test the access token locally</li>\n<li>Retrieve Google Ads API data into our production environment</li>\n</ol>\n<h3 id=\"step-61-how-to-get-an-access-token\">Step 6.1: How to get an access token</h3>\n<p>First of all, you need to browse to the <a href=\"https://console.cloud.google.com/marketplace/product/google/googleads.googleapis.com\" rel=\"nofollow\" target=\"_blank\">Google Ads API</a> in Google Cloud Platform and click to Enable it.</p>\n<p>So, when we attempt to fetch our Google Ads data, Google asks for our permission to let this app access our ads data. If we say yes, Google gives us an access token. This token then lets our computer talk to the Google Ads API without having to interact each time.</p>\n<p>Before doing anything, GCP will ask you to set up a â€œconsent screenâ€. This screen is like a friendly message to users, letting them know that our app wants to look at their Google Ads data.</p>\n<p>Itâ€™s a way to make sure users are aware and agree to let our app access their information. To get started, browse to the <a href=\"https://console.cloud.google.com/apis/credentials/consent\" rel=\"nofollow\" target=\"_blank\">OAuth consent screen</a> section of your GCP project.</p>\n<p>Here, click on â€œCONFIGURE CONSENT SCREENâ€.</p>\n<p><img alt=\"Configure Consent Screen\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_configure-consent-screen.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Configure Consent Screen\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_configure-consent-screen.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Select <strong>External</strong> as the User Type and then click â€œCREATEâ€.</p>\n<p>Give your app a name and add your email address.</p>\n<p><img alt=\"App Name\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_name-and-email-consent.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"App Name\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_name-and-email-consent.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Add your email to the <strong>Developer email address</strong>, too, and then click â€œSAVE AND CONTINUEâ€.</p>\n<p>In the next screen, click on â€œADD OR REMOVE SCOPESâ€. Scopes govern what your app is allowed to do with the APIs.</p>\n<p>Search for google ads and select the <strong>Google Ads API</strong>. Click UPDATE when done.</p>\n<p><img alt=\"Google Ads API\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_add-google-ads-scope.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Google Ads API\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_add-google-ads-scope.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Then, click â€œSAVE AND CONTINUEâ€ to proceed to the â€œTest usersâ€ step.</p>\n<p>Here, click â€œADD USERSâ€. Add your email address and click â€œADDâ€.</p>\n<p><img alt=\"Test Users\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_add-test-user.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Test Users\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_add-test-user.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Make sure to include your email because our app is currently in the â€œTestingâ€ phase. During this phase, only the emails that are added can be used by the app. So, adding your email is crucial to get your Google Ads data.</p>\n<p>Click on â€œSAVE AND CONTINUEâ€ to proceed to the Summary step, and then â€œBACK TO DASHBOARDâ€ when done with configuring the consent screen.</p>\n<p>Now that the consent screen has been configured, you can browse to <a href=\"https://console.cloud.google.com/apis/credentials\" rel=\"nofollow\" target=\"_blank\">Credentials</a> again.</p>\n<p>Here, click on â€œCREATE CREDENTIALSâ€ and this time choose OAuth client ID.</p>\n<p><img alt=\"OAuth Client ID\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_oauth-client-id.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"OAuth Client ID\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_oauth-client-id.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Under <strong>Application type</strong>, select <strong>Desktop app</strong>, give a name to your OAuth client ID, and click on â€œCREATEâ€:</p>\n<p><img alt=\"OAuth Client ID Name\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_create-oauth-id.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"OAuth Client ID Name\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_create-oauth-id.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Download your client ID as a JSON file and click on OK.</p>\n<p><img alt=\"Download JSON\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_download-oauth-json.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Download JSON\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_download-oauth-json.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Save it in a secure location.</p>\n<h3 id=\"step-62-how-to-test-the-access-token-locally\">Step 6.2: How to test the access token locally</h3>\n<p>Now, letâ€™s go back to <code>RStudio</code> or <code>VSCode</code> on our local machine. Open a new script and load these packages:</p>\n<pre># Packages\nlibrary(gargle)\nlibrary(rgoogleads)\n</pre>\n<p>Then, weâ€™ll import the OAuth Client ID credentials that we just created by using the function <code>gargle_oauth_client_from_json()</code>. The name of your client can be whatever you prefer:</p>\n<pre># Create gargle client\nmy_client = gargle_oauth_client_from_json(\n    path = \"/Users/arbenkqiku/Desktop/mage-ai/mage-demo-client-id.json\",\n    name = \"Google Ads App\"\n)\n</pre>\n<p>Then, we can add the following scope and email to our token request:</p>\n<pre>scopes = \"https://www.googleapis.com/auth/adwords\"\nemail = \"<a class=\"__cf_email__\" data-cfemail=\"15746777707b3b7e647c7e60557278747c793b767a78\" href=\"/cdn-cgi/l/email-protection\">[emailÂ protected]</a>\"\n</pre>\n<p>â€‹Finally, we can go through the process of acquiring a token by running this function:</p>\n<pre># Create a token by using Gargle\nmy_token = gargle2.0_token(\n    email = email,  \n    package = \"rgoogleads\",  \n    scope = scopes,  \n    client = my_client\n)\n</pre>\n<p>This will open a browser window.</p>\n<p>Do you recognize the name of the App? Thatâ€™s the name of our application! Weâ€™re now going through the process of authorizing our app to access our Google Ads data. Now, select your email.</p>\n<p><img alt=\"Select Email\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_authorize-app.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Select Email\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_authorize-app.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Google will tell you that this app isnâ€™t verified, as its status is still â€œtestingâ€.</p>\n<p>However, it is our own app, so we can safely click on â€œContinueâ€.</p>\n<p>Authorize the app to â€œSee, edit, create and delete your Google Ads accounts and dataâ€¦â€ and click on â€œContinueâ€.</p>\n<p><img alt=\"Authorize App\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_authorize-google-ads-access.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Authorize App\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_authorize-google-ads-access.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>If everything worked correctly, you should see a message saying, â€œAuthentication complete. Please close this page and return to R.â€</p>\n<p>Now, if we review the content of the variable <code>my_token</code>, which contains our access token, we can review the information again, for example the email associated with the token, the scopes, and so forth.</p>\n<p><img alt=\"Token Info\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_review-token.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Token Info\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_review-token.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>We can now test if the token works properly by running the <code>gads_auth()</code> function. Nothing should really happen here, as with the token we can authenticate non-interactively.</p>\n<pre># Authenticate by using the previously created token\ngads_auth(token = my_token)\n</pre>\n<p>Letâ€™s run a simple function of the <code>rgoogleads</code> package to see if we can access our data:</p>\n<pre># get list of accessible accounts\ngads_get_accessible_customers()\n</pre>\n<p>Yes, I am able to retrieve the accounts that I have access to!</p>\n<p><img alt=\"Accessible Accounts\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_ads-accounts-listed.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Accessible Accounts\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_ads-accounts-listed.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>However, we are not ready for production yet. In fact, if we type this code:</p>\n<pre># where is the cache of the token located\nmy_token$cache_path\n</pre>\n<p>Weâ€™ll get the result that the token is cached in a local directory, such as <code>~/Library/Caches/gargle</code>.</p>\n<p>This means that when we try to load <code>my_token</code> in production, it will look for the local path instead of a path on the VM.</p>\n<p>So, we need to change the cache path to our Mage directory on the VM. This is how youâ€™d do it:</p>\n<pre># change path of cache to mage main directory\nmy_token$cache_path = \"/home/src\"\n\n# save token again with changed directory\nsaveRDS(my_token, file = \"google_ads_token_mage_demo.RDS\")\n</pre>\n<p>Here is the full code to generate, test, and save the token:</p>\n<pre># Packages\nlibrary(gargle)\nlibrary(rgoogleads)\n\n# Create gargle client\nmy_client = gargle_oauth_client_from_json(path = \"/Users/arbenkqiku/Desktop/mage-ai/mage-demo-client-id.json\",\n                                          name = \"Google Ads App\")\n\n# Define scope and email\nscopes = \"https://www.googleapis.com/auth/adwords\"\nemail = \"<a class=\"__cf_email__\" data-cfemail=\"fa9b88989f94d4918b93918fba9d979b9396d4999597\" href=\"/cdn-cgi/l/email-protection\">[emailÂ protected]</a>\"\n\n# Create a token by using Gargle\nmy_token = gargle2.0_token(email = email,  \n                           package = \"rgoogleads\",  \n                           scope = scopes,  \n                           client = my_client)\n\n# Authenticate by using the previously created token\ngads_auth(token = my_token)\n\n# Test token by getting the list of accessible accounts\ngads_get_accessible_customers()\n\n# Change path of cache to mage main directory, so you can use the token in production\nmy_token$cache_path = \"/home/src\"\n\n# Save token with changed directory\nsaveRDS(my_token, file = \"google_ads_token_mage_demo.RDS\")\n</pre>\n<h3 id=\"step-63-how-to-retrieve-data-from-the-google-ads-api-in-a-production-environment\">Step 6.3: How to retrieve data from the Google Ads API in a production environment</h3>\n<p>Now that we have generated the access token, you can copy-paste the JSON file from your local machine to the VM directory by using Visual Studio Code. Follow the exact steps you took to copy-paste the service account JSON file before.</p>\n<p>Next, we can go back to Mage, add a Data loader block, and select R as the programming language.</p>\n<p><img alt=\"Data Loader\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_new-data-loader-with-r.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Data Loader\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_new-data-loader-with-r.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Name the block <code>google_ads</code> and click on â€œSave and add blockâ€.</p>\n<p>In the block code, we need to first load the necessary packages.</p>\n<pre>library(\"pacman\")\np_load(rgoogleads)\np_load(dplyr)\np_load(purrr)\n\nload_data &lt;- function() {\n\n}\n</pre>\n<p>Then, we need to load our access token, authenticate with it, and set the Google Ads account ID we want to get the data from.</p>\n<pre># load Google Ads access token\nmy_token = readRDS(file = \"google_ads_token_mage_demo.RDS\")\n    \n# Authenticate with the token\ngads_auth(token = my_token)\n\n# Set the Google Ads account id you want to get data from\ngads_set_customer_id('123-123-1234')\n</pre>\n<p>Here is the query that weâ€™re using to retrieve our data. Weâ€™ll retrieve impressions, clicks, and cost segmented by date, from â€œ2023-10-19â€ until â€œ2023-11-01â€.</p>\n<pre># run query\ngoogle_ads_account_data = gads_get_report(\n  resource    = \"customer\",\n  fields      = c(\"segments.date\",\n                  \"metrics.impressions\",\n                  \"metrics.clicks\",\n                  \"metrics.cost_micros\"),\n  date_from   = \"2023-10-19\",\n  date_to     = \"2023-11-01\"\n)\n</pre>\n<p>The first argument you need to define is the resource you are getting the data from, in our case <code>customer</code>.</p>\n<p>You can find <a href=\"https://developers.google.com/google-ads/api/fields/v13/overview#list-of-all-resources\" rel=\"nofollow\" target=\"_blank\">here</a> the list of all available resources.</p>\n<p>For example, if you would like to retrieve data at the ad group level, you should define the resource as <code>ad_group</code>.</p>\n<p>To build our query, we can use the <a href=\"https://developers.google.com/google-ads/api/fields/v13/customer_query_builder\" rel=\"nofollow\" target=\"_blank\">Google Ads query builder</a>, which can be used for any resource, in our case <code>customer</code>.</p>\n<p><img alt=\"Google Ads Query Builder\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_build-customer-query.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Google Ads Query Builder\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_build-customer-query.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Below you can select attributes, segments, or metrics:</p>\n<p><img alt=\"Google Ads Query Builder\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_select-attributes-segments-metrics.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Google Ads Query Builder\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_select-attributes-segments-metrics.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>When you select fields, it will start populating the query in the user interface of the builder.</p>\n<p>This is very useful to know what the metrics and dimensions are called in the Google Ads API.</p>\n<p>Here is the final part of our Data loader block, which should always be a variable containing data, as we have to pass something to the next block.</p>\n<pre># return data\ngoogle_ads_account_data\n</pre>\n<p>Here is the complete code block weâ€™re working with:</p>\n<pre>library(\"pacman\")\np_load(rgoogleads)\np_load(dplyr)\np_load(purrr)\n\nload_data &lt;- function() {\n    # Specify your data loading logic here\n    # Return value: loaded dataframe\n    \n    # load Google Ads access token\n    my_token = readRDS(file = \"google_ads_token_mage_demo.RDS\")\n    \n    # Authenticate with the token\n    gads_auth(token = my_token)\n    \n    # Set the Google Ads account id you want to get data from\n    gads_set_customer_id('123-123-1234')\n\n    # run query\n    google_ads_account_data = gads_get_report(\n      resource    = \"customer\",\n      fields      = c(\"segments.date\",\n                      \"metrics.impressions\",\n                      \"metrics.clicks\",\n                      \"metrics.cost_micros\"),\n      date_from   = \"2023-10-19\",\n      date_to     = \"2023-11-01\"\n    )\n\n# return data for next block\ngoogle_ads_account_data\n}\n</pre>\n<p>If you run this code, you should be able to see clicks, cost, and impressions segmented by date.</p>\n<p><img alt=\"Google Ads Data\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_ads-data-table.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Google Ads Data\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_ads-data-table.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Weâ€™re now done with this Data Loader block. Next, letâ€™s move on to <strong>transformers</strong>.</p>\n<h2 id=\"step-7-how-to-join-and-export-data-to-google-bigquery-in-a-production-environment\">Step 7: How to join and export data to Google BigQuery in a production environment</h2>\n<p>This step has 2 sub-steps:</p>\n<ol>\n<li>Join the data from GA4 and Google Ads with a Transformer block</li>\n<li>Export the data to Google BigQuery with a Data Exporter block</li>\n</ol>\n<h3 id=\"step-71-join-the-data-from-ga4-and-google-ads-with-a-transformer-block\">Step 7.1: Join the data from GA4 and Google Ads with a Transformer block</h3>\n<p>In Mage, add a new <strong>Transformer</strong> block and select <strong>R</strong> as the programming language.</p>\n<p>Give the block a name like <code>join_ga4_google_ads</code> and click on â€œSave and add blockâ€.</p>\n<p>In the Tree, we can now see that the Transformer block named <code>join_ga4_google_ads</code> only receives data from the Data Loader block <code>google_ads</code>. We need to also link the Data Loader <code>ga4</code> with the Transformer.</p>\n<p>To do this, you simply need to drag and drop the arrow from the <code>ga4</code> block to the <code>join_ga4_google_ads</code> Transformer.</p>\n<p><img alt=\"Join Data\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_join-ga4-transformer.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Join Data\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_join-ga4-transformer.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>The first thing that weâ€™ll do in the Transformer block is to add the final variables from the previous Data loader blocks to the <code>transform()</code> function.</p>\n<p><img alt=\"Add Variables\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_transform-data-loader-functions.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Add Variables\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_transform-data-loader-functions.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Next, we can add the following packages on top of the <code>transform()</code> function:</p>\n<pre>library(\"pacman\")\np_load(tibble, dplyr, purrr, stringr, lubridate)\n</pre>\n<p>The first piece of code that weâ€™re adding is this:</p>\n<pre># Build a row with the exact time\ncheck_time = tibble(\n    Date = Sys.time(),\n    Impressions = 0,\n    Sessions = 0,\n    Clicks = 0,\n    Cost = 0,\n    Goals = 0\n)\n</pre>\n<p>I am creating this tibble called <code>check_time</code> only so that later in BigQuery we can verify whether our schedule from Mage is working correctly.</p>\n<p>Then, we can finally join the Google Ads data with the GA4 data, and also return the <code>merged_data</code> variable for the next block:</p>\n<pre># Merge Google Ads with GA4 Data\nmerged_data = google_ads_account_data %&gt;%\n  \n  left_join(sessions_goals_ga4, by = c(\"date\" = \"date\")) %&gt;%\n  \n  # reorder and capitalise columns\n  select(date, impressions, sessions, clicks, cost, goals) %&gt;% \n  set_names(names(.) %&gt;% str_to_title()) %&gt;%\n  \n  # add check_time variable to verify schedule\n  mutate(Date = Date %&gt;% as_datetime()) %&gt;%\n  bind_rows(check_time) %&gt;%\n\n  # replace NAs with 0\n  replace(is.na(.), 0) %&gt;%\n  \n  arrange(desc(Date))\n\n# Return merged_data variable for next block\nmerged_data\n</pre>\n<p>If everything worked properly, you should get something similar to this:</p>\n<p><img alt=\"Merged Data\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_joined-data-after-transformation.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Merged Data\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_joined-data-after-transformation.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>I am aware that weâ€™re joining Google Ads data with GA4 data from all sources, and we should actually only join GA4 data coming from Google Ads. However, the goal of this guide is simply to show how to perform data engineering tasks with digital data.</p>\n<h3 id=\"step-72-export-the-data-to-google-bigquery-with-a-data-exporter-block\">Step 7.2: Export the data to Google BigQuery with a Data Exporter block</h3>\n<p>Now that we joined data successfully from Google Ads and GA4, weâ€™re ready to export the data to BigQuery.</p>\n<p>Browse to the <a href=\"https://console.cloud.google.com/bigquery/\" rel=\"nofollow\" target=\"_blank\">BigQuery console</a> in your Google Cloud Platform project.</p>\n<p>BigQuery has the following data hierarchy: <strong>project -&gt; dataset -&gt; table.</strong></p>\n<p>We already have a project, so now we need to create a dataset where our tables will reside. Click on the three dots on the right of your project, and then on â€œCreate data setâ€:</p>\n<p><img alt=\"Create Dataset\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_create-bq-dataset.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Create Dataset\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_create-bq-dataset.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Give a name to your data set, select a region, and click on â€œCREATE DATA SETâ€:</p>\n<p><img alt=\"Dataset Name\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_configure-bq-dataset.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Dataset Name\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_configure-bq-dataset.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Back in Mage, add a <strong>Data Explorer</strong> block and choose <strong>R</strong> as the programming language again.</p>\n<p>Name the block <code>biq_query_export</code> and click on â€œSave and add blockâ€.</p>\n<p>This is what your data tree should look like.</p>\n<p><img alt=\"Data Tree\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_mage-data-tree.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Data Tree\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_mage-data-tree.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Go the the <code>big_query_export</code> block, and add <code>merged_data</code> as the argument of the function <code>export_data()</code>. Also, letâ€™s load the <code>bigrquery</code> package.</p>\n<pre>library(\"pacman\")\np_load(bigrquery)\n\nexport_data &lt;- function(merged_data) {\n    # Specify your data exporting logic here\n    # Return value: exported dataframe\n    \n}\n</pre>\n<p>To authenticate with BigQuery, we can actually use the service account key that we previously created for GA4.</p>\n<p>The only thing that changes is the function <code>bq_auth()</code> instead of <code>ga_auth()</code>.</p>\n<p>This is great news as it means we donâ€™t have to go through yet another cumbersome authentication process:</p>\n<pre># Authenticate\nbq_auth(path = \"mage-ai-test-405614-2e1e1c865c18.json\")\n</pre>\n<p>In fact, you can use the same service account key to authenticate with multiple Google services such as Google Drive or Google Sheets.</p>\n<p>There are different R packages for these services, such as <code>googledrive</code> and <code>googlesheets4</code>.</p>\n<p>Granted, you need to authorize the respective APIs in the Google Cloud Platform as shown previously, but this is a great time saver!</p>\n<p>The next thing to do is to create a table reference for BigQuery.</p>\n<p>As you may remember, we previously created only a data set, so we now need to create a placeholder for our table.</p>\n<p>To do so, we need to define our project name, data set, and table. The project name and data set are already defined and we can retrieve these from BigQuery. The table name is up to you.</p>\n<pre># Define Big Query Project data\nproject = \"mage-ai-test-405614\"\ndata_set = \"mage_demo\"\ntable = \"merged_data\"\n\n# Define table\ntable = bq_table(project = project, dataset = data_set, table = table)\n</pre>\n<p>To find the right project and data set name, go to BigQuery and click on the data set you created.</p>\n<p>To the right, you should see the <strong>Data set ID</strong>, which comprises <code>project_name.data_set_name</code>. You can separate and copy those values to insert them into the code above.</p>\n<p><img alt=\"Data Set ID\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_dataset-info.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Data Set ID\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_dataset-info.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>In the following code, if the table exists, we delete and recreate it before uploading data.</p>\n<p>Iâ€™m doing this every 5 minutes for demonstration, but in real production, Iâ€™d likely run it less frequently, adding only the new data instead of recreating the whole table.</p>\n<pre>if(bq_table_exists(table)){\n  # if table already exists, delete it\n  bq_table_delete(table)\n\t\n\t# recreate table so that we can fill it out\n  bq_table_create(table, merged_data)\n\t\n\t# fill out table\n  bq_table_upload(table, merged_data)\n}else{\n  bq_table_create(table, merged_data)\n  bq_table_upload(table, merged_data)\n}\n</pre>\n<p>Here is the final code:</p>\n<pre>library(\"pacman\")\np_load(bigrquery)\n\nexport_data &lt;- function(merged_data) {\n    # Specify your data exporting logic here\n    # Return value: exported dataframe\n\n    # Authenticate\n    bq_auth(path = \"mage-ai-test-405614-2e1e1c865c18.json\")\n\n    # Define Big Query Project data\n    project = \"mage-ai-test-405614\"\n    data_set = \"mage_demo\"\n    table = \"merged_data\"\n\n    # Create table reference\n    table = bq_table(project = project, dataset = data_set, table = table)\n\n    if(bq_table_exists(table)){\n      # if table already exists, delete it\n      bq_table_delete(table)\n\t\n\t  # recreate table so that we can fill it out\n      bq_table_create(table, merged_data)\n\t\n\t  # fill out table\n      bq_table_upload(table, merged_data)\n    }else{\n      bq_table_create(table, merged_data)\n      bq_table_upload(table, merged_data)\n    }\n}\n</pre>\n<p>If you run the code, you should have a new table called <code>merged_data</code> in BigQuery. If you click PREVIEW, you should be able to see data within.</p>\n<p><img alt=\"BigQuery Table\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_bigquery-preview.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"BigQuery Table\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_bigquery-preview.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Our pipeline is complete, as you can see all the blocks have a green tick:</p>\n<p><img alt=\"Pipeline Complete\" data-lazy-src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_mage-pipeline-complete.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Pipeline Complete\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.business-science.io/assets/r_mage_gcp_mage-pipeline-complete.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<h2 id=\"step-8-how-to-schedule-a-data-pipeline-that-automatically-updates-every-5-minutes\">Step 8: How to schedule a data pipeline that automatically updates every 5 minutes</h2>\n<p>There are 2 sub-steps:</p>\n<ol>\n<li>Test the entire pipeline (verify it runs)</li>\n<li>Create a schedule</li>\n</ol>\n<h3 id=\"step-81-test-the-entire-pipeline-verify-it-runs\">Step 8.1: Test the entire pipeline (verify it runs)</h3>\n<p>Only because each block ran successfully, there is no guarantee that the entire pipeline will run smoothly. So, we have to run the entire pipeline before creating a schedule.</p>\n<p>In Mage, click on â€œTriggersâ€:</p>\n<p><img alt=\"Triggers\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_mage-triggers.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Triggers\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_mage-triggers.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>At the top, click on <strong>Run @once</strong>.</p>\n<p>This will produce a trigger, and youâ€™ll see that its status will change to <code>running</code>:</p>\n<p><img alt=\"Trigger Running\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_trigger-running.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Trigger Running\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_trigger-running.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>When done, it should say <code>completed</code> and switch to inactive state.</p>\n<p>If we now refresh the BigQuery table, we can see that it has an updated date/time for the rows. This means that our pipeline ran successfully!</p>\n<p><img alt=\"BigQuery Table\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_date-time-bigquery-updated.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"BigQuery Table\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_date-time-bigquery-updated.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<h3 id=\"step-82-create-a-schedule\">Step 8.2: Create a schedule</h3>\n<p>Now that we know that our pipeline works properly, letâ€™s create a trigger that runs every 5 minutes.</p>\n<p>In Mageâ€™s Triggers view, click on <strong>New trigger.</strong></p>\n<p>Select <strong>Schedule</strong> as the trigger type.</p>\n<p><img alt=\"Schedule Trigger\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_mage-new-schedule-trigger.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Schedule Trigger\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_mage-new-schedule-trigger.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Given that the trigger will run every 5 minutes, letâ€™s name it <code>every_5_minutes</code>.</p>\n<p>Select custom as frequency and give the following cron expression: <code>*/5 * * * *</code>.</p>\n<p><img alt=\"Cron Expression\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_every-five-minutes.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Cron Expression\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_every-five-minutes.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>A <strong><em>cron</em></strong> expression is like a schedule for your computer tasks.</p>\n<p>Itâ€™s a simple set of instructions that tells your system when to run a specific job.</p>\n<p>The expression consists of five parts, representing minutes, hours, days, months, and days of the week. For example, <code>*/15 * * * *</code> means â€œevery 15 minutes, every hour, every day, every month, every day of the weekâ€.</p>\n<p>When ready with the trigger, click on <strong>Save changes</strong>.</p>\n<p><img alt=\"Save Changes\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_save-schedule-trigger.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Save Changes\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_save-schedule-trigger.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Now you have created your trigger, but as you can see its status is inactive. To start it, click on <strong>Start trigger</strong>.</p>\n<p><img alt=\"Start Trigger\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_start-schedule-trigger.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Start Trigger\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/r_mage_gcp_start-schedule-trigger.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>The status switches to <code>active</code>. If you browse back to the Triggers view, it will show you when itâ€™s set to trigger next.</p>\n<p><img alt=\"Next Trigger\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_trigger-next-run-date.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Next Trigger\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_trigger-next-run-date.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Be mindful of the fact that the time zone in Mage is in UTC.</p>\n<p>Once the timer is set to go off, its status should change to <code>running</code>.</p>\n<p>After itâ€™s run, you can now refresh the BigQuery table and see that the data has now been updated again.</p>\n<p><img alt=\"BigQuery Table\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_bigquery-schedule-updated.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"BigQuery Table\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/assets/r_mage_gcp_bigquery-schedule-updated.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p>Congratulations! Our journey is complete. I hope you had fun and learned something useful.</p>\n<p>If you have any comments, please post them below. If you want to connect with me, Arben, <a href=\"https://www.linkedin.com/in/arben-kqiku-301457117/\" rel=\"nofollow\" target=\"_blank\">here is my LinkedIn</a>!</p>\n<h1 id=\"conclusion\">Conclusion:</h1>\n<p>Using R in production is possible with tools like Mage and Google Cloud Platform. If you are an aspiring Digital Analytics professional, you now have a clear pathway forward for using R, Mage, and Google Cloud Platform to build your own data pipelines.</p>\n<p>However, if you are a Digital Analytics professional, you may be wondering how to get started with R. You may be wondering how to learn R, how to learn R for Digital Analytics, and how to learn R for Digital Analytics in a way that is practical and useful.</p>\n<p><strong>If you need to learn R for data analytics and data science, then I can help. Read on.</strong></p>\n<h1 id=\"struggling-to-become-a-data-scientist\">Struggling to become a data scientist?</h1>\n<p>You know the feeling. Being unhappy with your current job.</p>\n<p>Promotions arenâ€™t happening. Youâ€™re stuck. Feeling Hopeless. Confusedâ€¦</p>\n<p>And youâ€™re praying that the next job interview will go better than the last 12â€¦</p>\n<p>â€¦ But you know it wonâ€™t. Not unless you take control of your career.</p>\n<p>The good news isâ€¦</p>\n<h1 id=\"i-can-help-you-speed-it-up\">I Can Help You Speed It Up.</h1>\n<p>Iâ€™ve helped 6,107+ students learn data science for business from an elite business consultantâ€™s perspective.</p>\n<p>Iâ€™ve worked with Fortune 500 companies like S&amp;P Global, Apple, MRM McCann, and more.</p>\n<p>And I built a training program that gets my students life-changing data science careers (donâ€™t believe me? <a href=\"https://university.business-science.io/p/5-course-bundle-machine-learning-web-apps-time-series/\" rel=\"nofollow\" target=\"_blank\">see my testimonials here</a>):</p>\n<h4 class=\"text-center\">\n6-Figure Data Science Job at CVS Health ($125K)<br/><div style=\"height:10px;\"></div>\nSenior VP Of Analytics At JP Morgan ($200K)<br/><div style=\"height:10px;\"></div>\n50%+ Raises &amp; Promotions ($150K)<br/><div style=\"height:10px;\"></div>\nLead Data Scientist at Northwestern Mutual ($175K)<br/><div style=\"height:10px;\"></div>\n2X-ed Salary (From $60K to $120K)<br/><div style=\"height:10px;\"></div>\n2 Competing ML Job Offers ($150K)<br/><div style=\"height:10px;\"></div>\nPromotion to Lead Data Scientist ($175K)<br/><div style=\"height:10px;\"></div>\nData Scientist Job at Verizon ($125K+)<br/><div style=\"height:10px;\"></div>\nData Scientist Job at CitiBank ($100K + Bonus)<br/><div style=\"height:10px;\"></div>\n</h4>\n<h1 id=\"whenever-you-are-ready-heres-the-system-they-are-taking\">Whenever you are ready, hereâ€™s the system they are taking:</h1>\n<p><a href=\"https://university.business-science.io/p/5-course-bundle-machine-learning-web-apps-time-series\" rel=\"nofollow\" target=\"_blank\">Hereâ€™s the system</a> that has gotten aspiring data scientists, career transitioners, and life long learners data science jobs and promotionsâ€¦</p>\n<p><img alt=\"What They're Doing - 5 Course R-Track\" data-lazy-src=\"https://i2.wp.com/www.business-science.io/assets/rtrack_what_theyre_doing_2.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"What They're Doing - 5 Course R-Track\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.business-science.io/assets/rtrack_what_theyre_doing_2.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<p style=\"font-size: 36px;text-align: center;\">\n<a href=\"https://university.business-science.io/p/5-course-bundle-machine-learning-web-apps-time-series\" rel=\"nofollow\" target=\"_blank\">\n<strong>Join My 5-Course R-Track Program Now!</strong><br/><small style=\"font-size:24px;\">(And Become The Data Scientist You Were Meant To Be...)</small>\n</a>\n</p>\n<p>P.S. - Samantha landed her NEW Data Science R Developer job at CVS Health (Fortune 500). <a href=\"https://university.business-science.io/p/5-course-bundle-machine-learning-web-apps-time-series\" rel=\"nofollow\" target=\"_blank\">This could be you.</a></p>\n<p><img alt=\"Success Samantha Got The Job\" data-lazy-src=\"https://i0.wp.com/www.business-science.io/img/success_samantha_got_job.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Success Samantha Got The Job\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.business-science.io/img/success_samantha_got_job.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://www.business-science.io/code-tools/2023/12/02/how-to-use-r-in-production-mage-ai-google-cloud.html\"> business-science.io</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div> </hr></div>\n</article>",
      "main_text": "Data Engineering in R: How to Build Your First Data Pipeline with R, Mage, and Google Cloud Platform (in under 45 Minutes)\nPosted on\nDecember 2, 2023\nby\nBusiness Science\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nbusiness-science.io\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nHey guys, welcome back to my\nR-tips newsletter\n. In todayâ€™s R-Tip,\nArben Kqiku\nis sharing his\nexact 8-step framework\nfor taking R into production for Digital Analytics projects. Youâ€™ll learn how to use R, Mage.ai, and Google Cloud Platform (GCP) to build your first data engineering pipeline\nin under 45 minutes.\nAbout the Author\nArben\nis a digital analytics and Google Cloud Platform (GCP) expert. Heâ€™s also a Business Science University student. In this post, Arben shares how to use R in production, with Mage.ai and Google Cloud.\nThis article was originally published on\nSimo Ahavaâ€™s website\n, which is focused on aspiring Digital Analytics Professionals. Weâ€™ve republished it here with permission to help spread the word of R in production with new tools including Mage.ai and Google Cloud Platform.\nLetâ€™s dive in!\nTable of Contents\nHereâ€™s what youâ€™re learning today:\nThe Problem:\nWeâ€™ll cover a case study from a recent problem Arben had in Multi-Touch Campaign Attribution.\nThe Solution: Arbenâ€™s 8-Step Framework:\nArbenâ€™s sharing his exact process for how he sets up production R data engineering pipelines on GCP with R and Mage.ai (perfect if itâ€™s your first time).\nFull Code Demo:\nEXACTLY HOW TO BUILD YOUR FIRST DATA SCIENCE PIPELINE (IN UNDER 45 minutes).\nWhat You Make Today:\nBelow you can see an architectural overview of what weâ€™ll build today.\nWhat You Make Today!\nThe 8-Step Framework to Accomplish This:\nHereâ€™s the 8-step framework that Arben will walk you through today:\nThe 8 steps you follow\nThe 8 Things Youâ€™ll learn in this tutorial:\nHow to create a Google Cloud project.\nHow to set up a virtual machine.\nHow to access your virtual machine remotely.\nHow to install Mage.ai on the virtual machine to handle the automation.\nHow to retrieve data from the GA4 API in a production environment.\nHow to retrieve data from the Google Ads API in a production environment.\nHow to export data to Google BigQuery in a production environment.\nHow to schedule a data pipeline that automatically updates every 5 minutes.\nSPECIAL ANNOUNCEMENT: ChatGPT for Data Scientists Workshop on December 13th\nInside the workshop\nIâ€™ll share how I built a Machine Learning Powered Production Shiny App with\nChatGPT\n(extends this data analysis to an\ninsane\nproduction app):\nWhat:\nChatGPT for Data Scientists\nWhen:\nWednesday December 13th, 2pm EST\nHow It Will Help You:\nWhether you are new to data science or are an expert, ChatGPT is changing the game. Thereâ€™s a ton of hype. But how can ChatGPT actually help you become a better data scientist and help you stand out in your career? Iâ€™ll show you inside\nmy free chatgpt for data scientists workshop\n.\nPrice:\nDoes\nFree\nsound good?\nHow To Join:\nðŸ‘‰ Register Here\nR-Tips Weekly\nThis article is part of R-Tips Weekly, a\nweekly tutorial\nthat shows you step-by-step how to do common R coding tasks. Pretty cool, right?\nHere are the links to get set up. ðŸ‘‡\nGet the Code\nThe Problem: Multi-Touch Campaign Attribution in Digital Analytics\nAs a digital analyst, I often need to combine data from different sources and display it in a dashboard. This is especially true when Iâ€™m working with Google Analytics 4 (GA4) and Google Ads for Campaign Attribution.\nCase Study: Digital Analytics and Multi-Touch Campaign Attribution\nFor instance, clients run campaigns on platforms like Google Ads and Meta Ads, and\nthey want to understand the impact of each channel or even individual campaigns.\nTo address this, we usually:\nUse\nconversion data\nfrom a third-party source, like Google Analytics, and\nCombine it with other data such as impressions, clicks, and cost from the advertising channels.\nThis helps us\ncalculate the cost per conversion\nfor each channel more accurately.\nBuilding the Multi-Touch Attribution Data Engineering Pipeline\nTo build a data engineering pipeline, we need to factor in:\nAccessibility:\nMake sure we can easily get data from different sources, such as Google Ads, Meta Ads, and GA4.\nData integration:\nCombine data from different sources accurately.\nStorage:\nCreate a data warehouse in Google BigQuery for the joined data and make it accessible to data visualization tools.\nMaintenance:\nFind a way to automate these steps without needing manual intervention. That way stakeholders will have access to almost real-time data.\nOur Tech Stack: R, Mage.ai, Google Cloud Platform, and VSCode IDE\nRegister for R-Tips Newsletter Here\nTo build this pipeline, weâ€™ll use:\nR: To retrieve data from the APIs and combine it.\nMage.ai: To automate the Extract Transform Load (ETL) process.\nGoogle Cloud Platform (GCP): To store the data and make it accessible to data visualization tools.\nVSCode IDE: To access the virtual machine remotely.\n1. R: To retrieve data from the APIs and combine it\nIf you are new to R:\nInstall R here:\nhttps://www.r-project.org/\nAccess to 20,000+ of open source R packages here:\nhttps://cran.r-project.org/\nPackages weâ€™ll use today:\ntidyverse\n: To work with data and make the data pipeline.\ngoogleAnalyticsR\n: To retrieve data from the GA4 API.\nrgoogleads\n: To retrieve data from the Google Ads API.\nbigrquery\n: To export data to Google BigQuery.\ngargle\n: For Google authentication.\n2. Mage.ai: To automate the Extract Transform Load (ETL) process\nI love R and I am so thankful that\nTommy Dang\nand his team included it in Mage.\nMage AI\nIf you are new to Mage:\nMage.ai is a tool that helps you automate the ETL process. Itâ€™s a great tool for data scientists who want to automate their data engineering pipelines.\nMage.ai:\nhttps://mage.ai/\nThe screenshot below comes from Mage. Mage is a data engineering tool that allows you to build your ETL (extract, transform, and load) pipelines. What I love about Mage is that it is easy to use, you can visualize your data pipelines and it supports multiple programming languages: SQL, Python.. and R!\nIn addition to building our pipeline, weâ€™ll use Mage to\nschedule your pipelines\n, as you can see in the example below.\nRegister for R-Tips Newsletter Here\n3. Google Cloud Platform (GCP): To store the data and make it accessible to data visualization tools.\nYou can run Mage on your local machine or in the cloud.\nObviously, if you run it locally, your computer needs to be on all the time, which is not ideal. Therefore, weâ€™ll create a virtual machine (VM) on the Google Cloud Platform and run Mage from there.\nA virtual machine (VM) on GCP is like a computer in the cloud. Itâ€™s not a physical machine you can touch; instead, itâ€™s a powerful, remote computer that you can use to run your software and store your data.\nGoogle Cloud Platform (GCP)\nIf you are new to Google Cloud Platform (GCP):\nGoogle Cloud Platform (GCP) is a cloud computing platform that allows you to store data and make it accessible to data visualization tools.\nYouâ€™ll need to create a Google Cloud account to use GCP.\nGoogle Cloud Platform:\nhttps://cloud.google.com/\nTo use GCP, you need a payment method. But worry not, as of today, If you have never used GCP,\nyou get a credit of $300\n. So, go to the Google Cloud Console and create an account:\nhttps://console.cloud.google.com/welcome\n.\nOnce you have used your free credits, you need to add a credit card to your account, by going under â€œBILLINGâ€:\n4. VSCode IDE: To access the virtual machine remotely\nTo access the virtual machine from our computer, weâ€™ll use Visual Studio Code, which is a lovely, free code editor that supports many programming languages.\nVSCode IDE\nIf you are new to VSCode IDE:\nVSCode IDE is a free code editor that supports many programming languages including R, Python, C++ and has extensions for tools like Remote SSH (covered in this tutorial).\nInstall the VSCode IDE here:\nhttps://code.visualstudio.com/\nThe Solution: Arbenâ€™s 8-Step Framework for Data Engineering in R with Mage and GCP (in under 45 minutes)\nThe 8 steps you follow\nNow for my\n8-step framework\nfor building a data engineering pipeline in R with Mage.ai and GCP.\nThese are the steps I follow when Iâ€™m building a data engineering pipeline for a client.\nOnce you are familiar with my framework, you can build your own data engineering pipelines\nin under 45 minutes.\nHeads up, this is a comprehensive tutorial.\nThis is because I wanted to build the training I wish I had when I solved this problem for the first time. I hope you enjoy it!\nStep 1: How to create a Google Cloud project\nIn order to use GCP, we need a project. Later, everything that weâ€™ll do will be within this project.\nSo, go back to https://console.cloud.google.com/welcome and create a new project by first clicking on the project selector in the top left.\nThen click on â€œNEW PROJECTâ€:\nNext, name your project. I called my project\nmage-ai-test\n.\nFinally, click on â€œCREATEâ€. Then simply wait until your project is created. Once you have selected your project, type â€œvm instancesâ€ in the search bar, and select â€œVM instancesâ€.\nThis will lead to the following screen:\nStep 2: How to set up a virtual machine\nThere are 4 sub-steps:\nActivate the Compute Engine APIâ€™s features\nSet up SSH keys\nCreate a virtual machine\nConnect to the virtual machine via SSH\nStep 2.1: Activate the Compute Engine APIâ€™s features\nOn GCP, to use specific features, you must activate the corresponding APIs:\nFor example, weâ€™ll enable the Google Analytics API later to get data from GA4.\nTo make a virtual machine, we need to enable the Compute Engine API.\nAfterward, youâ€™ll see this screen, but we wonâ€™t create a VM instance just yetâ€¦\nStep 2.2: Set up SSH keys\nNext, we need to create SSH keys that will allow us to access our virtual machine from our computer.\nSSH keys are like special keys that help your computer talk securely to another computer, such as a virtual machine.\nItâ€™s a way for your computer to prove itâ€™s really you when connecting to the virtual machine. Itâ€™s like having a secret handshake between your computer and the virtual machine, making sure they can trust each other without needing to type in a password every time.\nCreate SSH and Public Keys\nWe need to create two SSH keys, a private and a public key. Think of SSH keys like a pair of magic keys for your online accounts. You have one key that you keep secret (the private key) and another key that you share with others (the public key).\nPrivate Key (Secret Key):\nThis is like the key to your front door that only you have. You keep it safe on your computer, and itâ€™s a secret. Itâ€™s used to unlock and access your accounts securely.\nPublic Key (Shared Key):\nThis is like a lock that matches your private key.\nWhen you connect to a server or service, you use your private key to prove you are who you say you are. The server then checks this with your public key to make sure itâ€™s really you. This way, even if someone gets your public key, they canâ€™t do anything without the private key, which stays safe on your computer. Itâ€™s a bit like having a special lock and key where only your key can open it.\nTo create your keys, hop to the terminal in your local machine and type the following code:\nssh-keygen -t rsa -f ~/.ssh/mage-ai-test -C arbenkqiku\nThe end of the code should be your username, in my case\narbenkqiku\n. If you donâ€™t know your user name, type\nwhoami\nin the terminal and press enter. This will output your username.\nOnce you enter the code mentioned above, youâ€™ll be prompted to insert your computerâ€™s password, if you have any. Once you add your password, your SSH keys will be created.\nNow, go to the directory where your SSH keys can be found.\ncd\nstands for â€œchange directoryâ€:\ncd ~/.ssh\nThis is where your public private and public SSH keys are located.\nNow, type the following code to display the content of your public SSH key in the terminal.\ncat mage-ai-test.pub\nThis will show the content of your public SSH key that we will later paste into our VM.\nStep 2.3: Create a virtual machine\nNow, letâ€™s go back to Google Cloud Platform and click on â€œCREATE INSTANCEâ€ in the VM instances overview.\nGive a name to the VM instance and select the region closest to you:\nGo to the â€œBoot diskâ€ section and click on â€œCHANGEâ€:\nSelect the following options:\nUnder Firewall, select the following options:\nThis is important, as otherwise we wonâ€™t be able to access Mage by using the IP address of our VM, youâ€™ll understand later what I mean by this.\nUnder Advanced Options > Security, click on â€œADD ITEMâ€. Here is where weâ€™ll add our\npublic SSH key\n.\nCopy the entire SSH public key and paste it.\nFinally, click on â€œCREATEâ€. It may take some time to create the VM.\nOnce done, your new VM will appear here. Also, youâ€™ll see that your VM will have an â€œExternal IPâ€.\nYou can use this â€œExternal IPâ€ and your SSH private key to connect to this VM. Letâ€™s do this!\nStep 3: How to access your virtual machine remotely\nStep 3 has 2 sub-steps:\nHow to connect to your VM via SSH\nHow to connect via VSCode IDE (using Remote â€“ SSH extension)\nStep 3.1: How to connect to your VM via SSH\nGo back to the terminal in your local machine and go to the directory where the SSH keys are located:\ncd ~/.ssh\nNext, type this command:\nssh -i mage-ai-test\n[emailÂ protected]\nIâ€™ll break it down to you so you know what to replace:\nssh -i name_of_private_key user_name@gcp_vm_instance_external_ip\nYouâ€™ll likely will be prompted to enter your password again, and also to add the â€œExternal IPâ€ as a host. Just follow the instructions and you should be able to connect to your VM.\nAs you can see from the image below, we connected to the VM named\nmage-demo-test\n. And if you recall, in â€œBoot diskâ€ options, we selected Ubuntu as our operating system.\nStep 3.2: How to connect via VSCode IDE (using Remote â€“ SSH extension)\nWe could do this whole process through the terminal, but it is much more user-friendly to do it through Visual Studio Code.\nVisual Studio Code is a very powerful code editor. Go to this link:\nhttps://code.visualstudio.com/download\n, and download Visual Studio Code.\nOnce you have installed it, go to â€œExtensionsâ€ and install â€œRemote â€“ SSHâ€.\nIn Visual Studio Code, go the the search bar and type >, and then select the following option:\nIn the configuration file that will open, you need to enter your details. Essentially, weâ€™re providing the details to connect to our VM.\nHost mage-demo-test # Give a name to your host\n  HostName 34.65.231.180 # Replace with the External IP address in GCP\n  User arbenkqiku # Replace this with your user name\n  IdentityFile /Users/arbenkqiku/.ssh/mage-ai-test # Path to private SSH key\nNow, we still have to go back to the terminal one last time and type this:\neval $(ssh-agent)\nssh-add /Users/arbenkqiku/.ssh/mage-ai-test # Path to private SSH key\nThen, type your password when prompted. This basically means that you can use your password when you try to access the VM through Visual Studio Code.\nNow, go back to the search bar of Visual Studio Code, type > and select the following option:\nIt should suggest the host that you just created, click on that host:\nThen, youâ€™ll be prompted to enter your password. Once you enter your password, youâ€™ll be connected to your VM.\nNow, click on the â€œRemote Explorerâ€ icon, and it should show that you connected to your VM:\nOn the top right, click this icon to display the terminal below:\nNow click on â€œTERMINALâ€. Congratulations, you have accessed your VM through Visual Studio Code!\nStep 4: How to install Mage.ai on the virtual machine to handle the automation\nTo install mage on GCP, I largely followed\nthis tutorial\n, but I will also explain every step here.\nTher are mainly 3 sub-steps:\nCreate the folder for Mage\nInstall\nDocker\nInstall\nMage\nAccess\nMage\nthrough the External IP from GCP\nStep 4.1: Create the folder for Mage\nFirst of all, letâ€™s create a directory in our VM for mage:\nmkdir mage-demo\nNow, if you type the following code, you should be able to see the newly created folder:\nls\nThen, letâ€™s access the folder:\ncd mage-demo\nStep 4.2: Install\nDocker\nNow, to install mage, we need to first install\nDocker\n.\nDocker is a platform for developing, shipping, and running applications. It uses containerization technology to package an application and its dependencies together into a single unit called a â€œcontainerâ€.\nIn the\nmage-demo\nfolder, letâ€™s download a GitHub repo that contains the installation for Docker:\ngit clone https://github.com/MichaelShoemaker/DockerComposeInstall.git\nLetâ€™s access the folder that contains the Docker installation:\ncd DockerComposeInstall\nLetâ€™s modify the file to make it executable:\nchmod +x InstallDocker\nThen, letâ€™s run it:\n./InstallDocker\nType this to verify that Docker has been installed correctly:\ndocker run hello-world\nThis should show the following message:\nStep 4.3: Install\nMage\nNow, letâ€™s go back to the initial directory:\ncd mage-demo\nNow, we can finally install mage with this command:\ndocker run -it -p 6789:6789 -v $(pwd):/home/src --restart always mageai/mageai /app/run_app.sh mage start mage-ai-test\nWith the command\n--restart always\n, weâ€™re asking the VM to always restart mage whenever the VM is shut down and later restarted.\nAt the end,\nmage-ai-test\nrepresents the name of our project.\nStep 4.4: Access\nMage\nthrough the External IP from GCP\nNow, to access mage through our External IP from GCP, we need to hop back on GCP first, as we need to create a\nfirewall rule\n.\nThis is necessary to control and regulate incoming and outgoing traffic to and from your VM on Google Cloud Platform. When you want to access mage through your External IP from GCP, a firewall rule is needed to explicitly allow the traffic to reach your VM.\nBrowse to Firewall in the Google Cloud Platform.\nClick on â€œCREATE FIREWALL RULEâ€:\nSelect the following options and click on â€œCREATEâ€:\nBasically, with this firewall rule in place, it means we can access mage via the external IP address by using port number 6789.\nNow, if you type\nyour VM external IP\nfollowed by\n:6789\nin your web browser you should be able to access mage.\nFor example, this is the URL I would use with my configuration:\nhttp://34.65.231.180:6789\n.\nAs you can see,\nmage-ai-test\nwas the name of our project in a previous command.\nCongrats, now you can create data pipelines that will run in the cloud!\nStep 5: How to retrieve data from the GA4 API in a production environment\nNow, we can finally create the pipeline.\nWeâ€™ll first focus on retrieving data from the Google Analytics 4 (GA4) API. We will accomplish this inside of\nMage\n.\nWe have the following sub-steps:\nCreate a new pipeline\nSelect a Mage block tyoe (Data Loader)\nUse R packages and code to retrieve data from the GA4 API\nGA4 API: How to get an access token\nHow to run GA Authentication in a production environment\nCreate a Google Analytics token\nTest\nR\nCode on Your Local Machine\nCreate the full\nR\nScript\nMake JSON service account key accessible to Mage\nAdd the\nR\nScript to Mage\nStep 5.1: Create a new pipeline\nTo start, click on\nNew pipeline > Standard (batch)\n:\nOn the left side, you can see all your files inside of\nMage\n`, even the pipeline that we have just created.\nIn the middle, you can see the blocks that you can use to build your pipelines. In this guide, weâ€™ll use\nData loader\n,\nTransformer\n, and\nData exporter\nblocks:\nStep 5.2: Select a Mage block type (Data Loader)\nThe Data loader block:\nAs mentioned previously, you can use Python, SQL, and R in each block. In our case, weâ€™ll use\nR\n. So, click on Data Loader and select R:\nName the block\nga4\n, then click Save and add block. You should now see the block on the right, together with a sample R code.\nStep 5.3: Use R packages and code to retrieve data from the GA4 API\nTo install and load packages, mage uses the pacman package. Once you load\npacman\n, you can install packages by using:\npacman::p_load(package1, package2, package3)\nâ€‹The first time you run the\np_load()\nfunction, it will install a package, and then it will simply load it. For this block, weâ€™ll install three packages:\nlibrary(\"pacman\")\npacman::p_load(dplyr, purrr, googleAnalyticsR)\n\nload_data <- function() {\n\n}\nStep 5.4: How to get an access token\nIn order to access GA4 data by using the\ngoogleAnalyticsR\npackage, developed by Mark Edmondson, you need an access token.\nAn access token is like your digital ID card; it confirms your identity and verifies that you truly have permission to access the GA4 properties youâ€™re attempting to retrieve data from.\nTo get an access token, you can run the following function in the RStudio console in your local machine:\nga_auth()\n.\nOnce you run this function, youâ€™ll be redirected to a browser window where youâ€™ll select your account:\nWith this, you are basically giving permission to the googleAnalyticsR package to access your GA4 properties.\nHowever, the problem is that weâ€™ll run our data pipeline in a production environment where you cannot interact with the browser.\nSo, we need to find another way to solve this problem.\nIn fact, if I try to run the function\nga_auth()\non Mage,\nit throws an error\n:\nSo, we need to generate a Google Analytics token that we can use in a production environment.\nStep 5.5: How to run GA Authentication in a production environment (without a browser)\nEnable Google Analytics Reporting API\nFirst, letâ€™s go back to GCP and browse to Enabled APIs & services.\nClick on â€œENABLE APIS AND SERVICESâ€.\nSearch for\nGoogle Analytics\n, click the\nGoogle Analytics Reporting API\nresult, and then choose\nENABLE\n.\nThis means that our project is now eligible to use the Google Analytics Reporting API.\nRepeat steps to Enable Google Analytics Data API\nNext, repeat these API-enabling steps for the\nGoogle Analytics Data API.\nOnce done, we have the APIs enabled but we still havenâ€™t created the required token.\nStep 5.6: How to create a Google Analytics token\nBrowse to\nCredentials\nin the Google Cloud console.\nHover over â€œCREATE CREDENTIALSâ€ and click on Service account.\nGive the service account a name and then click CREATE AND CONTINUE.\nGive the service account the Editor role and then click on Continue.\nFinally, click on\nDONE\n.\nNow that the service account has been created, go back to the Credentials view and youâ€™ll see the account that you just created. Click on it.\nThen, click the\nKEYS\ntab and choose to\nCreate new key\n.\nSelect\nJSON\nas the key type and click\nCreate\n.\nThis should download your key as a JSON file.\nImportant: Store it in a safe place.\nBasically, the service account is like an account that has permission to act on your behalf. When you want your application or service to communicate with the GA4 API, it needs to prove its identity. Instead of using a userâ€™s personal Google account, which may not be appropriate for server-to-server communication, you can use a service account.\nNow, as if it were a real user, we need to go to the GA4 property and add our service account email. So, go back to\nCredentials\nand copy your service accountâ€™s\nemail address\n:\nNext, open Google Analytics 4, go to your property, and click on\nProperty access management\nin Admin:\nAdd your service account email address to the list of users, give it Viewer permissions, and click on Add to add the service account as a user to the GA4 property.\nStep 5.7: Test R Code on Your Local Machine\nNow, before adding code to Mage, I like to test it on my local machine to make sure that everything works properly.\nSo, on your local machine, open a new R script and try the following code:\n# Packages ----\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(googleAnalyticsR)\n\n# Authenticate ----  \n\n# path to your JSON service account that we saved earlier\nga_auth(json_file = \"/Users/arbenkqiku/Desktop/mage-ai/mage-ai-test-405614-2e1e1c865c18.json\")\nâ€‹If everything works correctly, you should see the following message:\nThat means that your pipeline can now communicate with the GA4 Reporting API without any extra authentication flows.\nStep 5.8: Create the R Script\nNow, what I want to retrieve from GA4 are the sessions where a lead generation conversion event happened.\nIn the case of this client of mine, either someone submitted a form, clicked on the WhatsApp icon to talk to them privately, or clicked on the phone icon to call them.\nSo, in the the next piece of code I want to create a filter with all the event names I am interested in, namely the event names equal to\nform_submit_lead\nor\nwhatsapp_click\nor\nphone_click\n.\n# GA4 property ID\nproperty_id = \"1234567\"\n\n# Create filter\ngoals_filter = ga_data_filter(\"eventName\" == \"form_submit_lead\" | \"eventName\" == \"whatsapp_click\" | \"eventName\" == \"phone_click\")\nIn the next piece of code, we have the actual query to GA4:\n# Get conversions from GA4\ngoals_data = ga_data(propertyId = property_id,         \n                     date_range = c(\"2023-10-01\", \"2023-11-08\"),        \n                     dimensions = c(\"date\"),        \n                     metrics = c(\"sessions\"),        \n                     dim_filter = goals_filter) %>%     \n\n# rename sessions to goals\nset_names(c(\"date\", \"goals\"))\nBasically, weâ€™re getting the sessions from 1st October 2023 until 8th November 2023, segmented by date, and only when one of the events mentioned earlier occurred.\nThis is what the final table looks like in my case:\nIt is not always easy to know what certain fields are called in the GA4 API. You can go to\nthis website\nand look for a specific field. For example, if we look for â€œchannelâ€, you can see all the different fields that contain â€œchannelâ€ and what they are called in the GA4 API.\nNow, in addition to retrieving the sessions where a conversion event occurred, I also want to retrieve the sessions segmented by day, so Iâ€™ll use this query:\n# Get sessions from GA4\nsessions_data = ga_data(\n    propertyId = property_id,                      \n    date_range = c(\"2023-10-01\", \"2023-11-08\"),        \n    dimensions = c(\"date\"),                     \n    metrics = c(\"sessions\")\n)\nThis returns a table of sessions segmented by date.\nNow, to join the sessions with the conversions:\n# Merge GA4 goals and sessions\nsessions_goals_ga4 = sessions_data %>%   \n\t# join sessions with goals  \n    full_join(goals_data) %>%   \n\t# replace all NAs with 0  \n    replace(is.na(.), 0)\nThis is the final result:\nHere is the complete code.\nAt the end of the script, I added the\nsessions_goals_ga4\ndataframe. This is because in Mage, weâ€™re using this code within a Data Loader block. We need to return a dataframe for the next block, otherwise the next block doesnâ€™t have any data to play with.\n# Packages ----\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(googleAnalyticsR)\n\n# Authenticate ----  \n\t# path to your JSON service account that we save earlier\nga_auth(json_file = \"/Users/arbenkqiku/Desktop/mage-ai/mage-ai-test-405614-2e1e1c865c18.json\")  \n\n# GA4 property ID\nproperty_id = \"1234567\"\n\n# Create filter\ngoals_filter = ga_data_filter(\"eventName\" == \"form_submit_lead\" | \"eventName\" == \"whatsapp_click\" | \"eventName\" == \"phone_click\")\n\n# Get conversions from GA4\ngoals_data = ga_data(propertyId = property_id,         \n                     date_range = c(\"2023-10-01\", \"2023-11-08\"),        \n                     dimensions = c(\"date\"),        \n                     metrics = c(\"sessions\"),        \n                     dim_filter = goals_filter) %>%     \n\n\t# rename sessions to goals\nset_names(c(\"date\", \"goals\"))\n\n# Get sessions from GA4\nsessions_data = ga_data(propertyId = property_id,                      \n                        date_range = c(\"2023-10-01\", \"2023-11-08\"),        \n                        dimensions = c(\"date\"),                     \n                        metrics = c(\"sessions\"))\n\n# Merge GA4 goals and sessions\nsessions_goals_ga4 = sessions_data %>%   \n\t# join sessions with goals  \nfull_join(goals_data) %>%   \n\t# replace all NAs with 0  \nreplace(is.na(.), 0)\n\n# Final data frame for next block in mage.ai\nsessions_goals_ga4\nStep 5.9: Make JSON service account key accessible to Mage\nNow, before we copy this code to Mage, we need to make our JSON service account key accessible to Mage, as for now it is only available on our local machine.\nRemember, Mage is installed on our virtual machine. We need to paste the JSON service account key there.\nOpen Visual Studio Code and click on â€œOpenâ€.\nGo to the path where your JSON service account key is located in your local machine. You should be able to see your service account key in the left panel.\nRight-click and copy it.\nNext, go to the search bar, type > and connect to your virtual machine.\nOnce you are in the VM, click on â€œOpenâ€¦â€ and access the folder where Mage is installed. Click on â€œOKâ€.\nOn the left side you should now see the files contained in that folder.\nRight-click in that area and choose\nPaste\nto paste your service account JSON file into the project.\nYou should see your service account file now successfully added to the files in your VM.\nIn Mage, you can use the function\nlist.files()\nto see that the service account key is available.\nStep 5.10: Add the R Script to Mage\nNow, take the code that we previously played with in RStudio and paste it into Mage. You need to make some adjustments, though.\nThe main change is that the bulk of the code is now within the\nload_data()\nfunction. The only code thatâ€™s run outside that function are the library loads.\nAnother thing that changes is the path to the service account key. This now needs to reference the path to the file in your VM. As it should be in the root of your project, you just need to add the filename.\nlibrary(\"pacman\")\npacman::p_load(dplyr, purrr, googleAnalyticsR)\n\nload_data <- function() {\n    # Specify your data loading logic here\n    # Return value: loaded dataframe\n\n    # Retrieve data ----\n    # path to your JSON service account\n    ga_auth(json_file = \"mage-ai-test-405614-2e1e1c865c18.json\")\n\n    # GA4 property ID\n    property_id = \"1234567\"\n\n    # Create filter\n    goals_filter = ga_data_filter(\"eventName\" == \"form_submit_lead\" | \"eventName\" == \"whatsapp_click\" | \"eventName\" == \"phone_click\")\n\n    # Get conversions from GA4\n    goals_data = ga_data(propertyId = property_id, \n                         date_range = c(\"2023-10-01\", \"2023-11-08\"),\n                         dimensions = c(\"date\"),\n                         metrics = c(\"sessions\"),\n                         dim_filter = goals_filter,\n    ) %>% \n    \n    set_names(c(\"date\", \"goals\"))\n\n    # Get sessions from GA4\n    sessions_data = ga_data(propertyId = property_id, \n                            date_range = c(\"2023-10-01\", \"2023-11-08\"),\n                            dimensions = c(\"date\"),\n                            metrics = c(\"sessions\"))\n\n    # Merge GA4 goals and sessions\n    sessions_goals_ga4 = sessions_data %>% \n    # join sessions with goals\n    full_join(goals_data) %>% \n    # replace all NAs with 0\n    replace(is.na(.), 0)\n\n    # Final data frame\n    sessions_goals_ga4\n}\nIf everything worked properly, Mage will provide a preview of the data retrieved:\nAs you can see, our Data loader block has a green tick next to it, which means that it was able to run successfully.\nLater, we can use this data that we retrieved from GA4 for whatever purpose we want. However, before playing around with it, letâ€™s download some data from Google Ads!\nStep 6: How to retrieve data from the Google Ads API in a production environment\nTo retrieve data from the Google Ads API, weâ€™ll use the R package\nrgoogleads\n, developed by Alexey Seleznev. Unfortunately, with this package it is not possible to use a service account key.\nInstead, weâ€™ll have to generate an access token by using the\ngargle\npackage. The goal of\ngargle\n, as explained on their website, is to â€œtake some of the agonizing pain out of working with Google APIsâ€.\nThis step has 4 sub-steps:\nGet an access token\nTest the access token locally\nRetrieve Google Ads API data into our production environment\nStep 6.1: How to get an access token\nFirst of all, you need to browse to the\nGoogle Ads API\nin Google Cloud Platform and click to Enable it.\nSo, when we attempt to fetch our Google Ads data, Google asks for our permission to let this app access our ads data. If we say yes, Google gives us an access token. This token then lets our computer talk to the Google Ads API without having to interact each time.\nBefore doing anything, GCP will ask you to set up a â€œconsent screenâ€. This screen is like a friendly message to users, letting them know that our app wants to look at their Google Ads data.\nItâ€™s a way to make sure users are aware and agree to let our app access their information. To get started, browse to the\nOAuth consent screen\nsection of your GCP project.\nHere, click on â€œCONFIGURE CONSENT SCREENâ€.\nSelect\nExternal\nas the User Type and then click â€œCREATEâ€.\nGive your app a name and add your email address.\nAdd your email to the\nDeveloper email address\n, too, and then click â€œSAVE AND CONTINUEâ€.\nIn the next screen, click on â€œADD OR REMOVE SCOPESâ€. Scopes govern what your app is allowed to do with the APIs.\nSearch for google ads and select the\nGoogle Ads API\n. Click UPDATE when done.\nThen, click â€œSAVE AND CONTINUEâ€ to proceed to the â€œTest usersâ€ step.\nHere, click â€œADD USERSâ€. Add your email address and click â€œADDâ€.\nMake sure to include your email because our app is currently in the â€œTestingâ€ phase. During this phase, only the emails that are added can be used by the app. So, adding your email is crucial to get your Google Ads data.\nClick on â€œSAVE AND CONTINUEâ€ to proceed to the Summary step, and then â€œBACK TO DASHBOARDâ€ when done with configuring the consent screen.\nNow that the consent screen has been configured, you can browse to\nCredentials\nagain.\nHere, click on â€œCREATE CREDENTIALSâ€ and this time choose OAuth client ID.\nUnder\nApplication type\n, select\nDesktop app\n, give a name to your OAuth client ID, and click on â€œCREATEâ€:\nDownload your client ID as a JSON file and click on OK.\nSave it in a secure location.\nStep 6.2: How to test the access token locally\nNow, letâ€™s go back to\nRStudio\nor\nVSCode\non our local machine. Open a new script and load these packages:\n# Packages\nlibrary(gargle)\nlibrary(rgoogleads)\nThen, weâ€™ll import the OAuth Client ID credentials that we just created by using the function\ngargle_oauth_client_from_json()\n. The name of your client can be whatever you prefer:\n# Create gargle client\nmy_client = gargle_oauth_client_from_json(\n    path = \"/Users/arbenkqiku/Desktop/mage-ai/mage-demo-client-id.json\",\n    name = \"Google Ads App\"\n)\nThen, we can add the following scope and email to our token request:\nscopes = \"https://www.googleapis.com/auth/adwords\"\nemail = \"\n[emailÂ protected]\n\"\nâ€‹Finally, we can go through the process of acquiring a token by running this function:\n# Create a token by using Gargle\nmy_token = gargle2.0_token(\n    email = email,  \n    package = \"rgoogleads\",  \n    scope = scopes,  \n    client = my_client\n)\nThis will open a browser window.\nDo you recognize the name of the App? Thatâ€™s the name of our application! Weâ€™re now going through the process of authorizing our app to access our Google Ads data. Now, select your email.\nGoogle will tell you that this app isnâ€™t verified, as its status is still â€œtestingâ€.\nHowever, it is our own app, so we can safely click on â€œContinueâ€.\nAuthorize the app to â€œSee, edit, create and delete your Google Ads accounts and dataâ€¦â€ and click on â€œContinueâ€.\nIf everything worked correctly, you should see a message saying, â€œAuthentication complete. Please close this page and return to R.â€\nNow, if we review the content of the variable\nmy_token\n, which contains our access token, we can review the information again, for example the email associated with the token, the scopes, and so forth.\nWe can now test if the token works properly by running the\ngads_auth()\nfunction. Nothing should really happen here, as with the token we can authenticate non-interactively.\n# Authenticate by using the previously created token\ngads_auth(token = my_token)\nLetâ€™s run a simple function of the\nrgoogleads\npackage to see if we can access our data:\n# get list of accessible accounts\ngads_get_accessible_customers()\nYes, I am able to retrieve the accounts that I have access to!\nHowever, we are not ready for production yet. In fact, if we type this code:\n# where is the cache of the token located\nmy_token$cache_path\nWeâ€™ll get the result that the token is cached in a local directory, such as\n~/Library/Caches/gargle\n.\nThis means that when we try to load\nmy_token\nin production, it will look for the local path instead of a path on the VM.\nSo, we need to change the cache path to our Mage directory on the VM. This is how youâ€™d do it:\n# change path of cache to mage main directory\nmy_token$cache_path = \"/home/src\"\n\n# save token again with changed directory\nsaveRDS(my_token, file = \"google_ads_token_mage_demo.RDS\")\nHere is the full code to generate, test, and save the token:\n# Packages\nlibrary(gargle)\nlibrary(rgoogleads)\n\n# Create gargle client\nmy_client = gargle_oauth_client_from_json(path = \"/Users/arbenkqiku/Desktop/mage-ai/mage-demo-client-id.json\",\n                                          name = \"Google Ads App\")\n\n# Define scope and email\nscopes = \"https://www.googleapis.com/auth/adwords\"\nemail = \"\n[emailÂ protected]\n\"\n\n# Create a token by using Gargle\nmy_token = gargle2.0_token(email = email,  \n                           package = \"rgoogleads\",  \n                           scope = scopes,  \n                           client = my_client)\n\n# Authenticate by using the previously created token\ngads_auth(token = my_token)\n\n# Test token by getting the list of accessible accounts\ngads_get_accessible_customers()\n\n# Change path of cache to mage main directory, so you can use the token in production\nmy_token$cache_path = \"/home/src\"\n\n# Save token with changed directory\nsaveRDS(my_token, file = \"google_ads_token_mage_demo.RDS\")\nStep 6.3: How to retrieve data from the Google Ads API in a production environment\nNow that we have generated the access token, you can copy-paste the JSON file from your local machine to the VM directory by using Visual Studio Code. Follow the exact steps you took to copy-paste the service account JSON file before.\nNext, we can go back to Mage, add a Data loader block, and select R as the programming language.\nName the block\ngoogle_ads\nand click on â€œSave and add blockâ€.\nIn the block code, we need to first load the necessary packages.\nlibrary(\"pacman\")\np_load(rgoogleads)\np_load(dplyr)\np_load(purrr)\n\nload_data <- function() {\n\n}\nThen, we need to load our access token, authenticate with it, and set the Google Ads account ID we want to get the data from.\n# load Google Ads access token\nmy_token = readRDS(file = \"google_ads_token_mage_demo.RDS\")\n    \n# Authenticate with the token\ngads_auth(token = my_token)\n\n# Set the Google Ads account id you want to get data from\ngads_set_customer_id('123-123-1234')\nHere is the query that weâ€™re using to retrieve our data. Weâ€™ll retrieve impressions, clicks, and cost segmented by date, from â€œ2023-10-19â€ until â€œ2023-11-01â€.\n# run query\ngoogle_ads_account_data = gads_get_report(\n  resource    = \"customer\",\n  fields      = c(\"segments.date\",\n                  \"metrics.impressions\",\n                  \"metrics.clicks\",\n                  \"metrics.cost_micros\"),\n  date_from   = \"2023-10-19\",\n  date_to     = \"2023-11-01\"\n)\nThe first argument you need to define is the resource you are getting the data from, in our case\ncustomer\n.\nYou can find\nhere\nthe list of all available resources.\nFor example, if you would like to retrieve data at the ad group level, you should define the resource as\nad_group\n.\nTo build our query, we can use the\nGoogle Ads query builder\n, which can be used for any resource, in our case\ncustomer\n.\nBelow you can select attributes, segments, or metrics:\nWhen you select fields, it will start populating the query in the user interface of the builder.\nThis is very useful to know what the metrics and dimensions are called in the Google Ads API.\nHere is the final part of our Data loader block, which should always be a variable containing data, as we have to pass something to the next block.\n# return data\ngoogle_ads_account_data\nHere is the complete code block weâ€™re working with:\nlibrary(\"pacman\")\np_load(rgoogleads)\np_load(dplyr)\np_load(purrr)\n\nload_data <- function() {\n    # Specify your data loading logic here\n    # Return value: loaded dataframe\n    \n    # load Google Ads access token\n    my_token = readRDS(file = \"google_ads_token_mage_demo.RDS\")\n    \n    # Authenticate with the token\n    gads_auth(token = my_token)\n    \n    # Set the Google Ads account id you want to get data from\n    gads_set_customer_id('123-123-1234')\n\n    # run query\n    google_ads_account_data = gads_get_report(\n      resource    = \"customer\",\n      fields      = c(\"segments.date\",\n                      \"metrics.impressions\",\n                      \"metrics.clicks\",\n                      \"metrics.cost_micros\"),\n      date_from   = \"2023-10-19\",\n      date_to     = \"2023-11-01\"\n    )\n\n# return data for next block\ngoogle_ads_account_data\n}\nIf you run this code, you should be able to see clicks, cost, and impressions segmented by date.\nWeâ€™re now done with this Data Loader block. Next, letâ€™s move on to\ntransformers\n.\nStep 7: How to join and export data to Google BigQuery in a production environment\nThis step has 2 sub-steps:\nJoin the data from GA4 and Google Ads with a Transformer block\nExport the data to Google BigQuery with a Data Exporter block\nStep 7.1: Join the data from GA4 and Google Ads with a Transformer block\nIn Mage, add a new\nTransformer\nblock and select\nR\nas the programming language.\nGive the block a name like\njoin_ga4_google_ads\nand click on â€œSave and add blockâ€.\nIn the Tree, we can now see that the Transformer block named\njoin_ga4_google_ads\nonly receives data from the Data Loader block\ngoogle_ads\n. We need to also link the Data Loader\nga4\nwith the Transformer.\nTo do this, you simply need to drag and drop the arrow from the\nga4\nblock to the\njoin_ga4_google_ads\nTransformer.\nThe first thing that weâ€™ll do in the Transformer block is to add the final variables from the previous Data loader blocks to the\ntransform()\nfunction.\nNext, we can add the following packages on top of the\ntransform()\nfunction:\nlibrary(\"pacman\")\np_load(tibble, dplyr, purrr, stringr, lubridate)\nThe first piece of code that weâ€™re adding is this:\n# Build a row with the exact time\ncheck_time = tibble(\n    Date = Sys.time(),\n    Impressions = 0,\n    Sessions = 0,\n    Clicks = 0,\n    Cost = 0,\n    Goals = 0\n)\nI am creating this tibble called\ncheck_time\nonly so that later in BigQuery we can verify whether our schedule from Mage is working correctly.\nThen, we can finally join the Google Ads data with the GA4 data, and also return the\nmerged_data\nvariable for the next block:\n# Merge Google Ads with GA4 Data\nmerged_data = google_ads_account_data %>%\n  \n  left_join(sessions_goals_ga4, by = c(\"date\" = \"date\")) %>%\n  \n  # reorder and capitalise columns\n  select(date, impressions, sessions, clicks, cost, goals) %>% \n  set_names(names(.) %>% str_to_title()) %>%\n  \n  # add check_time variable to verify schedule\n  mutate(Date = Date %>% as_datetime()) %>%\n  bind_rows(check_time) %>%\n\n  # replace NAs with 0\n  replace(is.na(.), 0) %>%\n  \n  arrange(desc(Date))\n\n# Return merged_data variable for next block\nmerged_data\nIf everything worked properly, you should get something similar to this:\nI am aware that weâ€™re joining Google Ads data with GA4 data from all sources, and we should actually only join GA4 data coming from Google Ads. However, the goal of this guide is simply to show how to perform data engineering tasks with digital data.\nStep 7.2: Export the data to Google BigQuery with a Data Exporter block\nNow that we joined data successfully from Google Ads and GA4, weâ€™re ready to export the data to BigQuery.\nBrowse to the\nBigQuery console\nin your Google Cloud Platform project.\nBigQuery has the following data hierarchy:\nproject -> dataset -> table.\nWe already have a project, so now we need to create a dataset where our tables will reside. Click on the three dots on the right of your project, and then on â€œCreate data setâ€:\nGive a name to your data set, select a region, and click on â€œCREATE DATA SETâ€:\nBack in Mage, add a\nData Explorer\nblock and choose\nR\nas the programming language again.\nName the block\nbiq_query_export\nand click on â€œSave and add blockâ€.\nThis is what your data tree should look like.\nGo the the\nbig_query_export\nblock, and add\nmerged_data\nas the argument of the function\nexport_data()\n. Also, letâ€™s load the\nbigrquery\npackage.\nlibrary(\"pacman\")\np_load(bigrquery)\n\nexport_data <- function(merged_data) {\n    # Specify your data exporting logic here\n    # Return value: exported dataframe\n    \n}\nTo authenticate with BigQuery, we can actually use the service account key that we previously created for GA4.\nThe only thing that changes is the function\nbq_auth()\ninstead of\nga_auth()\n.\nThis is great news as it means we donâ€™t have to go through yet another cumbersome authentication process:\n# Authenticate\nbq_auth(path = \"mage-ai-test-405614-2e1e1c865c18.json\")\nIn fact, you can use the same service account key to authenticate with multiple Google services such as Google Drive or Google Sheets.\nThere are different R packages for these services, such as\ngoogledrive\nand\ngooglesheets4\n.\nGranted, you need to authorize the respective APIs in the Google Cloud Platform as shown previously, but this is a great time saver!\nThe next thing to do is to create a table reference for BigQuery.\nAs you may remember, we previously created only a data set, so we now need to create a placeholder for our table.\nTo do so, we need to define our project name, data set, and table. The project name and data set are already defined and we can retrieve these from BigQuery. The table name is up to you.\n# Define Big Query Project data\nproject = \"mage-ai-test-405614\"\ndata_set = \"mage_demo\"\ntable = \"merged_data\"\n\n# Define table\ntable = bq_table(project = project, dataset = data_set, table = table)\nTo find the right project and data set name, go to BigQuery and click on the data set you created.\nTo the right, you should see the\nData set ID\n, which comprises\nproject_name.data_set_name\n. You can separate and copy those values to insert them into the code above.\nIn the following code, if the table exists, we delete and recreate it before uploading data.\nIâ€™m doing this every 5 minutes for demonstration, but in real production, Iâ€™d likely run it less frequently, adding only the new data instead of recreating the whole table.\nif(bq_table_exists(table)){\n  # if table already exists, delete it\n  bq_table_delete(table)\n\t\n\t# recreate table so that we can fill it out\n  bq_table_create(table, merged_data)\n\t\n\t# fill out table\n  bq_table_upload(table, merged_data)\n}else{\n  bq_table_create(table, merged_data)\n  bq_table_upload(table, merged_data)\n}\nHere is the final code:\nlibrary(\"pacman\")\np_load(bigrquery)\n\nexport_data <- function(merged_data) {\n    # Specify your data exporting logic here\n    # Return value: exported dataframe\n\n    # Authenticate\n    bq_auth(path = \"mage-ai-test-405614-2e1e1c865c18.json\")\n\n    # Define Big Query Project data\n    project = \"mage-ai-test-405614\"\n    data_set = \"mage_demo\"\n    table = \"merged_data\"\n\n    # Create table reference\n    table = bq_table(project = project, dataset = data_set, table = table)\n\n    if(bq_table_exists(table)){\n      # if table already exists, delete it\n      bq_table_delete(table)\n\t\n\t  # recreate table so that we can fill it out\n      bq_table_create(table, merged_data)\n\t\n\t  # fill out table\n      bq_table_upload(table, merged_data)\n    }else{\n      bq_table_create(table, merged_data)\n      bq_table_upload(table, merged_data)\n    }\n}\nIf you run the code, you should have a new table called\nmerged_data\nin BigQuery. If you click PREVIEW, you should be able to see data within.\nOur pipeline is complete, as you can see all the blocks have a green tick:\nStep 8: How to schedule a data pipeline that automatically updates every 5 minutes\nThere are 2 sub-steps:\nTest the entire pipeline (verify it runs)\nCreate a schedule\nStep 8.1: Test the entire pipeline (verify it runs)\nOnly because each block ran successfully, there is no guarantee that the entire pipeline will run smoothly. So, we have to run the entire pipeline before creating a schedule.\nIn Mage, click on â€œTriggersâ€:\nAt the top, click on\nRun @once\n.\nThis will produce a trigger, and youâ€™ll see that its status will change to\nrunning\n:\nWhen done, it should say\ncompleted\nand switch to inactive state.\nIf we now refresh the BigQuery table, we can see that it has an updated date/time for the rows. This means that our pipeline ran successfully!\nStep 8.2: Create a schedule\nNow that we know that our pipeline works properly, letâ€™s create a trigger that runs every 5 minutes.\nIn Mageâ€™s Triggers view, click on\nNew trigger.\nSelect\nSchedule\nas the trigger type.\nGiven that the trigger will run every 5 minutes, letâ€™s name it\nevery_5_minutes\n.\nSelect custom as frequency and give the following cron expression:\n*/5 * * * *\n.\nA\ncron\nexpression is like a schedule for your computer tasks.\nItâ€™s a simple set of instructions that tells your system when to run a specific job.\nThe expression consists of five parts, representing minutes, hours, days, months, and days of the week. For example,\n*/15 * * * *\nmeans â€œevery 15 minutes, every hour, every day, every month, every day of the weekâ€.\nWhen ready with the trigger, click on\nSave changes\n.\nNow you have created your trigger, but as you can see its status is inactive. To start it, click on\nStart trigger\n.\nThe status switches to\nactive\n. If you browse back to the Triggers view, it will show you when itâ€™s set to trigger next.\nBe mindful of the fact that the time zone in Mage is in UTC.\nOnce the timer is set to go off, its status should change to\nrunning\n.\nAfter itâ€™s run, you can now refresh the BigQuery table and see that the data has now been updated again.\nCongratulations! Our journey is complete. I hope you had fun and learned something useful.\nIf you have any comments, please post them below. If you want to connect with me, Arben,\nhere is my LinkedIn\n!\nConclusion:\nUsing R in production is possible with tools like Mage and Google Cloud Platform. If you are an aspiring Digital Analytics professional, you now have a clear pathway forward for using R, Mage, and Google Cloud Platform to build your own data pipelines.\nHowever, if you are a Digital Analytics professional, you may be wondering how to get started with R. You may be wondering how to learn R, how to learn R for Digital Analytics, and how to learn R for Digital Analytics in a way that is practical and useful.\nIf you need to learn R for data analytics and data science, then I can help. Read on.\nStruggling to become a data scientist?\nYou know the feeling. Being unhappy with your current job.\nPromotions arenâ€™t happening. Youâ€™re stuck. Feeling Hopeless. Confusedâ€¦\nAnd youâ€™re praying that the next job interview will go better than the last 12â€¦\nâ€¦ But you know it wonâ€™t. Not unless you take control of your career.\nThe good news isâ€¦\nI Can Help You Speed It Up.\nIâ€™ve helped 6,107+ students learn data science for business from an elite business consultantâ€™s perspective.\nIâ€™ve worked with Fortune 500 companies like S&P Global, Apple, MRM McCann, and more.\nAnd I built a training program that gets my students life-changing data science careers (donâ€™t believe me?\nsee my testimonials here\n):\n6-Figure Data Science Job at CVS Health ($125K)\nSenior VP Of Analytics At JP Morgan ($200K)\n50%+ Raises & Promotions ($150K)\nLead Data Scientist at Northwestern Mutual ($175K)\n2X-ed Salary (From $60K to $120K)\n2 Competing ML Job Offers ($150K)\nPromotion to Lead Data Scientist ($175K)\nData Scientist Job at Verizon ($125K+)\nData Scientist Job at CitiBank ($100K + Bonus)\nWhenever you are ready, hereâ€™s the system they are taking:\nHereâ€™s the system\nthat has gotten aspiring data scientists, career transitioners, and life long learners data science jobs and promotionsâ€¦\nJoin My 5-Course R-Track Program Now!\n(And Become The Data Scientist You Were Meant To Be...)\nP.S. - Samantha landed her NEW Data Science R Developer job at CVS Health (Fortune 500).\nThis could be you.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nbusiness-science.io\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "Hey guys, welcome back to my R-tips newsletter. In todayâ€™s R-Tip, Arben Kqiku is sharing his exact 8-step framework for taking R into production for Digital Analytics projects. Youâ€™ll learn how to use R, Mage.ai, and Google Cloud Platform (GCP) to buil...",
      "meta_keywords": null,
      "og_description": "Hey guys, welcome back to my R-tips newsletter. In todayâ€™s R-Tip, Arben Kqiku is sharing his exact 8-step framework for taking R into production for Digital Analytics projects. Youâ€™ll learn how to use R, Mage.ai, and Google Cloud Platform (GCP) to buil...",
      "og_image": "https://www.business-science.io/assets/r_mage_gcp_workflow.jpg",
      "og_title": "Data Engineering in R: How to Build Your First Data Pipeline with R, Mage, and Google Cloud Platform (in under 45 Minutes) | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 44,
      "sitemap_lastmod": "2023-12-02T16:00:00+00:00",
      "twitter_description": "Hey guys, welcome back to my R-tips newsletter. In todayâ€™s R-Tip, Arben Kqiku is sharing his exact 8-step framework for taking R into production for Digital Analytics projects. Youâ€™ll learn how to use R, Mage.ai, and Google Cloud Platform (GCP) to buil...",
      "twitter_title": "Data Engineering in R: How to Build Your First Data Pipeline with R, Mage, and Google Cloud Platform (in under 45 Minutes) | R-bloggers",
      "url": "https://www.r-bloggers.com/2023/12/data-engineering-in-r-how-to-build-your-first-data-pipeline-with-r-mage-and-google-cloud-platform-in-under-45-minutes/",
      "word_count": 8804
    }
  }
}