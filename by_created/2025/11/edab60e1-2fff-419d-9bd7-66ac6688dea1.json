{
  "uuid": "edab60e1-2fff-419d-9bd7-66ac6688dea1",
  "created_at": "2025-11-22 19:58:03",
  "raw_json": {
    "article_author": null,
    "article_headline": null,
    "article_modified": null,
    "article_published": null,
    "article_section": null,
    "article_tags": null,
    "canonical_url": "https://www.r-bloggers.com/2025/07/repost-tidy-rag-in-r-with-ragnar/",
    "crawled_at": "2025-11-22T10:45:23.552148",
    "external_links": [
      {
        "href": "https://gettinggeneticsdone.blogspot.com/2025/07/tidy-rag-in-r-with-ragnar.html",
        "text": "Getting Genetics Done"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://blog.stephenturner.us/p/tidy-rag-in-r-with-ragnar",
        "text": "https://blog.stephenturner.us/p/tidy-rag-in-r-with-ragnar"
      },
      {
        "href": "https://ragnar.tidyverse.org/news/index.html",
        "text": "release notes"
      },
      {
        "href": "https://blog.stephenturner.us/p/gui-local-llm-rag",
        "text": null
      },
      {
        "href": "https://blog.stephenturner.us/p/gui-local-llm-rag",
        "text": null
      },
      {
        "href": "https://blog.stephenturner.us/p/gui-local-llm-rag",
        "text": "GUIs for Local LLMs with RAG"
      },
      {
        "href": "https://blog.stephenturner.us/p/gui-local-llm-rag",
        "text": null
      },
      {
        "href": "https://blog.stephenturner.us/p/gui-local-llm-rag",
        "text": null
      },
      {
        "href": "https://substack.com/profile/1536121-stephen-turner",
        "text": "Stephen Turner"
      },
      {
        "href": "https://blog.stephenturner.us/p/gui-local-llm-rag",
        "text": "Read full story"
      },
      {
        "href": "https://blog.stephenturner.us/p/local-rag-app-open-webui-zotero-library",
        "text": null
      },
      {
        "href": "https://blog.stephenturner.us/p/local-rag-app-open-webui-zotero-library",
        "text": null
      },
      {
        "href": "https://blog.stephenturner.us/p/local-rag-app-open-webui-zotero-library",
        "text": "Build a local RAG application with Open WebUI to chat with your Zotero library"
      },
      {
        "href": "https://blog.stephenturner.us/p/local-rag-app-open-webui-zotero-library",
        "text": null
      },
      {
        "href": "https://blog.stephenturner.us/p/local-rag-app-open-webui-zotero-library",
        "text": null
      },
      {
        "href": "https://substack.com/profile/1536121-stephen-turner",
        "text": "Stephen Turner"
      },
      {
        "href": "https://blog.stephenturner.us/p/local-rag-app-open-webui-zotero-library",
        "text": "Read full story"
      },
      {
        "href": "https://ragnar.tidyverse.org/",
        "text": "ragnar"
      },
      {
        "href": "https://ellmer.tidyverse.org/",
        "text": "ellmer"
      },
      {
        "href": "https://ellmer.tidyverse.org/",
        "text": "ellmer"
      },
      {
        "href": "https://simonpcouch.github.io/chores/",
        "text": "chores"
      },
      {
        "href": "https://simonpcouch.github.io/gander/",
        "text": "gander"
      },
      {
        "href": "https://mlverse.github.io/mall/",
        "text": "mall"
      },
      {
        "href": "https://github.com/tidyverse/ragnar",
        "text": "source"
      },
      {
        "href": "https://ragnar.tidyverse.org/",
        "text": "documentation"
      },
      {
        "href": "https://datascience.virginia.edu/",
        "text": "datascience.virginia.edu"
      },
      {
        "href": "https://platform.openai.com/",
        "text": "platform.openai.com"
      },
      {
        "href": "https://datascience.virginia.edu/",
        "text": "datascience.virginia.edu"
      },
      {
        "href": "https://ragnar.tidyverse.org/",
        "text": "ragnar documentation"
      },
      {
        "href": "https://datascience.virginia.edu/research/active-grants",
        "text": "active grants listing page"
      },
      {
        "href": "https://datascience.virginia.edu/research/active-grants",
        "text": "UVA SDS Active Grants"
      },
      {
        "href": "https://openai.com/api/pricing/",
        "text": "API pricing page"
      },
      {
        "href": "https://substackcdn.com/image/fetch/$s_!5IA-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f5b7cf8-6f68-4881-b66f-9f82e661e33e_1546x724.png",
        "text": null
      },
      {
        "href": "https://ollama.com/search?c=tools",
        "text": "models that support tool use"
      },
      {
        "href": "https://ollama.com/search?c=embedding",
        "text": "text embedding models"
      },
      {
        "href": "https://huggingface.co/nomic-ai/nomic-embed-text-v1",
        "text": "Nomic Embed"
      },
      {
        "href": "https://youtu.be/owDd1CJ17uQ",
        "text": "https://youtu.be/owDd1CJ17uQ"
      },
      {
        "href": "https://gettinggeneticsdone.blogspot.com/2025/07/tidy-rag-in-r-with-ragnar.html",
        "text": "Getting Genetics Done"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "h1_title": "R-bloggers",
    "html_title": "Repost: Tidy RAG in R with ragnar | R-bloggers",
    "images": [
      {
        "alt": "GUIs for Local LLMs with RAG",
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": "GUIs for Local LLMs with RAG",
        "base64": null,
        "src": "https://i0.wp.com/substackcdn.com/image/fetch/$s_!iwct!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb030a0ce-9159-41eb-8508-7ed7fdf3245b_1329x943.png?resize=140%2C140&ssl=1"
      },
      {
        "alt": "Build a local RAG application with Open WebUI to chat with your Zotero library",
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": "Build a local RAG application with Open WebUI to chat with your Zotero library",
        "base64": null,
        "src": "https://i1.wp.com/substackcdn.com/image/fetch/$s_!TlEc!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe0728de-ae64-44cd-80a3-325f742ecb89_1159x1169.png?resize=140%2C140&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i1.wp.com/substackcdn.com/image/fetch/$s_!5IA-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f5b7cf8-6f68-4881-b66f-9f82e661e33e_1546x724.png?resize=450%2C256&ssl=1"
      }
    ],
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/stephen-turner/",
        "text": "Stephen Turner"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "lang": "en-US",
    "main_html": "<article class=\"post-394133 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Repost: Tidy RAG in R with ragnar</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">July 15, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/stephen-turner/\">Stephen Turner</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://gettinggeneticsdone.blogspot.com/2025/07/tidy-rag-in-r-with-ragnar.html\"> Getting Genetics Done</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47--><p><mark> Reposted from the original at: <a href=\"https://blog.stephenturner.us/p/tidy-rag-in-r-with-ragnar\" rel=\"nofollow\" target=\"_blank\">https://blog.stephenturner.us/p/tidy-rag-in-r-with-ragnar</a></mark></p><p><i>Retrieval augmented generation in R using the ragnar package. Demonstration: scraping text from relevant links on a website and using RAG to ask about a university’s grant funding.</i></p><p> </p><p><em><strong>Note:</strong><span> After I wrote this post last week, \nthe Tidyverse team released ragnar 0.2.0 on July 12. Everything here \nshould still work, but take a look at the </span><a href=\"https://ragnar.tidyverse.org/news/index.html\" rel=\"nofollow\" target=\"_blank\">release notes</a><span> to learn about some nice new features that aren’t covered here.</span></em></p><div><hr/></div><p>I’ve written a little about retrieval-augmented generation (RAG) here before. First, about GUIs for local LLMs with RAG:</p><div class=\"digestPostEmbed-flwiST\" data-component-name=\"DigestPostEmbed\"><a href=\"https://blog.stephenturner.us/p/gui-local-llm-rag\" rel=\"nofollow\" target=\"_blank\"></a><div class=\"pencraft pc-display-flex pc-gap-16 pc-reset\"><a href=\"https://blog.stephenturner.us/p/gui-local-llm-rag\" rel=\"nofollow\" target=\"_blank\"><div class=\"pencraft pc-reset\" style=\"height: 70px; width: 70px;\"><picture><source type=\"image/webp\"/><img alt=\"GUIs for Local LLMs with RAG\" class=\"img-OACg1c smSquare-NGbPBa pencraft pc-reset\" data-lazy-src=\"https://i0.wp.com/substackcdn.com/image/fetch/$s_!iwct!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb030a0ce-9159-41eb-8508-7ed7fdf3245b_1329x943.png?resize=140%2C140&amp;ssl=1\" data-recalc-dims=\"1\" height=\"140\" loading=\"lazy\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" width=\"140\"/><noscript><img alt=\"GUIs for Local LLMs with RAG\" class=\"img-OACg1c smSquare-NGbPBa pencraft pc-reset\" data-recalc-dims=\"1\" height=\"140\" loading=\"lazy\" src=\"https://i0.wp.com/substackcdn.com/image/fetch/$s_!iwct!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb030a0ce-9159-41eb-8508-7ed7fdf3245b_1329x943.png?resize=140%2C140&amp;ssl=1\" width=\"140\"/></noscript></picture></div></a><div class=\"pencraft pc-display-flex pc-flexDirection-column pc-reset\"><a href=\"https://blog.stephenturner.us/p/gui-local-llm-rag\" rel=\"nofollow\" target=\"_blank\"><h4 class=\"pencraft pc-reset color-pub-primary-text-NyXPlw line-height-24-jnGwiv font-display-nhmvtD size-20-P_cSRT weight-bold-DmI9lw reset-IxiVJZ\">GUIs for Local LLMs with RAG</h4></a><div class=\"pencraft pc-display-flex pc-gap-4 pc-alignItems-center pc-reset\"><a href=\"https://blog.stephenturner.us/p/gui-local-llm-rag\" rel=\"nofollow\" target=\"_blank\"></a><div class=\"pencraft pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA\"><a href=\"https://blog.stephenturner.us/p/gui-local-llm-rag\" rel=\"nofollow\" target=\"_blank\"></a><a class=\"inheritColor-WetTGJ\" href=\"https://substack.com/profile/1536121-stephen-turner\" rel=\"nofollow\" target=\"_blank\">Stephen Turner</a></div><div class=\"pencraft pc-reset color-pub-secondary-text-hGQ02T reset-IxiVJZ\">·</div><div class=\"pencraft pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA\">Mar 14</div></div><div class=\"pencraft pc-display-flex pc-gap-16 pc-paddingTop-0 pc-paddingBottom-0 pc-alignItems-center pc-reset\"><a class=\"pencraft pc-reset align-center-y7ZD4w line-height-20-t4M0El font-text-qe4AeH size-13-hZTUKr weight-medium-fw81nC reset-IxiVJZ\" href=\"https://blog.stephenturner.us/p/gui-local-llm-rag\" rel=\"nofollow\" target=\"_blank\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-alignItems-center pc-reset link-HREYZo\"><span class=\"pencraft pc-reset color-accent-BVX_7M line-height-20-t4M0El font-text-qe4AeH size-14-MLPa7j weight-semibold-uqA4FV reset-IxiVJZ\">Read full story</span><svg class=\"lucide lucide-arrow-right\" fill=\"none\" height=\"16\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\"></svg></div></a></div></div></div></div><p>…and later on building a little RAG app to chat with a bunch of PDFs in your Zotero library using Open WebUI:</p><div class=\"digestPostEmbed-flwiST\" data-component-name=\"DigestPostEmbed\"><a href=\"https://blog.stephenturner.us/p/local-rag-app-open-webui-zotero-library\" rel=\"nofollow\" target=\"_blank\"></a><div class=\"pencraft pc-display-flex pc-gap-16 pc-reset\"><a href=\"https://blog.stephenturner.us/p/local-rag-app-open-webui-zotero-library\" rel=\"nofollow\" target=\"_blank\"><div class=\"pencraft pc-reset\" style=\"height: 70px; width: 70px;\"><picture><source type=\"image/webp\"/><img alt=\"Build a local RAG application with Open WebUI to chat with your Zotero library\" class=\"img-OACg1c smSquare-NGbPBa pencraft pc-reset\" data-lazy-src=\"https://i1.wp.com/substackcdn.com/image/fetch/$s_!TlEc!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe0728de-ae64-44cd-80a3-325f742ecb89_1159x1169.png?resize=140%2C140&amp;ssl=1\" data-recalc-dims=\"1\" height=\"140\" loading=\"lazy\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" width=\"140\"/><noscript><img alt=\"Build a local RAG application with Open WebUI to chat with your Zotero library\" class=\"img-OACg1c smSquare-NGbPBa pencraft pc-reset\" data-recalc-dims=\"1\" height=\"140\" loading=\"lazy\" src=\"https://i1.wp.com/substackcdn.com/image/fetch/$s_!TlEc!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe0728de-ae64-44cd-80a3-325f742ecb89_1159x1169.png?resize=140%2C140&amp;ssl=1\" width=\"140\"/></noscript></picture></div></a><div class=\"pencraft pc-display-flex pc-flexDirection-column pc-reset\"><a href=\"https://blog.stephenturner.us/p/local-rag-app-open-webui-zotero-library\" rel=\"nofollow\" target=\"_blank\"><h4 class=\"pencraft pc-reset color-pub-primary-text-NyXPlw line-height-24-jnGwiv font-display-nhmvtD size-20-P_cSRT weight-bold-DmI9lw reset-IxiVJZ\">Build a local RAG application with Open WebUI to chat with your Zotero library</h4></a><div class=\"pencraft pc-display-flex pc-gap-4 pc-alignItems-center pc-reset\"><a href=\"https://blog.stephenturner.us/p/local-rag-app-open-webui-zotero-library\" rel=\"nofollow\" target=\"_blank\"></a><div class=\"pencraft pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA\"><a href=\"https://blog.stephenturner.us/p/local-rag-app-open-webui-zotero-library\" rel=\"nofollow\" target=\"_blank\"></a><a class=\"inheritColor-WetTGJ\" href=\"https://substack.com/profile/1536121-stephen-turner\" rel=\"nofollow\" target=\"_blank\">Stephen Turner</a></div><div class=\"pencraft pc-reset color-pub-secondary-text-hGQ02T reset-IxiVJZ\">·</div><div class=\"pencraft pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA\">Apr 5</div></div><div class=\"pencraft pc-display-flex pc-gap-16 pc-paddingTop-0 pc-paddingBottom-0 pc-alignItems-center pc-reset\"><a class=\"pencraft pc-reset align-center-y7ZD4w line-height-20-t4M0El font-text-qe4AeH size-13-hZTUKr weight-medium-fw81nC reset-IxiVJZ\" href=\"https://blog.stephenturner.us/p/local-rag-app-open-webui-zotero-library\" rel=\"nofollow\" target=\"_blank\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-alignItems-center pc-reset link-HREYZo\"><span class=\"pencraft pc-reset color-accent-BVX_7M line-height-20-t4M0El font-text-qe4AeH size-14-MLPa7j weight-semibold-uqA4FV reset-IxiVJZ\">Read full story</span><svg class=\"lucide lucide-arrow-right\" fill=\"none\" height=\"16\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\"></svg></div></a></div></div></div></div><p>In\n an oversimplified nutshell: LLMs can’t help you with things that are \nnot in their training data or are past their training cutoff date. With \nRAG, you can provide relevant snippets from those documents as context \nto the LLM so that its answers are grounded in a collection of known \ncontent from a trusted document corpus. </p><p>Even more oversimplified: RAG lets you “chat with your documents.”</p><p><span>In\n this post I’ll demonstrate how to scrape text from a website and \nimplement a RAG workflow in R using a new addition to the tidyverse: </span><strong><a href=\"https://ragnar.tidyverse.org/\" rel=\"nofollow\" target=\"_blank\">ragnar</a></strong><span>, along with functionality from </span><a href=\"https://ellmer.tidyverse.org/\" rel=\"nofollow\" target=\"_blank\">ellmer</a><span> to interact with LLM APIs through R.</span></p><h2 class=\"header-anchor-post\">Demonstration<div class=\"pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent\"><div class=\"pencraft pc-display-contents pc-reset pubTheme-yiXxQA\"><div class=\"pencraft pc-reset header-anchor offset-top\" id=\"§demonstration\"></div></div></div></h2><p><span>Python has historically dominated the AI product development space, but with recent additions like </span><a href=\"https://ellmer.tidyverse.org/\" rel=\"nofollow\" target=\"_blank\">ellmer</a><span>, </span><a href=\"https://simonpcouch.github.io/chores/\" rel=\"nofollow\" target=\"_blank\">chores</a><span>, </span><a href=\"https://simonpcouch.github.io/gander/\" rel=\"nofollow\" target=\"_blank\">gander</a><span>, and </span><a href=\"https://mlverse.github.io/mall/\" rel=\"nofollow\" target=\"_blank\">mall</a><span>, R is quickly catching up.</span></p><p><span>Here I’m going to use the new </span><strong>ragnar</strong><span> package in the tidyverse (</span><a href=\"https://github.com/tidyverse/ragnar\" rel=\"nofollow\" target=\"_blank\">source</a><span>, </span><a href=\"https://ragnar.tidyverse.org/\" rel=\"nofollow\" target=\"_blank\">documentation</a><span>) to build a little RAG workflow in R that uses the OpenAI API. </span></p><p><span>I’m going to ingest information from the UVA School of Data Science (SDS) website at </span><strong><a href=\"https://datascience.virginia.edu/\" rel=\"nofollow\" target=\"_blank\">datascience.virginia.edu</a></strong><span>, then ask some questions that won’t have answers in the base model’s training data.</span></p><h3 class=\"header-anchor-post\">Setup<div class=\"pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent\"><div class=\"pencraft pc-display-contents pc-reset pubTheme-yiXxQA\"><div class=\"pencraft pc-reset header-anchor offset-top\" id=\"§setup\"></div></div></div></h3><p><span>If you want to follow along you’ll need an OpenAI API key. You can set that up at </span><a href=\"https://platform.openai.com/\" rel=\"nofollow\" target=\"_blank\">platform.openai.com</a><span>. Once you do that, run </span><code>usethis::edit_r_environ() </code><span>to add a new </span><code>OPENAI_API_KEY</code><span> environment variable, and restart your R session.</span></p><p>In\n R I’m going to need the ellmer and ragnar packages. Because ragnar \nisn’t yet on CRAN, I’ll have to install it with pak or devtools.</p><pre>install.packages(\"ellmer\")\npak::pak(\"tidyverse/ragnar\")</pre><h3 class=\"header-anchor-post\">Create a vector store<div class=\"pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent\"><div class=\"pencraft pc-display-contents pc-reset pubTheme-yiXxQA\"><div class=\"pencraft pc-reset header-anchor offset-top\" id=\"§create-a-vector-store\"></div></div></div></h3><p><span>The first thing I want to do is to find all the links to other pages at </span><a href=\"https://datascience.virginia.edu/\" rel=\"nofollow\" target=\"_blank\">datascience.virginia.edu</a><span>, scrape all of that content, and stick it into a DuckDB database. Most of this is modified straight from the </span><a href=\"https://ragnar.tidyverse.org/\" rel=\"nofollow\" target=\"_blank\">ragnar documentation</a><span>, hence the context chunking still looks like I’m ingesting a book.</span></p><pre>library(ragnar)\n\n# Find all links on a page\nbase_url &lt;- \"https://datascience.virginia.edu/\"\npages &lt;- ragnar_find_links(base_url)\n\n# Create and connect to a vector store\nstore_location &lt;- \"pairedends.ragnar.duckdb\"\nstore &lt;- ragnar_store_create(\n  store_location,\n  embed = \\(x) ragnar::embed_openai(x),\n  overwrite=TRUE\n)\n\n# Read each website and chunk it up\nfor (page in pages) {\n  message(\"ingesting: \", page)\n  chunks &lt;- page |&gt;\n    ragnar_read(frame_by_tags = c(\"h1\", \"h2\", \"h3\")) |&gt;\n    ragnar_chunk(boundaries = c(\"paragraph\", \"sentence\")) |&gt;\n    # add context to chunks\n    dplyr::mutate(\n      text = glue::glue(\n        r\"---(\n        # Excerpt from UVA School of Data Science (SDS) page\"\n        link: {origin}\n        chapter: {h1}\n        section: {h2}\n        subsection: {h3}\n        content: {text}\n\n        )---\"\n      )\n    )\n  ragnar_store_insert(store, chunks)\n}\n# Build the index\nragnar_store_build_index(store)</pre><h3 class=\"header-anchor-post\">Retrieval<div class=\"pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent\"><div class=\"pencraft pc-display-contents pc-reset pubTheme-yiXxQA\"><div class=\"pencraft pc-reset header-anchor offset-top\" id=\"§retrieval\"></div></div></div></h3><p>Now\n suppose we want to ask questions about research grant funding at the \nUVA School of Data Science (SDS). First, let’s see what ChatGPT tells us\n without providing any context at all when we ask it to tell us about \nSDS’s active grant funding.</p><blockquote><p>I don’t have specific \ninformation about “SDS’s active grant funding” because “SDS” could refer\n to several different organizations or entities (e.g., Social and \nDecision Sciences departments, Sustainable Development Solutions, \nStudents for a Democratic Society, or a company with the acronym SDS).</p></blockquote><p><span>Now\n let’s use the OpenAI API providing context from the vector store we \njust created that should have information about UVA SDS’s active funding\n from their </span><a href=\"https://datascience.virginia.edu/research/active-grants\" rel=\"nofollow\" target=\"_blank\">active grants listing page</a><span>.</span></p><pre>library(ragnar)\nstore_location &lt;- \"pairedends.ragnar.duckdb\"\nstore &lt;- ragnar_store_connect(store_location, read_only = TRUE)\n\n# Get relevant chunks\ntext &lt;- \"Tell me about some of SDS's active grant funding.\"\nrelevant_chunks &lt;- ragnar_retrieve_vss(\n  store,\n  text,\n  top_k = 10\n)\nrelevant_chunks\n\n#'  Register ellmer tool\n#' You can register an ellmer tool to let the LLM retrieve chunks.\nsystem_prompt &lt;- stringr::str_squish(\n  r\"--(\n  You are an expert about UVA's School of Data Science.\n  You are concise. You always respond by first direct\n  quoting material from the SDS website, then adding\n  your own additional context and interpertation.\n  Always include links to the source materials used.\n  )--\"\n)\nchat &lt;- ellmer::chat_openai(\n  system_prompt,\n  model = \"gpt-4.1-mini\",\n  params = ellmer::params(temperature = .5)\n)\n\n# Register a retrieve tool with ellmer\nragnar_register_tool_retrieve(chat, store, top_k = 10)\n\n# Run the query\nchat$chat(text)</pre><p>Now when asking about some of SDS’s active grant funding, we get a better response:</p><blockquote><p>Here are some examples of active grant funding at UVA's School of Data Science (SDS):</p><ul><li><p>Resource\n and Data Exchange (RDE) has a grant award of $5,000,000 with a \nperformance period from Feb 29, 2024 to Feb 27, 2029, currently 25% \ncompleted.</p></li><li><p>Biomedical Data Science Innovation Labs: An Intensive Research Project Development Program has an award amount of $1,943,352.</p></li><li><p>Supporting\n Pre-Service Teachers Mathematical Discourse through Co-Design of \nTeaching Simulation Tools is sponsored by the US NSF with a total award \nof $250,000.</p></li><li><p>Activity Aware Bayesian Deep Learning is sponsored by the US NSF.</p></li><li><p>Enhancing\n Security and Privacy of Community Cyberinfrastructures for \nCollaborative Research has a total award of $882,518 from the US NSF.</p></li><li><p>Evaluating the Efficacy of Repurposed Medications has an award amount of $86,134.</p></li><li><p>Accelerating racial and ethnic equity in SCI rehabilitation outcomes has an award amount of $53,170.</p></li><li><p>The application of data science on financial systems with an emphasis on safety and security has an award amount of $5,000.</p></li></ul><p>These grants cover a range of topics from education, biomedical innovation, security, to social equity in rehabilitation.</p><p><span>Source: </span><a href=\"https://datascience.virginia.edu/research/active-grants\" rel=\"nofollow\" target=\"_blank\">UVA SDS Active Grants</a></p></blockquote><h2 class=\"header-anchor-post\">API cost and local models<div class=\"pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent\"><div class=\"pencraft pc-display-contents pc-reset pubTheme-yiXxQA\"><div class=\"pencraft pc-reset header-anchor offset-top\" id=\"§api-cost-and-local-models\"></div></div></div></h2><p><span>\n As I’m writing this, the cost for GPT-4.1 mini is ridiculously cheap at\n $0.40 cents per million input tokens (see more on their </span><a href=\"https://openai.com/api/pricing/\" rel=\"nofollow\" target=\"_blank\">API pricing page</a><span>). </span><strong>The demonstration here cost me $0.01 cent</strong><span> (the text embedding and vector storage cost a fraction of a penny in addition to the input/output completions). </span></p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!5IA-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f5b7cf8-6f68-4881-b66f-9f82e661e33e_1546x724.png\" rel=\"nofollow\" target=\"_blank\"><div class=\"image2-inset\"><picture><source type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-lazy-src=\"https://i1.wp.com/substackcdn.com/image/fetch/$s_!5IA-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f5b7cf8-6f68-4881-b66f-9f82e661e33e_1546x724.png?resize=450%2C256&amp;ssl=1\" data-recalc-dims=\"1\" height=\"256 .6868131868132\" loading=\"lazy\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" width=\"450\"/><noscript><img 161117390?img='https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f5b7cf8-6f68-4881-b66f-9f82e661e33e_1546x724.png\",\"isProcessing\":false,\"align\":null,\"offset\":false}\"' 6f5b7cf8-6f68-4881-b66f-9f82e661e33e_1546x724.png\",\"srcnowatermark\":null,\"fullscreen\":null,\"imagesiz=\"\" alt=\"\" blog.stephenturner.us=\"\" class=\"sizing-normal\" data-attrs=\"{\" data-recalc-dims=\"1\" height=\"256 .6868131868132\" i=\"\" images=\"\" loading=\"lazy\" png\",\"href\":null,\"belowthefold\":true,\"topimage\":false,\"internalredirect\":\"https:=\"\" public=\"\" src=\"https://i1.wp.com/substackcdn.com/image/fetch/$s_!5IA-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f5b7cf8-6f68-4881-b66f-9f82e661e33e_1546x724.png?resize=450%2C256&amp;ssl=1\" src\":\"https:=\"\" substack-post-media.s3.amazonaws.com=\"\" width=\"450\"/></noscript></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><div class=\"pencraft pc-reset icon-container view-image\"><svg class=\"lucide lucide-maximize2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"></svg></div></div></div></div></a></figure></div><p><span>There are plenty of open/local </span><a href=\"https://ollama.com/search?c=tools\" rel=\"nofollow\" target=\"_blank\">models that support tool use</a><span>, as well as open/local </span><a href=\"https://ollama.com/search?c=embedding\" rel=\"nofollow\" target=\"_blank\">text embedding models</a><span>, all of which can be run through Ollama. I tried the same exercise above using </span><a href=\"https://huggingface.co/nomic-ai/nomic-embed-text-v1\" rel=\"nofollow\" target=\"_blank\">Nomic Embed</a><span>\n through Ollama for text embedding, and tried several with tool calling \nabilities, including qwen3, mistral, llama3.1, llama3.2, llama3.3, and \nthe new llama4, and the results were all </span><em>terrible</em><span>.\n I don't know if this was due to the inferiority of the models \nthemselves, or if this was the embedding model that I chose, which \nincidentally happened to be the most popular embedding model available \nin Ollama. Just put $1 on your OpenAI API account and get to work and \nstop worrying about it.</span></p><div class=\"subscribe-widget is-signed-up is-fully-subscribed\" data-component-name=\"SubscribeWidget\"><div class=\"pencraft pc-reset button-wrapper\"><div class=\"pencraft pc-display-flex pc-justifyContent-center pc-reset\"></div></div></div><h2 class=\"header-anchor-post\">Learning more<div class=\"pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent\"><div class=\"pencraft pc-display-contents pc-reset pubTheme-yiXxQA\"><div class=\"pencraft pc-reset header-anchor offset-top\" id=\"§learning-more\"></div></div></div></h2><p><span>This recent webinar from Posit CTO Joe Cheng doesn’t cover RAG at all. In fact, he mentions near the top that RAG should </span><em><strong>not </strong></em><span>be\n your first choice when simply changing a system prompt would be good \nenough. It’s a good talk and I learned a few nice things along the way.</span></p><div class=\"youtube-wrap\" data-attrs=\"{\" data-component-name=\"Youtube2ToDOM\" id=\"youtube2-owDd1CJ17uQ\" videoid\":\"owdd1cj17uq\",\"starttime\":null,\"endtime\":null}\"=\"\"><div class=\"youtube-inner\"></div></div><div class=\"subscribe-widget is-signed-up is-fully-subscribed\" data-component-name=\"SubscribeWidget\"><div class=\"pencraft pc-reset button-wrapper\"><div class=\"pencraft pc-display-flex pc-justifyContent-center pc-reset\"><a href=\"https://youtu.be/owDd1CJ17uQ\" rel=\"nofollow\" target=\"_blank\">https://youtu.be/owDd1CJ17uQ</a></div></div></div><div class=\"blogger-post-footer\">Getting Genetics Done by Stephen Turner is licensed under a Creative Commons Attribution (CC BY) License.</div>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://gettinggeneticsdone.blogspot.com/2025/07/tidy-rag-in-r-with-ragnar.html\"> Getting Genetics Done</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
    "main_text": "Repost: Tidy RAG in R with ragnar\nPosted on\nJuly 15, 2025\nby\nStephen Turner\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nGetting Genetics Done\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nReposted from the original at:\nhttps://blog.stephenturner.us/p/tidy-rag-in-r-with-ragnar\nRetrieval augmented generation in R using the ragnar package. Demonstration: scraping text from relevant links on a website and using RAG to ask about a university’s grant funding.\nNote:\nAfter I wrote this post last week, \nthe Tidyverse team released ragnar 0.2.0 on July 12. Everything here \nshould still work, but take a look at the\nrelease notes\nto learn about some nice new features that aren’t covered here.\nI’ve written a little about retrieval-augmented generation (RAG) here before. First, about GUIs for local LLMs with RAG:\nGUIs for Local LLMs with RAG\nStephen Turner\n·\nMar 14\nRead full story\n…and later on building a little RAG app to chat with a bunch of PDFs in your Zotero library using Open WebUI:\nBuild a local RAG application with Open WebUI to chat with your Zotero library\nStephen Turner\n·\nApr 5\nRead full story\nIn\n an oversimplified nutshell: LLMs can’t help you with things that are \nnot in their training data or are past their training cutoff date. With \nRAG, you can provide relevant snippets from those documents as context \nto the LLM so that its answers are grounded in a collection of known \ncontent from a trusted document corpus.\nEven more oversimplified: RAG lets you “chat with your documents.”\nIn\n this post I’ll demonstrate how to scrape text from a website and \nimplement a RAG workflow in R using a new addition to the tidyverse:\nragnar\n, along with functionality from\nellmer\nto interact with LLM APIs through R.\nDemonstration\nPython has historically dominated the AI product development space, but with recent additions like\nellmer\n,\nchores\n,\ngander\n, and\nmall\n, R is quickly catching up.\nHere I’m going to use the new\nragnar\npackage in the tidyverse (\nsource\n,\ndocumentation\n) to build a little RAG workflow in R that uses the OpenAI API.\nI’m going to ingest information from the UVA School of Data Science (SDS) website at\ndatascience.virginia.edu\n, then ask some questions that won’t have answers in the base model’s training data.\nSetup\nIf you want to follow along you’ll need an OpenAI API key. You can set that up at\nplatform.openai.com\n. Once you do that, run\nusethis::edit_r_environ()\nto add a new\nOPENAI_API_KEY\nenvironment variable, and restart your R session.\nIn\n R I’m going to need the ellmer and ragnar packages. Because ragnar \nisn’t yet on CRAN, I’ll have to install it with pak or devtools.\ninstall.packages(\"ellmer\")\npak::pak(\"tidyverse/ragnar\")\nCreate a vector store\nThe first thing I want to do is to find all the links to other pages at\ndatascience.virginia.edu\n, scrape all of that content, and stick it into a DuckDB database. Most of this is modified straight from the\nragnar documentation\n, hence the context chunking still looks like I’m ingesting a book.\nlibrary(ragnar)\n\n# Find all links on a page\nbase_url <- \"https://datascience.virginia.edu/\"\npages <- ragnar_find_links(base_url)\n\n# Create and connect to a vector store\nstore_location <- \"pairedends.ragnar.duckdb\"\nstore <- ragnar_store_create(\n  store_location,\n  embed = \\(x) ragnar::embed_openai(x),\n  overwrite=TRUE\n)\n\n# Read each website and chunk it up\nfor (page in pages) {\n  message(\"ingesting: \", page)\n  chunks <- page |>\n    ragnar_read(frame_by_tags = c(\"h1\", \"h2\", \"h3\")) |>\n    ragnar_chunk(boundaries = c(\"paragraph\", \"sentence\")) |>\n    # add context to chunks\n    dplyr::mutate(\n      text = glue::glue(\n        r\"---(\n        # Excerpt from UVA School of Data Science (SDS) page\"\n        link: {origin}\n        chapter: {h1}\n        section: {h2}\n        subsection: {h3}\n        content: {text}\n\n        )---\"\n      )\n    )\n  ragnar_store_insert(store, chunks)\n}\n# Build the index\nragnar_store_build_index(store)\nRetrieval\nNow\n suppose we want to ask questions about research grant funding at the \nUVA School of Data Science (SDS). First, let’s see what ChatGPT tells us\n without providing any context at all when we ask it to tell us about \nSDS’s active grant funding.\nI don’t have specific \ninformation about “SDS’s active grant funding” because “SDS” could refer\n to several different organizations or entities (e.g., Social and \nDecision Sciences departments, Sustainable Development Solutions, \nStudents for a Democratic Society, or a company with the acronym SDS).\nNow\n let’s use the OpenAI API providing context from the vector store we \njust created that should have information about UVA SDS’s active funding\n from their\nactive grants listing page\n.\nlibrary(ragnar)\nstore_location <- \"pairedends.ragnar.duckdb\"\nstore <- ragnar_store_connect(store_location, read_only = TRUE)\n\n# Get relevant chunks\ntext <- \"Tell me about some of SDS's active grant funding.\"\nrelevant_chunks <- ragnar_retrieve_vss(\n  store,\n  text,\n  top_k = 10\n)\nrelevant_chunks\n\n#'  Register ellmer tool\n#' You can register an ellmer tool to let the LLM retrieve chunks.\nsystem_prompt <- stringr::str_squish(\n  r\"--(\n  You are an expert about UVA's School of Data Science.\n  You are concise. You always respond by first direct\n  quoting material from the SDS website, then adding\n  your own additional context and interpertation.\n  Always include links to the source materials used.\n  )--\"\n)\nchat <- ellmer::chat_openai(\n  system_prompt,\n  model = \"gpt-4.1-mini\",\n  params = ellmer::params(temperature = .5)\n)\n\n# Register a retrieve tool with ellmer\nragnar_register_tool_retrieve(chat, store, top_k = 10)\n\n# Run the query\nchat$chat(text)\nNow when asking about some of SDS’s active grant funding, we get a better response:\nHere are some examples of active grant funding at UVA's School of Data Science (SDS):\nResource\n and Data Exchange (RDE) has a grant award of $5,000,000 with a \nperformance period from Feb 29, 2024 to Feb 27, 2029, currently 25% \ncompleted.\nBiomedical Data Science Innovation Labs: An Intensive Research Project Development Program has an award amount of $1,943,352.\nSupporting\n Pre-Service Teachers Mathematical Discourse through Co-Design of \nTeaching Simulation Tools is sponsored by the US NSF with a total award \nof $250,000.\nActivity Aware Bayesian Deep Learning is sponsored by the US NSF.\nEnhancing\n Security and Privacy of Community Cyberinfrastructures for \nCollaborative Research has a total award of $882,518 from the US NSF.\nEvaluating the Efficacy of Repurposed Medications has an award amount of $86,134.\nAccelerating racial and ethnic equity in SCI rehabilitation outcomes has an award amount of $53,170.\nThe application of data science on financial systems with an emphasis on safety and security has an award amount of $5,000.\nThese grants cover a range of topics from education, biomedical innovation, security, to social equity in rehabilitation.\nSource:\nUVA SDS Active Grants\nAPI cost and local models\nAs I’m writing this, the cost for GPT-4.1 mini is ridiculously cheap at\n $0.40 cents per million input tokens (see more on their\nAPI pricing page\n).\nThe demonstration here cost me $0.01 cent\n(the text embedding and vector storage cost a fraction of a penny in addition to the input/output completions).\nThere are plenty of open/local\nmodels that support tool use\n, as well as open/local\ntext embedding models\n, all of which can be run through Ollama. I tried the same exercise above using\nNomic Embed\nthrough Ollama for text embedding, and tried several with tool calling \nabilities, including qwen3, mistral, llama3.1, llama3.2, llama3.3, and \nthe new llama4, and the results were all\nterrible\n.\n I don't know if this was due to the inferiority of the models \nthemselves, or if this was the embedding model that I chose, which \nincidentally happened to be the most popular embedding model available \nin Ollama. Just put $1 on your OpenAI API account and get to work and \nstop worrying about it.\nLearning more\nThis recent webinar from Posit CTO Joe Cheng doesn’t cover RAG at all. In fact, he mentions near the top that RAG should\nnot\nbe\n your first choice when simply changing a system prompt would be good \nenough. It’s a good talk and I learned a few nice things along the way.\nhttps://youtu.be/owDd1CJ17uQ\nGetting Genetics Done by Stephen Turner is licensed under a Creative Commons Attribution (CC BY) License.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nGetting Genetics Done\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "meta_description": "Reposted from the original at: https://blog.stephenturner.us/p/tidy-rag-in-r-with-ragnarRetrieval augmented generation in R using the ragnar package. Demonstration: scraping text from relevant links on a website and using RAG to ask about a unive...",
    "meta_keywords": null,
    "og_description": "Reposted from the original at: https://blog.stephenturner.us/p/tidy-rag-in-r-with-ragnarRetrieval augmented generation in R using the ragnar package. Demonstration: scraping text from relevant links on a website and using RAG to ask about a unive...",
    "og_image": "https://substackcdn.com/image/fetch/$s_!iwct!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb030a0ce-9159-41eb-8508-7ed7fdf3245b_1329x943.png",
    "og_title": "Repost: Tidy RAG in R with ragnar | R-bloggers",
    "raw_jsonld_article": null,
    "reading_time_min": 7.3,
    "sitemap_lastmod": null,
    "twitter_description": "Reposted from the original at: https://blog.stephenturner.us/p/tidy-rag-in-r-with-ragnarRetrieval augmented generation in R using the ragnar package. Demonstration: scraping text from relevant links on a website and using RAG to ask about a unive...",
    "twitter_title": "Repost: Tidy RAG in R with ragnar | R-bloggers",
    "url": "https://www.r-bloggers.com/2025/07/repost-tidy-rag-in-r-with-ragnar/",
    "word_count": 1457
  }
}