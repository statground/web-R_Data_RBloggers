{
  "id": "d9293b38dc59718097c834e4f8e5b12139aeb2f2",
  "url": "https://www.r-bloggers.com/2024/12/depression-incidence-by-county-and-vote-for-trump-by-ellis2013nz/",
  "created_at_utc": "2025-11-22T19:59:35Z",
  "data": null,
  "raw_original": {
    "uuid": "d97fa6b4-1241-41d7-8bff-fee06484a07a",
    "created_at": "2025-11-22 19:59:35",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2024/12/depression-incidence-by-county-and-vote-for-trump-by-ellis2013nz/",
      "crawled_at": "2025-11-22T10:56:31.832359",
      "external_links": [
        {
          "href": "https://freerangestats.info/blog/2024/12/23/depression-and-vote",
          "text": "free range statistics - R"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://bsky.app/profile/mchinn.bsky.social/post/3ldwkfv7uz22v",
          "text": "skeet floated across my Bluesky feed"
        },
        {
          "href": "https://fromthebottomoftheheap.net/2021/02/02/random-effects-in-gams/",
          "text": "a great discussion of this"
        },
        {
          "href": "https://freerangestats.info/blog/2024/12/23/depression-and-vote",
          "text": "free range statistics - R"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Depression incidence by county and vote for Trump by @ellis2013nz | R-bloggers",
      "images": [
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/freerangestats.info/img/0286-ols.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/freerangestats.info/img/0286-glm.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/freerangestats.info/img/0286-glmer.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/freerangestats.info/img/0286-gam.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/freerangestats.info/img/0286-counties-map.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/freerangestats.info/img/0286-rubber-sheet.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/freerangestats.info/img/0286-gam-spatial.png?w=450&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/free-range-statistics-r/",
          "text": "free range statistics - R"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-389396 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Depression incidence by county and vote for Trump by @ellis2013nz</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">December 22, 2024</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/free-range-statistics-r/\">free range statistics - R</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://freerangestats.info/blog/2024/12/23/depression-and-vote\"> free range statistics - R</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47--><p>A <a href=\"https://bsky.app/profile/mchinn.bsky.social/post/3ldwkfv7uz22v\" rel=\"nofollow\" target=\"_blank\">skeet floated across my Bluesky feed</a> that looked at the cross-sectional relationship between incidence of depression in 2020 and voting for Trump in the 2024 Presidential election. The data in the skeet and immediate blog post was at state level, but the hypothesis of interest in an article that sparked all this was an individual one (are depressed people voting for Trump). I don’t have the individual level microdata that might help explore the actual hypothesis, but I was surprised to see that the state-level regression had a significant evidence of an effect, and wondered if this would continue at the county level, which still has relatively accessible data.</p>\n<p>This also led me down an interesting but familiar rabbit hole of multilevel modelling in the presence of a spatial correlation nuisance.</p>\n<h2 id=\"ordinary-least-squares\">Ordinary Least Squares</h2>\n<p>Well, it turns out depression at the county level does correlate with voting for Trump, as we can see with this first, simple chart which shows the expected vote based on a model fit with ordinary least squares (OLS):</p>\n<object data=\"https://freerangestats.info/img/0286-ols.svg\" type=\"image/svg+xml\" width=\"450\"><img data-lazy-src=\"https://i1.wp.com/freerangestats.info/img/0286-ols.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i1.wp.com/freerangestats.info/img/0286-ols.png?w=450&amp;ssl=1\"/></noscript></object>\n<p>I’ll be fitting some more fancy models and getting better charts further down, but the basic message is the same as in this one – counties with higher incidence of depression had a higher proportion of their vote going to Trump than was the case with counties with lower levels of depression.</p>\n<p>Before I say anything else or show any code, let’s get straight that this is very possibly not a causal link. In fact there are at least three things that are plausibly happening here:</p>\n<ol>\n<li>People who are more depressed were more likely to vote for Trump (or less likely to turn up to vote against him, which given voluntary voting, has a similar result although for importantly different reasons)</li>\n<li>People (who may themselves be not depressed) who are in areas with lots of depressed people around them were more likely to vote for Trump (eg because voters think “Trump will be able to do something about all the depressed people around here”)</li>\n<li>Some underlying factor (eg economic, social or cultural conditions) that leads to some areas having higher rates of depression also leads to higher votes for Trump, through some other mechanism</li>\n</ol>\n<p>My expectation is that #3 is the more likely explanation, but I personally don’t actually have evidence to choose between them. Nor are these hypotheses mutually exclusive; two or all of them might be true at once.</p>\n<p>OK here’s the code that gets that data and produces the first chart and a simple model with a statistically significant effect:</p>\n<figure class=\"highlight\"><pre>library(tidyverse)\nlibrary(readxl)\nlibrary(mgcv)\nlibrary(lme4)\nlibrary(sf)\n\n# county level prevalence of depression at (have to hit the 'download' button)\n# https://stacks.cdc.gov/view/cdc/129404\ndep &lt;- read_excel(\"cdc_129404_DS1.xlsx\", skip = 1)\n\nfn &lt;- \"2024_US_County_Level_Presidential_Results.csv\"\nif(!file.exists(fn)){\n  download.file(\"https://raw.githubusercontent.com/tonmcg/US_County_Level_Election_Results_08-24/refs/heads/master/2024_US_County_Level_Presidential_Results.csv\",\n                destfile = fn)\n}\n\nvotes &lt;- read_csv(\"2024_US_County_Level_Presidential_Results.csv\")\n\ncombined &lt;- votes |&gt;\n  inner_join(dep, by = c(\"county_fips\" = \"CountyFIPS code\")) |&gt;\n  mutate(cpe = `Crude Prevalence Estimate` / 100,\n         aape = `Age-adjusted Prevalence Estimate` / 100)\n\n# what was missed in this join?\nvotes |&gt;\n  anti_join(dep, by = c(\"county_fips\" = \"CountyFIPS code\")) |&gt;\n  count(state_name)\n# 37 counties in Alaska, 9 and Connecticut and 7 in DC. Will ignore these\n# for my purposes.\n\n\n#========================modelling==================\n\n\n#----------Ordinary Least Squares------------------\n\nmodel &lt;- lm(per_gop ~ cpe, data = combined)\nsummary(model)\n# note several things could be happening here:\n# - depressed people makes you vote for Trump\n# - being around depressed people makes you vote for Trump\n# - some underlying condition (eg economic) both leads to higher depression\n#   and more likely to vote for Trump. This seems the most likely.\n\nthe_caption = \"Source: data from tonmcg and CDC; analysis by freerangestats.info\"\n\n# draw chart:\ncombined |&gt;\n  ggplot(aes(x= cpe, y = per_gop)) +\n  geom_point(colour = \"steelblue\", alpha = 0.5) +\n  geom_smooth(method = \"lm\", fill = \"black\", colour = \"white\", alpha = 0.8) +\n  scale_x_continuous(label = percent) +\n  scale_y_continuous(label = percent) +\n  labs(x = \"Crude prevalence estimate of depression\",\n       y = \"Percentage vote for Trump in 2024 election\",\n       subtitle = \"Line is ordinary least squares fit to all county data together\",\n       title = \"Counties with more depression voted more for Trump\",\n       caption = the_caption)</pre></figure>\n<p>Excerpt from the results:</p>\n<pre>Coefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.40002    0.01861   21.49   &lt;2e-16 ***\ncpe          1.27547    0.08712   14.64   &lt;2e-16 ***\n</pre>\n<h2 id=\"generalized-linear-model-with-a-quasibinomial-response\">Generalized linear model with a quasibinomial response</h2>\n<p>Now, I wanted to improve this for all sorts of reasons, although I suspected it was actually good enough for pragmatic purposes - case proven really, that counties with more depressed people voted more for Trump. Proven enough to justify the further work with additional data needed to explore why. But I had some statistical loose ends to tidy up. First of which is that vote is a proportion, and it feels icky to use OLS (which can send values above 1 and below 0) to model a proportion when we have generalized linear models (GLMs) designed for the job and easily available.</p>\n<p>I didn’t want to use a straight logistic regression because the county-level data is far more dispersed than would be expected if it really were individuals making their own voting decisions. But a GLM with a quasi-binomial response keeps the link function used in logistic regression and the relationship of the mean and variance, while allowing the variance to be larger (or smaller) by some consistent ratio. Here’s what I get with that GLM:</p>\n<object data=\"https://freerangestats.info/img/0286-glm.svg\" type=\"image/svg+xml\" width=\"450\"><img data-lazy-src=\"https://i2.wp.com/freerangestats.info/img/0286-glm.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i2.wp.com/freerangestats.info/img/0286-glm.png?w=450&amp;ssl=1\"/></noscript></object>\n<p>…created with this code. Note that we now have started to weight counties based on their overall number of voters, which makes particular sense for a binomial or similar family response. I suspect this is one of the key issues driving the line vertically down, compared to the OLS version. The other key difference of course is that now it is slightly curved, as the ‘linear’ in a GLM is on the link scale, not the scale the response is originally observed on and used for this chart.</p>\n<figure class=\"highlight\"><pre>#----------------Quasibinomial GLM----------------\n\nmodel2 &lt;- glm(per_gop ~ cpe, \n              family = quasibinomial, data = combined, weights = total_votes)\nsummary(model2)\n\npreds2 &lt;- predict(model2, type = \"response\", se.fit = TRUE)\n\n# draw chart:\ncombined |&gt;\n  mutate(fit = preds2$fit,\n         se = preds2$se.fit,\n         lower = fit - 1.96 * se,\n         upper = fit + 1.96 * se) |&gt;\n  ggplot(aes(x = cpe, y = per_gop)) +\n  geom_point(colour = \"steelblue\", alpha = 0.5) +\n  geom_ribbon(aes(ymin = lower, ymax = upper), fill = \"black\", alpha = 0.5) +\n  geom_line(aes(y = fit), colour = \"white\") +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(limits = c(0, 1), label = percent) +\n  scale_x_continuous(label  = percent)  +\n  labs(x = \"Crude prevalence estimate of depression\",\n       y = \"Percentage vote for Trump in 2024 election\",\n       subtitle = \"Line is generalized linear model with quasibinomial response, fit to all county data together\",\n       title = \"Counties with more depression voted more for Trump\",\n       caption = the_caption)</pre></figure>\n<p>Here’s an excerpt from that summary of model2:</p>\n<pre>Coefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.82178    0.06823  -26.70   &lt;2e-16 ***\ncpe          9.25748    0.34153   27.11   &lt;2e-16 ***\n</pre>\n<p>We see <code>cpe</code> (crude prevalence estimate, ie not the age-standardised one) has very definitely “significant” evidence that it isn’t zero, with a point estimate of 9.3 and a standard error of only 0.3.</p>\n<h2 id=\"introducing-a-state-effect\">Introducing a state effect</h2>\n<p>One thing that all the world knows is how spatially-based are US politics. Everything is thought of in terms of states, in particular, and smaller areas sometimes. It follows naturally from the ways that US politics is discussed that we should use a multi-level ie mixed-effects model with state as a random intercept, when looking at something like the overall relationship between depression and voting. In other words, we have to let the vote for Trump in any state vary for all the state-specific things that aren’t in our model, and see if after doing that we still get an overall  (constant nation-wide) relationship between depression and voting in the counties within each state.</p>\n<p>I often reach to the <code>lme4</code> library by Bates, Bolker and Walker as my starting point for mixed effects models and this is the results in this case:</p>\n<object data=\"https://freerangestats.info/img/0286-glmer.svg\" type=\"image/svg+xml\" width=\"450\"><img data-lazy-src=\"https://i1.wp.com/freerangestats.info/img/0286-glmer.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i1.wp.com/freerangestats.info/img/0286-glmer.png?w=450&amp;ssl=1\"/></noscript></object>\n<p>Note we have a bunch of parallel (on link scale) lines, one per state, with their height varying by the state random effect. I love the effect of this chart, but unfortunately <code>lme4::glmer</code> which is used in this case doesn’t let us use a quasibinomial family response; we have to use a binomial response which forces the variance to equal <code>p(1-p)/n</code>, not just be proportional to it. The net result is that the confidence intervals are much narrower than is justified.</p>\n<p>An alternative way to fit a similar model is the the <code>gam()</code> function from the amazing <code>mgcv</code> library by Simon Wood. There’s <a href=\"https://fromthebottomoftheheap.net/2021/02/02/random-effects-in-gams/\" rel=\"nofollow\" target=\"_blank\">a great discussion of this</a> on Gavin Simpson’s blog. By specifying a spline around a categorical factor like <code>s(state_factor, bs = 're')</code> (‘re’ stands for random effect) we can use <code>gam()</code> to add random intercepts while using the full range of families available to <code>gam()</code> including quasibinomial. That gives us this alternative version of the last model; this time with much fatter (and realistic) confidence intervals!:</p>\n<object data=\"https://freerangestats.info/img/0286-gam.svg\" type=\"image/svg+xml\" width=\"450\"><img data-lazy-src=\"https://i0.wp.com/freerangestats.info/img/0286-gam.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i0.wp.com/freerangestats.info/img/0286-gam.png?w=450&amp;ssl=1\"/></noscript></object>\n<p>The confidence intervals are now very fat. But there’s still no doubt about the significance of the evidence of the relationship of the crude prevalence of depression on voting behaviour, even after allowing a random state-level intercept.</p>\n<p>Here’s the code for both the <code>glmer</code> and <code>gam</code> versions of this random state effect model:</p>\n<figure class=\"highlight\"><pre>#---------------------With state random effect with lmer4::glmer--------------------\n\nmodel4 &lt;- lme4::glmer(per_gop ~ cpe + (1 | state_name), \n                      family = \"binomial\", data = combined, \n                      weights = total_votes)\n# note can't use quasibinomial family with glmer so we aren;t really dealing\n# properly with the overdispersion. what to do about that? Confidence intervals\n# will be too narrow. Various alternatives posisble.\n\nsummary(model4)\n\npreds4 &lt;- predict(model4, se.fit = TRUE, type = \"response\")\n\ncombined |&gt;\n  mutate(fit = preds4$fit,\n         se = preds4$se.fit,\n         lower = fit - 1.96 * se,\n         upper = fit + 1.96 * se) |&gt;\n  ggplot(aes(x = cpe, group = state_name)) +\n  geom_point(aes(y = per_gop, colour = state_name), alpha = 0.5) +\n  geom_ribbon(aes(ymin = lower, ymax = upper), fill = \"black\", alpha = 0.5) +\n  geom_line(aes(y = fit, colour = state_name)) +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(limits = c(0, 1), label = percent) +\n  scale_x_continuous(label  = percent)  +\n  labs(x = \"Crude prevalence estimate of depression\",\n       y = \"Percentage vote for Trump in 2024 election\",\n       subtitle = \"Lines are logistic regression with state-level random intercept effect (confidence intervals are too narrow)\",\n       title = \"Counties with more depression voted more for Trump\",\n       caption = the_caption)\n\n#--------------state random effect with mgcv::gam--------------\n# gam lets us have a random effect and a wider range of families\n# see https://fromthebottomoftheheap.net/2021/02/02/random-effects-in-gams/\n\n# must be a factor to use as a random effect in gam():\ncombined &lt;- mutate(combined, state_name = as.factor(state_name))\n\nmodel5 &lt;- gam(per_gop ~ cpe + s(state_name, bs = 're') , \n              family = quasibinomial, weights = total_votes,\n              data = combined)\nsummary(model5)\n# note standard error for cpe is much higher 0.6224, compared to 0 .0107\n\npreds5 &lt;- predict(model5, se.fit = TRUE, type = \"response\")\n\ncombined |&gt;\n  mutate(fit = preds5$fit,\n         se = preds5$se.fit,\n         lower = fit - 1.96 * se,\n         upper = fit + 1.96 * se) |&gt;\n  ggplot(aes(x = cpe, group = state_name)) +\n  geom_point(aes(y = per_gop, colour = state_name), alpha = 0.5) +\n  geom_ribbon(aes(ymin = lower, ymax = upper), fill = \"black\", alpha = 0.5) +\n  geom_line(aes(y = fit, colour = state_name)) +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(limits = c(0, 1), label = percent) +\n  scale_x_continuous(label  = percent)  +\n  labs(x = \"Crude prevalence estimate of depression\",\n       y = \"Percentage vote for Trump in 2024 election\",\n       subtitle = \"Lines are quasibinomial generalized additive model with state-level random intercept\",\n       title = \"Counties with more depression voted more for Trump\",\n       caption = the_caption)</pre></figure>\n<p>Excerpt from the gam results (the better of the two, with fatter confidence intervals but still very significantly different from zero):</p>\n<pre>per_gop ~ cpe + s(state_name, bs = \"re\")\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -3.2466     0.2802  -11.59   &lt;2e-16 ***\ncpe          16.3333     0.6224   26.24   &lt;2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nApproximate significance of smooth terms:\n                edf Ref.df     F p-value    \ns(state_name) 48.44     49 20.54  &lt;2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nR-sq.(adj) =  0.345   Deviance explained = 40.3%\nGCV = 3333.9  Scale est. = 3387.6    n = 3107\n</pre>\n<h2 id=\"allowing-for-spatial-autocorrelation\">Allowing for spatial autocorrelation</h2>\n<p>OK we’re not quite there yet. The final thing at the back of my mind is that so far, we have treated counties as though they are independent, equally valuable observations. This is pretty common in these types of cross-sectional regression, but it’s not fair; it exaggerates the value of each county data point. The values of depression and Trump vote in two adjacent counties are, frankly, not equally valuable independent observations. Once you have one, you have a good chance of predicting the values in the county next door. By failing to account for this, we are treating our data as more valuable than it is, which translates to over-confidence in our inferences and confidence intervals that are too narrow.</p>\n<p>How to fix this? Well, there are numerous ways, but my favourite pragmatic correction is to add a fixed effect that is a sort of rubber sheet laid across the geography of interest. This can be done with <code>gam()</code> by including in the formula something like <code>+ s(x, y)</code>, where x and y are the centrepoints of the regions from where we have sourced observations.</p>\n<blockquote>\n<p>Note - the other ways of correcting for this all seem to me to be <em>way</em> more complicated than this. Perhaps they are better! One thing I’m sure, it’s much better to do it my way than to ignore spatial autocorrelation altogether, which seems to be the near-universal approach. How often do you see an adjustment for spatial autocorrelation in a regression of US counties or states?</p>\n</blockquote>\n<p>Now, even my pragmatic method is going to be a bother, because we need to get spatial data that isn’t available in our sources so far. The next chunk of code downloads shapefiles of all the US counties, calculates the centroids of each, and puts it into shape to join to our existing data.</p>\n<figure class=\"highlight\"><pre>#-----------gam, spatial, state effect--------------\n# each county isn't really an independent data point, as counties next to eachother\n# probably have lots in common. A great thing about gam is that not only can we\n# have a quasibinomial family, we can do gam core business of adding in splines,\n# including a two dimensional \"rubber mat\" that effectively knocks out our \n# spatial correlation problem for us.\n#\n# but first we need to know the centroids of all the counties:\n\nfn &lt;- \"cb_2023_us_county_500k.zip\"\nif(!file.exists(fn)){\n  download.file('https://www2.census.gov/geo/tiger/GENZ2023/shp/cb_2023_us_county_500k.zip',\n                destfile = \"cb_2023_us_county_500k.zip\", mode = \"wb\")\n}\nunzip(fn)\n\ncounties &lt;- st_read(\"cb_2023_us_county_500k.shp\")\ncounty_cent &lt;- counties |&gt;\n  st_centroid() \n\nsc &lt;- st_coordinates(county_cent)\n\ncounty_cent &lt;- county_cent |&gt;\n  mutate(x = sc[, 1],\n         y = sc[, 2],\n         # combine the two digit state code with the 3 digit county code:\n         county_fips = paste0(STATEFP, COUNTYFP))\n\n# check that we have successfully re-created the country_fips on same basis\n# as our voting and depression data:\ncombined |&gt;\n  left_join(county_cent, by = \"county_fips\") |&gt;\n  select(county_name, NAME)\n\ncombined2 &lt;- combined |&gt;\n  left_join(county_cent, by = \"county_fips\")\n\n# check the county centres are where we expect. Note Alaska still missing\n# (because voting data is not by country so lost on the first join)\nggplot(combined2, aes(x = x, y = y, colour = state_name)) + \n  geom_point() +\n  theme(legend.position = \"none\") +\n  coord_map() +\n  labs(title = \"Centres of counties after merging data\")</pre></figure>\n<p>This gives us this plot to check that we haven’t (for example) mangled states, or latitude and longitude:</p>\n<object data=\"https://freerangestats.info/img/0286-counties-map.svg\" type=\"image/svg+xml\" width=\"450\"><img data-lazy-src=\"https://i0.wp.com/freerangestats.info/img/0286-counties-map.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i0.wp.com/freerangestats.info/img/0286-counties-map.png?w=450&amp;ssl=1\"/></noscript></object>\n<p>Very nice. Now we can fit the model, with this code</p>\n<figure class=\"highlight\"><pre>model6 &lt;- gam(per_gop ~ cpe + s(x, y) + s(state_name, bs = 're') , \n              family = quasibinomial, weights = total_votes,\n              data = combined2)\n\n# the spatial rubber mat that is correcting for spatial correlation for us;\n# scheme=1 is what makes it draw a perspective plot rather than contour or\n# heatmap):\nplot(model6, select = 1, scheme = 1, main = \"Higher vote for GOP\")</pre></figure>\n<p>That gives us this ‘rubber mat’ that I’ve included. The bit in the bottom left is Hawaii.</p>\n<object data=\"https://freerangestats.info/img/0286-rubber-sheet.svg\" type=\"image/svg+xml\" width=\"450\"><img data-lazy-src=\"https://i0.wp.com/freerangestats.info/img/0286-rubber-sheet.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i0.wp.com/freerangestats.info/img/0286-rubber-sheet.png?w=450&amp;ssl=1\"/></noscript></object>\n<p>Basically this is going to absorb the variance that can be explained by mere proximity of one county to another. Which means that what is left to be explained by either the state random effect, or the relationship between depression and voting, is a fairer estimate.</p>\n<p>Now, when we try to visualise this, the lines ar emuch squigglier than our previous charts. So I’ve chosen to put this into a faceted plot with a panel for each state. Here’s the end result:</p>\n<object data=\"https://freerangestats.info/img/0286-gam-spatial.svg\" type=\"image/svg+xml\" width=\"450\"><img data-lazy-src=\"https://i2.wp.com/freerangestats.info/img/0286-gam-spatial.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i2.wp.com/freerangestats.info/img/0286-gam-spatial.png?w=450&amp;ssl=1\"/></noscript></object>\n<p>… created with this code:</p>\n<figure class=\"highlight\"><pre>preds6 &lt;- predict(model6, se.fit = TRUE, type = \"response\")\n\ncombined2 |&gt;\n  mutate(fit = preds6$fit,\n         se = preds6$se.fit,\n         lower = fit - 1.96 * se,\n         upper = fit + 1.96 * se) |&gt;\n  ggplot(aes(x = cpe, group = state_name)) +\n  geom_point(aes(y = per_gop, colour = state_name), alpha = 0.5) +\n  geom_ribbon(aes(ymin = lower, ymax = upper), fill = \"black\", alpha = 0.5) +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(limits = c(0, 1), label = percent) +\n  scale_x_continuous(label  = percent)  +\n  labs(x = \"Crude prevalence estimate of depression\",\n       y = \"Percentage vote for Trump in 2024 election\",\n       subtitle = \"Grey ribbons are 95% confidence intervals from quasibinomial generalized additive model with spatial effect and state-level random intercept effect\",\n       title = \"Counties with more depression voted more for Trump\",\n       caption = the_caption) +\n  facet_wrap(~state_name)</pre></figure>\n<p>Now, I think this is the best model I’ve fit to this data. The prevalence of depression (<code>cpe</code>) is still very much a significant (definitely non-zero) effect, and the large magnitude of this is comparable to the simpler models used so far. But we’ve got confidence that this isn’t just an artefact of the spatial closeness of counties, or of other non-included state level effects. So the extra work is worth it.</p>\n<pre>Parametric coefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -2.7972    20.7488  -0.135    0.893    \ncpe          15.5908     0.6778  23.001   &lt;2e-16 ***\n---\nSignif. codes:  \n0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nApproximate significance of smooth terms:\n                edf Ref.df     F p-value    \ns(x,y)        28.39  28.94 7.995  &lt;2e-16 ***\ns(state_name) 49.00  49.00 7.949  &lt;2e-16 ***\n</pre>\n<p>That’s all folks. I guess the lesson here (not that these blogs are lessons) is really just to allow for spatial effects: both categorical ones that fit into a mixed effects / multilevel paradigm (eg random intercept at state level); and those that are more subtle spatial autocorrelation. Really, this should be done much more.</p>\n<p>And <code>mgcv::gam()</code> is a great tool to address both of these at once.</p>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://freerangestats.info/blog/2024/12/23/depression-and-vote\"> free range statistics - R</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
      "main_text": "Depression incidence by county and vote for Trump by @ellis2013nz\nPosted on\nDecember 22, 2024\nby\nfree range statistics - R\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nfree range statistics - R\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nA\nskeet floated across my Bluesky feed\nthat looked at the cross-sectional relationship between incidence of depression in 2020 and voting for Trump in the 2024 Presidential election. The data in the skeet and immediate blog post was at state level, but the hypothesis of interest in an article that sparked all this was an individual one (are depressed people voting for Trump). I don’t have the individual level microdata that might help explore the actual hypothesis, but I was surprised to see that the state-level regression had a significant evidence of an effect, and wondered if this would continue at the county level, which still has relatively accessible data.\nThis also led me down an interesting but familiar rabbit hole of multilevel modelling in the presence of a spatial correlation nuisance.\nOrdinary Least Squares\nWell, it turns out depression at the county level does correlate with voting for Trump, as we can see with this first, simple chart which shows the expected vote based on a model fit with ordinary least squares (OLS):\nI’ll be fitting some more fancy models and getting better charts further down, but the basic message is the same as in this one – counties with higher incidence of depression had a higher proportion of their vote going to Trump than was the case with counties with lower levels of depression.\nBefore I say anything else or show any code, let’s get straight that this is very possibly not a causal link. In fact there are at least three things that are plausibly happening here:\nPeople who are more depressed were more likely to vote for Trump (or less likely to turn up to vote against him, which given voluntary voting, has a similar result although for importantly different reasons)\nPeople (who may themselves be not depressed) who are in areas with lots of depressed people around them were more likely to vote for Trump (eg because voters think “Trump will be able to do something about all the depressed people around here”)\nSome underlying factor (eg economic, social or cultural conditions) that leads to some areas having higher rates of depression also leads to higher votes for Trump, through some other mechanism\nMy expectation is that #3 is the more likely explanation, but I personally don’t actually have evidence to choose between them. Nor are these hypotheses mutually exclusive; two or all of them might be true at once.\nOK here’s the code that gets that data and produces the first chart and a simple model with a statistically significant effect:\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(mgcv)\nlibrary(lme4)\nlibrary(sf)\n\n# county level prevalence of depression at (have to hit the 'download' button)\n# https://stacks.cdc.gov/view/cdc/129404\ndep <- read_excel(\"cdc_129404_DS1.xlsx\", skip = 1)\n\nfn <- \"2024_US_County_Level_Presidential_Results.csv\"\nif(!file.exists(fn)){\n  download.file(\"https://raw.githubusercontent.com/tonmcg/US_County_Level_Election_Results_08-24/refs/heads/master/2024_US_County_Level_Presidential_Results.csv\",\n                destfile = fn)\n}\n\nvotes <- read_csv(\"2024_US_County_Level_Presidential_Results.csv\")\n\ncombined <- votes |>\n  inner_join(dep, by = c(\"county_fips\" = \"CountyFIPS code\")) |>\n  mutate(cpe = `Crude Prevalence Estimate` / 100,\n         aape = `Age-adjusted Prevalence Estimate` / 100)\n\n# what was missed in this join?\nvotes |>\n  anti_join(dep, by = c(\"county_fips\" = \"CountyFIPS code\")) |>\n  count(state_name)\n# 37 counties in Alaska, 9 and Connecticut and 7 in DC. Will ignore these\n# for my purposes.\n\n#========================modelling==================\n\n#----------Ordinary Least Squares------------------\n\nmodel <- lm(per_gop ~ cpe, data = combined)\nsummary(model)\n# note several things could be happening here:\n# - depressed people makes you vote for Trump\n# - being around depressed people makes you vote for Trump\n# - some underlying condition (eg economic) both leads to higher depression\n#   and more likely to vote for Trump. This seems the most likely.\n\nthe_caption = \"Source: data from tonmcg and CDC; analysis by freerangestats.info\"\n\n# draw chart:\ncombined |>\n  ggplot(aes(x= cpe, y = per_gop)) +\n  geom_point(colour = \"steelblue\", alpha = 0.5) +\n  geom_smooth(method = \"lm\", fill = \"black\", colour = \"white\", alpha = 0.8) +\n  scale_x_continuous(label = percent) +\n  scale_y_continuous(label = percent) +\n  labs(x = \"Crude prevalence estimate of depression\",\n       y = \"Percentage vote for Trump in 2024 election\",\n       subtitle = \"Line is ordinary least squares fit to all county data together\",\n       title = \"Counties with more depression voted more for Trump\",\n       caption = the_caption)\nExcerpt from the results:\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.40002    0.01861   21.49   <2e-16 ***\ncpe          1.27547    0.08712   14.64   <2e-16 ***\nGeneralized linear model with a quasibinomial response\nNow, I wanted to improve this for all sorts of reasons, although I suspected it was actually good enough for pragmatic purposes - case proven really, that counties with more depressed people voted more for Trump. Proven enough to justify the further work with additional data needed to explore why. But I had some statistical loose ends to tidy up. First of which is that vote is a proportion, and it feels icky to use OLS (which can send values above 1 and below 0) to model a proportion when we have generalized linear models (GLMs) designed for the job and easily available.\nI didn’t want to use a straight logistic regression because the county-level data is far more dispersed than would be expected if it really were individuals making their own voting decisions. But a GLM with a quasi-binomial response keeps the link function used in logistic regression and the relationship of the mean and variance, while allowing the variance to be larger (or smaller) by some consistent ratio. Here’s what I get with that GLM:\n…created with this code. Note that we now have started to weight counties based on their overall number of voters, which makes particular sense for a binomial or similar family response. I suspect this is one of the key issues driving the line vertically down, compared to the OLS version. The other key difference of course is that now it is slightly curved, as the ‘linear’ in a GLM is on the link scale, not the scale the response is originally observed on and used for this chart.\n#----------------Quasibinomial GLM----------------\n\nmodel2 <- glm(per_gop ~ cpe, \n              family = quasibinomial, data = combined, weights = total_votes)\nsummary(model2)\n\npreds2 <- predict(model2, type = \"response\", se.fit = TRUE)\n\n# draw chart:\ncombined |>\n  mutate(fit = preds2$fit,\n         se = preds2$se.fit,\n         lower = fit - 1.96 * se,\n         upper = fit + 1.96 * se) |>\n  ggplot(aes(x = cpe, y = per_gop)) +\n  geom_point(colour = \"steelblue\", alpha = 0.5) +\n  geom_ribbon(aes(ymin = lower, ymax = upper), fill = \"black\", alpha = 0.5) +\n  geom_line(aes(y = fit), colour = \"white\") +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(limits = c(0, 1), label = percent) +\n  scale_x_continuous(label  = percent)  +\n  labs(x = \"Crude prevalence estimate of depression\",\n       y = \"Percentage vote for Trump in 2024 election\",\n       subtitle = \"Line is generalized linear model with quasibinomial response, fit to all county data together\",\n       title = \"Counties with more depression voted more for Trump\",\n       caption = the_caption)\nHere’s an excerpt from that summary of model2:\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -1.82178    0.06823  -26.70   <2e-16 ***\ncpe          9.25748    0.34153   27.11   <2e-16 ***\nWe see\ncpe\n(crude prevalence estimate, ie not the age-standardised one) has very definitely “significant” evidence that it isn’t zero, with a point estimate of 9.3 and a standard error of only 0.3.\nIntroducing a state effect\nOne thing that all the world knows is how spatially-based are US politics. Everything is thought of in terms of states, in particular, and smaller areas sometimes. It follows naturally from the ways that US politics is discussed that we should use a multi-level ie mixed-effects model with state as a random intercept, when looking at something like the overall relationship between depression and voting. In other words, we have to let the vote for Trump in any state vary for all the state-specific things that aren’t in our model, and see if after doing that we still get an overall  (constant nation-wide) relationship between depression and voting in the counties within each state.\nI often reach to the\nlme4\nlibrary by Bates, Bolker and Walker as my starting point for mixed effects models and this is the results in this case:\nNote we have a bunch of parallel (on link scale) lines, one per state, with their height varying by the state random effect. I love the effect of this chart, but unfortunately\nlme4::glmer\nwhich is used in this case doesn’t let us use a quasibinomial family response; we have to use a binomial response which forces the variance to equal\np(1-p)/n\n, not just be proportional to it. The net result is that the confidence intervals are much narrower than is justified.\nAn alternative way to fit a similar model is the the\ngam()\nfunction from the amazing\nmgcv\nlibrary by Simon Wood. There’s\na great discussion of this\non Gavin Simpson’s blog. By specifying a spline around a categorical factor like\ns(state_factor, bs = 're')\n(‘re’ stands for random effect) we can use\ngam()\nto add random intercepts while using the full range of families available to\ngam()\nincluding quasibinomial. That gives us this alternative version of the last model; this time with much fatter (and realistic) confidence intervals!:\nThe confidence intervals are now very fat. But there’s still no doubt about the significance of the evidence of the relationship of the crude prevalence of depression on voting behaviour, even after allowing a random state-level intercept.\nHere’s the code for both the\nglmer\nand\ngam\nversions of this random state effect model:\n#---------------------With state random effect with lmer4::glmer--------------------\n\nmodel4 <- lme4::glmer(per_gop ~ cpe + (1 | state_name), \n                      family = \"binomial\", data = combined, \n                      weights = total_votes)\n# note can't use quasibinomial family with glmer so we aren;t really dealing\n# properly with the overdispersion. what to do about that? Confidence intervals\n# will be too narrow. Various alternatives posisble.\n\nsummary(model4)\n\npreds4 <- predict(model4, se.fit = TRUE, type = \"response\")\n\ncombined |>\n  mutate(fit = preds4$fit,\n         se = preds4$se.fit,\n         lower = fit - 1.96 * se,\n         upper = fit + 1.96 * se) |>\n  ggplot(aes(x = cpe, group = state_name)) +\n  geom_point(aes(y = per_gop, colour = state_name), alpha = 0.5) +\n  geom_ribbon(aes(ymin = lower, ymax = upper), fill = \"black\", alpha = 0.5) +\n  geom_line(aes(y = fit, colour = state_name)) +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(limits = c(0, 1), label = percent) +\n  scale_x_continuous(label  = percent)  +\n  labs(x = \"Crude prevalence estimate of depression\",\n       y = \"Percentage vote for Trump in 2024 election\",\n       subtitle = \"Lines are logistic regression with state-level random intercept effect (confidence intervals are too narrow)\",\n       title = \"Counties with more depression voted more for Trump\",\n       caption = the_caption)\n\n#--------------state random effect with mgcv::gam--------------\n# gam lets us have a random effect and a wider range of families\n# see https://fromthebottomoftheheap.net/2021/02/02/random-effects-in-gams/\n\n# must be a factor to use as a random effect in gam():\ncombined <- mutate(combined, state_name = as.factor(state_name))\n\nmodel5 <- gam(per_gop ~ cpe + s(state_name, bs = 're') , \n              family = quasibinomial, weights = total_votes,\n              data = combined)\nsummary(model5)\n# note standard error for cpe is much higher 0.6224, compared to 0 .0107\n\npreds5 <- predict(model5, se.fit = TRUE, type = \"response\")\n\ncombined |>\n  mutate(fit = preds5$fit,\n         se = preds5$se.fit,\n         lower = fit - 1.96 * se,\n         upper = fit + 1.96 * se) |>\n  ggplot(aes(x = cpe, group = state_name)) +\n  geom_point(aes(y = per_gop, colour = state_name), alpha = 0.5) +\n  geom_ribbon(aes(ymin = lower, ymax = upper), fill = \"black\", alpha = 0.5) +\n  geom_line(aes(y = fit, colour = state_name)) +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(limits = c(0, 1), label = percent) +\n  scale_x_continuous(label  = percent)  +\n  labs(x = \"Crude prevalence estimate of depression\",\n       y = \"Percentage vote for Trump in 2024 election\",\n       subtitle = \"Lines are quasibinomial generalized additive model with state-level random intercept\",\n       title = \"Counties with more depression voted more for Trump\",\n       caption = the_caption)\nExcerpt from the gam results (the better of the two, with fatter confidence intervals but still very significantly different from zero):\nper_gop ~ cpe + s(state_name, bs = \"re\")\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -3.2466     0.2802  -11.59   <2e-16 ***\ncpe          16.3333     0.6224   26.24   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nApproximate significance of smooth terms:\n                edf Ref.df     F p-value    \ns(state_name) 48.44     49 20.54  <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nR-sq.(adj) =  0.345   Deviance explained = 40.3%\nGCV = 3333.9  Scale est. = 3387.6    n = 3107\nAllowing for spatial autocorrelation\nOK we’re not quite there yet. The final thing at the back of my mind is that so far, we have treated counties as though they are independent, equally valuable observations. This is pretty common in these types of cross-sectional regression, but it’s not fair; it exaggerates the value of each county data point. The values of depression and Trump vote in two adjacent counties are, frankly, not equally valuable independent observations. Once you have one, you have a good chance of predicting the values in the county next door. By failing to account for this, we are treating our data as more valuable than it is, which translates to over-confidence in our inferences and confidence intervals that are too narrow.\nHow to fix this? Well, there are numerous ways, but my favourite pragmatic correction is to add a fixed effect that is a sort of rubber sheet laid across the geography of interest. This can be done with\ngam()\nby including in the formula something like\n+ s(x, y)\n, where x and y are the centrepoints of the regions from where we have sourced observations.\nNote - the other ways of correcting for this all seem to me to be\nway\nmore complicated than this. Perhaps they are better! One thing I’m sure, it’s much better to do it my way than to ignore spatial autocorrelation altogether, which seems to be the near-universal approach. How often do you see an adjustment for spatial autocorrelation in a regression of US counties or states?\nNow, even my pragmatic method is going to be a bother, because we need to get spatial data that isn’t available in our sources so far. The next chunk of code downloads shapefiles of all the US counties, calculates the centroids of each, and puts it into shape to join to our existing data.\n#-----------gam, spatial, state effect--------------\n# each county isn't really an independent data point, as counties next to eachother\n# probably have lots in common. A great thing about gam is that not only can we\n# have a quasibinomial family, we can do gam core business of adding in splines,\n# including a two dimensional \"rubber mat\" that effectively knocks out our \n# spatial correlation problem for us.\n#\n# but first we need to know the centroids of all the counties:\n\nfn <- \"cb_2023_us_county_500k.zip\"\nif(!file.exists(fn)){\n  download.file('https://www2.census.gov/geo/tiger/GENZ2023/shp/cb_2023_us_county_500k.zip',\n                destfile = \"cb_2023_us_county_500k.zip\", mode = \"wb\")\n}\nunzip(fn)\n\ncounties <- st_read(\"cb_2023_us_county_500k.shp\")\ncounty_cent <- counties |>\n  st_centroid() \n\nsc <- st_coordinates(county_cent)\n\ncounty_cent <- county_cent |>\n  mutate(x = sc[, 1],\n         y = sc[, 2],\n         # combine the two digit state code with the 3 digit county code:\n         county_fips = paste0(STATEFP, COUNTYFP))\n\n# check that we have successfully re-created the country_fips on same basis\n# as our voting and depression data:\ncombined |>\n  left_join(county_cent, by = \"county_fips\") |>\n  select(county_name, NAME)\n\ncombined2 <- combined |>\n  left_join(county_cent, by = \"county_fips\")\n\n# check the county centres are where we expect. Note Alaska still missing\n# (because voting data is not by country so lost on the first join)\nggplot(combined2, aes(x = x, y = y, colour = state_name)) + \n  geom_point() +\n  theme(legend.position = \"none\") +\n  coord_map() +\n  labs(title = \"Centres of counties after merging data\")\nThis gives us this plot to check that we haven’t (for example) mangled states, or latitude and longitude:\nVery nice. Now we can fit the model, with this code\nmodel6 <- gam(per_gop ~ cpe + s(x, y) + s(state_name, bs = 're') , \n              family = quasibinomial, weights = total_votes,\n              data = combined2)\n\n# the spatial rubber mat that is correcting for spatial correlation for us;\n# scheme=1 is what makes it draw a perspective plot rather than contour or\n# heatmap):\nplot(model6, select = 1, scheme = 1, main = \"Higher vote for GOP\")\nThat gives us this ‘rubber mat’ that I’ve included. The bit in the bottom left is Hawaii.\nBasically this is going to absorb the variance that can be explained by mere proximity of one county to another. Which means that what is left to be explained by either the state random effect, or the relationship between depression and voting, is a fairer estimate.\nNow, when we try to visualise this, the lines ar emuch squigglier than our previous charts. So I’ve chosen to put this into a faceted plot with a panel for each state. Here’s the end result:\n… created with this code:\npreds6 <- predict(model6, se.fit = TRUE, type = \"response\")\n\ncombined2 |>\n  mutate(fit = preds6$fit,\n         se = preds6$se.fit,\n         lower = fit - 1.96 * se,\n         upper = fit + 1.96 * se) |>\n  ggplot(aes(x = cpe, group = state_name)) +\n  geom_point(aes(y = per_gop, colour = state_name), alpha = 0.5) +\n  geom_ribbon(aes(ymin = lower, ymax = upper), fill = \"black\", alpha = 0.5) +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(limits = c(0, 1), label = percent) +\n  scale_x_continuous(label  = percent)  +\n  labs(x = \"Crude prevalence estimate of depression\",\n       y = \"Percentage vote for Trump in 2024 election\",\n       subtitle = \"Grey ribbons are 95% confidence intervals from quasibinomial generalized additive model with spatial effect and state-level random intercept effect\",\n       title = \"Counties with more depression voted more for Trump\",\n       caption = the_caption) +\n  facet_wrap(~state_name)\nNow, I think this is the best model I’ve fit to this data. The prevalence of depression (\ncpe\n) is still very much a significant (definitely non-zero) effect, and the large magnitude of this is comparable to the simpler models used so far. But we’ve got confidence that this isn’t just an artefact of the spatial closeness of counties, or of other non-included state level effects. So the extra work is worth it.\nParametric coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -2.7972    20.7488  -0.135    0.893    \ncpe          15.5908     0.6778  23.001   <2e-16 ***\n---\nSignif. codes:  \n0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nApproximate significance of smooth terms:\n                edf Ref.df     F p-value    \ns(x,y)        28.39  28.94 7.995  <2e-16 ***\ns(state_name) 49.00  49.00 7.949  <2e-16 ***\nThat’s all folks. I guess the lesson here (not that these blogs are lessons) is really just to allow for spatial effects: both categorical ones that fit into a mixed effects / multilevel paradigm (eg random intercept at state level); and those that are more subtle spatial autocorrelation. Really, this should be done much more.\nAnd\nmgcv::gam()\nis a great tool to address both of these at once.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nfree range statistics - R\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "A skeet floated across my Bluesky feed that looked at the cross-sectional relationship between incidence of depression in 2020 and voting for Trump in the 2024 Presidential election. The data in the skeet and immediate blog post was at state level, but...",
      "meta_keywords": null,
      "og_description": "A skeet floated across my Bluesky feed that looked at the cross-sectional relationship between incidence of depression in 2020 and voting for Trump in the 2024 Presidential election. The data in the skeet and immediate blog post was at state level, but...",
      "og_image": "https://freerangestats.info/img/0286-ols.png",
      "og_title": "Depression incidence by county and vote for Trump by @ellis2013nz | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 16.3,
      "sitemap_lastmod": null,
      "twitter_description": "A skeet floated across my Bluesky feed that looked at the cross-sectional relationship between incidence of depression in 2020 and voting for Trump in the 2024 Presidential election. The data in the skeet and immediate blog post was at state level, but...",
      "twitter_title": "Depression incidence by county and vote for Trump by @ellis2013nz | R-bloggers",
      "url": "https://www.r-bloggers.com/2024/12/depression-incidence-by-county-and-vote-for-trump-by-ellis2013nz/",
      "word_count": 3258
    }
  }
}