{
  "uuid": "7e9b0bd1-bed5-4393-9cf1-b0b30757aa62",
  "created_at": "2025-11-22 19:58:58",
  "raw_json": {
    "article_author": null,
    "article_headline": null,
    "article_modified": null,
    "article_published": null,
    "article_section": null,
    "article_tags": null,
    "canonical_url": "https://www.r-bloggers.com/2025/03/converting-arbitrarily-large-csvs-to-parquet-with-r/",
    "crawled_at": "2025-11-22T10:51:26.483919",
    "external_links": [
      {
        "href": "https://lorentzen.ch/index.php/2025/03/30/converting-arbitrarily-large-csvs-to-parquet-with-r/",
        "text": "R – Michael's and Christian's Blog"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://lorentzen.ch/index.php/2025/03/22/converting-csv-to-parquet/",
        "text": "recent post"
      },
      {
        "href": "https://pola.rs/",
        "text": "Polars"
      },
      {
        "href": "https://duckdb.org/",
        "text": "DuckDB"
      },
      {
        "href": "https://github.com/pola-rs/r-polars",
        "text": "polars}"
      },
      {
        "href": "https://duckdb.org/",
        "text": "DuckDB"
      },
      {
        "href": "https://github.com/lorentzenchr/notebooks/blob/master/blogposts/2025-03-30%20csv%20to%20parquet.R",
        "text": "R script"
      },
      {
        "href": "https://lorentzen.ch/index.php/2025/03/30/converting-arbitrarily-large-csvs-to-parquet-with-r/",
        "text": "R – Michael's and Christian's Blog"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "h1_title": "R-bloggers",
    "html_title": "Converting arbitrarily large CSVs to Parquet with R | R-bloggers",
    "images": [
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i2.wp.com/lorentzen.ch/wp-content/uploads/2025/03/image-3.png?w=578&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i0.wp.com/lorentzen.ch/wp-content/uploads/2025/03/image-2.png?w=578&ssl=1"
      }
    ],
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/michael-mayer/",
        "text": "Michael Mayer"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "lang": "en-US",
    "main_html": "<article class=\"post-391552 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Converting arbitrarily large CSVs to Parquet with R</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">March 30, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/michael-mayer/\">Michael Mayer</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://lorentzen.ch/index.php/2025/03/30/converting-arbitrarily-large-csvs-to-parquet-with-r/\"> R – Michael's and Christian's Blog</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<p>In this <a href=\"https://lorentzen.ch/index.php/2025/03/22/converting-csv-to-parquet/\" rel=\"nofollow\" target=\"_blank\">recent post</a>, we have used <a href=\"https://pola.rs/\" rel=\"nofollow\" target=\"_blank\"><strong>Polars</strong></a> and <a href=\"https://duckdb.org/\" rel=\"nofollow\" target=\"_blank\"><strong>DuckDB</strong></a> to convert a large CSV file to Parquet in steaming mode – and Python. </p>\n<p>Different people have contacted me and asked: “and in R?”</p>\n<p>Simple answer: We have DuckDB, and we have different Polars bindings. Here, we are using {<a href=\"https://github.com/pola-rs/r-polars\" rel=\"nofollow\" target=\"_blank\">polars}</a> which is currently being overhauled into {neopandas}.</p>\n<p>So let’s not wait any longer!</p>\n<p><img alt=\"\" data-lazy-src=\"https://i2.wp.com/lorentzen.ch/wp-content/uploads/2025/03/image-3.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" decoding=\"async\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"\" data-recalc-dims=\"1\" decoding=\"async\" src=\"https://i2.wp.com/lorentzen.ch/wp-content/uploads/2025/03/image-3.png?w=578&amp;ssl=1\"/></noscript><br/><img alt=\"\" data-lazy-src=\"https://i0.wp.com/lorentzen.ch/wp-content/uploads/2025/03/image-2.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" decoding=\"async\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"\" data-recalc-dims=\"1\" decoding=\"async\" src=\"https://i0.wp.com/lorentzen.ch/wp-content/uploads/2025/03/image-2.png?w=578&amp;ssl=1\"/></noscript></p>\n<p>Run times are on a Windows system with an Intel i7-13700H CPU. </p>\n<h2 class=\"wp-block-heading\">Generate 2.2 GB csv file</h2>\n<p>We use {data.table} to dump a randomly generated dataset with 100 Mio rows into a csv file.</p>\n<div class=\"wp-block-ub-tabbed-content wp-block-ub-tabbed-content-holder wp-block-ub-tabbed-content-horizontal-holder-mobile wp-block-ub-tabbed-content-horizontal-holder-tablet\" id=\"ub-tabbed-content-03f6b536-ed1b-4b0e-b53a-cfa4850e5003\" style=\"\">\n<div class=\"wp-block-ub-tabbed-content-tab-holder horizontal-tab-width-mobile horizontal-tab-width-tablet\">\n<div class=\"wp-block-ub-tabbed-content-tabs-title wp-block-ub-tabbed-content-tabs-title-mobile-horizontal-tab wp-block-ub-tabbed-content-tabs-title-tablet-horizontal-tab\" role=\"tablist\" style=\"justify-content: flex-start; \"><div aria-controls=\"ub-tabbed-content-03f6b536-ed1b-4b0e-b53a-cfa4850e5003-panel-0\" aria-selected=\"true\" class=\"wp-block-ub-tabbed-content-tab-title-wrap active\" id=\"ub-tabbed-content-03f6b536-ed1b-4b0e-b53a-cfa4850e5003-tab-0\" role=\"tab\" style=\"--ub-tabbed-title-background-color: #6d6d6d; --ub-tabbed-active-title-color: inherit; --ub-tabbed-active-title-background-color: #6d6d6d; text-align: left; \" tabindex=\"-1\">\n<div class=\"wp-block-ub-tabbed-content-tab-title\">R</div>\n</div></div>\n</div>\n<div class=\"wp-block-ub-tabbed-content-tabs-content\" style=\"\"><div aria-labelledby=\"ub-tabbed-content-03f6b536-ed1b-4b0e-b53a-cfa4850e5003-tab-0\" class=\"wp-block-ub-tabbed-content-tab-content-wrap active\" id=\"ub-tabbed-content-03f6b536-ed1b-4b0e-b53a-cfa4850e5003-panel-0\" role=\"tabpanel\" tabindex=\"0\">\n<pre>library(data.table)\n\nset.seed(1)\n\nn &lt;- 1e8\n\ndf &lt;- data.frame(\n  X = sample(letters[1:3], n, TRUE),\n  Y = runif(n),\n  Z = sample(1:5, n, TRUE)\n)\n\nfwrite(df, \"data.csv\")</pre>\n</div></div>\n</div>\n<h2 class=\"wp-block-heading\">DuckDB</h2>\n<p>Then, we use <a href=\"https://duckdb.org/\" rel=\"nofollow\" target=\"_blank\">DuckDB</a> to fire a query to the file and stream the result into Parquet. </p>\n<p>Threads and RAM can be set on the fly, which is very convenient. Setting a low memory limit (e.g., 500 MB) will work – try it out!</p>\n<div class=\"wp-block-ub-tabbed-content wp-block-ub-tabbed-content-holder wp-block-ub-tabbed-content-horizontal-holder-mobile wp-block-ub-tabbed-content-horizontal-holder-tablet\" id=\"ub-tabbed-content-28dd201b-d12f-401b-9254-3e42c9ca1a73\" style=\"\">\n<div class=\"wp-block-ub-tabbed-content-tab-holder horizontal-tab-width-mobile horizontal-tab-width-tablet\">\n<div class=\"wp-block-ub-tabbed-content-tabs-title wp-block-ub-tabbed-content-tabs-title-mobile-horizontal-tab wp-block-ub-tabbed-content-tabs-title-tablet-horizontal-tab\" role=\"tablist\" style=\"justify-content: flex-start; \"><div aria-controls=\"ub-tabbed-content-28dd201b-d12f-401b-9254-3e42c9ca1a73-panel-0\" aria-selected=\"true\" class=\"wp-block-ub-tabbed-content-tab-title-wrap active\" id=\"ub-tabbed-content-28dd201b-d12f-401b-9254-3e42c9ca1a73-tab-0\" role=\"tab\" style=\"--ub-tabbed-title-background-color: #6d6d6d; --ub-tabbed-active-title-color: inherit; --ub-tabbed-active-title-background-color: #6d6d6d; text-align: center; \" tabindex=\"-1\">\n<div class=\"wp-block-ub-tabbed-content-tab-title\">R</div>\n</div></div>\n</div>\n<div class=\"wp-block-ub-tabbed-content-tabs-content\" style=\"\"><div aria-labelledby=\"ub-tabbed-content-28dd201b-d12f-401b-9254-3e42c9ca1a73-tab-0\" class=\"wp-block-ub-tabbed-content-tab-content-wrap active\" id=\"ub-tabbed-content-28dd201b-d12f-401b-9254-3e42c9ca1a73-panel-0\" role=\"tabpanel\" tabindex=\"0\">\n<pre>library(duckdb)\n\ncon &lt;- dbConnect(duckdb(config = list(threads = \"8\", memory_limit = \"4GB\")))\n\nsystem.time( # 3.5s\n  dbSendQuery(\n    con,\n    \"\n    COPY (\n      SELECT Y, Z\n      FROM 'data.csv'\n      WHERE X == 'a'\n      ORDER BY Y\n    ) TO 'data.parquet' (FORMAT parquet, COMPRESSION zstd)\n    \"\n  )\n)\n\n# Check\ndbGetQuery(con, \"SELECT COUNT(*) N FROM 'data.parquet'\") # 33329488\ndbGetQuery(con, \"SELECT * FROM 'data.parquet' LIMIT 5\")\n#              Y Z\n# 1 5.355105e-09 4\n# 2 9.080395e-09 5\n# 3 2.258457e-08 2\n# 4 3.445894e-08 2\n# 5 6.891787e-08 1</pre>\n</div></div>\n</div>\n<p>3.5 seconds – wow! The resulting file looks good. It is 125 MB large.</p>\n<h2 class=\"wp-block-heading\">Polars</h2>\n<p>Let’s do the same with Polars.</p>\n<pre># Sys.setenv(NOT_CRAN = \"true\")\n# install.packages(\"polars\", repos = \"https://community.r-multiverse.org\")\nlibrary(polars)\n\npolars_info()\n\nsystem.time( # 9s\n  (\n    pl$scan_csv(\"data.csv\")\n    $filter(pl$col(\"X\") == \"a\")\n    $drop(\"X\")\n    $sort(\"Y\")\n    $sink_parquet(\"data.parquet\", row_group_size = 1e5)\n  )\n)\n\n# Check\npl$scan_parquet(\"data.parquet\")$head()$collect()\n# shape: (5, 2)\n# ┌───────────┬─────┐\n# │ Y         ┆ Z   │\n# │ ---       ┆ --- │\n# │ f64       ┆ i64 │\n# ╞═══════════╪═════╡\n# │ 5.3551e-9 ┆ 4   │\n# │ 9.0804e-9 ┆ 5   │\n# │ 2.2585e-8 ┆ 2   │\n# │ 3.4459e-8 ┆ 2   │\n# │ 6.8918e-8 ┆ 1   │\n# └───────────┴─────┘</pre>\n<p>With nine seconds, it is slower than DuckDB. But the output looks as expected and has the same size as with DuckDB.</p>\n<h2 class=\"wp-block-heading\">Final words</h2>\n<ul class=\"wp-block-list\">\n<li>With DuckDB or Polars, conversion of CSVs to Parquet is easy and fast, even in larger-than-RAM situations.</li>\n<li>We can apply filters, selects, sorts etc. on the fly.</li>\n<li>Let’s keep an eye on Polars in R. It looks really interesting.</li>\n</ul>\n<p><a href=\"https://github.com/lorentzenchr/notebooks/blob/master/blogposts/2025-03-30%20csv%20to%20parquet.R\" rel=\"nofollow\" target=\"_blank\">R script</a></p>\n<p></p>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://lorentzen.ch/index.php/2025/03/30/converting-arbitrarily-large-csvs-to-parquet-with-r/\"> R – Michael's and Christian's Blog</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
    "main_text": "Converting arbitrarily large CSVs to Parquet with R\nPosted on\nMarch 30, 2025\nby\nMichael Mayer\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nR – Michael's and Christian's Blog\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nIn this\nrecent post\n, we have used\nPolars\nand\nDuckDB\nto convert a large CSV file to Parquet in steaming mode – and Python.\nDifferent people have contacted me and asked: “and in R?”\nSimple answer: We have DuckDB, and we have different Polars bindings. Here, we are using {\npolars}\nwhich is currently being overhauled into {neopandas}.\nSo let’s not wait any longer!\nRun times are on a Windows system with an Intel i7-13700H CPU.\nGenerate 2.2 GB csv file\nWe use {data.table} to dump a randomly generated dataset with 100 Mio rows into a csv file.\nR\nlibrary(data.table)\n\nset.seed(1)\n\nn <- 1e8\n\ndf <- data.frame(\n  X = sample(letters[1:3], n, TRUE),\n  Y = runif(n),\n  Z = sample(1:5, n, TRUE)\n)\n\nfwrite(df, \"data.csv\")\nDuckDB\nThen, we use\nDuckDB\nto fire a query to the file and stream the result into Parquet.\nThreads and RAM can be set on the fly, which is very convenient. Setting a low memory limit (e.g., 500 MB) will work – try it out!\nR\nlibrary(duckdb)\n\ncon <- dbConnect(duckdb(config = list(threads = \"8\", memory_limit = \"4GB\")))\n\nsystem.time( # 3.5s\n  dbSendQuery(\n    con,\n    \"\n    COPY (\n      SELECT Y, Z\n      FROM 'data.csv'\n      WHERE X == 'a'\n      ORDER BY Y\n    ) TO 'data.parquet' (FORMAT parquet, COMPRESSION zstd)\n    \"\n  )\n)\n\n# Check\ndbGetQuery(con, \"SELECT COUNT(*) N FROM 'data.parquet'\") # 33329488\ndbGetQuery(con, \"SELECT * FROM 'data.parquet' LIMIT 5\")\n#              Y Z\n# 1 5.355105e-09 4\n# 2 9.080395e-09 5\n# 3 2.258457e-08 2\n# 4 3.445894e-08 2\n# 5 6.891787e-08 1\n3.5 seconds – wow! The resulting file looks good. It is 125 MB large.\nPolars\nLet’s do the same with Polars.\n# Sys.setenv(NOT_CRAN = \"true\")\n# install.packages(\"polars\", repos = \"https://community.r-multiverse.org\")\nlibrary(polars)\n\npolars_info()\n\nsystem.time( # 9s\n  (\n    pl$scan_csv(\"data.csv\")\n    $filter(pl$col(\"X\") == \"a\")\n    $drop(\"X\")\n    $sort(\"Y\")\n    $sink_parquet(\"data.parquet\", row_group_size = 1e5)\n  )\n)\n\n# Check\npl$scan_parquet(\"data.parquet\")$head()$collect()\n# shape: (5, 2)\n# ┌───────────┬─────┐\n# │ Y         ┆ Z   │\n# │ ---       ┆ --- │\n# │ f64       ┆ i64 │\n# ╞═══════════╪═════╡\n# │ 5.3551e-9 ┆ 4   │\n# │ 9.0804e-9 ┆ 5   │\n# │ 2.2585e-8 ┆ 2   │\n# │ 3.4459e-8 ┆ 2   │\n# │ 6.8918e-8 ┆ 1   │\n# └───────────┴─────┘\nWith nine seconds, it is slower than DuckDB. But the output looks as expected and has the same size as with DuckDB.\nFinal words\nWith DuckDB or Polars, conversion of CSVs to Parquet is easy and fast, even in larger-than-RAM situations.\nWe can apply filters, selects, sorts etc. on the fly.\nLet’s keep an eye on Polars in R. It looks really interesting.\nR script\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nR – Michael's and Christian's Blog\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "meta_description": "How to convert that huge csv to parquet? Now in R!",
    "meta_keywords": null,
    "og_description": "How to convert that huge csv to parquet? Now in R!",
    "og_image": "https://lorentzen.ch/wp-content/uploads/2025/03/image-3.png",
    "og_title": "Converting arbitrarily large CSVs to Parquet with R | R-bloggers",
    "raw_jsonld_article": null,
    "reading_time_min": 2.9,
    "sitemap_lastmod": null,
    "twitter_description": "How to convert that huge csv to parquet? Now in R!",
    "twitter_title": "Converting arbitrarily large CSVs to Parquet with R | R-bloggers",
    "url": "https://www.r-bloggers.com/2025/03/converting-arbitrarily-large-csvs-to-parquet-with-r/",
    "word_count": 573
  }
}