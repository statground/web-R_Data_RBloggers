{
  "uuid": "a66d92ad-31ce-4f84-9622-390599dcb87a",
  "created_at": "2025-11-22 19:58:49",
  "raw_json": {
    "article_author": null,
    "article_headline": null,
    "article_modified": null,
    "article_published": null,
    "article_section": null,
    "article_tags": null,
    "canonical_url": "https://www.r-bloggers.com/2025/04/tree-methods/",
    "crawled_at": "2025-11-22T10:50:19.453359",
    "external_links": [
      {
        "href": "https://mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/",
        "text": "mlr-org"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://cran.r-project.org/web/packages/rpart/",
        "text": "rpart"
      },
      {
        "href": "https://cran.r-project.org/web/packages/ggparty/vignettes/ggparty-graphic-partying.html",
        "text": "ggparty"
      },
      {
        "href": "https://cran.r-project.org/web/packages/ranger/index.html",
        "text": "ranger"
      },
      {
        "href": "https://cran.r-project.org/web/packages/rpart/",
        "text": "rpart"
      },
      {
        "href": "https://cran.r-project.org/web/packages/ranger/index.html",
        "text": "ranger"
      },
      {
        "href": "https://cran.r-project.org/web/views/MachineLearning.html",
        "text": "CRAN Task View about Machine Learning and Statistical Learning"
      },
      {
        "href": "https://mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/",
        "text": "mlr-org"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "h1_title": "R-bloggers",
    "html_title": "Tree Methods | R-bloggers",
    "images": [
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i0.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-6-1.png?w=450&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i1.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-7-1.png?w=578&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i0.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-8-1.png?w=578&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i2.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-9-1.png?w=578&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i0.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-13-1.png?w=450&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i0.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-18-1.png?w=450&ssl=1"
      }
    ],
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/giuseppe-casalicchio/",
        "text": "Giuseppe Casalicchio"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "lang": "en-US",
    "main_html": "<article class=\"post-392068 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Tree Methods</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">April 13, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/giuseppe-casalicchio/\">Giuseppe Casalicchio</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/\"> mlr-org</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<section class=\"level1\" id=\"goal\">\n<h1>Goal</h1>\n<p>The goal for this exercise is to familiarize yourself with two very important machine learning methods, the decision tree and random forest. After this exercise, you should be able to train these models and extract important information to understand the model internals.</p>\n</section>\n<section class=\"level1\" id=\"exercises\">\n<h1>Exercises</h1>\n<section class=\"level2\" id=\"fit-a-decision-tree\">\n<h2 class=\"anchored\" data-anchor-id=\"fit-a-decision-tree\">Fit a decision tree</h2>\n<p>Use <code>task = tsk(\"german_credit\")</code> to create the classification task for the <code>german_credit</code> data and create a decision tree learner (e.g., a CART learner). Train the decision tree on the <code>german_credit</code> classification task. Look at the output of the trained decision tree (you have to access the raw model object).</p>\n<details>\n<summary>\n<strong>Hint 1:</strong>\n</summary>\nThe learner we are focusing on here is a decision tree implemented in <a href=\"https://cran.r-project.org/web/packages/rpart/\" rel=\"nofollow\" target=\"_blank\"><code>rpart</code></a>. The corresponding <code>mlr3</code> learner key is <code>\"classif.rpart\"</code>. For this exercise, we use the learner with the default hyperparameters. The raw model object can be accessed from the <code>$model</code> slot of the trained learner.\n</details>\n<details>\n<summary>\n<strong>Hint 2:</strong>\n</summary>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>library(mlr3)\ntask = tsk(...)\nlrn_rpart = lrn(...) # create the learner\nlrn_rpart$train(...) # train the learner on the task\nlrn_rpart$... # access the raw model object that was fitted</pre>\n</div>\n</details>\n<div class=\"callout callout-style-default callout-note callout-titled\">\n<div aria-controls=\"callout-1\" aria-expanded=\"false\" aria-label=\"Toggle callout\" class=\"callout-header d-flex align-content-center\" data-bs-=\"\" data-bs-toggle=\"collapse\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nSolution\n</div>\n<div class=\"callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end\"><i class=\"callout-toggle\"></i></div>\n</div>\n<div class=\"callout-1-contents callout-collapse collapse\" id=\"callout-1\">\n<div class=\"callout-body-container callout-body\">\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>library(mlr3)\ntask = tsk(\"german_credit\")\nlrn_rpart = lrn(\"classif.rpart\")\nlrn_rpart$train(task)\nlrn_rpart$model</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>n= 1000 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 1000 300 good (0.7000000 0.3000000)  \n    2) status=0&lt;= ... &lt; 200 DM,... &gt;= 200 DM / salary for at least 1 year 457  60 good (0.8687090 0.1312910) *\n    3) status=no checking account,... &lt; 0 DM 543 240 good (0.5580110 0.4419890)  \n      6) duration&lt; 22.5 306 106 good (0.6535948 0.3464052)  \n       12) credit_history=no credits taken/all credits paid back duly,existing credits paid back duly till now,all credits at this bank paid back duly 278  85 good (0.6942446 0.3057554)  \n         24) amount&lt; 7491.5 271  79 good (0.7084871 0.2915129)  \n           48) purpose=others,car (new),car (used),furniture/equipment,domestic appliances,vacation,retraining,business 256  69 good (0.7304688 0.2695312)  \n             96) duration&lt; 11.5 73   9 good (0.8767123 0.1232877) *\n             97) duration&gt;=11.5 183  60 good (0.6721311 0.3278689)  \n              194) amount&gt;=1387.5 118  29 good (0.7542373 0.2457627) *\n              195) amount&lt; 1387.5 65  31 good (0.5230769 0.4769231)  \n                390) property=unknown / no property,car or other 45  14 good (0.6888889 0.3111111) *\n                391) property=building soc. savings agr. / life insurance,real estate 20   3 bad (0.1500000 0.8500000) *\n           49) purpose=radio/television,repairs 15   5 bad (0.3333333 0.6666667) *\n         25) amount&gt;=7491.5 7   1 bad (0.1428571 0.8571429) *\n       13) credit_history=delay in paying off in the past,critical account/other credits elsewhere 28   7 bad (0.2500000 0.7500000) *\n      7) duration&gt;=22.5 237 103 bad (0.4345992 0.5654008)  \n       14) savings=500 &lt;= ... &lt; 1000 DM,... &gt;= 1000 DM 41  12 good (0.7073171 0.2926829) *\n       15) savings=unknown/no savings account,... &lt; 100 DM,100 &lt;= ... &lt; 500 DM 196  74 bad (0.3775510 0.6224490)  \n         30) duration&lt; 47.5 160  69 bad (0.4312500 0.5687500)  \n           60) purpose=car (new) 23   6 good (0.7391304 0.2608696) *\n           61) purpose=others,car (used),furniture/equipment,domestic appliances,repairs,retraining,business 137  52 bad (0.3795620 0.6204380) *\n         31) duration&gt;=47.5 36   5 bad (0.1388889 0.8611111) *</pre>\n</div>\n</div>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"visualize-the-tree-structure\">\n<h2 class=\"anchored\" data-anchor-id=\"visualize-the-tree-structure\">Visualize the tree structure</h2>\n<p>To interpret the model and to gain more information about the decision making of predictions, we decide to take a closer look at the decision tree structure by visualizing it.</p>\n<details>\n<summary>\n<strong>Hint 1:</strong>\n</summary>\n<p>See code example in the help page <code>?rpart::plot.rpart</code> which shows how to use the <code>plot</code> and <code>text</code> function to the <code>rpart</code> model object. Note that different packages exist to plot the decision tree structure in a visually more appealing way:</p>\n<ul>\n<li>The <code>rpart.plot</code> function from the equally named package <code>rpart.plot</code> which is applied on the raw <code>rpart</code> model object.</li>\n<li>The <code>plot.party</code> function from the package <code>partykit</code> which is applied to a <code>rpart</code> model object after converting it into a <code>party</code> model object using the <code>as.party</code> function.</li>\n<li>The <code>ggparty</code> function from the equally named package <code>ggparty</code> which is applied after converting the <code>rpart</code> model object into a <code>party</code> model object using the <code>as.party</code> function.</li>\n</ul>\n</details>\n<details>\n<summary>\n<strong>Hint 2:</strong>\n</summary>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>library(\"rpart\")\n...(lrn_rpart$...)\ntext(lrn_rpart$...)\n\n# Alternative using e.g. the rpart.plot package\nlibrary(\"rpart.plot\")\n...(lrn_rpart$...)</pre>\n</div>\n</details>\n<div class=\"callout callout-style-default callout-note callout-titled\">\n<div aria-controls=\"callout-2\" aria-expanded=\"false\" aria-label=\"Toggle callout\" class=\"callout-header d-flex align-content-center\" data-bs-=\"\" data-bs-toggle=\"collapse\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nSolution\n</div>\n<div class=\"callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end\"><i class=\"callout-toggle\"></i></div>\n</div>\n<div class=\"callout-2-contents callout-collapse collapse\" id=\"callout-2\">\n<div class=\"callout-body-container callout-body\">\n<p>The possibility of visualizing a tree makes it interpretable and helps to understand how new predictions are calculated.</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>library(rpart.plot)</pre>\n<div class=\"cell-output cell-output-stderr\">\n<pre>Loading required package: rpart</pre>\n</div>\n<pre>rpart.plot(lrn_rpart$model)</pre>\n<div class=\"cell-output-display\">\n<div class=\"quarto-figure quarto-figure-center\">\n<figure class=\"figure\">\n<p><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-lazy-src=\"https://i0.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-6-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-6-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<p><strong>Note:</strong> Other functions to visualize an <code>rpart</code> tree are:</p>\n<ul>\n<li>The (very) basic <code>rpart</code> plot method:</li>\n</ul>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>plot(lrn_rpart$model)\ntext(lrn_rpart$model, use.n = TRUE)</pre>\n<div class=\"cell-output-display\">\n<div class=\"quarto-figure quarto-figure-center\">\n<figure class=\"figure\">\n<p><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-lazy-src=\"https://i1.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-7-1.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" style=\"width:100.0%\"/><noscript><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-7-1.png?w=578&amp;ssl=1\" style=\"width:100.0%\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<ul>\n<li>Convert the <code>rpart</code> object to a <code>party</code> object to automatically use the respective <code>plot()</code> method:</li>\n</ul>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>library(partykit)</pre>\n<div class=\"cell-output cell-output-stderr\">\n<pre>Loading required package: grid</pre>\n</div>\n<div class=\"cell-output cell-output-stderr\">\n<pre>Loading required package: libcoin</pre>\n</div>\n<div class=\"cell-output cell-output-stderr\">\n<pre>Loading required package: mvtnorm</pre>\n</div>\n<pre>partytree = as.party(lrn_rpart$model)\nplot(partytree)</pre>\n<div class=\"cell-output-display\">\n<div class=\"quarto-figure quarto-figure-center\">\n<figure class=\"figure\">\n<p><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-lazy-src=\"https://i0.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-8-1.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" style=\"width:100.0%\"/><noscript><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-8-1.png?w=578&amp;ssl=1\" style=\"width:100.0%\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<ul>\n<li>Use <a href=\"https://cran.r-project.org/web/packages/ggparty/vignettes/ggparty-graphic-partying.html\" rel=\"nofollow\" target=\"_blank\"><code>ggparty</code></a> to create highly customizable plots:</li>\n</ul>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>library(ggparty)</pre>\n<div class=\"cell-output cell-output-stderr\">\n<pre>Loading required package: ggplot2</pre>\n</div>\n<pre>ggparty(partytree) +\n  geom_edge() +\n  geom_edge_label() +\n  geom_node_splitvar() +\n  # pass list to gglist containing all ggplot components we want to plot for each\n  # (default: terminal) node\n  geom_node_plot(gglist = list(geom_bar(aes_string(x = NA, fill = \"credit_risk\"),\n    position = position_fill()), xlab(\"Credit Risk\")))</pre>\n<div class=\"cell-output cell-output-stderr\">\n<pre>Warning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.</pre>\n</div>\n<div class=\"cell-output-display\">\n<div class=\"quarto-figure quarto-figure-center\">\n<figure class=\"figure\">\n<p><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-lazy-src=\"https://i2.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-9-1.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" style=\"width:100.0%\"/><noscript><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-9-1.png?w=578&amp;ssl=1\" style=\"width:100.0%\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"fit-a-random-forest\">\n<h2 class=\"anchored\" data-anchor-id=\"fit-a-random-forest\">Fit a random forest</h2>\n<p>To get a more powerful learner we decide to also fit a random forest. Therefore, fit a random forest with default hyperparameters to the <code>german_credit</code> task.</p>\n<details>\n<summary>\nReminder\n</summary>\n<p>One of the drawbacks of using trees is the instability of the predictor. Small changes in the data may lead to a very different model and therefore a high variance of the predictions. The random forest takes advantages of that and reduces the variance by applying bagging to decision trees.</p>\n</details>\n<details>\n<summary>\n<strong>Hint 1:</strong>\n</summary>\n<p>Use the <code>mlr3</code> learner <code>classif.ranger</code> which uses the <a href=\"https://cran.r-project.org/web/packages/ranger/index.html\" rel=\"nofollow\" target=\"_blank\"><code>ranger</code></a> implementation to train a random forest.</p>\n</details>\n<details>\n<summary>\n<strong>Hint 2:</strong>\n</summary>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>library(mlr3)\nlibrary(mlr3learners)\n\nlrn_ranger = lrn(...) # create the learner\nlrn_ranger$...(...) # train the learner on the task</pre>\n</div>\n</details>\n<div class=\"callout callout-style-default callout-note callout-titled\">\n<div aria-controls=\"callout-3\" aria-expanded=\"false\" aria-label=\"Toggle callout\" class=\"callout-header d-flex align-content-center\" data-bs-=\"\" data-bs-toggle=\"collapse\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nSolution\n</div>\n<div class=\"callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end\"><i class=\"callout-toggle\"></i></div>\n</div>\n<div class=\"callout-3-contents callout-collapse collapse\" id=\"callout-3\">\n<div class=\"callout-body-container callout-body\">\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>library(mlr3)\nlibrary(mlr3learners)\n\nlrn_ranger = lrn(\"classif.ranger\")\nlrn_ranger$train(task)</pre>\n</div>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"roc-analysis\">\n<h2 class=\"anchored\" data-anchor-id=\"roc-analysis\">ROC Analysis</h2>\n<p>The bank wants to use a tree-based model to predict the credit risk. Conduct a simple benchmark to assess if a decision tree or a random forest works better for these purposes. Specifically, the bank wants that among credit applications the system predicts to be “good”, it can expect at most 10% to be “bad”. Simultaneously, the bank aims at correctly classifying 90% or more of all applications that are “good”. Visualize the benchmark results in a way that helps answer this question. Can the bank expect the model to fulfil their requirements? Which model performs better?</p>\n<details>\n<summary>\n<strong>Hint 1:</strong>\n</summary>\nA benchmark requires three arguments: a task, a list of learners, and a resampling object.\n</details>\n<section class=\"level3\" id=\"solution-3\">\n<h3 class=\"anchored\" data-anchor-id=\"solution-3\">Solution</h3>\n<details>\n<summary>\n<strong>Click me</strong>\n</summary>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>tree = lrn(\"classif.rpart\", predict_type = \"prob\")\nforest = lrn(\"classif.ranger\", predict_type = \"prob\")\n\nlrns = list(tree, forest)\n\ncv5 = rsmp(\"cv\", folds = 5)\ncv5$instantiate(task)\n\nbmr = benchmark(benchmark_grid(task, lrns, cv5))</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>INFO  [19:03:32.422] [mlr3] Running benchmark with 10 resampling iterations\nINFO  [19:03:32.502] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 1/5)\nINFO  [19:03:32.619] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 2/5)\nINFO  [19:03:32.719] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 3/5)\nINFO  [19:03:32.813] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 4/5)\nINFO  [19:03:32.908] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 5/5)\nINFO  [19:03:33.022] [mlr3] Applying learner 'classif.ranger' on task 'german_credit' (iter 1/5)\nINFO  [19:03:33.233] [mlr3] Applying learner 'classif.ranger' on task 'german_credit' (iter 2/5)\nINFO  [19:03:33.354] [mlr3] Applying learner 'classif.ranger' on task 'german_credit' (iter 3/5)\nINFO  [19:03:33.477] [mlr3] Applying learner 'classif.ranger' on task 'german_credit' (iter 4/5)\nINFO  [19:03:33.600] [mlr3] Applying learner 'classif.ranger' on task 'german_credit' (iter 5/5)\nINFO  [19:03:34.013] [mlr3] Finished benchmark</pre>\n</div>\n<pre>mlr3viz::autoplot(bmr, type = \"prc\")</pre>\n<div class=\"cell-output-display\">\n<div class=\"quarto-figure quarto-figure-center\">\n<figure class=\"figure\">\n<p><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-lazy-src=\"https://i0.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-13-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-13-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<p>While the random forest dominates the decision tree, neither model can fulfil the bank’s requirement of a precision and recall of &gt;90%.</p>\n</details>\n</section>\n</section>\n<section class=\"level2\" id=\"understand-hyperparameters\">\n<h2 class=\"anchored\" data-anchor-id=\"understand-hyperparameters\">Understand hyperparameters</h2>\n<p>Use <code>task = tsk(\"german_credit\")</code> to create the classification task for the <code>german_credit</code> data. In this exercise, we want to fit decision trees and random forests with different hyperparameters (which can have a significant impact on the performance). Each learner implemented in <code>R</code> (e.g. <code>ranger</code> or <code>rpart</code>) has a lot of control settings that directly influence the model fitting (the so-called hyperparameters). Here, we will consdider the hyperparameters <code>mtry</code> for the <code>ranger</code> learner and <code>maxdepth</code> for the <code>rpart</code> learner.</p>\n<p>Your task is to manually create a list containing multiple <code>rpart</code> and <code>ranger</code> learners with different hyperparameter values (e.g., try out increasing <code>maxdepth</code> values for <code>rpart</code>). In the next step, we will use this list to see how the model performance changes for different hyperparameter values.</p>\n<ul>\n<li><p>The help page of ranger (<code>?ranger</code>) gives a detailed explanation of the hyperparameters:</p>\n<blockquote class=\"blockquote\">\n<p><strong><code>mtry</code>:</strong> Number of variables to possibly split at in each node. Default is the (rounded down) square root of the number variables. Alternatively, a single argument function returning an integer, given the number of independent variables.</p>\n</blockquote>\n<p>NOTE: In a <code>ranger</code> learner created with <code>mlr3</code>, you have the possibility to set <code>mtry.ratio</code> instead of <code>mtry</code> which allows you to set the fraction of variables to be used instead of having to set the number of variables.</p></li>\n<li><p>For <code>rpart</code>, we have to dig a bit deeper. Looking at <code>?rpart</code> contains no description about the hyperparameters. To get further information we have to open <code>?rpart.control</code>:</p>\n<blockquote class=\"blockquote\">\n<p><strong><code>maxdepth</code>:</strong> Set the maximum depth of any node of the final tree, with the root node counted as depth 0. Values greater than 30 rpart will give nonsense results on 32-bit machines.</p>\n</blockquote></li>\n</ul>\n<details>\n<summary>\n<strong>Hint 1:</strong>\n</summary>\n<p>The learners we are focusing on here is a decision tree implemented in <a href=\"https://cran.r-project.org/web/packages/rpart/\" rel=\"nofollow\" target=\"_blank\"><code>rpart</code></a> and a random forest implemented in <a href=\"https://cran.r-project.org/web/packages/ranger/index.html\" rel=\"nofollow\" target=\"_blank\"><code>ranger</code></a>. The corresponding <code>mlr3</code> learner key is <code>\"classif.rpart\"</code> and <code>\"classif.ranger\"</code>. In <code>mlr3</code>, we can get an overview about all hyperparameters in the <code>$param_set</code> slot. With a <code>mlr3</code> learner it is possible to get help about the underlying method by using the <code>$help()</code> method (e.g. <code>?lrn_ranger$help()</code>):</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>lrn(\"classif.rpart\")$help()\nlrn(\"classif.ranger\")$help()</pre>\n</div>\nIf you are looking for a short description of the meaning of a hyperparameter, you need to look at the help page of the corresponding package that implements the learner, e.g. <code>?rpart::rpart.control</code> and <code>?ranger::ranger</code>.\n</details>\n<details>\n<summary>\n<strong>Hint 2:</strong>\n</summary>\n<p>The possible choices for the hyperparameters can also be viewed with <code>$param_set</code>. Setting the hyperparameters can be done directly in the <code>lrn()</code> call:</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre># Define a list of learners for the benchmark:\nlrns = list(\n  lrn(\"classif.rpart\", ...),\n  lrn(\"classif.rpart\", ...),\n  lrn(\"classif.rpart\", ...),\n  lrn(\"classif.ranger\", ...),\n  lrn(\"classif.ranger\", ...),\n  lrn(\"classif.ranger\", ...))</pre>\n</div>\n</details>\n<div class=\"callout callout-style-default callout-note callout-titled\">\n<div aria-controls=\"callout-4\" aria-expanded=\"false\" aria-label=\"Toggle callout\" class=\"callout-header d-flex align-content-center\" data-bs-=\"\" data-bs-toggle=\"collapse\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nSolution\n</div>\n<div class=\"callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end\"><i class=\"callout-toggle\"></i></div>\n</div>\n<div class=\"callout-4-contents callout-collapse collapse\" id=\"callout-4\">\n<div class=\"callout-body-container callout-body\">\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>library(mlr3verse)\nset.seed(31415L)\n\ntask = mlr3::tsk(\"german_credit\")\n\nlrns = list(\n  lrn(\"classif.rpart\", maxdepth = 1),\n  lrn(\"classif.rpart\", maxdepth = 5),\n  lrn(\"classif.rpart\", maxdepth = 20),\n  lrn(\"classif.ranger\", mtry.ratio = 0.2),\n  lrn(\"classif.ranger\", mtry.ratio = 0.5),\n  lrn(\"classif.ranger\", mtry.ratio = 0.8))</pre>\n</div>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"comparison-of-trees-and-random-forests\">\n<h2 class=\"anchored\" data-anchor-id=\"comparison-of-trees-and-random-forests\">Comparison of trees and random forests</h2>\n<p>Does it make a difference w.r.t. model performance if we use different hyperparameters? Use the learners from the previous exercise and compare them in a benchmark. Use 5-fold cross-validation as resampling technique and the classification error as performance measure. Visualize the results of the benchmark.</p>\n<details>\n<summary>\n<strong>Hint 1:</strong>\n</summary>\nThe function to conduct the benchmark is <code>benchmark</code> and requires to define the resampling with <code>rsmp</code> and the benchmark grid with <code>benchmark_grid</code>.\n</details>\n<details>\n<summary>\n<strong>Hint 2:</strong>\n</summary>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>set.seed(31415L)\n\nlrns = list(\n  lrn(\"classif.rpart\", maxdepth = 1),\n  lrn(\"classif.rpart\", maxdepth = 5),\n  lrn(\"classif.rpart\", maxdepth = 20),\n  lrn(\"classif.ranger\", mtry.ratio = 0.2),\n  lrn(\"classif.ranger\", mtry.ratio = 0.5),\n  lrn(\"classif.ranger\", mtry.ratio = 0.8))\n\ncv5 = rsmp(..., folds = ...)\ncv5$instantiate(...)\n\nbmr = ...(...(task, lrns, cv5))\n\nmlr3viz::autoplot(bmr, measure = msr(\"classif.ce\"))</pre>\n</div>\n</details>\n<div class=\"callout callout-style-default callout-note callout-titled\">\n<div aria-controls=\"callout-5\" aria-expanded=\"false\" aria-label=\"Toggle callout\" class=\"callout-header d-flex align-content-center\" data-bs-=\"\" data-bs-toggle=\"collapse\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nSolution\n</div>\n<div class=\"callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end\"><i class=\"callout-toggle\"></i></div>\n</div>\n<div class=\"callout-5-contents callout-collapse collapse\" id=\"callout-5\">\n<div class=\"callout-body-container callout-body\">\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>set.seed(31415L)\n\nlrns = list(\n  lrn(\"classif.rpart\", id = \"rpart_md1\", maxdepth = 1, predict_type = \"prob\"),\n  lrn(\"classif.rpart\", id = \"rpart_md5\", maxdepth = 5, predict_type = \"prob\"),\n  lrn(\"classif.rpart\", id = \"rpart_md20\", maxdepth = 20, predict_type = \"prob\"),\n  lrn(\"classif.ranger\", id = \"rf_mtryr0.2\", mtry.ratio = 0.2, predict_type = \"prob\"),\n  lrn(\"classif.ranger\", id = \"rf_mtryr0.5\", mtry.ratio = 0.5, predict_type = \"prob\"),\n  lrn(\"classif.ranger\", id = \"rf_mtry0.8\", mtry.ratio = 0.8, predict_type = \"prob\"))\n\ncv5 = rsmp(\"cv\", folds = 5)\ncv5$instantiate(task)\n\nbmr = benchmark(benchmark_grid(task, lrns, cv5))</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>INFO  [19:03:34.711] [mlr3] Running benchmark with 30 resampling iterations\nINFO  [19:03:34.784] [mlr3] Applying learner 'rpart_md1' on task 'german_credit' (iter 1/5)\nINFO  [19:03:34.816] [mlr3] Applying learner 'rpart_md1' on task 'german_credit' (iter 2/5)\nINFO  [19:03:34.847] [mlr3] Applying learner 'rpart_md1' on task 'german_credit' (iter 3/5)\nINFO  [19:03:34.878] [mlr3] Applying learner 'rpart_md1' on task 'german_credit' (iter 4/5)\nINFO  [19:03:34.910] [mlr3] Applying learner 'rpart_md1' on task 'german_credit' (iter 5/5)\nINFO  [19:03:34.940] [mlr3] Applying learner 'rpart_md5' on task 'german_credit' (iter 1/5)\nINFO  [19:03:34.971] [mlr3] Applying learner 'rpart_md5' on task 'german_credit' (iter 2/5)\nINFO  [19:03:35.009] [mlr3] Applying learner 'rpart_md5' on task 'german_credit' (iter 3/5)\nINFO  [19:03:35.041] [mlr3] Applying learner 'rpart_md5' on task 'german_credit' (iter 4/5)\nINFO  [19:03:35.072] [mlr3] Applying learner 'rpart_md5' on task 'german_credit' (iter 5/5)\nINFO  [19:03:35.073] [mlr3] Applying learner 'rpart_md20' on task 'german_credit' (iter 1/5)\nINFO  [19:03:35.119] [mlr3] Applying learner 'rpart_md20' on task 'german_credit' (iter 2/5)\nINFO  [19:03:35.160] [mlr3] Applying learner 'rpart_md20' on task 'german_credit' (iter 3/5)\nINFO  [19:03:35.202] [mlr3] Applying learner 'rpart_md20' on task 'german_credit' (iter 4/5)\nINFO  [19:03:35.244] [mlr3] Applying learner 'rpart_md20' on task 'german_credit' (iter 5/5)\nINFO  [19:03:35.286] [mlr3] Applying learner 'rf_mtryr0.2' on task 'german_credit' (iter 1/5)\nINFO  [19:03:35.330] [mlr3] Applying learner 'rf_mtryr0.2' on task 'german_credit' (iter 2/5)\nINFO  [19:03:35.373] [mlr3] Applying learner 'rf_mtryr0.2' on task 'german_credit' (iter 3/5)\nINFO  [19:03:35.422] [mlr3] Applying learner 'rf_mtryr0.2' on task 'german_credit' (iter 4/5)\nINFO  [19:03:35.467] [mlr3] Applying learner 'rf_mtryr0.2' on task 'german_credit' (iter 5/5)\nINFO  [19:03:35.518] [mlr3] Applying learner 'rf_mtryr0.5' on task 'german_credit' (iter 1/5)\nINFO  [19:03:35.571] [mlr3] Applying learner 'rf_mtryr0.5' on task 'german_credit' (iter 2/5)\nINFO  [19:03:35.626] [mlr3] Applying learner 'rf_mtryr0.5' on task 'german_credit' (iter 3/5)\nINFO  [19:03:35.683] [mlr3] Applying learner 'rf_mtryr0.5' on task 'german_credit' (iter 4/5)\nINFO  [19:03:35.738] [mlr3] Applying learner 'rf_mtryr0.5' on task 'german_credit' (iter 5/5)\nINFO  [19:03:35.794] [mlr3] Applying learner 'rf_mtry0.8' on task 'german_credit' (iter 1/5)\nINFO  [19:03:35.850] [mlr3] Applying learner 'rf_mtry0.8' on task 'german_credit' (iter 2/5)\nINFO  [19:03:35.902] [mlr3] Applying learner 'rf_mtry0.8' on task 'german_credit' (iter 3/5)\nINFO  [19:03:35.955] [mlr3] Applying learner 'rf_mtry0.8' on task 'german_credit' (iter 4/5)\nINFO  [19:03:36.014] [mlr3] Applying learner 'rf_mtry0.8' on task 'german_credit' (iter 5/5)\nINFO  [19:03:36.324] [mlr3] Finished benchmark</pre>\n</div>\n<pre>mlr3viz::autoplot(bmr, measure = msr(\"classif.ce\"))</pre>\n<div class=\"cell-output-display\">\n<div class=\"quarto-figure quarto-figure-center\">\n<figure class=\"figure\">\n<p><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-lazy-src=\"https://i0.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-18-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-18-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<p>Looking at the boxplots reveals that the performance of the learners highly depends on the choice of the hyperparameters.</p>\n<p><br/></p>\n<p><strong>Follow up question:</strong> How to properly set the hyperparameters? Answer: Hyperparameter optimization (see next use case)</p>\n</div>\n</div>\n</div>\n</section>\n</section>\n<section class=\"level1\" id=\"summary\">\n<h1>Summary</h1>\n<ul>\n<li>We learned how to use two of the most widely used learner for building a tree with <code>rpart</code> and a random forest with <code>ranger</code>.</li>\n<li>Finally, we looked at different hyperparameter and how they affect the performance in a benchmark.</li>\n<li>The next step would be to use an algorithm to automatically search for good hyperparameter configurations.</li>\n</ul>\n</section>\n<section class=\"level1\" id=\"further-information\">\n<h1>Further information</h1>\n<p><strong>Tree implementations:</strong> One of the longest paragraphs in the <a href=\"https://cran.r-project.org/web/views/MachineLearning.html\" rel=\"nofollow\" target=\"_blank\">CRAN Task View about Machine Learning and Statistical Learning</a> gives an overview of existing tree implementations:</p>\n<blockquote class=\"blockquote\">\n<p>“[…] Tree-structured models for regression, classification and survival analysis, following the ideas in the CART book, are implemented in rpart (shipped with base R) and tree. Package rpart is recommended for computing CART-like trees. A rich toolbox of partitioning algorithms is available in Weka, package RWeka provides an interface to this implementation, including the J4.8-variant of C4.5 and M5. The Cubist package fits rule-based models (similar to trees) with linear regression models in the terminal leaves, instance-based corrections and boosting. The C50 package can fit C5.0 classification trees, rule-based models, and boosted versions of these. pre can fit rule-based models for a wider range of response variable types. […]”</p>\n</blockquote>\n</section>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/\"> mlr-org</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
    "main_text": "Tree Methods\nPosted on\nApril 13, 2025\nby\nGiuseppe Casalicchio\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nmlr-org\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nGoal\nThe goal for this exercise is to familiarize yourself with two very important machine learning methods, the decision tree and random forest. After this exercise, you should be able to train these models and extract important information to understand the model internals.\nExercises\nFit a decision tree\nUse\ntask = tsk(\"german_credit\")\nto create the classification task for the\ngerman_credit\ndata and create a decision tree learner (e.g., a CART learner). Train the decision tree on the\ngerman_credit\nclassification task. Look at the output of the trained decision tree (you have to access the raw model object).\nHint 1:\nThe learner we are focusing on here is a decision tree implemented in\nrpart\n. The corresponding\nmlr3\nlearner key is\n\"classif.rpart\"\n. For this exercise, we use the learner with the default hyperparameters. The raw model object can be accessed from the\n$model\nslot of the trained learner.\nHint 2:\nlibrary(mlr3)\ntask = tsk(...)\nlrn_rpart = lrn(...) # create the learner\nlrn_rpart$train(...) # train the learner on the task\nlrn_rpart$... # access the raw model object that was fitted\nSolution\nlibrary(mlr3)\ntask = tsk(\"german_credit\")\nlrn_rpart = lrn(\"classif.rpart\")\nlrn_rpart$train(task)\nlrn_rpart$model\nn= 1000 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 1000 300 good (0.7000000 0.3000000)  \n    2) status=0<= ... < 200 DM,... >= 200 DM / salary for at least 1 year 457  60 good (0.8687090 0.1312910) *\n    3) status=no checking account,... < 0 DM 543 240 good (0.5580110 0.4419890)  \n      6) duration< 22.5 306 106 good (0.6535948 0.3464052)  \n       12) credit_history=no credits taken/all credits paid back duly,existing credits paid back duly till now,all credits at this bank paid back duly 278  85 good (0.6942446 0.3057554)  \n         24) amount< 7491.5 271  79 good (0.7084871 0.2915129)  \n           48) purpose=others,car (new),car (used),furniture/equipment,domestic appliances,vacation,retraining,business 256  69 good (0.7304688 0.2695312)  \n             96) duration< 11.5 73   9 good (0.8767123 0.1232877) *\n             97) duration>=11.5 183  60 good (0.6721311 0.3278689)  \n              194) amount>=1387.5 118  29 good (0.7542373 0.2457627) *\n              195) amount< 1387.5 65  31 good (0.5230769 0.4769231)  \n                390) property=unknown / no property,car or other 45  14 good (0.6888889 0.3111111) *\n                391) property=building soc. savings agr. / life insurance,real estate 20   3 bad (0.1500000 0.8500000) *\n           49) purpose=radio/television,repairs 15   5 bad (0.3333333 0.6666667) *\n         25) amount>=7491.5 7   1 bad (0.1428571 0.8571429) *\n       13) credit_history=delay in paying off in the past,critical account/other credits elsewhere 28   7 bad (0.2500000 0.7500000) *\n      7) duration>=22.5 237 103 bad (0.4345992 0.5654008)  \n       14) savings=500 <= ... < 1000 DM,... >= 1000 DM 41  12 good (0.7073171 0.2926829) *\n       15) savings=unknown/no savings account,... < 100 DM,100 <= ... < 500 DM 196  74 bad (0.3775510 0.6224490)  \n         30) duration< 47.5 160  69 bad (0.4312500 0.5687500)  \n           60) purpose=car (new) 23   6 good (0.7391304 0.2608696) *\n           61) purpose=others,car (used),furniture/equipment,domestic appliances,repairs,retraining,business 137  52 bad (0.3795620 0.6204380) *\n         31) duration>=47.5 36   5 bad (0.1388889 0.8611111) *\nVisualize the tree structure\nTo interpret the model and to gain more information about the decision making of predictions, we decide to take a closer look at the decision tree structure by visualizing it.\nHint 1:\nSee code example in the help page\n?rpart::plot.rpart\nwhich shows how to use the\nplot\nand\ntext\nfunction to the\nrpart\nmodel object. Note that different packages exist to plot the decision tree structure in a visually more appealing way:\nThe\nrpart.plot\nfunction from the equally named package\nrpart.plot\nwhich is applied on the raw\nrpart\nmodel object.\nThe\nplot.party\nfunction from the package\npartykit\nwhich is applied to a\nrpart\nmodel object after converting it into a\nparty\nmodel object using the\nas.party\nfunction.\nThe\nggparty\nfunction from the equally named package\nggparty\nwhich is applied after converting the\nrpart\nmodel object into a\nparty\nmodel object using the\nas.party\nfunction.\nHint 2:\nlibrary(\"rpart\")\n...(lrn_rpart$...)\ntext(lrn_rpart$...)\n\n# Alternative using e.g. the rpart.plot package\nlibrary(\"rpart.plot\")\n...(lrn_rpart$...)\nSolution\nThe possibility of visualizing a tree makes it interpretable and helps to understand how new predictions are calculated.\nlibrary(rpart.plot)\nLoading required package: rpart\nrpart.plot(lrn_rpart$model)\nNote:\nOther functions to visualize an\nrpart\ntree are:\nThe (very) basic\nrpart\nplot method:\nplot(lrn_rpart$model)\ntext(lrn_rpart$model, use.n = TRUE)\nConvert the\nrpart\nobject to a\nparty\nobject to automatically use the respective\nplot()\nmethod:\nlibrary(partykit)\nLoading required package: grid\nLoading required package: libcoin\nLoading required package: mvtnorm\npartytree = as.party(lrn_rpart$model)\nplot(partytree)\nUse\nggparty\nto create highly customizable plots:\nlibrary(ggparty)\nLoading required package: ggplot2\nggparty(partytree) +\n  geom_edge() +\n  geom_edge_label() +\n  geom_node_splitvar() +\n  # pass list to gglist containing all ggplot components we want to plot for each\n  # (default: terminal) node\n  geom_node_plot(gglist = list(geom_bar(aes_string(x = NA, fill = \"credit_risk\"),\n    position = position_fill()), xlab(\"Credit Risk\")))\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\nFit a random forest\nTo get a more powerful learner we decide to also fit a random forest. Therefore, fit a random forest with default hyperparameters to the\ngerman_credit\ntask.\nReminder\nOne of the drawbacks of using trees is the instability of the predictor. Small changes in the data may lead to a very different model and therefore a high variance of the predictions. The random forest takes advantages of that and reduces the variance by applying bagging to decision trees.\nHint 1:\nUse the\nmlr3\nlearner\nclassif.ranger\nwhich uses the\nranger\nimplementation to train a random forest.\nHint 2:\nlibrary(mlr3)\nlibrary(mlr3learners)\n\nlrn_ranger = lrn(...) # create the learner\nlrn_ranger$...(...) # train the learner on the task\nSolution\nlibrary(mlr3)\nlibrary(mlr3learners)\n\nlrn_ranger = lrn(\"classif.ranger\")\nlrn_ranger$train(task)\nROC Analysis\nThe bank wants to use a tree-based model to predict the credit risk. Conduct a simple benchmark to assess if a decision tree or a random forest works better for these purposes. Specifically, the bank wants that among credit applications the system predicts to be “good”, it can expect at most 10% to be “bad”. Simultaneously, the bank aims at correctly classifying 90% or more of all applications that are “good”. Visualize the benchmark results in a way that helps answer this question. Can the bank expect the model to fulfil their requirements? Which model performs better?\nHint 1:\nA benchmark requires three arguments: a task, a list of learners, and a resampling object.\nSolution\nClick me\ntree = lrn(\"classif.rpart\", predict_type = \"prob\")\nforest = lrn(\"classif.ranger\", predict_type = \"prob\")\n\nlrns = list(tree, forest)\n\ncv5 = rsmp(\"cv\", folds = 5)\ncv5$instantiate(task)\n\nbmr = benchmark(benchmark_grid(task, lrns, cv5))\nINFO  [19:03:32.422] [mlr3] Running benchmark with 10 resampling iterations\nINFO  [19:03:32.502] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 1/5)\nINFO  [19:03:32.619] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 2/5)\nINFO  [19:03:32.719] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 3/5)\nINFO  [19:03:32.813] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 4/5)\nINFO  [19:03:32.908] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 5/5)\nINFO  [19:03:33.022] [mlr3] Applying learner 'classif.ranger' on task 'german_credit' (iter 1/5)\nINFO  [19:03:33.233] [mlr3] Applying learner 'classif.ranger' on task 'german_credit' (iter 2/5)\nINFO  [19:03:33.354] [mlr3] Applying learner 'classif.ranger' on task 'german_credit' (iter 3/5)\nINFO  [19:03:33.477] [mlr3] Applying learner 'classif.ranger' on task 'german_credit' (iter 4/5)\nINFO  [19:03:33.600] [mlr3] Applying learner 'classif.ranger' on task 'german_credit' (iter 5/5)\nINFO  [19:03:34.013] [mlr3] Finished benchmark\nmlr3viz::autoplot(bmr, type = \"prc\")\nWhile the random forest dominates the decision tree, neither model can fulfil the bank’s requirement of a precision and recall of >90%.\nUnderstand hyperparameters\nUse\ntask = tsk(\"german_credit\")\nto create the classification task for the\ngerman_credit\ndata. In this exercise, we want to fit decision trees and random forests with different hyperparameters (which can have a significant impact on the performance). Each learner implemented in\nR\n(e.g.\nranger\nor\nrpart\n) has a lot of control settings that directly influence the model fitting (the so-called hyperparameters). Here, we will consdider the hyperparameters\nmtry\nfor the\nranger\nlearner and\nmaxdepth\nfor the\nrpart\nlearner.\nYour task is to manually create a list containing multiple\nrpart\nand\nranger\nlearners with different hyperparameter values (e.g., try out increasing\nmaxdepth\nvalues for\nrpart\n). In the next step, we will use this list to see how the model performance changes for different hyperparameter values.\nThe help page of ranger (\n?ranger\n) gives a detailed explanation of the hyperparameters:\nmtry\n:\nNumber of variables to possibly split at in each node. Default is the (rounded down) square root of the number variables. Alternatively, a single argument function returning an integer, given the number of independent variables.\nNOTE: In a\nranger\nlearner created with\nmlr3\n, you have the possibility to set\nmtry.ratio\ninstead of\nmtry\nwhich allows you to set the fraction of variables to be used instead of having to set the number of variables.\nFor\nrpart\n, we have to dig a bit deeper. Looking at\n?rpart\ncontains no description about the hyperparameters. To get further information we have to open\n?rpart.control\n:\nmaxdepth\n:\nSet the maximum depth of any node of the final tree, with the root node counted as depth 0. Values greater than 30 rpart will give nonsense results on 32-bit machines.\nHint 1:\nThe learners we are focusing on here is a decision tree implemented in\nrpart\nand a random forest implemented in\nranger\n. The corresponding\nmlr3\nlearner key is\n\"classif.rpart\"\nand\n\"classif.ranger\"\n. In\nmlr3\n, we can get an overview about all hyperparameters in the\n$param_set\nslot. With a\nmlr3\nlearner it is possible to get help about the underlying method by using the\n$help()\nmethod (e.g.\n?lrn_ranger$help()\n):\nlrn(\"classif.rpart\")$help()\nlrn(\"classif.ranger\")$help()\nIf you are looking for a short description of the meaning of a hyperparameter, you need to look at the help page of the corresponding package that implements the learner, e.g.\n?rpart::rpart.control\nand\n?ranger::ranger\n.\nHint 2:\nThe possible choices for the hyperparameters can also be viewed with\n$param_set\n. Setting the hyperparameters can be done directly in the\nlrn()\ncall:\n# Define a list of learners for the benchmark:\nlrns = list(\n  lrn(\"classif.rpart\", ...),\n  lrn(\"classif.rpart\", ...),\n  lrn(\"classif.rpart\", ...),\n  lrn(\"classif.ranger\", ...),\n  lrn(\"classif.ranger\", ...),\n  lrn(\"classif.ranger\", ...))\nSolution\nlibrary(mlr3verse)\nset.seed(31415L)\n\ntask = mlr3::tsk(\"german_credit\")\n\nlrns = list(\n  lrn(\"classif.rpart\", maxdepth = 1),\n  lrn(\"classif.rpart\", maxdepth = 5),\n  lrn(\"classif.rpart\", maxdepth = 20),\n  lrn(\"classif.ranger\", mtry.ratio = 0.2),\n  lrn(\"classif.ranger\", mtry.ratio = 0.5),\n  lrn(\"classif.ranger\", mtry.ratio = 0.8))\nComparison of trees and random forests\nDoes it make a difference w.r.t. model performance if we use different hyperparameters? Use the learners from the previous exercise and compare them in a benchmark. Use 5-fold cross-validation as resampling technique and the classification error as performance measure. Visualize the results of the benchmark.\nHint 1:\nThe function to conduct the benchmark is\nbenchmark\nand requires to define the resampling with\nrsmp\nand the benchmark grid with\nbenchmark_grid\n.\nHint 2:\nset.seed(31415L)\n\nlrns = list(\n  lrn(\"classif.rpart\", maxdepth = 1),\n  lrn(\"classif.rpart\", maxdepth = 5),\n  lrn(\"classif.rpart\", maxdepth = 20),\n  lrn(\"classif.ranger\", mtry.ratio = 0.2),\n  lrn(\"classif.ranger\", mtry.ratio = 0.5),\n  lrn(\"classif.ranger\", mtry.ratio = 0.8))\n\ncv5 = rsmp(..., folds = ...)\ncv5$instantiate(...)\n\nbmr = ...(...(task, lrns, cv5))\n\nmlr3viz::autoplot(bmr, measure = msr(\"classif.ce\"))\nSolution\nset.seed(31415L)\n\nlrns = list(\n  lrn(\"classif.rpart\", id = \"rpart_md1\", maxdepth = 1, predict_type = \"prob\"),\n  lrn(\"classif.rpart\", id = \"rpart_md5\", maxdepth = 5, predict_type = \"prob\"),\n  lrn(\"classif.rpart\", id = \"rpart_md20\", maxdepth = 20, predict_type = \"prob\"),\n  lrn(\"classif.ranger\", id = \"rf_mtryr0.2\", mtry.ratio = 0.2, predict_type = \"prob\"),\n  lrn(\"classif.ranger\", id = \"rf_mtryr0.5\", mtry.ratio = 0.5, predict_type = \"prob\"),\n  lrn(\"classif.ranger\", id = \"rf_mtry0.8\", mtry.ratio = 0.8, predict_type = \"prob\"))\n\ncv5 = rsmp(\"cv\", folds = 5)\ncv5$instantiate(task)\n\nbmr = benchmark(benchmark_grid(task, lrns, cv5))\nINFO  [19:03:34.711] [mlr3] Running benchmark with 30 resampling iterations\nINFO  [19:03:34.784] [mlr3] Applying learner 'rpart_md1' on task 'german_credit' (iter 1/5)\nINFO  [19:03:34.816] [mlr3] Applying learner 'rpart_md1' on task 'german_credit' (iter 2/5)\nINFO  [19:03:34.847] [mlr3] Applying learner 'rpart_md1' on task 'german_credit' (iter 3/5)\nINFO  [19:03:34.878] [mlr3] Applying learner 'rpart_md1' on task 'german_credit' (iter 4/5)\nINFO  [19:03:34.910] [mlr3] Applying learner 'rpart_md1' on task 'german_credit' (iter 5/5)\nINFO  [19:03:34.940] [mlr3] Applying learner 'rpart_md5' on task 'german_credit' (iter 1/5)\nINFO  [19:03:34.971] [mlr3] Applying learner 'rpart_md5' on task 'german_credit' (iter 2/5)\nINFO  [19:03:35.009] [mlr3] Applying learner 'rpart_md5' on task 'german_credit' (iter 3/5)\nINFO  [19:03:35.041] [mlr3] Applying learner 'rpart_md5' on task 'german_credit' (iter 4/5)\nINFO  [19:03:35.072] [mlr3] Applying learner 'rpart_md5' on task 'german_credit' (iter 5/5)\nINFO  [19:03:35.073] [mlr3] Applying learner 'rpart_md20' on task 'german_credit' (iter 1/5)\nINFO  [19:03:35.119] [mlr3] Applying learner 'rpart_md20' on task 'german_credit' (iter 2/5)\nINFO  [19:03:35.160] [mlr3] Applying learner 'rpart_md20' on task 'german_credit' (iter 3/5)\nINFO  [19:03:35.202] [mlr3] Applying learner 'rpart_md20' on task 'german_credit' (iter 4/5)\nINFO  [19:03:35.244] [mlr3] Applying learner 'rpart_md20' on task 'german_credit' (iter 5/5)\nINFO  [19:03:35.286] [mlr3] Applying learner 'rf_mtryr0.2' on task 'german_credit' (iter 1/5)\nINFO  [19:03:35.330] [mlr3] Applying learner 'rf_mtryr0.2' on task 'german_credit' (iter 2/5)\nINFO  [19:03:35.373] [mlr3] Applying learner 'rf_mtryr0.2' on task 'german_credit' (iter 3/5)\nINFO  [19:03:35.422] [mlr3] Applying learner 'rf_mtryr0.2' on task 'german_credit' (iter 4/5)\nINFO  [19:03:35.467] [mlr3] Applying learner 'rf_mtryr0.2' on task 'german_credit' (iter 5/5)\nINFO  [19:03:35.518] [mlr3] Applying learner 'rf_mtryr0.5' on task 'german_credit' (iter 1/5)\nINFO  [19:03:35.571] [mlr3] Applying learner 'rf_mtryr0.5' on task 'german_credit' (iter 2/5)\nINFO  [19:03:35.626] [mlr3] Applying learner 'rf_mtryr0.5' on task 'german_credit' (iter 3/5)\nINFO  [19:03:35.683] [mlr3] Applying learner 'rf_mtryr0.5' on task 'german_credit' (iter 4/5)\nINFO  [19:03:35.738] [mlr3] Applying learner 'rf_mtryr0.5' on task 'german_credit' (iter 5/5)\nINFO  [19:03:35.794] [mlr3] Applying learner 'rf_mtry0.8' on task 'german_credit' (iter 1/5)\nINFO  [19:03:35.850] [mlr3] Applying learner 'rf_mtry0.8' on task 'german_credit' (iter 2/5)\nINFO  [19:03:35.902] [mlr3] Applying learner 'rf_mtry0.8' on task 'german_credit' (iter 3/5)\nINFO  [19:03:35.955] [mlr3] Applying learner 'rf_mtry0.8' on task 'german_credit' (iter 4/5)\nINFO  [19:03:36.014] [mlr3] Applying learner 'rf_mtry0.8' on task 'german_credit' (iter 5/5)\nINFO  [19:03:36.324] [mlr3] Finished benchmark\nmlr3viz::autoplot(bmr, measure = msr(\"classif.ce\"))\nLooking at the boxplots reveals that the performance of the learners highly depends on the choice of the hyperparameters.\nFollow up question:\nHow to properly set the hyperparameters? Answer: Hyperparameter optimization (see next use case)\nSummary\nWe learned how to use two of the most widely used learner for building a tree with\nrpart\nand a random forest with\nranger\n.\nFinally, we looked at different hyperparameter and how they affect the performance in a benchmark.\nThe next step would be to use an algorithm to automatically search for good hyperparameter configurations.\nFurther information\nTree implementations:\nOne of the longest paragraphs in the\nCRAN Task View about Machine Learning and Statistical Learning\ngives an overview of existing tree implementations:\n“[…] Tree-structured models for regression, classification and survival analysis, following the ideas in the CART book, are implemented in rpart (shipped with base R) and tree. Package rpart is recommended for computing CART-like trees. A rich toolbox of partitioning algorithms is available in Weka, package RWeka provides an interface to this implementation, including the J4.8-variant of C4.5 and M5. The Cubist package fits rule-based models (similar to trees) with linear regression models in the terminal leaves, instance-based corrections and boosting. The C50 package can fit C5.0 classification trees, rule-based models, and boosted versions of these. pre can fit rule-based models for a wider range of response variable types. […]”\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nmlr-org\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "meta_description": "Goal The goal for this exercise is to familiarize yourself with two very important machine learning methods, the decision tree and random forest. After this exercise, you should be able to train these models and extract important information to ...",
    "meta_keywords": null,
    "og_description": "Goal The goal for this exercise is to familiarize yourself with two very important machine learning methods, the decision tree and random forest. After this exercise, you should be able to train these models and extract important information to ...",
    "og_image": "https://mlr-org.com/gallery/appliedml/2025-04-10-intro-tree-methods-sol/index_files/figure-html/unnamed-chunk-6-1.png",
    "og_title": "Tree Methods | R-bloggers",
    "raw_jsonld_article": null,
    "reading_time_min": 14.7,
    "sitemap_lastmod": null,
    "twitter_description": "Goal The goal for this exercise is to familiarize yourself with two very important machine learning methods, the decision tree and random forest. After this exercise, you should be able to train these models and extract important information to ...",
    "twitter_title": "Tree Methods | R-bloggers",
    "url": "https://www.r-bloggers.com/2025/04/tree-methods/",
    "word_count": 2943
  }
}