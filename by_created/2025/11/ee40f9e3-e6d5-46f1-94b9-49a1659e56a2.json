{
  "uuid": "ee40f9e3-e6d5-46f1-94b9-49a1659e56a2",
  "created_at": "2025-11-17 20:38:35",
  "raw_json": {
    "article_author": null,
    "article_headline": null,
    "article_modified": null,
    "article_published": null,
    "article_section": null,
    "article_tags": null,
    "canonical_url": "https://www.r-bloggers.com/2024/01/clearer-understanding-of-95-confidence-interval-through-the-lens-of-simulation/",
    "crawled_at": "2025-11-17T09:18:11.675195",
    "external_links": [
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/",
        "text": "r on Everyday Is A School Day"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/#objectives",
        "text": null
      },
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/#ci",
        "text": "What Is Confidence Interval?"
      },
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/#mean",
        "text": "What Does It Actually Mean?"
      },
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/#pop",
        "text": "What If We Know The Truth Of The Population?"
      },
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/#rct",
        "text": "Let’s Simulate Multiple RCT"
      },
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/#viz",
        "text": "Let’s Visualize!"
      },
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/#thoughts",
        "text": "Final Thoughts/Lessons Learnt"
      },
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/#ci",
        "text": null
      },
      {
        "href": "https://en.wikipedia.org/wiki/Confidence_interval",
        "text": "Wikipedia"
      },
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/#mean",
        "text": null
      },
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/#let-the-simulation-begin",
        "text": null
      },
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/#pop",
        "text": null
      },
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/#rct",
        "text": null
      },
      {
        "href": "https://stats.stackexchange.com/questions/183225/confidence-interval-from-rs-prop-test-differs-from-hand-calculation-and-resul",
        "text": "Wilson’s score method"
      },
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/#viz",
        "text": null
      },
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/#thoughts",
        "text": null
      },
      {
        "href": "https://matthewbjane.quarto.pub/guide-to-effect-sizes-and-confidence-intervals",
        "text": "Guide to Effect Sizes and Confidence Intervals"
      },
      {
        "href": "https://www.amazon.com/Confidence-Intervals-Clinical-Research-Pradhan/dp/1138048984",
        "text": "Confidence Intervals for Discrete Data in Clinical Research"
      },
      {
        "href": "https://www.kenkoonwong.com/blog/",
        "text": "comment or visit my other blogs"
      },
      {
        "href": "https://twitter.com/kenkoonwong/",
        "text": "twitter"
      },
      {
        "href": "https://github.com/kenkoonwong/",
        "text": "GitHub"
      },
      {
        "href": "https://med-mastodon.com/@kenkoonwong",
        "text": "Mastodon"
      },
      {
        "href": "https://www.kenkoonwong.com/contact/",
        "text": "contact me"
      },
      {
        "href": "https://www.kenkoonwong.com/blog/confidenceinterval/",
        "text": "r on Everyday Is A School Day"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "h1_title": "R-bloggers",
    "html_title": "Clearer Understanding of 95% Confidence Interval Through The Lens of Simulation | R-bloggers",
    "images": [
      {
        "alt": "image",
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": "image",
        "base64": null,
        "src": "https://i2.wp.com/www.kenkoonwong.com/blog/confidenceinterval/feature.jpg?w=60%25&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i0.wp.com/www.kenkoonwong.com/blog/confidenceinterval/population.jpg?w=578&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i1.wp.com/www.kenkoonwong.com/blog/confidenceinterval/index_files/figure-html/unnamed-chunk-6-1.png?w=450&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i1.wp.com/www.kenkoonwong.com/blog/confidenceinterval/nonsig.png?w=578&ssl=1"
      }
    ],
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/r-on-everyday-is-a-school-day/",
        "text": "r on Everyday Is A School Day"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "lang": "en-US",
    "main_html": "<article class=\"post-381527 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Clearer Understanding of 95% Confidence Interval Through The Lens of Simulation</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">January 14, 2024</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/r-on-everyday-is-a-school-day/\">r on Everyday Is A School Day</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/\"> r on Everyday Is A School Day</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 3.8.9--><blockquote>\n<p>I’m now more confident in my understanding of the 95% confidence interval, but less certain about confidence intervals in general, knowing that we can’t be sure if our current interval includes the true population parameter. On a brighter note, if we have the correct confidence interval, it could still encompass the true parameter even when it’s not statistically significant. I find that quite refreshing</p>\n</blockquote>\n<p align=\"center\">\n<img alt=\"image\" data-lazy-src=\"https://i2.wp.com/www.kenkoonwong.com/blog/confidenceinterval/feature.jpg?w=60%25&amp;ssl=1\" data-recalc-dims=\"1\" height=\"auto\" loading=\"lazy\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"image\" data-recalc-dims=\"1\" height=\"auto\" loading=\"lazy\" src=\"https://i2.wp.com/www.kenkoonwong.com/blog/confidenceinterval/feature.jpg?w=60%25&amp;ssl=1\"/></noscript>\n</p>\n<p>I always thought I knew what a confidence interval was until I revisited the topic. There are plenty of great resources out there covering the same material. However, nothing beats learning through trial and error with your own code and simulations. This may be a repetition of materials available on the web.</p>\n<h3 id=\"objectives\">Objectives:\n  <a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/#objectives\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h3>\n<ul>\n<li>\n<a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/#ci\" rel=\"nofollow\" target=\"_blank\">What Is Confidence Interval?</a></li>\n<li>\n<a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/#mean\" rel=\"nofollow\" target=\"_blank\">What Does It Actually Mean?</a></li>\n<li>Let The Simulation Begin\n<ul>\n<li>\n<a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/#pop\" rel=\"nofollow\" target=\"_blank\">What If We Know The Truth Of The Population?</a></li>\n<li>\n<a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/#rct\" rel=\"nofollow\" target=\"_blank\">Let’s Simulate Multiple RCT</a></li>\n<li>\n<a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/#viz\" rel=\"nofollow\" target=\"_blank\">Let’s Visualize!</a></li>\n</ul>\n</li>\n<li>\n<a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/#thoughts\" rel=\"nofollow\" target=\"_blank\">Final Thoughts/Lessons Learnt</a></li>\n</ul>\n<h3 id=\"ci\">What Is Confidence Interval?\n  <a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/#ci\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h3>\n<p>Per \n<a href=\"https://en.wikipedia.org/wiki/Confidence_interval\" rel=\"nofollow\" target=\"_blank\">Wikipedia</a>:</p>\n<blockquote>\n<p>Informally, in frequentist statistics, a confidence interval (CI) is an interval which is expected to typically contain the parameter being estimated. More specifically, given a confidence level gamma  (95% and 99% are typical values), a CI is a random interval which contains the parameter being estimated gamma % of the time. The confidence level, degree of confidence or confidence coefficient represents the long-run proportion of CIs (at the given confidence level) that theoretically contain the true value of the parameter.</p>\n</blockquote>\n<h3 id=\"mean\">What Does It Actually Mean?\n  <a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/#mean\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h3>\n<p>When conducting an experiment, calculating a 95% confidence interval for the treatment effect doesn’t mean there’s a 95% chance that this specific interval contains the true effect. Instead, it means that if you were to repeat the experiment many times, approximately 95% of those confidence intervals would contain the true effect. The 95% confidence level indicates how often the method will produce intervals that capture the true parameter rather than the probability that any single interval captures it. This understanding is essential to accurately interpret a single confidence interval in your study.</p>\n<p>It’s important to understand that there is no way to know whether your current confidence interval is part of the 95% that covers the true effect. This can be frustrating, but it’s a limitation of the method.</p>\n<p>It is more intuitive to assume that the current confidence interval is one of those 95% that contain the true estimate and interpret it that way. Additionally, the 95% confidence interval coverage does not need to be “significant” to cover the true parameter; it inherently contains if the interval so happens to be one of those 95%.</p>\n<p>If you’re still confused, don’t worry! Running simulations and visualizations can provide a clearer explanation. It’s worth noting that confidence intervals are estimated using different techniques, some more accurate than others, but we won’t be covering that here today.</p>\n<h3 id=\"let-the-simulation-begin\">Let The Simulation Begin\n  <a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/#let-the-simulation-begin\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h3>\n<h3 id=\"pop\">What If We Know The Truth Of The Population?\n  <a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/#pop\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h3>\n<p><img alt=\"\" data-lazy-src=\"https://i0.wp.com/www.kenkoonwong.com/blog/confidenceinterval/population.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.kenkoonwong.com/blog/confidenceinterval/population.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<pre>library(tidyverse)\nlibrary(kableExtra)\nlibrary(pwr)\n\n# population parameters\nn_pop &lt;- 10^6\nplacebo_effect &lt;- 0.2\ntreat_effect &lt;- 0.5\ntrue_y &lt;- treat_effect - placebo_effect\n\n# simulation \nset.seed(1)\nplacebo_pop &lt;- rbinom(n_pop, 1, placebo_effect) \ntreat_pop &lt;- rbinom(n_pop, 1, treat_effect)\n\n# population dataset\ndf_pop &lt;- tibble(outcome_placebo=placebo_pop, outcome_treat=treat_pop) |&gt;\n  mutate(id = row_number())\n</pre><p>Let’s set up a world where we know everything! Say, we know for sure whether a treatment works for certain people and won’t for others. Same for placebo. And also sometimes, both treatment and placebo work for certain people or nothing works. With this method, we constructed a world where we know the truth and simulation comes using sampling of this population.</p>\n<p>The above code sets up such environment. Let’s run through what they mean.</p>\n<ul>\n<li><code>n_pop</code> is the total population, in whom the condition we are interested in.</li>\n<li><code>placebo_effect</code> is set at 20%, meaning there is a probabiliy of successful outcome for 20% of the population if we were to use placebo. This could be that condition just takes time to cure itself, or that there is actual placebo effect.</li>\n<li><code>treatment_effect</code> is set at 50%, whereby 50% of population will achieve successful outcome when given the treatment.</li>\n<li>We then use <code>rbinom</code> to simulate both effects for ALL population of interest and save it into dataframe called <code>df_pop</code>.</li>\n</ul>\n<p>Here the placebo and treatment effects are made up. You can simple change the numbers to create another world. Here you can practice large, moderate, small or no effect.</p>\n<p>Let’s take a look what <code>df_pop</code> looks like</p>\n<pre>df_pop |&gt;\n  head(10) |&gt;\n  select(id, outcome_placebo, outcome_treat) |&gt;\n  kable()\n</pre><table>\n<thead>\n<tr>\n<th style=\"text-align:right;\"> id </th>\n<th style=\"text-align:right;\"> outcome_placebo </th>\n<th style=\"text-align:right;\"> outcome_treat </th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:right;\"> 1 </td>\n<td style=\"text-align:right;\"> 0 </td>\n<td style=\"text-align:right;\"> 0 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 2 </td>\n<td style=\"text-align:right;\"> 0 </td>\n<td style=\"text-align:right;\"> 1 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 3 </td>\n<td style=\"text-align:right;\"> 0 </td>\n<td style=\"text-align:right;\"> 1 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 4 </td>\n<td style=\"text-align:right;\"> 1 </td>\n<td style=\"text-align:right;\"> 0 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 5 </td>\n<td style=\"text-align:right;\"> 0 </td>\n<td style=\"text-align:right;\"> 0 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 6 </td>\n<td style=\"text-align:right;\"> 1 </td>\n<td style=\"text-align:right;\"> 1 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 7 </td>\n<td style=\"text-align:right;\"> 1 </td>\n<td style=\"text-align:right;\"> 0 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 8 </td>\n<td style=\"text-align:right;\"> 0 </td>\n<td style=\"text-align:right;\"> 1 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 9 </td>\n<td style=\"text-align:right;\"> 0 </td>\n<td style=\"text-align:right;\"> 1 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 10 </td>\n<td style=\"text-align:right;\"> 0 </td>\n<td style=\"text-align:right;\"> 1 </td>\n</tr>\n</tbody>\n</table>\n<p><code>id</code> is unique individual. <code>outcome_placebo</code> is the outcome when placebo is given. <code>outcome_treat</code> is outcome when treatment is given. <code>0</code> means not successful. <code>1</code> means successful. Notice how we have outcome for both placebo and treatment for each individual. Look at id <code>6</code> where outcome is successful regardless of treatment and placebo.</p>\n<p>There you have it! Your own made up world of finite population where you know what works, what doesn’t. The beauty of this is that we can then sample from this <code>known</code> world where we know exactly what the treatment effect is (not an estimate), a fixed parameter. Hence, there is no reason to calculate confidence interval because it does not make sense to have one.</p>\n<h3 id=\"rct\">Let’s Simulate Multiple RCT\n  <a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/#rct\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h3>\n<pre>n_cal &lt;- pwr.2p.test(h = ES.h(treat_effect,placebo_effect), power = 0.8, sig.level = 0.05)$n |&gt; ceiling()\n</pre><p>Assuming we want 80% power and alpha of 5%, and effect of <code>0.6435011</code> we need 38 per group.</p>\n<pre>df_full &lt;- tibble(iter=numeric(),sample=numeric(),mean=numeric(),lower=numeric(),upper=numeric(),pval=numeric())\n\nfor (j in 1:12) {\n  df &lt;- tibble(iter=numeric(),sample=numeric(),mean=numeric(),lower=numeric(),upper=numeric(),pval=numeric())\n  \n  # set.seed(1)\n  n &lt;- n_cal*2\n  \n  for (i in 1:100) {\n    df_sample &lt;- df_pop |&gt;\n      slice_sample(n = n) |&gt;\n      rowwise() |&gt;\n      mutate(random_treatment = sample(0:1,1),\n             outcome = case_when(\n               random_treatment == 1 ~ outcome_treat,\n               TRUE ~ outcome_placebo\n             )) \n    \n    treat &lt;- df_sample |&gt;\n      filter(random_treatment == 1) |&gt;\n      pull(outcome)\n    \n    placebo &lt;- df_sample |&gt;\n      filter(random_treatment == 0) |&gt;\n      pull(outcome)\n    \n    ci &lt;- prop.test(x = c(sum(treat),sum(placebo)), n = c(length(treat),length(placebo)), correct = F)\n    mean &lt;- mean(treat) - mean(placebo)\n    # lower &lt;- mean - 1.96*sqrt(mean*(1-mean)/n) #wald, let's use wilson instead\n    lower &lt;- ci$conf.int[1]\n    upper &lt;- ci$conf.int[2]\n    pvalue &lt;- ci$p.value\n    # upper &lt;-  mean + 1.96*sqrt(mean*(1-mean)/n) #wald, let's use wilson instead\n    df &lt;- df |&gt;\n      add_row(tibble(iter=j,sample=i,mean=mean,lower=lower,upper=upper,pval=pvalue))\n  }\n  df_full &lt;- df_full |&gt;\n    add_row(df)\n  \n}\n</pre><p>Let’s break down the code above:</p>\n<ul>\n<li>Create an empty dataframe called <code>df_full</code></li>\n<li>Run 2 for loops\n<ul>\n<li>1st for loop -&gt; 12 sets (these are sets of trials)</li>\n<li>2nd for loop -&gt; 100 trials per set (each trial means one experiment)</li>\n</ul>\n</li>\n<li>Set <code>n</code> for total of <code>2</code> times of calculated number needed for power of 80% and alpha of 5%</li>\n<li>Sample <code>2xn</code> of the population</li>\n<li>Assign randomly placebo or treatment for each individual, then select outcome accordingly</li>\n<li>Use <code>prop.test</code> for test of equal or given proportions\n<ul>\n<li>extract average treatment effect</li>\n<li>extract confidence interval (uses \n<a href=\"https://stats.stackexchange.com/questions/183225/confidence-interval-from-rs-prop-test-differs-from-hand-calculation-and-resul\" rel=\"nofollow\" target=\"_blank\">Wilson’s score method</a>)</li>\n<li>extract p-value (this is more to showcase meaning of power)</li>\n</ul>\n</li>\n<li>Append dataframe</li>\n</ul>\n<pre>df_full |&gt;\n  head(10) |&gt;\n  kable()\n</pre><table>\n<thead>\n<tr>\n<th style=\"text-align:right;\"> iter </th>\n<th style=\"text-align:right;\"> sample </th>\n<th style=\"text-align:right;\"> mean </th>\n<th style=\"text-align:right;\"> lower </th>\n<th style=\"text-align:right;\"> upper </th>\n<th style=\"text-align:right;\"> pval </th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:right;\"> 1 </td>\n<td style=\"text-align:right;\"> 1 </td>\n<td style=\"text-align:right;\"> 0.3473389 </td>\n<td style=\"text-align:right;\"> 0.1492637 </td>\n<td style=\"text-align:right;\"> 0.5454142 </td>\n<td style=\"text-align:right;\"> 0.0018010 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 1 </td>\n<td style=\"text-align:right;\"> 2 </td>\n<td style=\"text-align:right;\"> 0.1448864 </td>\n<td style=\"text-align:right;\"> -0.0569022 </td>\n<td style=\"text-align:right;\"> 0.3466749 </td>\n<td style=\"text-align:right;\"> 0.1746284 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 1 </td>\n<td style=\"text-align:right;\"> 3 </td>\n<td style=\"text-align:right;\"> 0.2464986 </td>\n<td style=\"text-align:right;\"> 0.0436915 </td>\n<td style=\"text-align:right;\"> 0.4493057 </td>\n<td style=\"text-align:right;\"> 0.0243074 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 1 </td>\n<td style=\"text-align:right;\"> 4 </td>\n<td style=\"text-align:right;\"> 0.3492723 </td>\n<td style=\"text-align:right;\"> 0.1482620 </td>\n<td style=\"text-align:right;\"> 0.5502827 </td>\n<td style=\"text-align:right;\"> 0.0016048 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 1 </td>\n<td style=\"text-align:right;\"> 5 </td>\n<td style=\"text-align:right;\"> 0.1842105 </td>\n<td style=\"text-align:right;\"> -0.0229481 </td>\n<td style=\"text-align:right;\"> 0.3913691 </td>\n<td style=\"text-align:right;\"> 0.0874454 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 1 </td>\n<td style=\"text-align:right;\"> 6 </td>\n<td style=\"text-align:right;\"> 0.1843137 </td>\n<td style=\"text-align:right;\"> -0.0384418 </td>\n<td style=\"text-align:right;\"> 0.4070693 </td>\n<td style=\"text-align:right;\"> 0.0913694 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 1 </td>\n<td style=\"text-align:right;\"> 7 </td>\n<td style=\"text-align:right;\"> 0.3756614 </td>\n<td style=\"text-align:right;\"> 0.1632469 </td>\n<td style=\"text-align:right;\"> 0.5880759 </td>\n<td style=\"text-align:right;\"> 0.0004565 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 1 </td>\n<td style=\"text-align:right;\"> 8 </td>\n<td style=\"text-align:right;\"> 0.4816355 </td>\n<td style=\"text-align:right;\"> 0.2976731 </td>\n<td style=\"text-align:right;\"> 0.6655978 </td>\n<td style=\"text-align:right;\"> 0.0000116 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 1 </td>\n<td style=\"text-align:right;\"> 9 </td>\n<td style=\"text-align:right;\"> 0.2437276 </td>\n<td style=\"text-align:right;\"> 0.0518956 </td>\n<td style=\"text-align:right;\"> 0.4355596 </td>\n<td style=\"text-align:right;\"> 0.0104277 </td>\n</tr>\n<tr>\n<td style=\"text-align:right;\"> 1 </td>\n<td style=\"text-align:right;\"> 10 </td>\n<td style=\"text-align:right;\"> 0.1777778 </td>\n<td style=\"text-align:right;\"> -0.0259180 </td>\n<td style=\"text-align:right;\"> 0.3814736 </td>\n<td style=\"text-align:right;\"> 0.0959556 </td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"viz\">Let’s Visualize!\n  <a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/#viz\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h3>\n<pre>df_full |&gt;\n  mutate(true_found = case_when(\n    lower &lt; true_y &amp; upper &gt;  true_y ~ 1,\n    TRUE ~ 0\n  )) |&gt;\n  ggplot(aes(x=sample,y=mean,color=as.factor(true_found))) +\n  geom_point(size=0.5) +\n  geom_errorbar(aes(ymin=lower,ymax=upper), alpha=0.5) +\n  geom_hline(yintercept = true_y) +\n  geom_hline(yintercept = 0, color = \"pink\", alpha = 0.5) +\n  # geom_ribbon(aes(ymin = -0.2, ymax = 0, xmin = 0, xmax = 101), fill = \"pink\", alpha = 0.3) +\n  ylab(\"Average Treatment Effect\") +\n  xlab(\"Trials\") +\n  ggtitle(label = \"Visualizing 95% Confidence Intervalssss\", subtitle = \"CI contains true estimate (torquoise), CI does not contain true estimate (red), \\nfaceted by sets of trials\") +\n  theme_minimal() +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = \"none\") +\n  facet_wrap(.~iter) \n</pre><img data-lazy-src=\"https://i1.wp.com/www.kenkoonwong.com/blog/confidenceinterval/index_files/figure-html/unnamed-chunk-6-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" style=\"display: block; margin: auto;\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.kenkoonwong.com/blog/confidenceinterval/index_files/figure-html/unnamed-chunk-6-1.png?w=450&amp;ssl=1\" style=\"display: block; margin: auto;\"/></noscript>\n<p>Let’s see what is going on here:</p>\n<ul>\n<li>Create a new column <code>true_found</code>\n<ul>\n<li>If the <code>lower</code> and <code>upper</code>, remember these are 95% CI, contain the true parameter (<code>true_y</code>) then throw a <code>1</code>, else <code>0</code></li>\n</ul>\n</li>\n<li>Create <code>ggplot</code>\n<ul>\n<li><code>x-axis</code>: 1 to 100 trials</li>\n<li><code>y-axis</code>: Average Treatment Effect</li>\n<li><code>errorbar</code>: lower and upper 95% CI</li>\n</ul>\n</li>\n<li>Color <code>torquoise</code>: 95%CI contain true treatment effect</li>\n<li>Color <code>red</code>: 95%CI does not contain true treatment effect</li>\n<li><code>Horizontal black</code> line: True treatment effect of the population</li>\n<li><code>Horizontal pink</code> line: Zero treatment effect, any trials with 95%CI crosses this will have p-value &gt;= 0.05</li>\n</ul>\n<p>This is quite fascinating! It is approximately true that ~95% (to be exact 93.75) of the confidence intervals contain the true parameter (treatment effect).</p>\n<p>Also note that there are quite a few trials were not able to correctly reject the null hypothesis, 19.8333333% to be exact. Does that look familiar? It’s beta, isn’t it? If we flipped it around, the proportion of trials that correctly rejected the null hypothesis were 80.1666667%, which is essentially our power!</p>\n<h3 id=\"thoughts\">Final Thoughts/Lessons Learnt\n  <a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/#thoughts\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h3>\n<ul>\n<li>\n<a href=\"https://matthewbjane.quarto.pub/guide-to-effect-sizes-and-confidence-intervals\" rel=\"nofollow\" target=\"_blank\">Guide to Effect Sizes and Confidence Intervals</a>, Highly recommended! I think, is going to be a great resource in the fundamentals of effect size and confidence interval. I’ll keep my eye on this as it develops into a living document!</li>\n<li>\n<a href=\"https://www.amazon.com/Confidence-Intervals-Clinical-Research-Pradhan/dp/1138048984\" rel=\"nofollow\" target=\"_blank\">Confidence Intervals for Discrete Data in Clinical Research</a> is also a great book diving deep into estimating confidence intervals using different formulae.</li>\n<li>It dawned on me that we can never be certain whether our current confidence interval, whether significant or not, contains the true parameter. It is only useful if we assume, our current confidence interval, is one of the approximately 95% of intervals that do contain the true parameter.</li>\n<li>Correct me if I’m wrong, one of the more positive note of confidence interval, if we have the “right” one, whether it crosses zero or not (e.g. accept the null), may still contain one of the true parameter. I found this suprisingly positive!</li>\n</ul>\n<pre>df_full |&gt;\n  mutate(true_found = case_when(\n    lower &lt; true_y &amp; upper &gt;  true_y ~ 1,\n    TRUE ~ 0\n  )) |&gt; \n  filter(true_found == 1, pval &gt;= 0.05) \n</pre><p><img alt=\"\" data-lazy-src=\"https://i1.wp.com/www.kenkoonwong.com/blog/confidenceinterval/nonsig.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.kenkoonwong.com/blog/confidenceinterval/nonsig.png?w=578&amp;ssl=1\"/></noscript>\nTake a look at iter 1, sample 21. Even though the ATE estimate is off &amp; failed to correctly reject the null hypotehsis, the CI still contains the true parameter (which is 0.3), which to me is quite fascinating!</p>\n<ul>\n<li>Finally, should we rename <code>confidence interval</code> to something else less confusing? Maybe it’s just me.</li>\n</ul>\n<br/>\n<br/>\n<p>If you like this article:</p>\n<ul>\n<li>please feel free to send me a \n<a href=\"https://www.kenkoonwong.com/blog/\" rel=\"nofollow\" target=\"_blank\">comment or visit my other blogs</a></li>\n<li>please feel free to follow me on \n<a href=\"https://twitter.com/kenkoonwong/\" rel=\"nofollow\" target=\"_blank\">twitter</a>, \n<a href=\"https://github.com/kenkoonwong/\" rel=\"nofollow\" target=\"_blank\">GitHub</a> or \n<a href=\"https://med-mastodon.com/@kenkoonwong\" rel=\"nofollow\" target=\"_blank\">Mastodon</a></li>\n<li>if you would like collaborate please feel free to \n<a href=\"https://www.kenkoonwong.com/contact/\" rel=\"nofollow\" target=\"_blank\">contact me</a></li>\n</ul>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://www.kenkoonwong.com/blog/confidenceinterval/\"> r on Everyday Is A School Day</a></strong>.</div>\n<hr>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</hr></div> </div>\n</article>",
    "main_text": "Clearer Understanding of 95% Confidence Interval Through The Lens of Simulation\nPosted on\nJanuary 14, 2024\nby\nr on Everyday Is A School Day\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nr on Everyday Is A School Day\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nI’m now more confident in my understanding of the 95% confidence interval, but less certain about confidence intervals in general, knowing that we can’t be sure if our current interval includes the true population parameter. On a brighter note, if we have the correct confidence interval, it could still encompass the true parameter even when it’s not statistically significant. I find that quite refreshing\nI always thought I knew what a confidence interval was until I revisited the topic. There are plenty of great resources out there covering the same material. However, nothing beats learning through trial and error with your own code and simulations. This may be a repetition of materials available on the web.\nObjectives:\nWhat Is Confidence Interval?\nWhat Does It Actually Mean?\nLet The Simulation Begin\nWhat If We Know The Truth Of The Population?\nLet’s Simulate Multiple RCT\nLet’s Visualize!\nFinal Thoughts/Lessons Learnt\nWhat Is Confidence Interval?\nPer\nWikipedia\n:\nInformally, in frequentist statistics, a confidence interval (CI) is an interval which is expected to typically contain the parameter being estimated. More specifically, given a confidence level gamma  (95% and 99% are typical values), a CI is a random interval which contains the parameter being estimated gamma % of the time. The confidence level, degree of confidence or confidence coefficient represents the long-run proportion of CIs (at the given confidence level) that theoretically contain the true value of the parameter.\nWhat Does It Actually Mean?\nWhen conducting an experiment, calculating a 95% confidence interval for the treatment effect doesn’t mean there’s a 95% chance that this specific interval contains the true effect. Instead, it means that if you were to repeat the experiment many times, approximately 95% of those confidence intervals would contain the true effect. The 95% confidence level indicates how often the method will produce intervals that capture the true parameter rather than the probability that any single interval captures it. This understanding is essential to accurately interpret a single confidence interval in your study.\nIt’s important to understand that there is no way to know whether your current confidence interval is part of the 95% that covers the true effect. This can be frustrating, but it’s a limitation of the method.\nIt is more intuitive to assume that the current confidence interval is one of those 95% that contain the true estimate and interpret it that way. Additionally, the 95% confidence interval coverage does not need to be “significant” to cover the true parameter; it inherently contains if the interval so happens to be one of those 95%.\nIf you’re still confused, don’t worry! Running simulations and visualizations can provide a clearer explanation. It’s worth noting that confidence intervals are estimated using different techniques, some more accurate than others, but we won’t be covering that here today.\nLet The Simulation Begin\nWhat If We Know The Truth Of The Population?\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(pwr)\n\n# population parameters\nn_pop <- 10^6\nplacebo_effect <- 0.2\ntreat_effect <- 0.5\ntrue_y <- treat_effect - placebo_effect\n\n# simulation \nset.seed(1)\nplacebo_pop <- rbinom(n_pop, 1, placebo_effect) \ntreat_pop <- rbinom(n_pop, 1, treat_effect)\n\n# population dataset\ndf_pop <- tibble(outcome_placebo=placebo_pop, outcome_treat=treat_pop) |>\n  mutate(id = row_number())\nLet’s set up a world where we know everything! Say, we know for sure whether a treatment works for certain people and won’t for others. Same for placebo. And also sometimes, both treatment and placebo work for certain people or nothing works. With this method, we constructed a world where we know the truth and simulation comes using sampling of this population.\nThe above code sets up such environment. Let’s run through what they mean.\nn_pop\nis the total population, in whom the condition we are interested in.\nplacebo_effect\nis set at 20%, meaning there is a probabiliy of successful outcome for 20% of the population if we were to use placebo. This could be that condition just takes time to cure itself, or that there is actual placebo effect.\ntreatment_effect\nis set at 50%, whereby 50% of population will achieve successful outcome when given the treatment.\nWe then use\nrbinom\nto simulate both effects for ALL population of interest and save it into dataframe called\ndf_pop\n.\nHere the placebo and treatment effects are made up. You can simple change the numbers to create another world. Here you can practice large, moderate, small or no effect.\nLet’s take a look what\ndf_pop\nlooks like\ndf_pop |>\n  head(10) |>\n  select(id, outcome_placebo, outcome_treat) |>\n  kable()\nid\noutcome_placebo\noutcome_treat\n1\n0\n0\n2\n0\n1\n3\n0\n1\n4\n1\n0\n5\n0\n0\n6\n1\n1\n7\n1\n0\n8\n0\n1\n9\n0\n1\n10\n0\n1\nid\nis unique individual.\noutcome_placebo\nis the outcome when placebo is given.\noutcome_treat\nis outcome when treatment is given.\n0\nmeans not successful.\n1\nmeans successful. Notice how we have outcome for both placebo and treatment for each individual. Look at id\n6\nwhere outcome is successful regardless of treatment and placebo.\nThere you have it! Your own made up world of finite population where you know what works, what doesn’t. The beauty of this is that we can then sample from this\nknown\nworld where we know exactly what the treatment effect is (not an estimate), a fixed parameter. Hence, there is no reason to calculate confidence interval because it does not make sense to have one.\nLet’s Simulate Multiple RCT\nn_cal <- pwr.2p.test(h = ES.h(treat_effect,placebo_effect), power = 0.8, sig.level = 0.05)$n |> ceiling()\nAssuming we want 80% power and alpha of 5%, and effect of\n0.6435011\nwe need 38 per group.\ndf_full <- tibble(iter=numeric(),sample=numeric(),mean=numeric(),lower=numeric(),upper=numeric(),pval=numeric())\n\nfor (j in 1:12) {\n  df <- tibble(iter=numeric(),sample=numeric(),mean=numeric(),lower=numeric(),upper=numeric(),pval=numeric())\n  \n  # set.seed(1)\n  n <- n_cal*2\n  \n  for (i in 1:100) {\n    df_sample <- df_pop |>\n      slice_sample(n = n) |>\n      rowwise() |>\n      mutate(random_treatment = sample(0:1,1),\n             outcome = case_when(\n               random_treatment == 1 ~ outcome_treat,\n               TRUE ~ outcome_placebo\n             )) \n    \n    treat <- df_sample |>\n      filter(random_treatment == 1) |>\n      pull(outcome)\n    \n    placebo <- df_sample |>\n      filter(random_treatment == 0) |>\n      pull(outcome)\n    \n    ci <- prop.test(x = c(sum(treat),sum(placebo)), n = c(length(treat),length(placebo)), correct = F)\n    mean <- mean(treat) - mean(placebo)\n    # lower <- mean - 1.96*sqrt(mean*(1-mean)/n) #wald, let's use wilson instead\n    lower <- ci$conf.int[1]\n    upper <- ci$conf.int[2]\n    pvalue <- ci$p.value\n    # upper <-  mean + 1.96*sqrt(mean*(1-mean)/n) #wald, let's use wilson instead\n    df <- df |>\n      add_row(tibble(iter=j,sample=i,mean=mean,lower=lower,upper=upper,pval=pvalue))\n  }\n  df_full <- df_full |>\n    add_row(df)\n  \n}\nLet’s break down the code above:\nCreate an empty dataframe called\ndf_full\nRun 2 for loops\n1st for loop -> 12 sets (these are sets of trials)\n2nd for loop -> 100 trials per set (each trial means one experiment)\nSet\nn\nfor total of\n2\ntimes of calculated number needed for power of 80% and alpha of 5%\nSample\n2xn\nof the population\nAssign randomly placebo or treatment for each individual, then select outcome accordingly\nUse\nprop.test\nfor test of equal or given proportions\nextract average treatment effect\nextract confidence interval (uses\nWilson’s score method\n)\nextract p-value (this is more to showcase meaning of power)\nAppend dataframe\ndf_full |>\n  head(10) |>\n  kable()\niter\nsample\nmean\nlower\nupper\npval\n1\n1\n0.3473389\n0.1492637\n0.5454142\n0.0018010\n1\n2\n0.1448864\n-0.0569022\n0.3466749\n0.1746284\n1\n3\n0.2464986\n0.0436915\n0.4493057\n0.0243074\n1\n4\n0.3492723\n0.1482620\n0.5502827\n0.0016048\n1\n5\n0.1842105\n-0.0229481\n0.3913691\n0.0874454\n1\n6\n0.1843137\n-0.0384418\n0.4070693\n0.0913694\n1\n7\n0.3756614\n0.1632469\n0.5880759\n0.0004565\n1\n8\n0.4816355\n0.2976731\n0.6655978\n0.0000116\n1\n9\n0.2437276\n0.0518956\n0.4355596\n0.0104277\n1\n10\n0.1777778\n-0.0259180\n0.3814736\n0.0959556\nLet’s Visualize!\ndf_full |>\n  mutate(true_found = case_when(\n    lower < true_y & upper >  true_y ~ 1,\n    TRUE ~ 0\n  )) |>\n  ggplot(aes(x=sample,y=mean,color=as.factor(true_found))) +\n  geom_point(size=0.5) +\n  geom_errorbar(aes(ymin=lower,ymax=upper), alpha=0.5) +\n  geom_hline(yintercept = true_y) +\n  geom_hline(yintercept = 0, color = \"pink\", alpha = 0.5) +\n  # geom_ribbon(aes(ymin = -0.2, ymax = 0, xmin = 0, xmax = 101), fill = \"pink\", alpha = 0.3) +\n  ylab(\"Average Treatment Effect\") +\n  xlab(\"Trials\") +\n  ggtitle(label = \"Visualizing 95% Confidence Intervalssss\", subtitle = \"CI contains true estimate (torquoise), CI does not contain true estimate (red), \\nfaceted by sets of trials\") +\n  theme_minimal() +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = \"none\") +\n  facet_wrap(.~iter)\nLet’s see what is going on here:\nCreate a new column\ntrue_found\nIf the\nlower\nand\nupper\n, remember these are 95% CI, contain the true parameter (\ntrue_y\n) then throw a\n1\n, else\n0\nCreate\nggplot\nx-axis\n: 1 to 100 trials\ny-axis\n: Average Treatment Effect\nerrorbar\n: lower and upper 95% CI\nColor\ntorquoise\n: 95%CI contain true treatment effect\nColor\nred\n: 95%CI does not contain true treatment effect\nHorizontal black\nline: True treatment effect of the population\nHorizontal pink\nline: Zero treatment effect, any trials with 95%CI crosses this will have p-value >= 0.05\nThis is quite fascinating! It is approximately true that ~95% (to be exact 93.75) of the confidence intervals contain the true parameter (treatment effect).\nAlso note that there are quite a few trials were not able to correctly reject the null hypothesis, 19.8333333% to be exact. Does that look familiar? It’s beta, isn’t it? If we flipped it around, the proportion of trials that correctly rejected the null hypothesis were 80.1666667%, which is essentially our power!\nFinal Thoughts/Lessons Learnt\nGuide to Effect Sizes and Confidence Intervals\n, Highly recommended! I think, is going to be a great resource in the fundamentals of effect size and confidence interval. I’ll keep my eye on this as it develops into a living document!\nConfidence Intervals for Discrete Data in Clinical Research\nis also a great book diving deep into estimating confidence intervals using different formulae.\nIt dawned on me that we can never be certain whether our current confidence interval, whether significant or not, contains the true parameter. It is only useful if we assume, our current confidence interval, is one of the approximately 95% of intervals that do contain the true parameter.\nCorrect me if I’m wrong, one of the more positive note of confidence interval, if we have the “right” one, whether it crosses zero or not (e.g. accept the null), may still contain one of the true parameter. I found this suprisingly positive!\ndf_full |>\n  mutate(true_found = case_when(\n    lower < true_y & upper >  true_y ~ 1,\n    TRUE ~ 0\n  )) |> \n  filter(true_found == 1, pval >= 0.05)\nTake a look at iter 1, sample 21. Even though the ATE estimate is off & failed to correctly reject the null hypotehsis, the CI still contains the true parameter (which is 0.3), which to me is quite fascinating!\nFinally, should we rename\nconfidence interval\nto something else less confusing? Maybe it’s just me.\nIf you like this article:\nplease feel free to send me a\ncomment or visit my other blogs\nplease feel free to follow me on\ntwitter\n,\nGitHub\nor\nMastodon\nif you would like collaborate please feel free to\ncontact me\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nr on Everyday Is A School Day\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "meta_description": "I’m now more confident in my understanding of the 95% confidence interval, but less certain about confidence intervals in general, knowing that we can’t be sure if our current interval includes the true population parameter. On a brighter note, if we have the correct confidence interval, it could still encompass the true parameter even when it’s not statistically significant. I find that quite refreshing I always thought I knew what a confidence interval was until I revisited the topic. There are plenty of great resources out there covering the same material. However, nothing beats learning through trial and error with your own code and simulations. This may be a repetition of materials available on the web. Objectives: What Is Confidence Interval? What Does It Actually Mean? Let The Simulation Begin What If We Know The Truth Of The Population? Let’s Simulate Multiple RCT Let’s Visualize! Final Thoughts/Lessons Learnt What Is Confidence Interval? Per Wikipedia: Informally, in frequentist statistics, a confidence interval (CI) is an interval which is expected to typically contain the parameter being estimated. More specifically, given a confidence level gamma (95% and 99% are typical values), a CI is a random interval which contains the parameter being estimated gamma % of the time. The confidence level, degree of confidence or confidence coefficient represents the long-run proportion of CIs (at the given confidence level) that theoretically contain the true value of the parameter. What Does It Actually Mean? When conducting an experiment, calculating a 95% confidence interval for the treatment effect doesn’t mean there’s a 95% chance that this specific interval contains the true effect. Instead, it means that if you were to repeat the experiment many times, approximately 95% of those confidence intervals would contain the true effect. The 95% confidence level indicates how often the method will produce intervals that capture the true parameter rather than the probability that any single interval captures it. This understanding is essential to accurately interpret a single confidence interval in your study. It’s important to understand that there is no way to know whether your current confidence interval is part of the 95% that covers the true effect. This can be frustrating, but it’s a limitation of the method. It is more intuitive to assume that the current confidence interval is one of those 95% that contain the true estimate and interpret it that way. Additionally, the 95% confidence interval coverage does not need to be “significant” to cover the true parameter; it inherently contains if the interval so happens to be one of those 95%. If you’re still confused, don’t worry! Running simulations and visualizations can provide a clearer explanation. It’s worth noting that confidence intervals are estimated using different techniques, some more accurate than others, but we won’t be covering that here today. Let The Simulation Begin What If We Know The Truth Of The Population? library(tidyverse) library(kableExtra) library(pwr) # population parameters n_pop 12 sets (these are sets of trials) 2nd for loop -> 100 trials per set (each trial means one experiment) Set n for total of 2 times of calculated number needed for power of 80% and alpha of 5% Sample 2xn of the population Assign randomly placebo or treatment for each individual, then select outcome accordingly Use prop.test for test of equal or given proportions extract average treatment effect extract confidence interval (uses Wilson’s score method) extract p-value (this is more to showcase meaning of power) Append dataframe df_full |> head(10) |> kable() iter sample mean lower upper pval 1 1 0.3473389 0.1492637 0.5454142 0.0018010 1 2 0.1448864 -0.0569022 0.3466749 0.1746284 1 3 0.2464986 0.0436915 0.4493057 0.0243074 1 4 0.3492723 0.1482620 0.5502827 0.0016048 1 5 0.1842105 -0.0229481 0.3913691 0.0874454 1 6 0.1843137 -0.0384418 0.4070693 0.0913694 1 7 0.3756614 0.1632469 0.5880759 0.0004565 1 8 0.4816355 0.2976731 0.6655978 0.0000116 1 9 0.2437276 0.0518956 0.4355596 0.0104277 1 10 0.1777778 -0.0259180 0.3814736 0.0959556 Let’s Visualize! df_full |> mutate(true_found = case_when( lower true_y ~ 1, TRUE ~ 0 )) |> ggplot(aes(x=sample,y=mean,color=as.factor(true_found))) + geom_point(size=0.5) + geom_errorbar(aes(ymin=lower,ymax=upper), alpha=0.5) + geom_hline(yintercept = true_y) + geom_hline(yintercept = 0, color = \"pink\", alpha = 0.5) + # geom_ribbon(aes(ymin = -0.2, ymax = 0, xmin = 0, xmax = 101), fill = \"pink\", alpha = 0.3) + ylab(\"Average Treatment Effect\") + xlab(\"Trials\") + ggtitle(label = \"Visualizing 95% Confidence Intervalssss\", subtitle = \"CI contains true estimate (torquoise), CI does not contain true estimate (red), \\nfaceted by sets of trials\") + theme_minimal() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\") + facet_wrap(.~iter) Let’s see what is going on here: Create a new column true_found If the lower and upper, remember these are 95% CI, contain the true parameter (true_y) then throw a 1, else 0 Create ggplot x-axis: 1 to 100 trials y-axis: Average Treatment Effect errorbar: lower and upper 95% CI Color torquoise: 95%CI contain true treatment effect Color red: 95%CI does not contain true treatment effect Horizontal black line: True treatment effect of the population Horizontal pink line: Zero treatment effect, any trials with 95%CI crosses this will have p-value >= 0.05 This is quite fascinating! It is approximately true that ~95% (to be exact 93.75) of the confidence intervals contain the true parameter (treatment effect). Also note that there are quite a few trials were not able to correctly reject the null hypothesis, 19.8333333% to be exact. Does that look familiar? It’s beta, isn’t it? If we flipped it around, the proportion of trials that correctly rejected the null hypothesis were 80.1666667%, which is essentially our power! Final Thoughts/Lessons Learnt Guide to Effect Sizes and Confidence Intervals, Highly recommended! I think, is going to be a great resource in the fundamentals of effect size and confidence interval. I’ll keep my eye on this as it develops into a living document! Confidence Intervals for Discrete Data in Clinical Research is also a great book diving deep into estimating confidence intervals using different formulae. It dawned on me that we can never be certain whether our current confidence interval, whether significant or not, contains the true parameter. It is only useful if we assume, our current confidence interval, is one of the approximately 95% of intervals that do contain the true parameter. Correct me if I’m wrong, one of the more positive note of confidence interval, if we have the “right” one, whether it crosses zero or not (e.g. accept the null), may still contain one of the true parameter. I found this suprisingly positive! df_full |> mutate(true_found = case_when( lower true_y ~ 1, TRUE ~ 0 )) |> filter(true_found == 1, pval >= 0.05) Take a look at iter 1, sample 21. Even though the ATE estimate is off & failed to correctly reject the null hypotehsis, the CI still contains the true parameter (which is 0.3), which to me is quite fascinating! Finally, should we rename confidence interval to something else less confusing? Maybe it’s just me. If you like this article: please feel free to send me a comment or visit my other blogs please feel free to follow me on twitter, GitHub or Mastodon if you would like collaborate please feel free to contact me",
    "meta_keywords": null,
    "og_description": "I’m now more confident in my understanding of the 95% confidence interval, but less certain about confidence intervals in general, knowing that we can’t be sure if our current interval includes the true population parameter. On a brighter note, if we have the correct confidence interval, it could still encompass the true parameter even when it’s not statistically significant. I find that quite refreshing I always thought I knew what a confidence interval was until I revisited the topic. There are plenty of great resources out there covering the same material. However, nothing beats learning through trial and error with your own code and simulations. This may be a repetition of materials available on the web. Objectives: What Is Confidence Interval? What Does It Actually Mean? Let The Simulation Begin What If We Know The Truth Of The Population? Let’s Simulate Multiple RCT Let’s Visualize! Final Thoughts/Lessons Learnt What Is Confidence Interval? Per Wikipedia: Informally, in frequentist statistics, a confidence interval (CI) is an interval which is expected to typically contain the parameter being estimated. More specifically, given a confidence level gamma (95% and 99% are typical values), a CI is a random interval which contains the parameter being estimated gamma % of the time. The confidence level, degree of confidence or confidence coefficient represents the long-run proportion of CIs (at the given confidence level) that theoretically contain the true value of the parameter. What Does It Actually Mean? When conducting an experiment, calculating a 95% confidence interval for the treatment effect doesn’t mean there’s a 95% chance that this specific interval contains the true effect. Instead, it means that if you were to repeat the experiment many times, approximately 95% of those confidence intervals would contain the true effect. The 95% confidence level indicates how often the method will produce intervals that capture the true parameter rather than the probability that any single interval captures it. This understanding is essential to accurately interpret a single confidence interval in your study. It’s important to understand that there is no way to know whether your current confidence interval is part of the 95% that covers the true effect. This can be frustrating, but it’s a limitation of the method. It is more intuitive to assume that the current confidence interval is one of those 95% that contain the true estimate and interpret it that way. Additionally, the 95% confidence interval coverage does not need to be “significant” to cover the true parameter; it inherently contains if the interval so happens to be one of those 95%. If you’re still confused, don’t worry! Running simulations and visualizations can provide a clearer explanation. It’s worth noting that confidence intervals are estimated using different techniques, some more accurate than others, but we won’t be covering that here today. Let The Simulation Begin What If We Know The Truth Of The Population? library(tidyverse) library(kableExtra) library(pwr) # population parameters n_pop 12 sets (these are sets of trials) 2nd for loop -> 100 trials per set (each trial means one experiment) Set n for total of 2 times of calculated number needed for power of 80% and alpha of 5% Sample 2xn of the population Assign randomly placebo or treatment for each individual, then select outcome accordingly Use prop.test for test of equal or given proportions extract average treatment effect extract confidence interval (uses Wilson’s score method) extract p-value (this is more to showcase meaning of power) Append dataframe df_full |> head(10) |> kable() iter sample mean lower upper pval 1 1 0.3473389 0.1492637 0.5454142 0.0018010 1 2 0.1448864 -0.0569022 0.3466749 0.1746284 1 3 0.2464986 0.0436915 0.4493057 0.0243074 1 4 0.3492723 0.1482620 0.5502827 0.0016048 1 5 0.1842105 -0.0229481 0.3913691 0.0874454 1 6 0.1843137 -0.0384418 0.4070693 0.0913694 1 7 0.3756614 0.1632469 0.5880759 0.0004565 1 8 0.4816355 0.2976731 0.6655978 0.0000116 1 9 0.2437276 0.0518956 0.4355596 0.0104277 1 10 0.1777778 -0.0259180 0.3814736 0.0959556 Let’s Visualize! df_full |> mutate(true_found = case_when( lower true_y ~ 1, TRUE ~ 0 )) |> ggplot(aes(x=sample,y=mean,color=as.factor(true_found))) + geom_point(size=0.5) + geom_errorbar(aes(ymin=lower,ymax=upper), alpha=0.5) + geom_hline(yintercept = true_y) + geom_hline(yintercept = 0, color = \"pink\", alpha = 0.5) + # geom_ribbon(aes(ymin = -0.2, ymax = 0, xmin = 0, xmax = 101), fill = \"pink\", alpha = 0.3) + ylab(\"Average Treatment Effect\") + xlab(\"Trials\") + ggtitle(label = \"Visualizing 95% Confidence Intervalssss\", subtitle = \"CI contains true estimate (torquoise), CI does not contain true estimate (red), \\nfaceted by sets of trials\") + theme_minimal() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\") + facet_wrap(.~iter) Let’s see what is going on here: Create a new column true_found If the lower and upper, remember these are 95% CI, contain the true parameter (true_y) then throw a 1, else 0 Create ggplot x-axis: 1 to 100 trials y-axis: Average Treatment Effect errorbar: lower and upper 95% CI Color torquoise: 95%CI contain true treatment effect Color red: 95%CI does not contain true treatment effect Horizontal black line: True treatment effect of the population Horizontal pink line: Zero treatment effect, any trials with 95%CI crosses this will have p-value >= 0.05 This is quite fascinating! It is approximately true that ~95% (to be exact 93.75) of the confidence intervals contain the true parameter (treatment effect). Also note that there are quite a few trials were not able to correctly reject the null hypothesis, 19.8333333% to be exact. Does that look familiar? It’s beta, isn’t it? If we flipped it around, the proportion of trials that correctly rejected the null hypothesis were 80.1666667%, which is essentially our power! Final Thoughts/Lessons Learnt Guide to Effect Sizes and Confidence Intervals, Highly recommended! I think, is going to be a great resource in the fundamentals of effect size and confidence interval. I’ll keep my eye on this as it develops into a living document! Confidence Intervals for Discrete Data in Clinical Research is also a great book diving deep into estimating confidence intervals using different formulae. It dawned on me that we can never be certain whether our current confidence interval, whether significant or not, contains the true parameter. It is only useful if we assume, our current confidence interval, is one of the approximately 95% of intervals that do contain the true parameter. Correct me if I’m wrong, one of the more positive note of confidence interval, if we have the “right” one, whether it crosses zero or not (e.g. accept the null), may still contain one of the true parameter. I found this suprisingly positive! df_full |> mutate(true_found = case_when( lower true_y ~ 1, TRUE ~ 0 )) |> filter(true_found == 1, pval >= 0.05) Take a look at iter 1, sample 21. Even though the ATE estimate is off & failed to correctly reject the null hypotehsis, the CI still contains the true parameter (which is 0.3), which to me is quite fascinating! Finally, should we rename confidence interval to something else less confusing? Maybe it’s just me. If you like this article: please feel free to send me a comment or visit my other blogs please feel free to follow me on twitter, GitHub or Mastodon if you would like collaborate please feel free to contact me",
    "og_image": "https://www.kenkoonwong.com/blog/confidenceinterval/feature.jpg",
    "og_title": "Clearer Understanding of 95% Confidence Interval Through The Lens of Simulation | R-bloggers",
    "raw_jsonld_article": null,
    "reading_time_min": 10.2,
    "sitemap_lastmod": "2024-01-15T00:00:00+00:00",
    "twitter_description": "I’m now more confident in my understanding of the 95% confidence interval, but less certain about confidence intervals in general, knowing that we can’t be sure if our current interval includes the true population parameter. On a brighter note, if we have the correct confidence interval, it could still encompass the true parameter even when it’s not statistically significant. I find that quite refreshing I always thought I knew what a confidence interval was until I revisited the topic. There are plenty of great resources out there covering the same material. However, nothing beats learning through trial and error with your own code and simulations. This may be a repetition of materials available on the web. Objectives: What Is Confidence Interval? What Does It Actually Mean? Let The Simulation Begin What If We Know The Truth Of The Population? Let’s Simulate Multiple RCT Let’s Visualize! Final Thoughts/Lessons Learnt What Is Confidence Interval? Per Wikipedia: Informally, in frequentist statistics, a confidence interval (CI) is an interval which is expected to typically contain the parameter being estimated. More specifically, given a confidence level gamma (95% and 99% are typical values), a CI is a random interval which contains the parameter being estimated gamma % of the time. The confidence level, degree of confidence or confidence coefficient represents the long-run proportion of CIs (at the given confidence level) that theoretically contain the true value of the parameter. What Does It Actually Mean? When conducting an experiment, calculating a 95% confidence interval for the treatment effect doesn’t mean there’s a 95% chance that this specific interval contains the true effect. Instead, it means that if you were to repeat the experiment many times, approximately 95% of those confidence intervals would contain the true effect. The 95% confidence level indicates how often the method will produce intervals that capture the true parameter rather than the probability that any single interval captures it. This understanding is essential to accurately interpret a single confidence interval in your study. It’s important to understand that there is no way to know whether your current confidence interval is part of the 95% that covers the true effect. This can be frustrating, but it’s a limitation of the method. It is more intuitive to assume that the current confidence interval is one of those 95% that contain the true estimate and interpret it that way. Additionally, the 95% confidence interval coverage does not need to be “significant” to cover the true parameter; it inherently contains if the interval so happens to be one of those 95%. If you’re still confused, don’t worry! Running simulations and visualizations can provide a clearer explanation. It’s worth noting that confidence intervals are estimated using different techniques, some more accurate than others, but we won’t be covering that here today. Let The Simulation Begin What If We Know The Truth Of The Population? library(tidyverse) library(kableExtra) library(pwr) # population parameters n_pop 12 sets (these are sets of trials) 2nd for loop -> 100 trials per set (each trial means one experiment) Set n for total of 2 times of calculated number needed for power of 80% and alpha of 5% Sample 2xn of the population Assign randomly placebo or treatment for each individual, then select outcome accordingly Use prop.test for test of equal or given proportions extract average treatment effect extract confidence interval (uses Wilson’s score method) extract p-value (this is more to showcase meaning of power) Append dataframe df_full |> head(10) |> kable() iter sample mean lower upper pval 1 1 0.3473389 0.1492637 0.5454142 0.0018010 1 2 0.1448864 -0.0569022 0.3466749 0.1746284 1 3 0.2464986 0.0436915 0.4493057 0.0243074 1 4 0.3492723 0.1482620 0.5502827 0.0016048 1 5 0.1842105 -0.0229481 0.3913691 0.0874454 1 6 0.1843137 -0.0384418 0.4070693 0.0913694 1 7 0.3756614 0.1632469 0.5880759 0.0004565 1 8 0.4816355 0.2976731 0.6655978 0.0000116 1 9 0.2437276 0.0518956 0.4355596 0.0104277 1 10 0.1777778 -0.0259180 0.3814736 0.0959556 Let’s Visualize! df_full |> mutate(true_found = case_when( lower true_y ~ 1, TRUE ~ 0 )) |> ggplot(aes(x=sample,y=mean,color=as.factor(true_found))) + geom_point(size=0.5) + geom_errorbar(aes(ymin=lower,ymax=upper), alpha=0.5) + geom_hline(yintercept = true_y) + geom_hline(yintercept = 0, color = \"pink\", alpha = 0.5) + # geom_ribbon(aes(ymin = -0.2, ymax = 0, xmin = 0, xmax = 101), fill = \"pink\", alpha = 0.3) + ylab(\"Average Treatment Effect\") + xlab(\"Trials\") + ggtitle(label = \"Visualizing 95% Confidence Intervalssss\", subtitle = \"CI contains true estimate (torquoise), CI does not contain true estimate (red), \\nfaceted by sets of trials\") + theme_minimal() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = \"none\") + facet_wrap(.~iter) Let’s see what is going on here: Create a new column true_found If the lower and upper, remember these are 95% CI, contain the true parameter (true_y) then throw a 1, else 0 Create ggplot x-axis: 1 to 100 trials y-axis: Average Treatment Effect errorbar: lower and upper 95% CI Color torquoise: 95%CI contain true treatment effect Color red: 95%CI does not contain true treatment effect Horizontal black line: True treatment effect of the population Horizontal pink line: Zero treatment effect, any trials with 95%CI crosses this will have p-value >= 0.05 This is quite fascinating! It is approximately true that ~95% (to be exact 93.75) of the confidence intervals contain the true parameter (treatment effect). Also note that there are quite a few trials were not able to correctly reject the null hypothesis, 19.8333333% to be exact. Does that look familiar? It’s beta, isn’t it? If we flipped it around, the proportion of trials that correctly rejected the null hypothesis were 80.1666667%, which is essentially our power! Final Thoughts/Lessons Learnt Guide to Effect Sizes and Confidence Intervals, Highly recommended! I think, is going to be a great resource in the fundamentals of effect size and confidence interval. I’ll keep my eye on this as it develops into a living document! Confidence Intervals for Discrete Data in Clinical Research is also a great book diving deep into estimating confidence intervals using different formulae. It dawned on me that we can never be certain whether our current confidence interval, whether significant or not, contains the true parameter. It is only useful if we assume, our current confidence interval, is one of the approximately 95% of intervals that do contain the true parameter. Correct me if I’m wrong, one of the more positive note of confidence interval, if we have the “right” one, whether it crosses zero or not (e.g. accept the null), may still contain one of the true parameter. I found this suprisingly positive! df_full |> mutate(true_found = case_when( lower true_y ~ 1, TRUE ~ 0 )) |> filter(true_found == 1, pval >= 0.05) Take a look at iter 1, sample 21. Even though the ATE estimate is off & failed to correctly reject the null hypotehsis, the CI still contains the true parameter (which is 0.3), which to me is quite fascinating! Finally, should we rename confidence interval to something else less confusing? Maybe it’s just me. If you like this article: please feel free to send me a comment or visit my other blogs please feel free to follow me on twitter, GitHub or Mastodon if you would like collaborate please feel free to contact me",
    "twitter_title": "Clearer Understanding of 95% Confidence Interval Through The Lens of Simulation | R-bloggers",
    "url": "https://www.r-bloggers.com/2024/01/clearer-understanding-of-95-confidence-interval-through-the-lens-of-simulation/",
    "word_count": 2050
  }
}