{
  "uuid": "07c85105-60a2-491a-8d05-c972e3773a59",
  "created_at": "2025-11-17 20:38:32",
  "raw_json": {
    "article_author": null,
    "article_headline": null,
    "article_modified": null,
    "article_published": null,
    "article_section": null,
    "article_tags": null,
    "canonical_url": "https://www.r-bloggers.com/2024/01/r-doparallel-a-brain-friendly-introduction-to-parallelism-in-r/",
    "crawled_at": "2025-11-17T09:17:19.250342",
    "external_links": [
      {
        "href": "https://appsilon.com/r-doparallel/",
        "text": "Tag: r - Appsilon | Enterprise R Shiny Dashboards"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://appsilon.com/r-data-processing-frameworks/",
        "text": "Take a look at our detailed R Data Processing Frameworks comparison"
      },
      {
        "href": "https://appsilon.com/r-doparallel/#introduction",
        "text": "What is Parallelism and Why Should You Care?"
      },
      {
        "href": "https://appsilon.com/r-doparallel/#r-doparallel",
        "text": "R doParallel – Everything You Need to Know"
      },
      {
        "href": "https://appsilon.com/r-doparallel/#summary",
        "text": "Summing up R doParallel"
      },
      {
        "href": "https://appsilon.com/blog/",
        "text": "Appsilon Blog"
      },
      {
        "href": "https://appsilon.com/object-oriented-programming-in-r-part-1/",
        "text": "Take a look at the first of many articles in our new series"
      },
      {
        "href": "https://appsilon.com/r-doparallel/",
        "text": "Tag: r - Appsilon | Enterprise R Shiny Dashboards"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "h1_title": "R-bloggers",
    "html_title": "R doParallel: A Brain-Friendly Introduction to Parallelism in R | R-bloggers",
    "images": [
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://wordpress.appsilon.com/wp-content/uploads/2024/01/R-1.webp"
      },
      {
        "alt": "Image 1 - Number of CPU cores",
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": "Image 1 - Number of CPU cores",
        "base64": null,
        "src": "https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-1-Number-of-CPU-cores.webp"
      },
      {
        "alt": "Image 2 - Computation results",
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": "Image 2 - Computation results",
        "base64": null,
        "src": "https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-2-Computation-results.webp"
      },
      {
        "alt": "Image 3 - Runtime comparisons",
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": "Image 3 - Runtime comparisons",
        "base64": null,
        "src": "https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-3-Runtime-comparisons.webp"
      },
      {
        "alt": "Image 4 - Runtime for 1K iterations",
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": "Image 4 - Runtime for 1K iterations",
        "base64": null,
        "src": "https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-4-Runtime-for-1K-iterations.webp"
      },
      {
        "alt": "Image 5 - Runtime for 10K iterations",
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": "Image 5 - Runtime for 10K iterations",
        "base64": null,
        "src": "https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-5-Runtime-for-10K-iterations.webp"
      },
      {
        "alt": "Image 6 - Runtime for 100K iterations",
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": "Image 6 - Runtime for 100K iterations",
        "base64": null,
        "src": "https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-6-Runtime-for-100K-iterations.webp"
      },
      {
        "alt": "Image 7 - Runtime for 1M iterations",
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": "Image 7 - Runtime for 1M iterations",
        "base64": null,
        "src": "https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-7-Runtime-for-1M-iterations.webp"
      }
    ],
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/dario-radecic/",
        "text": "Dario Radečić"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "lang": "en-US",
    "main_html": "<article class=\"post-381585 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">R doParallel: A Brain-Friendly Introduction to Parallelism in R</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">January 18, 2024</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/dario-radecic/\">Dario Radečić</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://appsilon.com/r-doparallel/\"> Tag: r - Appsilon | Enterprise R Shiny Dashboards</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 3.8.9--><div><img alt=\"\" class=\"attachment-medium size-medium wp-post-image\" data-lazy-src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/R-1.webp\" decoding=\"async\" loading=\"lazy\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" style=\"margin-bottom: 15px;\" width=\"450\"/><noscript><img alt=\"\" class=\"attachment-medium size-medium wp-post-image\" decoding=\"async\" loading=\"lazy\" src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/R-1.webp\" style=\"margin-bottom: 15px;\" width=\"450\"/></noscript></div><p>Implementing parallel execution in your code can be both a blessing and a curse. On the one hand, you’re leveraging more power your CPU has to offer and increasing execution speed, but on the other, you’re sacrificing the simplicity of single-threaded programs.</p>\n<p>Luckily, <b>parallel processing in R is extremely developer-friendly</b>. You don’t have to change much on your end, and R works its magic behind the scenes. Today you’ll learn the basics of parallel execution in R with the R doParallel package. By the end, you’ll know how to parallelize loop operations in R and will know exactly how much faster multi-threaded R computations are.</p>\n<blockquote><p>Looking to speed up your data processing pipelines? <a href=\"https://appsilon.com/r-data-processing-frameworks/\" rel=\"nofollow\" target=\"_blank\">Take a look at our detailed R Data Processing Frameworks comparison</a>.</p></blockquote>\n<h3>Table of contents:</h3>\n<ul>\n<li><strong><a href=\"https://appsilon.com/r-doparallel/#introduction\" rel=\"nofollow\" target=\"_blank\">What is Parallelism and Why Should You Care?</a></strong></li>\n<li><strong><a href=\"https://appsilon.com/r-doparallel/#r-doparallel\" rel=\"nofollow\" target=\"_blank\">R doParallel – Everything You Need to Know</a></strong></li>\n<li><strong><a href=\"https://appsilon.com/r-doparallel/#summary\" rel=\"nofollow\" target=\"_blank\">Summing up R doParallel</a></strong></li>\n</ul>\n<hr>\n<h2 id=\"introduction\">What is Parallelism and Why Should You Care?</h2>\n<p>If you’re new to R and programming in general, it can be tough to fully wrap your head around parallelism. Let’s make things easier with an analogy.</p>\n<p>Imagine you’re a restaurant owner and the only employee there. Guests are coming in and it’s only your responsibility to show them to the table, take their order, prepare the food, and serve it. The problem is – <b>there’s only so much you can do</b>. The majority of the guests will be waiting a long time since you’re busy fulfilling earlier orders.</p>\n<p>On the other hand, if you employ two chefs and three waiters, you’ll drastically reduce the wait time. This will also allow you to serve more customers at once and prepare more meals simultaneously.</p>\n<p>The first approach (when you do everything by yourself) is what we refer to as <b>single-threaded execution</b> in computer science, while the second one is known as <b>multi-threaded execution</b>. The ultimate goal is to find the best approach for your specific use case. If you’re only serving 10 customers per day, maybe it makes sense to do everything yourself. But if you have a striving business, you don’t want to leave your customers waiting.</p>\n<p>You should also note that just because the second approach has 6 workers in total (two chefs, three waiters, and you), it doesn’t mean you’ll be exactly six times faster than when doing everything by yourself. Managing workers has some overhead time, just like managing CPU cores does.</p>\n<p>But in general, the concept of parallelism is a game changer. Here’s a couple of reasons why you must learn it as an R developer:</p>\n<ul>\n<li><b>Speed-up computation: </b>If you’re old enough to remember the days of single-core CPUs, you know that upgrading to a multi-core one made all the difference. Simply put, more cores equals more speed, that is if your R scripts take advantage of parallel processing (they don’t by default).</li>\n<li><b>Efficient use of resources: </b>Modern CPUs have multiple cores, and your R scripts only utilize one by default. Now, do you think that one core doing all the work while the rest sit idle is the best way to utilize compute resources? Likely no, you’re far better off by distributing tasks across more cores.</li>\n<li><b>Working on larger problems: </b>When you can distribute the load of processing data, you can handle larger datasets and more complex analyses that were previously out of reach. This is especially the case if you’re working in data science since modern datasets are typically huge in size.</li>\n</ul>\n<p>Up next, let’s go over R’s implementation of parallel execution – with the <code>doParallel</code> package.</p>\n<h2 id=\"r-doparallel\">R doParallel – Everything You Need to Know</h2>\n<h3>What is R doParallel?</h3>\n<p>The R doParallel package enables parallel computing using the <code>foreach</code> package, so you’ll have to install both (explained in the following section). In a nutshell, it allows you to run foreach loops in parallel by combining the <code>foreach()</code> function with the <code>%dopar%</code> operator. Anything that’s inside the loop’s body will be executed in parallel.</p>\n<p>This rest of the section will connect the concept of parallelism with a practical example by leveraging <code>foreach</code> and <code>doParallel</code> R packages.</p>\n<p>Let’s begin with the installation.</p>\n<h3>How to Install R doParallel</h3>\n<p>You can install both packages by running the <code>install.packages()</code> command from the R console. If you don’t want to install them one by one, pass in package names as a vector:</p>\n<pre>install.packages(c(\"foreach\", \"doParallel\"))</pre>\n<p>That’s it – you’re good to go!</p>\n<h3>Basic Usage Example</h3>\n<p>This section will walk you through a basic usage example of R doParallel. The goal here is to wrap your head around the logic and steps required to parallelize a loop in R.</p>\n<p>We’ll start by importing the packages and using the <code>detectCores()</code> function from the <code>doParallel</code> package. As the name suggests, it will return the number of cores your CPU has, and in our case, store it into a <code>n_cores</code> variable:</p>\n<pre>library(foreach)\r\nlibrary(doParallel)\r\n\r\n# How many cores does your CPU have\r\nn_cores &lt;- detectCores()\r\nn_cores</pre>\n<p>My M2 Pro Macbook Pro has 12 CPU cores:</p>\n<div class=\"wp-caption alignnone\" id=\"attachment_22907\" style=\"width: 367px\"><img alt=\"Image 1 - Number of CPU cores\" aria-describedby=\"caption-attachment-22907\" class=\"size-full wp-image-22907\" data-lazy-src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-1-Number-of-CPU-cores.webp\" decoding=\"async\" height=\"91\" loading=\"lazy\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" width=\"357\"/><noscript><img alt=\"Image 1 - Number of CPU cores\" aria-describedby=\"caption-attachment-22907\" class=\"size-full wp-image-22907\" decoding=\"async\" height=\"91\" loading=\"lazy\" src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-1-Number-of-CPU-cores.webp\" width=\"357\"/></noscript><p class=\"wp-caption-text\" id=\"caption-attachment-22907\">Image 1 – Number of CPU cores</p></div>\n<p>The next step is to create a cluster for parallel computation. The <code>makeCluster(n_cores - 1)</code> will initialize one for you with one less core than you have available. The reason for that is simple – <b>you want to leave at least one core for other system tasks</b>.</p>\n<p>Then, the <code>registerDoParallel()</code> functions sets up the cluster for use with the <code>foreach</code> package, enabling you to use parallel execution in your code:</p>\n<pre># Register cluster\r\ncluster &lt;- makeCluster(n_cores - 1)\r\nregisterDoParallel(cluster)</pre>\n<p>And that’s all you have to setup-wise. You now have everything needed to run R code in parallel.</p>\n<p>To demonstrate, we’ll parallelize a loop that will run 1000 times (<code>n_iterations</code>), square the number on each iteration, and store it in a list.</p>\n<p>To run the loop in parallel, you need to use the <code>foreach()</code> function, followed by <code>%dopar%</code>. Everything after curly brackets (inside the loop) will be executed in parallel.</p>\n<p>After running this code, it’s also a good idea to stop your cluster.</p>\n<p>Here’s the entire snippet:</p>\n<pre># How many times will the loop run\r\nn_iterations &lt;- 1000\r\n# To save the results\r\nresults &lt;- list()\r\n\r\n# Use foreach and %dopar% to run the loop in parallel\r\nresults &lt;- foreach(i = 1:n_iterations) %dopar% {\r\n  # Store the results\r\n  results[i] &lt;- i^2\r\n}\r\n\r\n# Don't fotget to stop the cluster\r\nstopCluster(cl = cluster)</pre>\n<p>The output of this code snippet is irrelevant, but here it is if you’re interested:</p>\n<div class=\"wp-caption alignnone\" id=\"attachment_22909\" style=\"width: 1008px\"><img alt=\"Image 2 - Computation results\" aria-describedby=\"caption-attachment-22909\" class=\"size-full wp-image-22909\" data-lazy-src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-2-Computation-results.webp\" decoding=\"async\" loading=\"lazy\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" width=\"450\"/><noscript><img alt=\"Image 2 - Computation results\" aria-describedby=\"caption-attachment-22909\" class=\"size-full wp-image-22909\" decoding=\"async\" loading=\"lazy\" src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-2-Computation-results.webp\" width=\"450\"/></noscript><p class=\"wp-caption-text\" id=\"caption-attachment-22909\">Image 2 – Computation results</p></div>\n<p>And that’s how you can run a loop in parallel in R. The question is – <b>will parallelization make your code run faster?</b> That’s what we’ll answer next.</p>\n<h3>Does R doParallel Make Your Code Execution Faster?</h3>\n<p>There’s a good reason why most code you’ll ever see is single-threaded – it’s simple to write, has no overhead in start time, and usually results in fewer errors.</p>\n<p>Setting up R loops to run in parallel involves some overhead time in setting up a cluster and managing the runtime (which happens behind the scenes). Depending on what you do, <b>your single-threaded code will sometimes be faster compared to its parallelized version</b>, all due to the mentioned overhead.</p>\n<p>That’s why we’ll set up a test in this section, and see how much time it takes to run the same piece of code on different numbers of cores, different numbers of times.</p>\n<p>The <code>test()</code> function does the following:</p>\n<ul>\n<li>Creates and registers a new cluster with <code>n_cores</code> CPU cores, and stops it after the computation.</li>\n<li>Uses <code>foreach</code> to perform iteration <code>n_iter</code> number of times.</li>\n<li>Keeps track of time needed in total, and time needed to do the actual computation.</li>\n<li>Returns a <code>data.frame</code> displaying the number of cores used, iterations made total running time, and total computation time.</li>\n</ul>\n<p>Here’s what this function looks like in the code:</p>\n<pre>test &lt;- function(n_cores, n_iter) {\r\n  # Keep track of the start time\r\n  time_start &lt;- Sys.time()\r\n\r\n  # Create and register cluster\r\n  cluster &lt;- makeCluster(n_cores)\r\n  registerDoParallel(cluster)\r\n\r\n  # Only for measuring computation time\r\n  time_start_processing &lt;- Sys.time()\r\n\r\n  # Do the processing\r\n  results &lt;- foreach(i = 1:n_iter) %dopar% {\r\n    i^2\r\n  }\r\n\r\n  # Only for measuring computation time\r\n  time_finish_processing &lt;- Sys.time()\r\n\r\n  # Stop the cluster\r\n  stopCluster(cl = cluster)\r\n\r\n  # Keep track of the end time\r\n  time_end &lt;- Sys.time()\r\n\r\n  # Return the report\r\n  return(data.frame(\r\n    cores = n_cores,\r\n    iterations = n_iter,\r\n    total_time = difftime(time_end, time_start, units = \"secs\"),\r\n    compute_time = difftime(time_finish_processing, time_start_processing, units = \"secs\")\r\n  ))\r\n}</pre>\n<p>And now for the test itself. We’ll test a combination of using 1, 6, and 11 cores for running the <code>test()</code> function 1K, 10K, 100K, and 1M times. After each iteration, the results will appended to <code>res_df</code>:</p>\n<pre>res_df &lt;- data.frame()\r\n\r\n# Arbitrary number of cores\r\nfor (n_cores in c(1, 6, 11)) {\r\n  # Arbitrary number of iterations\r\n  for (n_iter in c(1000, 10000, 100000, 1000000)) {\r\n    # Total runtime\r\n    current &lt;- test(n_cores, n_iter)\r\n    # Append to results\r\n    res_df &lt;- rbind(res_df, current)\r\n  }\r\n}\r\n\r\nres_df</pre>\n<p>Here are the results:</p>\n<div class=\"wp-caption alignnone\" id=\"attachment_22911\" style=\"width: 676px\"><img alt=\"Image 3 - Runtime comparisons\" aria-describedby=\"caption-attachment-22911\" class=\"size-full wp-image-22911\" data-lazy-src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-3-Runtime-comparisons.webp\" decoding=\"async\" loading=\"lazy\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" width=\"450\"/><noscript><img alt=\"Image 3 - Runtime comparisons\" aria-describedby=\"caption-attachment-22911\" class=\"size-full wp-image-22911\" decoding=\"async\" loading=\"lazy\" src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-3-Runtime-comparisons.webp\" width=\"450\"/></noscript><p class=\"wp-caption-text\" id=\"caption-attachment-22911\">Image 3 – Runtime comparisons</p></div>\n<p>Looking at the table data can only get you so far. Let’s visualize our runtimes to get a better grasp of compute and overhead times.</p>\n<p>There’s a <b>significant overhead</b> for utilizing and managing multiple CPU cores when there are not so many computations to go through. As you can see, using only 1 CPU core took the longest in compute time, but managing 11 of them takes a lot of overhead:</p>\n<div class=\"wp-caption alignnone\" id=\"attachment_22913\" style=\"width: 1399px\"><img alt=\"Image 4 - Runtime for 1K iterations\" aria-describedby=\"caption-attachment-22913\" class=\"size-full wp-image-22913\" data-lazy-src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-4-Runtime-for-1K-iterations.webp\" decoding=\"async\" loading=\"lazy\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" width=\"450\"/><noscript><img alt=\"Image 4 - Runtime for 1K iterations\" aria-describedby=\"caption-attachment-22913\" class=\"size-full wp-image-22913\" decoding=\"async\" loading=\"lazy\" src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-4-Runtime-for-1K-iterations.webp\" width=\"450\"/></noscript><p class=\"wp-caption-text\" id=\"caption-attachment-22913\">Image 4 – Runtime for 1K iterations</p></div>\n<p>If we take this to 10K iterations, things look interesting. <b>There’s no point in leveraging parallelization at this amount of data</b>, as it increases both compute and overhead time:</p>\n<div class=\"wp-caption alignnone\" id=\"attachment_22915\" style=\"width: 1399px\"><img alt=\"Image 5 - Runtime for 10K iterations\" aria-describedby=\"caption-attachment-22915\" class=\"size-full wp-image-22915\" data-lazy-src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-5-Runtime-for-10K-iterations.webp\" decoding=\"async\" loading=\"lazy\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" width=\"450\"/><noscript><img alt=\"Image 5 - Runtime for 10K iterations\" aria-describedby=\"caption-attachment-22915\" class=\"size-full wp-image-22915\" decoding=\"async\" loading=\"lazy\" src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-5-Runtime-for-10K-iterations.webp\" width=\"450\"/></noscript><p class=\"wp-caption-text\" id=\"caption-attachment-22915\">Image 5 – Runtime for 10K iterations</p></div>\n<p>Taking things one step further, to 100K iterations, we have an overall win when using 6 CPU cores. The 11-core simulation had the fastest runtime, but the <b>overhead of managing so many cores</b> took its toll on the total time:</p>\n<p> </p>\n<div class=\"wp-caption alignnone\" id=\"attachment_22917\" style=\"width: 1399px\"><img alt=\"Image 6 - Runtime for 100K iterations\" aria-describedby=\"caption-attachment-22917\" class=\"size-full wp-image-22917\" data-lazy-src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-6-Runtime-for-100K-iterations.webp\" decoding=\"async\" loading=\"lazy\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" width=\"450\"/><noscript><img alt=\"Image 6 - Runtime for 100K iterations\" aria-describedby=\"caption-attachment-22917\" class=\"size-full wp-image-22917\" decoding=\"async\" loading=\"lazy\" src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-6-Runtime-for-100K-iterations.webp\" width=\"450\"/></noscript><p class=\"wp-caption-text\" id=\"caption-attachment-22917\">Image 6 – Runtime for 100K iterations</p></div>\n<p>And finally, let’s take a look at 1M iterations. This is the point where the <b>overhead time becomes insignificant</b>. Both 6-core and 11-core implementations come close, and both are faster than a single-core implementation:</p>\n<div class=\"wp-caption alignnone\" id=\"attachment_22919\" style=\"width: 1399px\"><img alt=\"Image 7 - Runtime for 1M iterations\" aria-describedby=\"caption-attachment-22919\" class=\"size-full wp-image-22919\" data-lazy-src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-7-Runtime-for-1M-iterations.webp\" decoding=\"async\" loading=\"lazy\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" width=\"450\"/><noscript><img alt=\"Image 7 - Runtime for 1M iterations\" aria-describedby=\"caption-attachment-22919\" class=\"size-full wp-image-22919\" decoding=\"async\" loading=\"lazy\" src=\"https://wordpress.appsilon.com/wp-content/uploads/2024/01/Image-7-Runtime-for-1M-iterations.webp\" width=\"450\"/></noscript><p class=\"wp-caption-text\" id=\"caption-attachment-22919\">Image 7 – Runtime for 1M iterations</p></div>\n<p>To summarize the results – parallelization makes the compute time faster when there’s a significant amount of data to process. When that’s not the case, you’re better off sticking to a single-threaded execution. The code is simpler, and there’s no overhead to pay in terms of time required to manage multiple CPU cores.</p>\n<hr/>\n<h2 id=\"summary\">Summing up R doParallel</h2>\n<p>R does a great job of hiding these complexities behind the <code>foreach()</code> function and <code>%dopar%</code> command. But just because you can parallelize some operation it doesn’t mean you should. This point was made perfectly clear in the previous section. Code that runs in parallel is often more complex behind the scenes, and a lot more things can go wrong.</p>\n<p>You’ve learned the basics of R doParallel today. You now know how to run an iterative process in parallel, provided the underlying data structure stays the same. Make sure to stay tuned to <a href=\"https://appsilon.com/blog/\" rel=\"nofollow\" target=\"_blank\">Appsilon Blog</a>, as we definitely plan to cover parallelization in the realm of data frames and processing large datasets.</p>\n<blockquote><p>Did you know R supports Object-Oriented Programming? <a href=\"https://appsilon.com/object-oriented-programming-in-r-part-1/\" rel=\"nofollow\" target=\"_blank\">Take a look at the first of many articles in our new series</a>.</p></blockquote>\n<p>The post appeared first on appsilon.com/blog/.</p>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://appsilon.com/r-doparallel/\"> Tag: r - Appsilon | Enterprise R Shiny Dashboards</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div> </hr></div>\n</article>",
    "main_text": "R doParallel: A Brain-Friendly Introduction to Parallelism in R\nPosted on\nJanuary 18, 2024\nby\nDario Radečić\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nTag: r - Appsilon | Enterprise R Shiny Dashboards\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nImplementing parallel execution in your code can be both a blessing and a curse. On the one hand, you’re leveraging more power your CPU has to offer and increasing execution speed, but on the other, you’re sacrificing the simplicity of single-threaded programs.\nLuckily,\nparallel processing in R is extremely developer-friendly\n. You don’t have to change much on your end, and R works its magic behind the scenes. Today you’ll learn the basics of parallel execution in R with the R doParallel package. By the end, you’ll know how to parallelize loop operations in R and will know exactly how much faster multi-threaded R computations are.\nLooking to speed up your data processing pipelines?\nTake a look at our detailed R Data Processing Frameworks comparison\n.\nTable of contents:\nWhat is Parallelism and Why Should You Care?\nR doParallel – Everything You Need to Know\nSumming up R doParallel\nWhat is Parallelism and Why Should You Care?\nIf you’re new to R and programming in general, it can be tough to fully wrap your head around parallelism. Let’s make things easier with an analogy.\nImagine you’re a restaurant owner and the only employee there. Guests are coming in and it’s only your responsibility to show them to the table, take their order, prepare the food, and serve it. The problem is –\nthere’s only so much you can do\n. The majority of the guests will be waiting a long time since you’re busy fulfilling earlier orders.\nOn the other hand, if you employ two chefs and three waiters, you’ll drastically reduce the wait time. This will also allow you to serve more customers at once and prepare more meals simultaneously.\nThe first approach (when you do everything by yourself) is what we refer to as\nsingle-threaded execution\nin computer science, while the second one is known as\nmulti-threaded execution\n. The ultimate goal is to find the best approach for your specific use case. If you’re only serving 10 customers per day, maybe it makes sense to do everything yourself. But if you have a striving business, you don’t want to leave your customers waiting.\nYou should also note that just because the second approach has 6 workers in total (two chefs, three waiters, and you), it doesn’t mean you’ll be exactly six times faster than when doing everything by yourself. Managing workers has some overhead time, just like managing CPU cores does.\nBut in general, the concept of parallelism is a game changer. Here’s a couple of reasons why you must learn it as an R developer:\nSpeed-up computation:\nIf you’re old enough to remember the days of single-core CPUs, you know that upgrading to a multi-core one made all the difference. Simply put, more cores equals more speed, that is if your R scripts take advantage of parallel processing (they don’t by default).\nEfficient use of resources:\nModern CPUs have multiple cores, and your R scripts only utilize one by default. Now, do you think that one core doing all the work while the rest sit idle is the best way to utilize compute resources? Likely no, you’re far better off by distributing tasks across more cores.\nWorking on larger problems:\nWhen you can distribute the load of processing data, you can handle larger datasets and more complex analyses that were previously out of reach. This is especially the case if you’re working in data science since modern datasets are typically huge in size.\nUp next, let’s go over R’s implementation of parallel execution – with the\ndoParallel\npackage.\nR doParallel – Everything You Need to Know\nWhat is R doParallel?\nThe R doParallel package enables parallel computing using the\nforeach\npackage, so you’ll have to install both (explained in the following section). In a nutshell, it allows you to run foreach loops in parallel by combining the\nforeach()\nfunction with the\n%dopar%\noperator. Anything that’s inside the loop’s body will be executed in parallel.\nThis rest of the section will connect the concept of parallelism with a practical example by leveraging\nforeach\nand\ndoParallel\nR packages.\nLet’s begin with the installation.\nHow to Install R doParallel\nYou can install both packages by running the\ninstall.packages()\ncommand from the R console. If you don’t want to install them one by one, pass in package names as a vector:\ninstall.packages(c(\"foreach\", \"doParallel\"))\nThat’s it – you’re good to go!\nBasic Usage Example\nThis section will walk you through a basic usage example of R doParallel. The goal here is to wrap your head around the logic and steps required to parallelize a loop in R.\nWe’ll start by importing the packages and using the\ndetectCores()\nfunction from the\ndoParallel\npackage. As the name suggests, it will return the number of cores your CPU has, and in our case, store it into a\nn_cores\nvariable:\nlibrary(foreach)\nlibrary(doParallel)\n\n# How many cores does your CPU have\nn_cores <- detectCores()\nn_cores\nMy M2 Pro Macbook Pro has 12 CPU cores:\nImage 1 – Number of CPU cores\nThe next step is to create a cluster for parallel computation. The\nmakeCluster(n_cores - 1)\nwill initialize one for you with one less core than you have available. The reason for that is simple –\nyou want to leave at least one core for other system tasks\n.\nThen, the\nregisterDoParallel()\nfunctions sets up the cluster for use with the\nforeach\npackage, enabling you to use parallel execution in your code:\n# Register cluster\ncluster <- makeCluster(n_cores - 1)\nregisterDoParallel(cluster)\nAnd that’s all you have to setup-wise. You now have everything needed to run R code in parallel.\nTo demonstrate, we’ll parallelize a loop that will run 1000 times (\nn_iterations\n), square the number on each iteration, and store it in a list.\nTo run the loop in parallel, you need to use the\nforeach()\nfunction, followed by\n%dopar%\n. Everything after curly brackets (inside the loop) will be executed in parallel.\nAfter running this code, it’s also a good idea to stop your cluster.\nHere’s the entire snippet:\n# How many times will the loop run\nn_iterations <- 1000\n# To save the results\nresults <- list()\n\n# Use foreach and %dopar% to run the loop in parallel\nresults <- foreach(i = 1:n_iterations) %dopar% {\n  # Store the results\n  results[i] <- i^2\n}\n\n# Don't fotget to stop the cluster\nstopCluster(cl = cluster)\nThe output of this code snippet is irrelevant, but here it is if you’re interested:\nImage 2 – Computation results\nAnd that’s how you can run a loop in parallel in R. The question is –\nwill parallelization make your code run faster?\nThat’s what we’ll answer next.\nDoes R doParallel Make Your Code Execution Faster?\nThere’s a good reason why most code you’ll ever see is single-threaded – it’s simple to write, has no overhead in start time, and usually results in fewer errors.\nSetting up R loops to run in parallel involves some overhead time in setting up a cluster and managing the runtime (which happens behind the scenes). Depending on what you do,\nyour single-threaded code will sometimes be faster compared to its parallelized version\n, all due to the mentioned overhead.\nThat’s why we’ll set up a test in this section, and see how much time it takes to run the same piece of code on different numbers of cores, different numbers of times.\nThe\ntest()\nfunction does the following:\nCreates and registers a new cluster with\nn_cores\nCPU cores, and stops it after the computation.\nUses\nforeach\nto perform iteration\nn_iter\nnumber of times.\nKeeps track of time needed in total, and time needed to do the actual computation.\nReturns a\ndata.frame\ndisplaying the number of cores used, iterations made total running time, and total computation time.\nHere’s what this function looks like in the code:\ntest <- function(n_cores, n_iter) {\n  # Keep track of the start time\n  time_start <- Sys.time()\n\n  # Create and register cluster\n  cluster <- makeCluster(n_cores)\n  registerDoParallel(cluster)\n\n  # Only for measuring computation time\n  time_start_processing <- Sys.time()\n\n  # Do the processing\n  results <- foreach(i = 1:n_iter) %dopar% {\n    i^2\n  }\n\n  # Only for measuring computation time\n  time_finish_processing <- Sys.time()\n\n  # Stop the cluster\n  stopCluster(cl = cluster)\n\n  # Keep track of the end time\n  time_end <- Sys.time()\n\n  # Return the report\n  return(data.frame(\n    cores = n_cores,\n    iterations = n_iter,\n    total_time = difftime(time_end, time_start, units = \"secs\"),\n    compute_time = difftime(time_finish_processing, time_start_processing, units = \"secs\")\n  ))\n}\nAnd now for the test itself. We’ll test a combination of using 1, 6, and 11 cores for running the\ntest()\nfunction 1K, 10K, 100K, and 1M times. After each iteration, the results will appended to\nres_df\n:\nres_df <- data.frame()\n\n# Arbitrary number of cores\nfor (n_cores in c(1, 6, 11)) {\n  # Arbitrary number of iterations\n  for (n_iter in c(1000, 10000, 100000, 1000000)) {\n    # Total runtime\n    current <- test(n_cores, n_iter)\n    # Append to results\n    res_df <- rbind(res_df, current)\n  }\n}\n\nres_df\nHere are the results:\nImage 3 – Runtime comparisons\nLooking at the table data can only get you so far. Let’s visualize our runtimes to get a better grasp of compute and overhead times.\nThere’s a\nsignificant overhead\nfor utilizing and managing multiple CPU cores when there are not so many computations to go through. As you can see, using only 1 CPU core took the longest in compute time, but managing 11 of them takes a lot of overhead:\nImage 4 – Runtime for 1K iterations\nIf we take this to 10K iterations, things look interesting.\nThere’s no point in leveraging parallelization at this amount of data\n, as it increases both compute and overhead time:\nImage 5 – Runtime for 10K iterations\nTaking things one step further, to 100K iterations, we have an overall win when using 6 CPU cores. The 11-core simulation had the fastest runtime, but the\noverhead of managing so many cores\ntook its toll on the total time:\nImage 6 – Runtime for 100K iterations\nAnd finally, let’s take a look at 1M iterations. This is the point where the\noverhead time becomes insignificant\n. Both 6-core and 11-core implementations come close, and both are faster than a single-core implementation:\nImage 7 – Runtime for 1M iterations\nTo summarize the results – parallelization makes the compute time faster when there’s a significant amount of data to process. When that’s not the case, you’re better off sticking to a single-threaded execution. The code is simpler, and there’s no overhead to pay in terms of time required to manage multiple CPU cores.\nSumming up R doParallel\nR does a great job of hiding these complexities behind the\nforeach()\nfunction and\n%dopar%\ncommand. But just because you can parallelize some operation it doesn’t mean you should. This point was made perfectly clear in the previous section. Code that runs in parallel is often more complex behind the scenes, and a lot more things can go wrong.\nYou’ve learned the basics of R doParallel today. You now know how to run an iterative process in parallel, provided the underlying data structure stays the same. Make sure to stay tuned to\nAppsilon Blog\n, as we definitely plan to cover parallelization in the realm of data frames and processing large datasets.\nDid you know R supports Object-Oriented Programming?\nTake a look at the first of many articles in our new series\n.\nThe post appeared first on appsilon.com/blog/.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nTag: r - Appsilon | Enterprise R Shiny Dashboards\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "meta_description": "Implementing parallel execution in your code can be both a blessing and a curse. On the one hand, you’re leveraging more power your CPU has to offer and increasing execution speed, but on the other, you’re sacrificing the simplicity of single-threaded programs. Luckily, parallel processing in R is extremely developer-friendly. You don’t have to change […] The post appeared first on appsilon.com/blog/.",
    "meta_keywords": null,
    "og_description": "Implementing parallel execution in your code can be both a blessing and a curse. On the one hand, you’re leveraging more power your CPU has to offer and increasing execution speed, but on the other, you’re sacrificing the simplicity of single-threaded programs. Luckily, parallel processing in R is extremely developer-friendly. You don’t have to change […] The post appeared first on appsilon.com/blog/.",
    "og_image": "https://wordpress.appsilon.com/wp-content/uploads/2024/01/R-1.webp",
    "og_title": "R doParallel: A Brain-Friendly Introduction to Parallelism in R | R-bloggers",
    "raw_jsonld_article": null,
    "reading_time_min": 10.3,
    "sitemap_lastmod": "2024-01-18T13:44:07+00:00",
    "twitter_description": "Implementing parallel execution in your code can be both a blessing and a curse. On the one hand, you’re leveraging more power your CPU has to offer and increasing execution speed, but on the other, you’re sacrificing the simplicity of single-threaded programs. Luckily, parallel processing in R is extremely developer-friendly. You don’t have to change […] The post appeared first on appsilon.com/blog/.",
    "twitter_title": "R doParallel: A Brain-Friendly Introduction to Parallelism in R | R-bloggers",
    "url": "https://www.r-bloggers.com/2024/01/r-doparallel-a-brain-friendly-introduction-to-parallelism-in-r/",
    "word_count": 2070
  }
}