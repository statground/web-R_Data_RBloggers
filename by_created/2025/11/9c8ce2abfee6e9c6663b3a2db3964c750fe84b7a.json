{
  "id": "9c8ce2abfee6e9c6663b3a2db3964c750fe84b7a",
  "url": "https://www.r-bloggers.com/2025/04/down-a-rabbit-hole-with-arima-models/",
  "created_at_utc": "2025-11-22T19:58:52Z",
  "data": null,
  "raw_original": {
    "uuid": "60153618-a1f4-49a1-acbb-438b1f6edbba",
    "created_at": "2025-11-22 19:58:52",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2025/04/down-a-rabbit-hole-with-arima-models/",
      "crawled_at": "2025-11-22T10:50:43.529485",
      "external_links": [
        {
          "href": "https://rworks.dev/posts/arima-note/",
          "text": "R Works"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://rworks.dev/posts/revised_TimeGPT/",
          "text": "A First Look at TimeGPT using nixtlar"
        },
        {
          "href": "https://i0.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-2-1.png?ssl=1",
          "text": null
        },
        {
          "href": "https://i2.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-10-1.png?ssl=1",
          "text": null
        },
        {
          "href": "https://i1.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-13-1.png?ssl=1",
          "text": null
        },
        {
          "href": "https://i1.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-14-1.png?ssl=1",
          "text": null
        },
        {
          "href": "https://i1.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-15-1.png?ssl=1",
          "text": null
        },
        {
          "href": "https://link.springer.com/book/10.1007/978-1-4899-0004-3",
          "text": "Brockwell and Davis (1987)"
        },
        {
          "href": "https://i2.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-18-1.png?ssl=1",
          "text": null
        },
        {
          "href": "https://i0.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-21-1.png?ssl=1",
          "text": null
        },
        {
          "href": "https://rworks.dev/posts/arima-note/",
          "text": "R Works"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Down a Rabbit Hole with ARIMA Models | R-bloggers",
      "images": [
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-2-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAF4AAAATBAMAAADrOqfvAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAid2Zu0SrMu9mIlQQds0LZxKKAAAACXBIWXMAAA7EAAAOxAGVKw4bAAABTUlEQVQoFWNggAAeXyiDWCqVWIVQdQ2kqedRiCwgUofQZ0GTAG7TtRsW/zBgYLB3RdGGRYwlgYH1O/NToLJ8IJ6JohybGMcEBoaPTCUbGBjiNzCwAykUgCm2fgED1+9D3FYFDBwODGdRFAM5mGIzGBhYHAp5bBkYGP8wCKCrxxRLYzgKjSz2n4wH0NVjijXvnmgFVaU3i4EBrMMsDQgSwaJwMQaGIxeAIly/gB5dAJZikA9gYPCCMOEkkhgbUJqBs4GBgR+kEQiEgLgBxEACSGIcIGFmBwaG9RMgCh4zMBS/hDDhJJLYIdbpDAxMQLMlDkCkfzMw8IKtQnI/XIyBYXPUbQaG8wUMnK0Q5ax/gEFbADcZzICKXRQUlGWwCwCG+XtD4eQDYCkeoY/AOENVjiKm7o0qCeKd48QpxqOweTmGJPN2DCEGqBi7wOELAPJzVcN3PTC1AAAAAElFTkSuQmCC",
          "src": "https://latex.codecogs.com/png.latex?B%5Ek%20Y_t%20=%20Y_%7Bt-k%7D"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,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",
          "src": "https://latex.codecogs.com/png.latex?(1%E2%88%92%5Cphi_1B%E2%88%92%5Cphi_2B%5E2)(1%E2%88%92%5CPhi_1B%5E%7B24%7D)(1%E2%88%92B)Y_t=(1+%5Ctheta_1B)(1+%5CTheta_1B%5E%7B24%7D)%5Cvarepsilon_t"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,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",
          "src": "https://latex.codecogs.com/png.latex?(1%20-%20B)Y_t%20=%20(1%20+%20%5Ctheta_1B%20+%20%5Ctheta_2%20B%5E2%20+%20%5Ctheta_3%20B%5E3%20+%20%5Ctheta_4%20B%5E4)(1%20+%20%5CTheta_1%20B%5E%7B24%7D%20+%20%5CTheta_2%20B%5E%7B48%7D)%5Cvarepsilon_t"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-10-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-13-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-14-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-15-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAH0AAAA1BAMAAACepfkXAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAEInvq1R2Irsy3ZlEZs19rnf+AAAACXBIWXMAAA7EAAAOxAGVKw4bAAACzUlEQVRIDe1UTWjUQBh9s7qbTXdTgrIIFiRsRRAPVgW9CFtpjyKxh4ItQqzWiwgLevCgdC8qIkhOtShYBAUPFfZSEARbD+KxWxEqKHRvnkRoK6utECeZzGQSSLKkF0G/w8773nvf7PzlA2KjvALlS6yaLkyOGVf3tNJ9MQ7FJi9MvI1R02lVx6yJh+nGOIeJ0ydhxanp/PSEfuO+ne777/gLT6C2fsyNmuM4i1mWt/qTVSkfnUaW+qLDv5y+TpZ6UhNl48n1pH9Dz6+fipqWNjmT0z1ksnzhWfVwm0veWOiANEKMm+ScZogjfv1zoJ9NyGWyhhzH0vj9h5QAeVakWNB+hQRgCEaEcdPdTl1mNZbQgXaFcMyOhhfE1LzTlm1+PaAcl2kX95yIMl6+sCZodRwV4rv2NgXtg5K4qtKwGwbje4KXV+mxz2KO0Q/8qmB4t0UxCXIfKc4Rzi1OoYULQAMoPaUk32/RNajmEP0t1l0citUNke6n9ZaXXazDxF0hUHALsy1gh0wxvDO4wTl6/dQElH+DTjQgmYmB3jbUN64c2j96DWHrlHV6AR9sTLWgWo+/MUE7SMfr8F7EZeEVYFgg3NawAq1ikKPAo3rBYsryCDCzbuPJpoV7gdlHhXZA9V06r4OUzOLWoTObKNqYqFYPQJ8PHPKWGDumByryLu6tM0ac1VfhIG13/3KooVf13pV43T7+GKU/nbflYoqvLcqEN/uMz5TOMaA2ZEsEv+S593GabhY9Y36O3CmPRYNnnzmwgu16VIGfBzfI4yue9NEXw+KOtwie0Sc7GeAo8i+P3PzkDES1bvIl2vj9MLrxRz1XXovQo9q/kXu9BZge3d52G1prOxOUBxMfefzUXm8BCk010/vB8gip0tjVVLLV+70l8/+DfWzlwXIjfpNJyoC3fr2d8fz5sU/THpslknpLF/Ml9pYu6pN6i1z+B7VJoQDa0VOsAAAAAElFTkSuQmCC",
          "src": "https://latex.codecogs.com/png.latex?X_t%20=%20%20%5Csum_%7Bj=0%7D%5E%7B%5Cinfty%7D%20%5Cpsi_jZ_%7Bt-j%7D"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAB8AAAATBAMAAACaQstxAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAVGaJIrvddhDNq0TvmTJ+KqhmAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA2klEQVQYGWNgAAOOAjAFIYVMGBi4IOK9IIrJwJWBoRoiwKgApN0Y+BkYJkAEwHQ4Qz8DowJUwJCBgeMHgz8DqwNUYBcDA/sEBjUGHiCf9yDfAxCDLdl4FgMbUEB9azkDyDj+DQxJDJ5AAQcGBQYGngYG/waWDwwvgQIMjkDM1sCwh4H5AkMbkM39AEgAzXBj6GkAGyrCwA4WYGNYzcDA2cDAWKUdwsAAdDS3+gag3QIMjRxpQIYSUBsIsCwAUwwMEVAaxoBLMPhCZHgbYCq4BcAsPRgf5E4QAJIAT6AgKw1n4rsAAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?%5Ctheta(z)"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAACEAAAATBAMAAADseHn6AAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAVGYiRJkyiasQzbvddu8FjZ85AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA4ElEQVQYGTWQu2oCQRSGv1kvuMnqLlgl1RKCnaCQNNpsKaQMpLa2C+QBgk8wAe0C8REEq7xAKosQUsTCwjfxnzObgflv53DmAnGl38YRcTKdWFhHSkS/UbrS+E64MfXPBbiyTp4DN57gclQnM7F7GTzSk2id2nMTy7SakCkZPhwhh2TryP1EyYgSep6sSvjwCyWMtTMvl3DNu0xzLtDAnBVfNrBP15JWcdUpuPC4v9sdTNX3szxAt+At3VdwoyScQONVENZnAD2iVnWlaQ+4D7Hu7QXhL3S0dTIwE8E6dW/O2FUfR6Ejc3AAAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?%5Cphi(z)"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAARBAMAAADwJOuSAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAme9UMmZ2RLsiqxDdic3tCCnEAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAVklEQVQIHWNgAAMOCIWFZL0CFYy2hTI2CMOUvYQxFKAMlgYgg1GZxYEtAcgIq0hj45sAZExgCOBIBtIMDJPBJAMDuwOUYcnABmYxZ4V3ghmbuc8UgBgAp+4MG5OK6pcAAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?z%5Ej"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAEkAAAATBAMAAAAuSD1+AAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAVGaJIrvddhDNq0TvmTJ+KqhmAAAACXBIWXMAAA7EAAAOxAGVKw4bAAABo0lEQVQoFU2Rv2sUYRCGn++yd7vmcpclBmyXgDkwIIr+AStiQCEkRSApQwSbNJdKMM3aRPAHXilWp5VgcwbTSJDkP0h6i20tElJemXfmO4kD3zvvPDu7zHwLHlnfU9ROZPDmPzj3EKbjgw+eHpvmOkMzOGzcewJ7XhMKy3oLCkhHZgiFZJlZGMhYeF6TSdRxw1GEG3wkFBNwX7nblwSduWuYjVmlWU7AL+WOFSs1rCtbCKYDFpmR75x0azdNFTcPzkuOZf7kFwZbzx98pqW6d/gSG5EDrVy8SwZsQWNvo29wdsQ2T/WwtLVmKvgGt3URY/WR0HC4WiWX/FUXj3Ra6hrCDkU27qqLJHd4xNQp+6rbtUQjhBxtVIRBtiXwO8Jl3lc+9Dypd9lvuMxGrdqmDyV9n57vur+K8GpJm+s3vFXXWai+wCe49fWwNNjujXQdOa+zFzILsKSu9E6vgl2yfH/HoZhmHHqCTVgzq83gmYlCMMbEqDs5NRJMmpXp9SdY8ZpORVqb/WkSXzA4iXbu5q4+4KZw/fEPepaUbqSJmyjRC14B7C5NVQe5YQQAAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?%5Ctheta(z)/%5Cphi(z)"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAABIAAAASBAMAAACk4JNkAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAVBBmMpnvIt1Edomru8322y8xAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAfklEQVQIHWNgAAIBEAECTHAWowKIDwLMEArBYhFlUGRKB4kqcjgIMXQyMFxgmFDPYMCwCKxyD5C1AMzqBBpnwGDtwMDwnVOBmYFZcQMDw0VmBnMGJlagPaprhBUYGPgKgEoZQcrZQMR0EOELIgxAxCoQAVTLsOA5iAUCtwQYAJRMEFUk4aeUAAAAAElFTkSuQmCC",
          "src": "https://latex.codecogs.com/png.latex?%5Cpsi_j"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-18-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-21-1.png?w=450&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/joseph-rickert/",
          "text": "Joseph Rickert"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-391800 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Down a Rabbit Hole with ARIMA Models</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">April 10, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/joseph-rickert/\">Joseph Rickert</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://rworks.dev/posts/arima-note/\"> R Works</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<p>In my previous post <a href=\"https://rworks.dev/posts/revised_TimeGPT/\" rel=\"nofollow\" target=\"_blank\">A First Look at TimeGPT using nixtlar</a>, I used the <code>auto.arima()</code> function from the <code>forecast</code> package to fit an ARIMA model to a time series of electricity usage data in order to compare and ARIMA forecast with the <code>TimeGPT</code> forecast. While working out the bugs in that post, I also fit an automatic ARIMA model using the newer and improved <code>fable</code> package and was very surprised by the results. In this post, I will show what surprised me, work through my investigation, and present some practical consequences of the problem of ARIMA identifiability.</p>\n<p>Here are the necessary libraries and the data that we will be working with.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>library(tidyverse)\nlibrary(forecast)\nlibrary(fable)\nlibrary(tsibble)\nlibrary(nixtlar) # for the electricity data\nlibrary(feasts)\nlibrary(Metrics)</pre>\n</details>\n</div>\n<p>As in the <code>TimeGPT</code> post, I will use the BE electricity usage data set from the <code>nixtlar</code> package for fitting models and making forecasts. A plot of the data shows that the dime series seems to have some cyclic behavior punctuated by periods of extreme volatility.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>df &lt;- nixtlar::electricity\n#glimpse(df)\n\ndf2 &lt;- df |&gt; mutate(time = as.POSIXct(ds, format = \"%Y-%m-%d %H:%M:%S\")) |&gt; \n             filter(unique_id == \"BE\") |&gt; select(-unique_id, -ds)\n\np &lt;- df2 |&gt; ggplot(aes(x = time, y = y)) +\n  geom_line(color='darkblue') +\n  ggtitle(\" BE Electricity Usage Data\")\n\np</pre>\n</details>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><a class=\"lightbox\" data-gallery=\"quarto-lightbox-gallery-1\" href=\"https://i0.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-2-1.png?ssl=1\" rel=\"nofollow\" target=\"_blank\"><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i0.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-2-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-2-1.png?w=450&amp;ssl=1\"/></noscript></a></p>\n</figure>\n</div>\n</div>\n</div>\n<p>This next block of code splits the data into training and test data, with the last 24 observations from the BE data set being held out for forecasting.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>NF &lt;- 24\n\nBE_df_wide &lt;- df |&gt; pivot_wider(names_from = unique_id, values_from = y) |&gt;\n  select(ds, BE) |&gt; drop_na()\n\nBE_train_df &lt;- BE_df_wide %&gt;% filter(row_number() &lt;= n() - NF)\nBE_test_df &lt;- tail(BE_df_wide, NF)\nBE_train_df &lt;- BE_train_df |&gt; rename(y = BE) |&gt; mutate(unique_id = \"BE\")\nBE_test_df &lt;- BE_test_df |&gt; rename(y = BE)</pre>\n</details>\n</div>\n<p>Next, I format the data to make it for the <code>auto.arima()</code> function, which requires that the data be expressed as a <code>ts()</code> object.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>train &lt;- BE_train_df |&gt; select(-unique_id) |&gt;\nmutate(time = 1:length(ds))|&gt; select(-ds)\nelec_ts &lt;- ts(train$y, frequency = 24)</pre>\n</details>\n</div>\n<p>The function<code>forecast::arima()</code> fit an ARIMA(2,1,1)(1,0,1)[24]. It differenced the data to achieve stationarity, recognized the seasonal component to account for the daily cycle in the data, and included both auto regressive and moving average components. Just how reasonable the model and forecast are will become apparent later in the post.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>#forecast_fit &lt;- elec_ts |&gt;\n#forecast::auto.arima() |&gt;\n#forecast(h = NF , level = 95)\n#saveRDS(forecast_fit, \"arima_forecast.rds\")\nforecast_fit &lt;- readRDS(\"arima_forecast.rds\")\n\nff_sum &lt;- summary(forecast_fit)\n\nff_sum$model</pre>\n</details>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Series: elec_ts \nARIMA(2,1,1)(1,0,1)[24] \n\nCoefficients:\n         ar1     ar2      ma1    sar1    sma1\n      0.4325  0.0509  -0.9382  0.3206  0.1868\ns.e.  0.0329  0.0303   0.0205  0.0535  0.0565\n\nsigma^2 = 712:  log likelihood = -7784.54\nAIC=15581.08   AICc=15581.13   BIC=15613.55</pre>\n</div>\n</div>\n<p>Here, I extract the forecast and set up a data frame to hold the comparative forecasts.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>arima_fcst_df &lt;- BE_test_df |&gt; \n  mutate(time = ds,\n    BE_actual = y,\n    f_211101 = as.vector(forecast_fit$mean)) |&gt; \n  select(-ds, -y)\n\nhead(arima_fcst_df,3)</pre>\n</details>\n<div class=\"cell-output cell-output-stdout\">\n<pre># A tibble: 3 × 3\n  time                BE_actual f_211101\n  &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;\n1 2016-12-30 00:00:00      44.3     46.2\n2 2016-12-30 01:00:00      44.3     45.0\n3 2016-12-30 02:00:00      41.3     44.1</pre>\n</div>\n</div>\n<section class=\"level3\" id=\"fable\">\n<h3 class=\"anchored\" data-anchor-id=\"fable\">fable</h3>\n<p>Now, I go through the same process but using the functions from the <code>fable</code> package, which in many ways is a sophisticated upgrade to the <code>forecast</code> package with many helper functions that that encourage an efficient reproducible workflow. I learned quite a bit from the <code>forecast</code> package, but I regret that I took so long to discover <code>fable</code>.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>auto_train &lt;- BE_train_df |&gt; select(-unique_id) |&gt;\nmutate(time = as.POSIXct(ds, format = \"%Y-%m-%d %H:%M:%S\")) |&gt; select(-ds)\n  \nelec_ts_2 &lt;- auto_train |&gt; as_tsibble(index = time) |&gt; fill_gaps(time, .full = start())</pre>\n</details>\n</div>\n<p>Here is the automatic ARIMA model fit using the <code>fable</code> package and the big surprise. <code>fable</code> fits an ARIMA(0,1,4)(0,0,2)[24] to the data,which looks quite different from the ARIMA(2,1,1)(1,0,1)[24] model that the <code>forecast</code> package fit.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>fable_fit_1 &lt;- elec_ts_2 |&gt; model(\n    arima_fable = ARIMA(y)) |&gt; report()</pre>\n</details>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Series: y \nModel: ARIMA(0,1,4)(0,0,2)[24] \n\nCoefficients:\n          ma1      ma2      ma3      ma4    sma1    sma2\n      -0.5062  -0.2001  -0.0645  -0.0768  0.5040  0.1312\ns.e.   0.0248   0.0270   0.0275   0.0249  0.0246  0.0227\n\nsigma^2 estimated as 718.5:  log likelihood=-7792.24\nAIC=15598.49   AICc=15598.55   BIC=15636.37</pre>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"a-digression-about-notation\">\n<h2 class=\"anchored\" data-anchor-id=\"a-digression-about-notation\">A digression about notation</h2>\n<p>So, why do I say that the two models look to be quite different? Well, let’s translate the shorthand notation for the two models and see what the respective polynomials look like remembering how the backshift operator works: <img data-lazy-src=\"https://latex.codecogs.com/png.latex?B%5Ek%20Y_t%20=%20Y_%7Bt-k%7D\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?B%5Ek%20Y_t%20=%20Y_%7Bt-k%7D\"/></noscript>.</p>\n<section class=\"level4\" id=\"arima21110124-from-forecast-package\">\n<h4 class=\"anchored\" data-anchor-id=\"arima21110124-from-forecast-package\">ARIMA(2,1,1)(1,0,1)[24] from forecast package</h4>\n<p>This notation translates into:</p>\n<p><img data-lazy-src=\"https://latex.codecogs.com/png.latex?(1%E2%88%92%5Cphi_1B%E2%88%92%5Cphi_2B%5E2)(1%E2%88%92%5CPhi_1B%5E%7B24%7D)(1%E2%88%92B)Y_t=(1+%5Ctheta_1B)(1+%5CTheta_1B%5E%7B24%7D)%5Cvarepsilon_t\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?(1%E2%88%92%5Cphi_1B%E2%88%92%5Cphi_2B%5E2)(1%E2%88%92%5CPhi_1B%5E%7B24%7D)(1%E2%88%92B)Y_t=(1+%5Ctheta_1B)(1+%5CTheta_1B%5E%7B24%7D)%5Cvarepsilon_t\"/></noscript></p>\n</section>\n<section class=\"level4\" id=\"arima01400224-from-fable-package\">\n<h4 class=\"anchored\" data-anchor-id=\"arima01400224-from-fable-package\">ARIMA(0,1,4)(0,0,2)[24] from fable package</h4>\n<p>This notation translates into:</p>\n<p><img data-lazy-src=\"https://latex.codecogs.com/png.latex?(1%20-%20B)Y_t%20=%20(1%20+%20%5Ctheta_1B%20+%20%5Ctheta_2%20B%5E2%20+%20%5Ctheta_3%20B%5E3%20+%20%5Ctheta_4%20B%5E4)(1%20+%20%5CTheta_1%20B%5E%7B24%7D%20+%20%5CTheta_2%20B%5E%7B48%7D)%5Cvarepsilon_t\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?(1%20-%20B)Y_t%20=%20(1%20+%20%5Ctheta_1B%20+%20%5Ctheta_2%20B%5E2%20+%20%5Ctheta_3%20B%5E3%20+%20%5Ctheta_4%20B%5E4)(1%20+%20%5CTheta_1%20B%5E%7B24%7D%20+%20%5CTheta_2%20B%5E%7B48%7D)%5Cvarepsilon_t\"/></noscript></p>\n<p>These different equations don’t look similar to me, and I have no intuition as to why they should both be reasonable models for the data. But let’s see how the forecasts compare.</p>\n<p>Put the <code>fable</code> forecast upper case ARIMA into the data frame.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>fable_ARIMA_fcst_1 &lt;- fable_fit_1 |&gt; forecast(h = 24) \narima_fcst_df &lt;- arima_fcst_df |&gt; mutate(F_014002 =  as.vector(fable_ARIMA_fcst_1$.mean) )\nhead(arima_fcst_df,3)</pre>\n</details>\n<div class=\"cell-output cell-output-stdout\">\n<pre># A tibble: 3 × 4\n  time                BE_actual f_211101 F_014002\n  &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 2016-12-30 00:00:00      44.3     46.2     47.3\n2 2016-12-30 01:00:00      44.3     45.0     46.0\n3 2016-12-30 02:00:00      41.3     44.1     44.7</pre>\n</div>\n</div>\n<p>Plotting the two forecasts, we see that they appear to be virtually identical.</p>\n<div class=\"cell preview-image\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>compare_fore &lt;- function(file){\n  arima_fcst_long_df &lt;- file %&gt;%\n  pivot_longer(!time, names_to = \"method\", values_to = \"mean\")\n\nq &lt;- arima_fcst_long_df |&gt;\n  ggplot(aes(\n    x = time,\n    y = mean,\n    group = method,\n    color = method\n  )) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  geom_line() +\n  geom_point() +\n  ggtitle(\"Multiple ARIMA Forecasts\")\n\nq\n}\n\ncompare_fore(arima_fcst_df)</pre>\n</details>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><a class=\"lightbox\" data-gallery=\"quarto-lightbox-gallery-2\" href=\"https://i2.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-10-1.png?ssl=1\" rel=\"nofollow\" target=\"_blank\"><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i2.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-10-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-10-1.png?w=450&amp;ssl=1\"/></noscript></a></p>\n</figure>\n</div>\n</div>\n</div>\n</section>\n</section>\n<section class=\"level2\" id=\"an-investigation\">\n<h2 class=\"anchored\" data-anchor-id=\"an-investigation\">An investigation</h2>\n<p>To be on the safe side, I thought it was worthwhile checking to see that <code>fable</code> also agrees with the <code>forecast</code> package that an ARIMA(2,1,1)(1,0,1)[24] model is also a reasonable fit to the data. I use the <code>fable</code> package to fit the ARIMA(0,1,4)(0,0,2)[24] model discovered by the <code>forecast</code> package to the data. First, fit the ARIMA(2,1,1)(1,0,1)[24] model to the data.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>fable_fit_2 &lt;- elec_ts_2  %&gt;%\nas_tsibble() %&gt;%\nmodel(fable_ARIMA_fcst_2 = ARIMA(y ~ 0 + pdq(2, 1, 1) + PDQ(1, 0, 1))) %&gt;%\nreport()</pre>\n</details>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Series: y \nModel: ARIMA(2,1,1)(1,0,1)[24] \n\nCoefficients:\n         ar1     ar2      ma1    sar1    sma1\n      0.4310  0.0504  -0.9373  0.3290  0.1765\ns.e.  0.0328  0.0302   0.0204  0.0529  0.0560\n\nsigma^2 estimated as 711.8:  log likelihood=-7785.05\nAIC=15582.11   AICc=15582.16   BIC=15614.58</pre>\n</div>\n</div>\n<p>And then, make the forecast and add it to the plotting data frame.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>fable_ARIMA_fcst_2 &lt;- fable_fit_2 |&gt; forecast(h = 24)\n\narima_fcst_df &lt;- arima_fcst_df |&gt; mutate(F_211101 =  as.vector(fable_ARIMA_fcst_2$.mean) )\nhead(arima_fcst_df,3)</pre>\n</details>\n<div class=\"cell-output cell-output-stdout\">\n<pre># A tibble: 3 × 5\n  time                BE_actual f_211101 F_014002 F_211101\n  &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 2016-12-30 00:00:00      44.3     46.2     47.3     46.1\n2 2016-12-30 01:00:00      44.3     45.0     46.0     44.9\n3 2016-12-30 02:00:00      41.3     44.1     44.7     44.0</pre>\n</div>\n</div>\n<p>The following plot shows that f_211101, the original ARIMA(2,1,1)(1,0,1)[24] model from the <code>forecast</code> package, F_014002, the ARIMA(0,1,4)(0,0,2)[24] model from <code>fable,</code> and F_211101, the ARIMA(2,1,1)(1,0,1)[24] model from <code>fable</code> are all more or less on top of each other. Hence, both <code>fable</code> and <code>forecast</code> agree that the ARIMA(2,1,1)(1,0,1)[24] model is a reasonable fit to the data.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>compare_fore(arima_fcst_df)</pre>\n</details>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><a class=\"lightbox\" data-gallery=\"quarto-lightbox-gallery-3\" href=\"https://i1.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-13-1.png?ssl=1\" rel=\"nofollow\" target=\"_blank\"><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i1.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-13-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-13-1.png?w=450&amp;ssl=1\"/></noscript></a></p>\n</figure>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"checking-the-residuals\">\n<h2 class=\"anchored\" data-anchor-id=\"checking-the-residuals\">Checking the residuals</h2>\n<p>Next, to get an idea of how good these forecasts are relative to each other I check the residuals. The following plot shows that the residuals of the two <code>fable</code> ARIMA forecasts are very highly correlated.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>fable_fit_2_aug&lt;- fable_fit_2 %&gt;% augment()            # Get fitted values and residuals\nfable_fit_1_aug &lt;- fable_fit_1 %&gt;% augment() \nresid_fit_1 &lt;- fable_fit_1_aug$.innov\nresid_fit_2 &lt;- fable_fit_2_aug$.innov\nr_df &lt;- data_frame(resid_fit_1, resid_fit_2)\nr_df |&gt; ggplot(aes(resid_fit_1,resid_fit_2)) + geom_point(color = \"darkblue\") +\n        ylab(\"ARIMA(2,1,1)(1,0,1)[24]\") +\n        xlab(\"ARIMA(0,1,4)(0,0,2)[24]\") +\n        ggtitle(\".innov tesiduals from two `fable` ARIMA models\")</pre>\n</details>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><a class=\"lightbox\" data-gallery=\"quarto-lightbox-gallery-4\" href=\"https://i1.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-14-1.png?ssl=1\" rel=\"nofollow\" target=\"_blank\"><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i1.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-14-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-14-1.png?w=450&amp;ssl=1\"/></noscript></a></p>\n</figure>\n</div>\n</div>\n</div>\n<p>Let’s look at the residuals for the ARIMA(2,1,1)(1,0,1)[24] model in some detail. The plot of the innovative residuals looks like white noise, but the ACF plot shows a large spike at lag 23 and the distribution of the residuals has too sharp of a peak to be normal.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>fable_fit_2 |&gt; gg_tsresiduals()</pre>\n</details>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><a class=\"lightbox\" data-gallery=\"quarto-lightbox-gallery-5\" href=\"https://i1.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-15-1.png?ssl=1\" rel=\"nofollow\" target=\"_blank\"><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i1.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-15-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-15-1.png?w=450&amp;ssl=1\"/></noscript></a></p>\n</figure>\n</div>\n</div>\n</div>\n<p>Nevertheless, the Ljung-Box test for autocorrelation of the residuals looks pretty good. Under the hypothesis that the residuals come from a white noise process, the probability of observing what we did observe would be around 0.3 - too high to automatically reject the null hypothesis. I conclude that the model and forecast are pretty good, but there is some structure left in the residuals that leaves the door open for finding a better forecast.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>fable_fit_2_aug |&gt; features(.innov, ljung_box, lag = 48)</pre>\n</details>\n<div class=\"cell-output cell-output-stdout\">\n<pre># A tibble: 1 × 3\n  .model             lb_stat lb_pvalue\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;\n1 fable_ARIMA_fcst_2    52.4     0.307</pre>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"is-this-really-surprising\">\n<h2 class=\"anchored\" data-anchor-id=\"is-this-really-surprising\">Is this really surprising?</h2>\n<p>Should I have been surprised to see two different auto fit models for the same time series that produce forecasts that are really close to each other? Anyone who has ever tried to find a suitable ARIMA model by following the theory in the textbooks: looking at the ACF and PACF functions, etc., knows how fragile the process is. Indeed, the experts will tell you that the <em>identifiability</em> of ARIMA models is a well-known problem. Consider this note on page 305 from <a href=\"https://link.springer.com/book/10.1007/978-1-4899-0004-3\" rel=\"nofollow\" target=\"_blank\">Brockwell and Davis (1987)</a>:</p>\n<p><em>Of course, in the modelling of real data, there is rarely such a thing as the “true order”. For the process <img data-lazy-src=\"https://latex.codecogs.com/png.latex?X_t%20=%20%20%5Csum_%7Bj=0%7D%5E%7B%5Cinfty%7D%20%5Cpsi_jZ_%7Bt-j%7D\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?X_t%20=%20%20%5Csum_%7Bj=0%7D%5E%7B%5Cinfty%7D%20%5Cpsi_jZ_%7Bt-j%7D\"/></noscript> there may be many polynomials <img data-lazy-src=\"https://latex.codecogs.com/png.latex?%5Ctheta(z)\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?%5Ctheta(z)\"/></noscript>, <img data-lazy-src=\"https://latex.codecogs.com/png.latex?%5Cphi(z)\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?%5Cphi(z)\"/></noscript> such that the coefficients of <img data-lazy-src=\"https://latex.codecogs.com/png.latex?z%5Ej\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?z%5Ej\"/></noscript> in <img data-lazy-src=\"https://latex.codecogs.com/png.latex?%5Ctheta(z)/%5Cphi(z)\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?%5Ctheta(z)/%5Cphi(z)\"/></noscript> closely approximate <img data-lazy-src=\"https://latex.codecogs.com/png.latex?%5Cpsi_j\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?%5Cpsi_j\"/></noscript> for moderately small values of j. Correspondingly, there may be many ARMA processes with properties similar to {X,}. This problem of identifiability becomes much more serious for multivariate processes.</em></p>\n</section>\n<section class=\"level2\" id=\"variations-on-a-theme\">\n<h2 class=\"anchored\" data-anchor-id=\"variations-on-a-theme\">Variations on a theme</h2>\n<p>Because the two nearly identical solutions to the problem of finding a model that adequately fits the data are essentially linear equations, I imagine that they live somewhere close to each other in some multidimensinal vector space. Are there other solutions nearby? Are there better solutions? Given that I have two solutions, it seems reasonable to assume that minor perturbations of the p,d,q,P,D,Q parameters may turn up additional models with similar AICc and RMSE profiles. These questions seem worthy of some further investigation.</p>\n<p>Fiddling with the parameters mostly resulted in numerical errors of one sort or another or inferior solutions. But, I did find a third solution that is at least as good as the others. Notice that the AICc compares favorably with the other two models.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>fable_fit_3 &lt;- elec_ts_2  |&gt;\nas_tsibble() |&gt;\nmodel(F_013002 = ARIMA(y ~ 0 + pdq(0, 1, 3) + PDQ(0, 0, 2))) |&gt;\nreport()</pre>\n</details>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Series: y \nModel: ARIMA(0,1,3)(0,0,2)[24] \n\nCoefficients:\n          ma1      ma2      ma3    sma1    sma2\n      -0.5037  -0.2156  -0.0968  0.5082  0.1355\ns.e.   0.0246   0.0287   0.0252  0.0247  0.0226\n\nsigma^2 estimated as 722.2:  log likelihood=-7796.99\nAIC=15605.98   AICc=15606.03   BIC=15638.45</pre>\n</div>\n</div>\n<p>And once again, we see that all of the ARIMA forecasts sit on top of each other.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>fable_ARIMA_fcst_3 &lt;- fable_fit_3 |&gt; forecast(h = 24)\narima_fcst_df &lt;- arima_fcst_df |&gt; mutate(F_013002 =  as.vector(fable_ARIMA_fcst_3$.mean) )\ncompare_fore(arima_fcst_df)</pre>\n</details>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><a class=\"lightbox\" data-gallery=\"quarto-lightbox-gallery-6\" href=\"https://i2.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-18-1.png?ssl=1\" rel=\"nofollow\" target=\"_blank\"><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i2.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-18-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-18-1.png?w=450&amp;ssl=1\"/></noscript></a></p>\n</figure>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"are-there-better-solutions\">\n<h2 class=\"anchored\" data-anchor-id=\"are-there-better-solutions\">Are there better solutions?</h2>\n<p>For a final try to find a better forecast, I used the search feature of the fable::ARIMA function to systematically search through the model space constrained by p + q + P + Q &lt;= 6 p + q + P + Q &lt;= 6 &amp; (constant + d + D &lt;= 2). This algorithm ran fairly quickly and turned up yet another solution that is very close to the others.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>fable_fit_4 &lt;- elec_ts_2 |&gt;\n  model(arima_fable = ARIMA(y, stepwise = FALSE)) |&gt; \n  report()</pre>\n</details>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Series: y \nModel: ARIMA(2,1,1)(0,0,2)[24] \n\nCoefficients:\n         ar1     ar2      ma1    sma1    sma2\n      0.4463  0.0586  -0.9487  0.5019  0.1258\ns.e.  0.0321  0.0304   0.0197  0.0244  0.0228\n\nsigma^2 estimated as 714.6:  log likelihood=-7788.26\nAIC=15588.53   AICc=15588.58   BIC=15621</pre>\n</div>\n</div>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>fable_fit_4_fcst &lt;- fable_fit_4 |&gt; forecast(h = 24)\narima_fcst_df &lt;- arima_fcst_df |&gt; mutate(F_211002 =  as.vector(fable_fit_4_fcst$.mean) )\nhead(arima_fcst_df,3)</pre>\n</details>\n<div class=\"cell-output cell-output-stdout\">\n<pre># A tibble: 3 × 7\n  time                BE_actual f_211101 F_014002 F_211101 F_013002 F_211002\n  &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 2016-12-30 00:00:00      44.3     46.2     47.3     46.1     47.1     47.0\n2 2016-12-30 01:00:00      44.3     45.0     46.0     44.9     45.7     45.6\n3 2016-12-30 02:00:00      41.3     44.1     44.7     44.0     44.9     44.6</pre>\n</div>\n</div>\n<p>Plot and compare.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>compare_fore(arima_fcst_df)</pre>\n</details>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><a class=\"lightbox\" data-gallery=\"quarto-lightbox-gallery-7\" href=\"https://i0.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-21-1.png?ssl=1\" rel=\"nofollow\" target=\"_blank\"><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i0.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-21-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-21-1.png?w=450&amp;ssl=1\"/></noscript></a></p>\n</figure>\n</div>\n</div>\n</div>\n<p>Visually, the forecasts for all of the models look very similar. Let’s confirm this by checking the AICc and RMSE values one last time. They are indeed very close according to both metrics. And, as it turns out, the model discovered by the forecast package has the smallest AICc value and the smallest RMSE.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>c_df &lt;- data.frame(c(\"f_211101\", \"F_013002\", \"F_014002\", \"F_211002\", \"F_211101\"))\nnames(c_df) &lt;- c(\"Model\")\n\nrmse &lt;- c(rmse(arima_fcst_df$BE_actual,arima_fcst_df$f_211101),\n  rmse(arima_fcst_df$BE_actual,arima_fcst_df$F_013002),\n  rmse(arima_fcst_df$BE_actual,arima_fcst_df$F_014002),\n  rmse(arima_fcst_df$BE_actual,arima_fcst_df$F_211002),\n  rmse(arima_fcst_df$BE_actual,arima_fcst_df$F_211101))\n\nAICc &lt;- c(forecast_fit$model$aicc,\n                        as.numeric(glance(fable_fit_1)[\"AICc\"]), \n                        as.numeric(glance(fable_fit_2)[\"AICc\"]), \n                        as.numeric(glance(fable_fit_3)[\"AICc\"]), \n                        as.numeric(glance(fable_fit_4)[\"AICc\"]))\nc_df &lt;- cbind(c_df, rmse, AICc)\nc_df |&gt; arrange(AICc)</pre>\n</details>\n<div class=\"cell-output cell-output-stdout\">\n<pre>     Model     rmse     AICc\n1 f_211101 4.966623 15581.13\n2 F_014002 5.041250 15582.16\n3 F_211101 4.954435 15588.58\n4 F_013002 4.952944 15598.55\n5 F_211002 5.188436 15606.03</pre>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"summary\">\n<h2 class=\"anchored\" data-anchor-id=\"summary\">Summary</h2>\n<p>I have five different models for the BE Electricity Usage time series. Each provides a reasonably good fit based on comparing the RMSE of its forecast with the actual values of the hold-out test data. Because of the way that the automated ARIMA algorithms in the <code>forecast</code> and <code>fable</code> time series packages search for solutions, it seems reasonable to assume that these solutions are somehow “close” to each other in the solution space inhabited by the stochastic difference equations that specify the models. A reasonable question is: are there better models that live somewhere else in the solution space? Answering this means figuring out a way to exploit the structure that may still be in the residuals, a quest I may pursue another day.</p>\n</section>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://rworks.dev/posts/arima-note/\"> R Works</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
      "main_text": "Down a Rabbit Hole with ARIMA Models\nPosted on\nApril 10, 2025\nby\nJoseph Rickert\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nR Works\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nIn my previous post\nA First Look at TimeGPT using nixtlar\n, I used the\nauto.arima()\nfunction from the\nforecast\npackage to fit an ARIMA model to a time series of electricity usage data in order to compare and ARIMA forecast with the\nTimeGPT\nforecast. While working out the bugs in that post, I also fit an automatic ARIMA model using the newer and improved\nfable\npackage and was very surprised by the results. In this post, I will show what surprised me, work through my investigation, and present some practical consequences of the problem of ARIMA identifiability.\nHere are the necessary libraries and the data that we will be working with.\nShow the code\nlibrary(tidyverse)\nlibrary(forecast)\nlibrary(fable)\nlibrary(tsibble)\nlibrary(nixtlar) # for the electricity data\nlibrary(feasts)\nlibrary(Metrics)\nAs in the\nTimeGPT\npost, I will use the BE electricity usage data set from the\nnixtlar\npackage for fitting models and making forecasts. A plot of the data shows that the dime series seems to have some cyclic behavior punctuated by periods of extreme volatility.\nShow the code\ndf <- nixtlar::electricity\n#glimpse(df)\n\ndf2 <- df |> mutate(time = as.POSIXct(ds, format = \"%Y-%m-%d %H:%M:%S\")) |> \n             filter(unique_id == \"BE\") |> select(-unique_id, -ds)\n\np <- df2 |> ggplot(aes(x = time, y = y)) +\n  geom_line(color='darkblue') +\n  ggtitle(\" BE Electricity Usage Data\")\n\np\nThis next block of code splits the data into training and test data, with the last 24 observations from the BE data set being held out for forecasting.\nShow the code\nNF <- 24\n\nBE_df_wide <- df |> pivot_wider(names_from = unique_id, values_from = y) |>\n  select(ds, BE) |> drop_na()\n\nBE_train_df <- BE_df_wide %>% filter(row_number() <= n() - NF)\nBE_test_df <- tail(BE_df_wide, NF)\nBE_train_df <- BE_train_df |> rename(y = BE) |> mutate(unique_id = \"BE\")\nBE_test_df <- BE_test_df |> rename(y = BE)\nNext, I format the data to make it for the\nauto.arima()\nfunction, which requires that the data be expressed as a\nts()\nobject.\nShow the code\ntrain <- BE_train_df |> select(-unique_id) |>\nmutate(time = 1:length(ds))|> select(-ds)\nelec_ts <- ts(train$y, frequency = 24)\nThe function\nforecast::arima()\nfit an ARIMA(2,1,1)(1,0,1)[24]. It differenced the data to achieve stationarity, recognized the seasonal component to account for the daily cycle in the data, and included both auto regressive and moving average components. Just how reasonable the model and forecast are will become apparent later in the post.\nShow the code\n#forecast_fit <- elec_ts |>\n#forecast::auto.arima() |>\n#forecast(h = NF , level = 95)\n#saveRDS(forecast_fit, \"arima_forecast.rds\")\nforecast_fit <- readRDS(\"arima_forecast.rds\")\n\nff_sum <- summary(forecast_fit)\n\nff_sum$model\nSeries: elec_ts \nARIMA(2,1,1)(1,0,1)[24] \n\nCoefficients:\n         ar1     ar2      ma1    sar1    sma1\n      0.4325  0.0509  -0.9382  0.3206  0.1868\ns.e.  0.0329  0.0303   0.0205  0.0535  0.0565\n\nsigma^2 = 712:  log likelihood = -7784.54\nAIC=15581.08   AICc=15581.13   BIC=15613.55\nHere, I extract the forecast and set up a data frame to hold the comparative forecasts.\nShow the code\narima_fcst_df <- BE_test_df |> \n  mutate(time = ds,\n    BE_actual = y,\n    f_211101 = as.vector(forecast_fit$mean)) |> \n  select(-ds, -y)\n\nhead(arima_fcst_df,3)\n# A tibble: 3 × 3\n  time                BE_actual f_211101\n  <chr>                   <dbl>    <dbl>\n1 2016-12-30 00:00:00      44.3     46.2\n2 2016-12-30 01:00:00      44.3     45.0\n3 2016-12-30 02:00:00      41.3     44.1\nfable\nNow, I go through the same process but using the functions from the\nfable\npackage, which in many ways is a sophisticated upgrade to the\nforecast\npackage with many helper functions that that encourage an efficient reproducible workflow. I learned quite a bit from the\nforecast\npackage, but I regret that I took so long to discover\nfable\n.\nShow the code\nauto_train <- BE_train_df |> select(-unique_id) |>\nmutate(time = as.POSIXct(ds, format = \"%Y-%m-%d %H:%M:%S\")) |> select(-ds)\n  \nelec_ts_2 <- auto_train |> as_tsibble(index = time) |> fill_gaps(time, .full = start())\nHere is the automatic ARIMA model fit using the\nfable\npackage and the big surprise.\nfable\nfits an ARIMA(0,1,4)(0,0,2)[24] to the data,which looks quite different from the ARIMA(2,1,1)(1,0,1)[24] model that the\nforecast\npackage fit.\nShow the code\nfable_fit_1 <- elec_ts_2 |> model(\n    arima_fable = ARIMA(y)) |> report()\nSeries: y \nModel: ARIMA(0,1,4)(0,0,2)[24] \n\nCoefficients:\n          ma1      ma2      ma3      ma4    sma1    sma2\n      -0.5062  -0.2001  -0.0645  -0.0768  0.5040  0.1312\ns.e.   0.0248   0.0270   0.0275   0.0249  0.0246  0.0227\n\nsigma^2 estimated as 718.5:  log likelihood=-7792.24\nAIC=15598.49   AICc=15598.55   BIC=15636.37\nA digression about notation\nSo, why do I say that the two models look to be quite different? Well, let’s translate the shorthand notation for the two models and see what the respective polynomials look like remembering how the backshift operator works:\n.\nARIMA(2,1,1)(1,0,1)[24] from forecast package\nThis notation translates into:\nARIMA(0,1,4)(0,0,2)[24] from fable package\nThis notation translates into:\nThese different equations don’t look similar to me, and I have no intuition as to why they should both be reasonable models for the data. But let’s see how the forecasts compare.\nPut the\nfable\nforecast upper case ARIMA into the data frame.\nShow the code\nfable_ARIMA_fcst_1 <- fable_fit_1 |> forecast(h = 24) \narima_fcst_df <- arima_fcst_df |> mutate(F_014002 =  as.vector(fable_ARIMA_fcst_1$.mean) )\nhead(arima_fcst_df,3)\n# A tibble: 3 × 4\n  time                BE_actual f_211101 F_014002\n  <chr>                   <dbl>    <dbl>    <dbl>\n1 2016-12-30 00:00:00      44.3     46.2     47.3\n2 2016-12-30 01:00:00      44.3     45.0     46.0\n3 2016-12-30 02:00:00      41.3     44.1     44.7\nPlotting the two forecasts, we see that they appear to be virtually identical.\nShow the code\ncompare_fore <- function(file){\n  arima_fcst_long_df <- file %>%\n  pivot_longer(!time, names_to = \"method\", values_to = \"mean\")\n\nq <- arima_fcst_long_df |>\n  ggplot(aes(\n    x = time,\n    y = mean,\n    group = method,\n    color = method\n  )) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  geom_line() +\n  geom_point() +\n  ggtitle(\"Multiple ARIMA Forecasts\")\n\nq\n}\n\ncompare_fore(arima_fcst_df)\nAn investigation\nTo be on the safe side, I thought it was worthwhile checking to see that\nfable\nalso agrees with the\nforecast\npackage that an ARIMA(2,1,1)(1,0,1)[24] model is also a reasonable fit to the data. I use the\nfable\npackage to fit the ARIMA(0,1,4)(0,0,2)[24] model discovered by the\nforecast\npackage to the data. First, fit the ARIMA(2,1,1)(1,0,1)[24] model to the data.\nShow the code\nfable_fit_2 <- elec_ts_2  %>%\nas_tsibble() %>%\nmodel(fable_ARIMA_fcst_2 = ARIMA(y ~ 0 + pdq(2, 1, 1) + PDQ(1, 0, 1))) %>%\nreport()\nSeries: y \nModel: ARIMA(2,1,1)(1,0,1)[24] \n\nCoefficients:\n         ar1     ar2      ma1    sar1    sma1\n      0.4310  0.0504  -0.9373  0.3290  0.1765\ns.e.  0.0328  0.0302   0.0204  0.0529  0.0560\n\nsigma^2 estimated as 711.8:  log likelihood=-7785.05\nAIC=15582.11   AICc=15582.16   BIC=15614.58\nAnd then, make the forecast and add it to the plotting data frame.\nShow the code\nfable_ARIMA_fcst_2 <- fable_fit_2 |> forecast(h = 24)\n\narima_fcst_df <- arima_fcst_df |> mutate(F_211101 =  as.vector(fable_ARIMA_fcst_2$.mean) )\nhead(arima_fcst_df,3)\n# A tibble: 3 × 5\n  time                BE_actual f_211101 F_014002 F_211101\n  <chr>                   <dbl>    <dbl>    <dbl>    <dbl>\n1 2016-12-30 00:00:00      44.3     46.2     47.3     46.1\n2 2016-12-30 01:00:00      44.3     45.0     46.0     44.9\n3 2016-12-30 02:00:00      41.3     44.1     44.7     44.0\nThe following plot shows that f_211101, the original ARIMA(2,1,1)(1,0,1)[24] model from the\nforecast\npackage, F_014002, the ARIMA(0,1,4)(0,0,2)[24] model from\nfable,\nand F_211101, the ARIMA(2,1,1)(1,0,1)[24] model from\nfable\nare all more or less on top of each other. Hence, both\nfable\nand\nforecast\nagree that the ARIMA(2,1,1)(1,0,1)[24] model is a reasonable fit to the data.\nShow the code\ncompare_fore(arima_fcst_df)\nChecking the residuals\nNext, to get an idea of how good these forecasts are relative to each other I check the residuals. The following plot shows that the residuals of the two\nfable\nARIMA forecasts are very highly correlated.\nShow the code\nfable_fit_2_aug<- fable_fit_2 %>% augment()            # Get fitted values and residuals\nfable_fit_1_aug <- fable_fit_1 %>% augment() \nresid_fit_1 <- fable_fit_1_aug$.innov\nresid_fit_2 <- fable_fit_2_aug$.innov\nr_df <- data_frame(resid_fit_1, resid_fit_2)\nr_df |> ggplot(aes(resid_fit_1,resid_fit_2)) + geom_point(color = \"darkblue\") +\n        ylab(\"ARIMA(2,1,1)(1,0,1)[24]\") +\n        xlab(\"ARIMA(0,1,4)(0,0,2)[24]\") +\n        ggtitle(\".innov tesiduals from two `fable` ARIMA models\")\nLet’s look at the residuals for the ARIMA(2,1,1)(1,0,1)[24] model in some detail. The plot of the innovative residuals looks like white noise, but the ACF plot shows a large spike at lag 23 and the distribution of the residuals has too sharp of a peak to be normal.\nShow the code\nfable_fit_2 |> gg_tsresiduals()\nNevertheless, the Ljung-Box test for autocorrelation of the residuals looks pretty good. Under the hypothesis that the residuals come from a white noise process, the probability of observing what we did observe would be around 0.3 - too high to automatically reject the null hypothesis. I conclude that the model and forecast are pretty good, but there is some structure left in the residuals that leaves the door open for finding a better forecast.\nShow the code\nfable_fit_2_aug |> features(.innov, ljung_box, lag = 48)\n# A tibble: 1 × 3\n  .model             lb_stat lb_pvalue\n  <chr>                <dbl>     <dbl>\n1 fable_ARIMA_fcst_2    52.4     0.307\nIs this really surprising?\nShould I have been surprised to see two different auto fit models for the same time series that produce forecasts that are really close to each other? Anyone who has ever tried to find a suitable ARIMA model by following the theory in the textbooks: looking at the ACF and PACF functions, etc., knows how fragile the process is. Indeed, the experts will tell you that the\nidentifiability\nof ARIMA models is a well-known problem. Consider this note on page 305 from\nBrockwell and Davis (1987)\n:\nOf course, in the modelling of real data, there is rarely such a thing as the “true order”. For the process\nthere may be many polynomials\n,\nsuch that the coefficients of\nin\nclosely approximate\nfor moderately small values of j. Correspondingly, there may be many ARMA processes with properties similar to {X,}. This problem of identifiability becomes much more serious for multivariate processes.\nVariations on a theme\nBecause the two nearly identical solutions to the problem of finding a model that adequately fits the data are essentially linear equations, I imagine that they live somewhere close to each other in some multidimensinal vector space. Are there other solutions nearby? Are there better solutions? Given that I have two solutions, it seems reasonable to assume that minor perturbations of the p,d,q,P,D,Q parameters may turn up additional models with similar AICc and RMSE profiles. These questions seem worthy of some further investigation.\nFiddling with the parameters mostly resulted in numerical errors of one sort or another or inferior solutions. But, I did find a third solution that is at least as good as the others. Notice that the AICc compares favorably with the other two models.\nShow the code\nfable_fit_3 <- elec_ts_2  |>\nas_tsibble() |>\nmodel(F_013002 = ARIMA(y ~ 0 + pdq(0, 1, 3) + PDQ(0, 0, 2))) |>\nreport()\nSeries: y \nModel: ARIMA(0,1,3)(0,0,2)[24] \n\nCoefficients:\n          ma1      ma2      ma3    sma1    sma2\n      -0.5037  -0.2156  -0.0968  0.5082  0.1355\ns.e.   0.0246   0.0287   0.0252  0.0247  0.0226\n\nsigma^2 estimated as 722.2:  log likelihood=-7796.99\nAIC=15605.98   AICc=15606.03   BIC=15638.45\nAnd once again, we see that all of the ARIMA forecasts sit on top of each other.\nShow the code\nfable_ARIMA_fcst_3 <- fable_fit_3 |> forecast(h = 24)\narima_fcst_df <- arima_fcst_df |> mutate(F_013002 =  as.vector(fable_ARIMA_fcst_3$.mean) )\ncompare_fore(arima_fcst_df)\nAre there better solutions?\nFor a final try to find a better forecast, I used the search feature of the fable::ARIMA function to systematically search through the model space constrained by p + q + P + Q <= 6 p + q + P + Q <= 6 & (constant + d + D <= 2). This algorithm ran fairly quickly and turned up yet another solution that is very close to the others.\nShow the code\nfable_fit_4 <- elec_ts_2 |>\n  model(arima_fable = ARIMA(y, stepwise = FALSE)) |> \n  report()\nSeries: y \nModel: ARIMA(2,1,1)(0,0,2)[24] \n\nCoefficients:\n         ar1     ar2      ma1    sma1    sma2\n      0.4463  0.0586  -0.9487  0.5019  0.1258\ns.e.  0.0321  0.0304   0.0197  0.0244  0.0228\n\nsigma^2 estimated as 714.6:  log likelihood=-7788.26\nAIC=15588.53   AICc=15588.58   BIC=15621\nShow the code\nfable_fit_4_fcst <- fable_fit_4 |> forecast(h = 24)\narima_fcst_df <- arima_fcst_df |> mutate(F_211002 =  as.vector(fable_fit_4_fcst$.mean) )\nhead(arima_fcst_df,3)\n# A tibble: 3 × 7\n  time                BE_actual f_211101 F_014002 F_211101 F_013002 F_211002\n  <chr>                   <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>\n1 2016-12-30 00:00:00      44.3     46.2     47.3     46.1     47.1     47.0\n2 2016-12-30 01:00:00      44.3     45.0     46.0     44.9     45.7     45.6\n3 2016-12-30 02:00:00      41.3     44.1     44.7     44.0     44.9     44.6\nPlot and compare.\nShow the code\ncompare_fore(arima_fcst_df)\nVisually, the forecasts for all of the models look very similar. Let’s confirm this by checking the AICc and RMSE values one last time. They are indeed very close according to both metrics. And, as it turns out, the model discovered by the forecast package has the smallest AICc value and the smallest RMSE.\nShow the code\nc_df <- data.frame(c(\"f_211101\", \"F_013002\", \"F_014002\", \"F_211002\", \"F_211101\"))\nnames(c_df) <- c(\"Model\")\n\nrmse <- c(rmse(arima_fcst_df$BE_actual,arima_fcst_df$f_211101),\n  rmse(arima_fcst_df$BE_actual,arima_fcst_df$F_013002),\n  rmse(arima_fcst_df$BE_actual,arima_fcst_df$F_014002),\n  rmse(arima_fcst_df$BE_actual,arima_fcst_df$F_211002),\n  rmse(arima_fcst_df$BE_actual,arima_fcst_df$F_211101))\n\nAICc <- c(forecast_fit$model$aicc,\n                        as.numeric(glance(fable_fit_1)[\"AICc\"]), \n                        as.numeric(glance(fable_fit_2)[\"AICc\"]), \n                        as.numeric(glance(fable_fit_3)[\"AICc\"]), \n                        as.numeric(glance(fable_fit_4)[\"AICc\"]))\nc_df <- cbind(c_df, rmse, AICc)\nc_df |> arrange(AICc)\nModel     rmse     AICc\n1 f_211101 4.966623 15581.13\n2 F_014002 5.041250 15582.16\n3 F_211101 4.954435 15588.58\n4 F_013002 4.952944 15598.55\n5 F_211002 5.188436 15606.03\nSummary\nI have five different models for the BE Electricity Usage time series. Each provides a reasonably good fit based on comparing the RMSE of its forecast with the actual values of the hold-out test data. Because of the way that the automated ARIMA algorithms in the\nforecast\nand\nfable\ntime series packages search for solutions, it seems reasonable to assume that these solutions are somehow “close” to each other in the solution space inhabited by the stochastic difference equations that specify the models. A reasonable question is: are there better models that live somewhere else in the solution space? Answering this means figuring out a way to exploit the structure that may still be in the residuals, a quest I may pursue another day.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nR Works\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "In my previous post A First Look at TimeGPT using nixtlar, I used the auto.arima() function from the forecast package to fit an ARIMA model to a time series of electricity usage data in order to compare and ARIMA forecast with the TimeGPT foreca...",
      "meta_keywords": null,
      "og_description": "In my previous post A First Look at TimeGPT using nixtlar, I used the auto.arima() function from the forecast package to fit an ARIMA model to a time series of electricity usage data in order to compare and ARIMA forecast with the TimeGPT foreca...",
      "og_image": "https://rworks.dev/posts/arima-note/index_files/figure-html/unnamed-chunk-2-1.png",
      "og_title": "Down a Rabbit Hole with ARIMA Models | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 13.4,
      "sitemap_lastmod": null,
      "twitter_description": "In my previous post A First Look at TimeGPT using nixtlar, I used the auto.arima() function from the forecast package to fit an ARIMA model to a time series of electricity usage data in order to compare and ARIMA forecast with the TimeGPT foreca...",
      "twitter_title": "Down a Rabbit Hole with ARIMA Models | R-bloggers",
      "url": "https://www.r-bloggers.com/2025/04/down-a-rabbit-hole-with-arima-models/",
      "word_count": 2678
    }
  }
}