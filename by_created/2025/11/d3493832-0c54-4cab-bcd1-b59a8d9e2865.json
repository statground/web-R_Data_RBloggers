{
  "uuid": "d3493832-0c54-4cab-bcd1-b59a8d9e2865",
  "created_at": "2025-11-17 20:39:32",
  "raw_json": {
    "article_author": null,
    "article_headline": null,
    "article_modified": null,
    "article_published": null,
    "article_section": null,
    "article_tags": null,
    "canonical_url": "https://www.r-bloggers.com/2023/10/answering-some-tidymodels-questions/",
    "crawled_at": "2025-11-17T10:06:17.373145",
    "external_links": [
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/",
        "text": "R on Nicola Rennie"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://rinpharma.com/event/rinpharma2023/",
        "text": "R/Pharma 2023 Conference"
      },
      {
        "href": "https://nrennie.github.io/r-pharma-2023-tidymodels/",
        "text": "nrennie.github.io/r-pharma-2023-tidymodels"
      },
      {
        "href": "https://github.com/nrennie/r-pharma-2023-tidymodels",
        "text": "github.com/nrennie/r-pharma-2023-tidymodels"
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#pre-processing",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#all-the-binary-explanatory-variables-are-defined-as-numeric-0s-and-1s-dbl-would-it-be-better-to-convert-them-to-factors",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#is-there-a-good-standard-range-of-proportions-to-use-for-the-train-vs-test-split-of-datasets",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#does-the-initial_split-function-account-for-class-imbalance-and-maintain-that-proportion-in-the-split",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#when-you-pre-process-train-and-test-do-you-feed-the-parameters-from-train-to-process-test-for-example-when-you-normalise-a-variable-in-train-does-the-normalised-test-have-mean-and-standard-deviation-different-from-0",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#more-generally-if-you-have-a-large-enough-sample-size-with-a-large-imbalance-in-the-outcome-would-you-recommend-sub-sampling-the-larger-class",
        "text": null
      },
      {
        "href": "https://matthewrkaye.com/posts/2023-03-25-balancing-classes/balancing-classes.html",
        "text": "matthewrkaye.com/posts/2023-03-25-balancing-classes/balancing-classes.htm"
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#in-the-scenario-where-you-dont-want-to-do-a-cross-validation-split-is-it-possible-to-split-your-data-into-train-validation-and-test-splits",
        "text": null
      },
      {
        "href": "https://rsample.tidymodels.org/reference/initial_validation_split.html",
        "text": "rsample.tidymodels.org/reference/initial_validation_split.html"
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#is-there-a-component-to-add-a-sensitive-analysis-in-the-recipe-ie-i-want-independent-covariates-ae-then-perform-the-whole-workflow-again-to-then-add-covariate-f-too",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#how-can-i-get-a-dataframe-after-the-step_dummy-function",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#lasso-logistic-regression",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#is-it-necessary-to-add-family--binary-in-logistic_reg",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#why-do-you-use-glmnet-in-set_engine-for-lasso-logistic-regression-rather-than-another-one-from-the-list",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#the-logistic_reg-function-has-an-engine-parameter---does-it-matter-whether-the-engine-is-set-within-the-logistic_reg-or-outside-using-set_engine",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#what-are-the-advantages-and-disadvantages-of-lasso-logistic-regression-opposed-to-regular-logistic-regression",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#could-you-use-lasso-to-select-the-variables-and-then-use-those-in-a-standard-regression",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#would-using-an-elastic-net-a-trade-off-between-lasso-and-ridge-regression-at-this-stage-be-appropriate",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#how-did-you-take-care-of-over-fitting-the-model",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#is-there-variability-around-importance---similar-to-a-confidence-interval-in-ols-regression",
        "text": null
      },
      {
        "href": "https://koalaverse.github.io/vip/articles/vip.html#permutation-method",
        "text": "koalaverse.github.io/vip/articles/vip.html#permutation-method"
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#model-fitting-in-tidymodels",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#for-each-value-of-the-hyperparameter-is-its-performance-evaluated-using-cv-or-does-each-cv-iteration-use-a-different-hyperparameter-value",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#can-you-elaborate-what-extract_fit_parsnip-does-exactly-",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#if-the-model-has-already-been-fitted-during-the-tuning-step-can-we-not-just-extract-it-directly-rather-than-fitting-it-again-with-finalize_workflow",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#so-now-that-the-model-is-ready-how-do-we-use-it-to-make-predictions-for-new-data",
        "text": null
      },
      {
        "href": "https://github.com/nrennie/r-pharma-2023-tidymodels/blob/main/examples/example_01.R",
        "text": "example_01.R"
      },
      {
        "href": "https://github.com/nrennie/r-pharma-2023-tidymodels/blob/main/examples/example_02.R",
        "text": "example_02.R"
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#is-last_fit-taking-care-of-applying-pre-processing-steps-to-testing-set",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#different-types-of-models",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#can-this-be-used-for-deep-learning-as-well",
        "text": null
      },
      {
        "href": "https://www.tidymodels.org/learn/models/parsnip-nnet/",
        "text": "https://www.tidymodels.org/learn/models/parsnip-nnet/"
      },
      {
        "href": "https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/",
        "text": "Deep Learning and Scientific Computing with Rtorch"
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#for-models-fitted-in-stan-are-these-precompiled",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#what-about-xgboost",
        "text": null
      },
      {
        "href": "https://juliasilge.com/blog/xgboost-tune-volleyball/",
        "text": "juliasilge.com/blog/xgboost-tune-volleyball/"
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#other-questions",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#can-you-show-how-to-read-a-confusion-matrix",
        "text": null
      },
      {
        "href": "https://github.com/nrennie/r-pharma-2023-tidymodels/blob/main/examples/example_02.R",
        "text": "example_02.R"
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#should-i-be-worried-that-i-got-slightly-different-values-even-when-i-followed-the-same-steps-during-live-coding-and-used-setseed",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#im-wondering-whether-using-tidymodels-has-any-advantagesdisadvantages-compared-to-using-scikit-learn",
        "text": null
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#what-would-you-recommend-as-kind-of-the-next-step-in-learning-to-someone-who-is-new-to-this",
        "text": null
      },
      {
        "href": "https://www.tidymodels.org/",
        "text": "{tidymodels} documentation"
      },
      {
        "href": "https://www.tmwr.org/",
        "text": "Tidy Modeling with R"
      },
      {
        "href": "https://rfordatasci.com/",
        "text": "R4DS Online Learning Community"
      },
      {
        "href": "https://juliasilge.com/blog/",
        "text": "Blog by Julia Silge"
      },
      {
        "href": "https://giphy.com/gifs/originals-doxie-maia-dachsund-ZXwdJuk172dQwAqMGv",
        "text": "giphy.com"
      },
      {
        "href": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/",
        "text": "R on Nicola Rennie"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "h1_title": "R-bloggers",
    "html_title": "Answering some {tidymodels} questions | R-bloggers",
    "images": [
      {
        "alt": "Gif of confused sausage dog with questions marks above its head",
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": "Gif of confused sausage dog with questions marks above its head",
        "base64": null,
        "src": "https://i2.wp.com/raw.githubusercontent.com/nrennie/nrennie.rbind.io/main/content/blog/2023-10-23-tidymodels-questions/dog.gif?w=578&ssl=1"
      }
    ],
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/r-on-nicola-rennie/",
        "text": "R on Nicola Rennie"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "lang": "en-US",
    "main_html": "<article class=\"post-379336 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Answering some {tidymodels} questions</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">October 22, 2023</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/r-on-nicola-rennie/\">R on Nicola Rennie</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/\"> R on Nicola Rennie</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 3.8.9--><p>Last week I had the pleasure of running the <em>Introduction to machine learning with {tidymodels}</em> workshop as part of the \n<a href=\"https://rinpharma.com/event/rinpharma2023/\" rel=\"nofollow\" target=\"_blank\">R/Pharma 2023 Conference</a>. Thanks again to Phil Bowsher for the invitation, and to Eric Nantz for TA’ing the workshop and keeping an eye on all the questions coming in!</p>\n<p>During the workshop, we covered the pre-modelling steps with {tidymodels}, LASSO logistic regression, random forests, and support vector machines. The workshop materials can be found online:</p>\n<ul>\n<li>Slides: \n<a href=\"https://nrennie.github.io/r-pharma-2023-tidymodels/\" rel=\"nofollow\" target=\"_blank\">nrennie.github.io/r-pharma-2023-tidymodels</a></li>\n<li>GitHub: \n<a href=\"https://github.com/nrennie/r-pharma-2023-tidymodels\" rel=\"nofollow\" target=\"_blank\">github.com/nrennie/r-pharma-2023-tidymodels</a></li>\n</ul>\n<p>There were a few questions that we didn’t get the chance to answer. And in some cases, now that I’ve had a bit more time to think, I have better answers for some of the questions I did answer! So I’ve shared those answers here instead.</p>\n<h2 id=\"pre-processing\">Pre-processing\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#pre-processing\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h2>\n<h4 id=\"all-the-binary-explanatory-variables-are-defined-as-numeric-0s-and-1s-dbl-would-it-be-better-to-convert-them-to-factors\">All the binary (explanatory) variables are defined as numeric 0s and 1s <code>&lt;dbl&gt;</code>, would it be better to convert them to factors?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#all-the-binary-explanatory-variables-are-defined-as-numeric-0s-and-1s-dbl-would-it-be-better-to-convert-them-to-factors\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>We don’t need to convert them to factors here, and actually you’ll get an error if you do.</p>\n<h4 id=\"is-there-a-good-standard-range-of-proportions-to-use-for-the-train-vs-test-split-of-datasets\">Is there a good standard range of proportions to use for the train vs test split of datasets?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#is-there-a-good-standard-range-of-proportions-to-use-for-the-train-vs-test-split-of-datasets\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>This is one of those questions with no single answer. The <code>initial_split()</code> default is 75% training data. 80% training data is also commonly given as a starting point. With less training data, the parameter estimates have a higher variance. With less testing data, the performance measures have a higher variance. It also depends on how many observations you have – there is a tendency to use smaller testing sets for data that is very large. In contrast, for small datasets you may use something closer to a 50:50 split.</p>\n<h4 id=\"does-the-initial_split-function-account-for-class-imbalance-and-maintain-that-proportion-in-the-split\">Does the <code>initial_split()</code> function account for class imbalance and maintain that proportion in the split?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#does-the-initial_split-function-account-for-class-imbalance-and-maintain-that-proportion-in-the-split\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>To make sure that you have equivalent proportions of a particular variable in the resampled data as in the original data set, you can use the <code>strata</code> argument in the <code>initial_split()</code> function. By default, the <code>strata</code> argument is <code>NULL</code>, but you can provide a column name e.g. <code>hf_split &lt;- initial_split(heart_failure, strata = death)</code> to conduct stratified sampling. Remember that when you perform the initial split, you haven’t created <code> recipe</code> to define what the response variable is yet. There’s a similar argument in <code>vfold_cv()</code> for cross-validation samples.</p>\n<h4 id=\"when-you-pre-process-train-and-test-do-you-feed-the-parameters-from-train-to-process-test-for-example-when-you-normalise-a-variable-in-train-does-the-normalised-test-have-mean-and-standard-deviation-different-from-0\">When you pre-process train and test, do you feed the parameters from train to process test. For example, when you normalise a variable in train does the normalised test have mean and standard deviation different from 0?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#when-you-pre-process-train-and-test-do-you-feed-the-parameters-from-train-to-process-test-for-example-when-you-normalise-a-variable-in-train-does-the-normalised-test-have-mean-and-standard-deviation-different-from-0\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>The <code>step_normalize()</code> function creates a specification of a recipe step that will normalise numeric data to have a standard deviation of one and a mean of zero. <code>step_normalize()</code> estimates the variable standard deviations and means from the data used in the training argument. If you’re applying the process to new data, you can use the <code>bake()</code> function to apply the scaling to the new data using these estimates.</p>\n<h4 id=\"more-generally-if-you-have-a-large-enough-sample-size-with-a-large-imbalance-in-the-outcome-would-you-recommend-sub-sampling-the-larger-class\">More generally if you have a large enough sample size with a large imbalance in the outcome, would you recommend sub-sampling the larger class?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#more-generally-if-you-have-a-large-enough-sample-size-with-a-large-imbalance-in-the-outcome-would-you-recommend-sub-sampling-the-larger-class\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>It depends! Most statistical models and machine learning algorithms are based on predicting the <em>average</em>. If you want to find out what factors affect the average observation, then sub-sampling is probably not helpful. If you want to make sure you accurately predict minority classes, then sub-sampling may be beneficial.</p>\n<p>This blog post from Matt Kaye provides a nice discussion: \n<a href=\"https://matthewrkaye.com/posts/2023-03-25-balancing-classes/balancing-classes.html\" rel=\"nofollow\" target=\"_blank\">matthewrkaye.com/posts/2023-03-25-balancing-classes/balancing-classes.htm</a>.</p>\n<h4 id=\"in-the-scenario-where-you-dont-want-to-do-a-cross-validation-split-is-it-possible-to-split-your-data-into-train-validation-and-test-splits\">In the scenario where you don’t want to do a cross validation split, is it possible to split your data into train, validation and test splits?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#in-the-scenario-where-you-dont-want-to-do-a-cross-validation-split-is-it-possible-to-split-your-data-into-train-validation-and-test-splits\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>Yes, you can use the <code>initial_validation_split()</code> instead of <code>initial_split()</code>. See here for more details: \n<a href=\"https://rsample.tidymodels.org/reference/initial_validation_split.html\" rel=\"nofollow\" target=\"_blank\">rsample.tidymodels.org/reference/initial_validation_split.html</a>.</p>\n<h4 id=\"is-there-a-component-to-add-a-sensitive-analysis-in-the-recipe-ie-i-want-independent-covariates-ae-then-perform-the-whole-workflow-again-to-then-add-covariate-f-too\">Is there a component to add a sensitive analysis in the recipe (i.e. I want independent covariates A:E), then perform the whole workflow again to then add covariate F too?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#is-there-a-component-to-add-a-sensitive-analysis-in-the-recipe-ie-i-want-independent-covariates-ae-then-perform-the-whole-workflow-again-to-then-add-covariate-f-too\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>Yes, there are a set of functions in {workflows} that help you to add or remove variables from workflows. Look at the help functions for <code>workflow_variables()</code> by running <code>?workflow_variables()</code> to see examples of how it works.</p>\n<h4 id=\"how-can-i-get-a-dataframe-after-the-step_dummy-function\">How can I get a dataframe after the <code>step_dummy()</code> function?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#how-can-i-get-a-dataframe-after-the-step_dummy-function\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>To see what the <code>step_*</code> functions have done to the data, you can use <code>prep()</code> and <code>bake()</code> on the training data. For example:</p>\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre>1\n2\n3\n4\n5\n6\n7\n8\n9\n</pre></td>\n<td class=\"lntd\">\n<pre># make the recipe as in the examples\nhf_recipe &lt;- recipe(death ~ ., data = hf_train) |&gt; \n  step_dummy(sex) |&gt; \n  step_normalize(age, serum_creatinine:time)\n\n# return a tibble of the transformed training data\nhf_recipe |&gt; \n  prep(training = hf_train) |&gt; \n  bake(new_data = NULL)\n</pre></td></tr></table>\n</div>\n</div>\n<h2 id=\"lasso-logistic-regression\">LASSO logistic regression\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#lasso-logistic-regression\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h2>\n<h4 id=\"is-it-necessary-to-add-family--binary-in-logistic_reg\">Is it necessary to add <code>family = \"binary\"</code> in <code>logistic_reg()</code>?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#is-it-necessary-to-add-family--binary-in-logistic_reg\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>No, the <code>logistic_reg()</code> is specifically created for generalised linear models with binary outcomes - effectively the <code>family</code> argument is already defined. Unlike the <code>glm()</code> function in R which is for implementing multiple different types of generalised linear model - here, we need to be more specific and specify <code>family = \"binary\"</code>.</p>\n<h4 id=\"why-do-you-use-glmnet-in-set_engine-for-lasso-logistic-regression-rather-than-another-one-from-the-list\">Why do you use <code>\"glmnet\"</code> in <code>set_engine()</code> for LASSO logistic regression, rather than another one from the list?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#why-do-you-use-glmnet-in-set_engine-for-lasso-logistic-regression-rather-than-another-one-from-the-list\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>You can see all of the available engines using <code>show_engines()</code>. For example, for logistic regression we get:</p>\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n</pre></td>\n<td class=\"lntd\">\n<pre>show_engines(\"logistic_reg\")\n# A tibble: 7 × 2\n  engine    mode          \n  &lt;chr&gt;     &lt;chr&gt;         \n1 glm       classification\n2 glmnet    classification\n3 LiblineaR classification\n4 spark     classification\n5 keras     classification\n6 stan      classification\n7 brulee    classification\n</pre></td></tr></table>\n</div>\n</div><p>The <code>logistic_reg()</code> function can actually fit different types of models including simple logistic regression models, LASSO regression models, ridge regression models, and a mixture of LASSO and ridge models. This means that there are multiple engines that fit each of these type of models - <code>glmnet</code> is used for LASSO regression.</p>\n<h4 id=\"the-logistic_reg-function-has-an-engine-parameter---does-it-matter-whether-the-engine-is-set-within-the-logistic_reg-or-outside-using-set_engine\">The <code>logistic_reg()</code> function has an <code>engine</code> parameter - does it matter whether the engine is set within the <code>logistic_reg()</code> or outside using <code>set_engine()</code>?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#the-logistic_reg-function-has-an-engine-parameter---does-it-matter-whether-the-engine-is-set-within-the-logistic_reg-or-outside-using-set_engine\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>No, you can use either. If you use both, it will use the last engine you specify last.</p>\n<h4 id=\"what-are-the-advantages-and-disadvantages-of-lasso-logistic-regression-opposed-to-regular-logistic-regression\">What are the advantages and disadvantages of LASSO logistic regression opposed to ‘regular’ logistic regression?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#what-are-the-advantages-and-disadvantages-of-lasso-logistic-regression-opposed-to-regular-logistic-regression\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p><strong>Advantages</strong>: the main advantage, in my experience, has been automatic variable selection - no need to use stepwise procedures!. This is especially useful if you have a high number of candidate covariates. By pushing coefficients towards zero, LASSO regression also helps to avoid over-fitting - making the model more likely to perform better on unseen data.</p>\n<p><strong>Disadvantages</strong>: By shrinking the coefficients towards zero, this means that the coefficients from a LASSO model don’t represent the true relationship between an explanatory variable and the response. This makes models harder to interpret, and it’s difficult to estimate uncertainty in these coefficients as they are biased towards zero. The introduction of the hyperparameter also adds an additional layer of complexity to fitting the model. LASSO regression doesn’t usually perform well if you have lots of correlated variables - try using a ridge regression (or mixture) model instead.</p>\n<h4 id=\"could-you-use-lasso-to-select-the-variables-and-then-use-those-in-a-standard-regression\">Could you use LASSO to select the variables and then use those in a standard regression?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#could-you-use-lasso-to-select-the-variables-and-then-use-those-in-a-standard-regression\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>If your main aim is inference rather than prediction, then you’re right that LASSO is likely not the most appropriate final model. Instead you are best to perform feature selection and feed the selected features into something like a standard regression model. LASSO is one method of feature selection, so yes you could. You could of course also make use of a different feature selection method.</p>\n<h4 id=\"would-using-an-elastic-net-a-trade-off-between-lasso-and-ridge-regression-at-this-stage-be-appropriate\">Would using an Elastic Net (a trade off between LASSO and Ridge Regression) at this stage be appropriate?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#would-using-an-elastic-net-a-trade-off-between-lasso-and-ridge-regression-at-this-stage-be-appropriate\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>Yes, it could definitely work, and it’s actually a very small code change to implement. In the <code>mixture</code> argument of <code>logistic_reg()</code>, for LASSO regression we specify <code>mixture = 1</code>. If we specify <code>mixture = 0</code>, this implements a ridge regression model. Any value in between 0 and 1,⁠ specifies an elastic net model which mixes LASSO and ridge regression.</p>\n<h4 id=\"how-did-you-take-care-of-over-fitting-the-model\">How did you take care of over-fitting the model?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#how-did-you-take-care-of-over-fitting-the-model\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>LASSO regression penalises the model coefficients, and therefore is itself a way of avoiding over-fitting models. It shrinks the coefficients of some explanatory variables towards zero and helps you to avoid including additional variables that contribute towards over-fitting.</p>\n<h4 id=\"is-there-variability-around-importance---similar-to-a-confidence-interval-in-ols-regression\">Is there variability around importance - similar to a confidence interval in OLS regression?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#is-there-variability-around-importance---similar-to-a-confidence-interval-in-ols-regression\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>There are ways to measure the variability around the variable importance scores. For example, the {vip} package implements a permutation-based method. You can use this if you specify <code>method = \"permute\"</code> in the <code>vip::vi()</code> function. The permutation method allows you to compute standard errors (and other metrics) for the estimated variable importance scores. However, this isn’t similar to confidence intervals for coefficients in OLS regression.</p>\n<p>Read the {vip} package vignette for more details and examples: \n<a href=\"https://koalaverse.github.io/vip/articles/vip.html#permutation-method\" rel=\"nofollow\" target=\"_blank\">koalaverse.github.io/vip/articles/vip.html#permutation-method</a>.</p>\n<h2 id=\"model-fitting-in-tidymodels\">Model fitting in {tidymodels}\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#model-fitting-in-tidymodels\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h2>\n<h4 id=\"for-each-value-of-the-hyperparameter-is-its-performance-evaluated-using-cv-or-does-each-cv-iteration-use-a-different-hyperparameter-value\">For each value of the hyperparameter, is its performance evaluated using CV? Or does each CV iteration use a different hyperparameter value?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#for-each-value-of-the-hyperparameter-is-its-performance-evaluated-using-cv-or-does-each-cv-iteration-use-a-different-hyperparameter-value\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>The <code>vfold_cv()</code> has two arguments that control the number of times it is fitted. The <code>v</code> argument controls how many folds, the default is 10. The <code>repeats</code> argument controls how many times the v-fold partitioning is done. The default is 1.</p>\n<p>For each cross-validation fold, the model is fitted to each element in the grid of penalty values. So if you have 10 cross validation folds, with 1 repeat, and 25 values of the hyperparameter, you’ll have 250 fitted models in the tuning step. Try looking at the output <code>lasso_grid$.metrics</code>.</p>\n<h4 id=\"can-you-elaborate-what-extract_fit_parsnip-does-exactly-\">Can you elaborate what <code>extract_fit_parsnip()</code> does exactly ?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#can-you-elaborate-what-extract_fit_parsnip-does-exactly-\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>After you fit a model e.g. using the <code>fit()</code> function, you can extract the fitted parsnip model object. The parsnip object wraps the underlying model object e.g. the model object returned by <code>glmnet</code>. The output of <code>extract_fit_parsnip()</code> isn’t usually very pretty so I’d recommend using <code>tidy()</code> to convert the output into a nice tibble. For example, from the LASSO fit in <code>example_01.R</code>:</p>\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n</pre></td>\n<td class=\"lntd\">\n<pre>final_lasso |&gt;\n  fit(hf_train) |&gt;\n  extract_fit_parsnip() |&gt; \n  tidy()\n  \n# A tibble: 12 × 3\n   term                     estimate penalty\n   &lt;chr&gt;                       &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)               -0.985   0.0596\n 2 age                        0.0836  0.0596\n 3 smoking                    0       0.0596\n 4 anaemia                    0       0.0596\n 5 diabetes                   0       0.0596\n 6 high_blood_pressure        0       0.0596\n 7 serum_creatinine           0.336   0.0596\n 8 creatinine_phosphokinase   0       0.0596\n 9 platelets                  0       0.0596\n10 ejection_fraction         -0.270   0.0596\n11 time                      -0.908   0.0596\n12 sex_M                      0       0.0596\n</pre></td></tr></table>\n</div>\n</div>\n<h4 id=\"if-the-model-has-already-been-fitted-during-the-tuning-step-can-we-not-just-extract-it-directly-rather-than-fitting-it-again-with-finalize_workflow\">If the model has already been fitted during the tuning step can we not just extract it directly rather than fitting it again with <code>finalize_workflow()</code>?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#if-the-model-has-already-been-fitted-during-the-tuning-step-can-we-not-just-extract-it-directly-rather-than-fitting-it-again-with-finalize_workflow\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>Not in the examples here, although the model has been fitted many times during the tuning process, we never fit it to the whole training set during the tuning process - only to each of the cross-validation folds which are each a subset of the training data. We still need to calculate the rest of (non-tuned) parameters e.g. the LASSO coefficients when the model is fitted to the training data.</p>\n<h4 id=\"so-now-that-the-model-is-ready-how-do-we-use-it-to-make-predictions-for-new-data\">So, now that the model is ready, how do we use it to make predictions for new data?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#so-now-that-the-model-is-ready-how-do-we-use-it-to-make-predictions-for-new-data\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>As an example, let’s assume we’re looking at the LASSO model and you’ve run all the code in \n<a href=\"https://github.com/nrennie/r-pharma-2023-tidymodels/blob/main/examples/example_01.R\" rel=\"nofollow\" target=\"_blank\"><code>example_01.R</code></a> and \n<a href=\"https://github.com/nrennie/r-pharma-2023-tidymodels/blob/main/examples/example_02.R\" rel=\"nofollow\" target=\"_blank\"><code>example_02.R</code></a>. Let’s also assume that you have some <code>new_data</code> with the same format and columns as the original data, but without the response variable column. You can use the <code>predict()</code> function to apply the model to new data:</p>\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre>1\n2\n3\n</pre></td>\n<td class=\"lntd\">\n<pre>final_lasso |&gt; \n  fit(hf_train) |&gt; \n  predict(new_data)\n</pre></td></tr></table>\n</div>\n</div>\n<h4 id=\"is-last_fit-taking-care-of-applying-pre-processing-steps-to-testing-set\">Is <code>last_fit()</code> taking care of applying pre-processing steps to testing set?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#is-last_fit-taking-care-of-applying-pre-processing-steps-to-testing-set\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>Yes, this is the first (and only) time we’re actually using the testing data.</p>\n<h2 id=\"different-types-of-models\">Different types of models\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#different-types-of-models\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h2>\n<h4 id=\"can-this-be-used-for-deep-learning-as-well\">Can this be used for deep learning as well?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#can-this-be-used-for-deep-learning-as-well\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>You can fit neural networks with {tidymodels}. There’s some nice examples in the {tidymodels} documentation here: \n<a href=\"https://www.tidymodels.org/learn/models/parsnip-nnet/\" rel=\"nofollow\" target=\"_blank\">https://www.tidymodels.org/learn/models/parsnip-nnet/</a>. If you’re interested in deep learning in R, I’d also recommend having a look at \n<a href=\"https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/\" rel=\"nofollow\" target=\"_blank\"><em>Deep Learning and Scientific Computing with R <code>torch</code></em></a>. It uses the R interface to PyTorch, for an alternative approach to deep learning in R.</p>\n<h4 id=\"for-models-fitted-in-stan-are-these-precompiled\">For models fitted in Stan are these precompiled?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#for-models-fitted-in-stan-are-these-precompiled\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>I believe so. The Stan models in {tidymodels} using packages such as <code>{rstanarm}</code> to actually fit the models. Check the details of specific engines for more information.</p>\n<h4 id=\"what-about-xgboost\">What about XGBoost?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#what-about-xgboost\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>Yes, you can fit <code>XGBoost</code> models with {tidymodels}. Julia Silge has a nice blog post on using XGBoost to predict beach volleyball matches: \n<a href=\"https://juliasilge.com/blog/xgboost-tune-volleyball/\" rel=\"nofollow\" target=\"_blank\">juliasilge.com/blog/xgboost-tune-volleyball/</a></p>\n<h2 id=\"other-questions\">Other questions\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#other-questions\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h2>\n<h4 id=\"can-you-show-how-to-read-a-confusion-matrix\">Can you show how to read a confusion matrix?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#can-you-show-how-to-read-a-confusion-matrix\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>Yes, let’s say that the output of <code>conf_mat()</code> in \n<a href=\"https://github.com/nrennie/r-pharma-2023-tidymodels/blob/main/examples/example_02.R\" rel=\"nofollow\" target=\"_blank\"><code>example_02.R</code></a> looks like this:</p>\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre>1\n2\n3\n4\n</pre></td>\n<td class=\"lntd\">\n<pre>          Truth\nPrediction  0  1\n         0 37  9\n         1  1 13\n</pre></td></tr></table>\n</div>\n</div><p>This means that: there were 37 zeros that we correctly predicted were zeros; and there was 1 zero that we incorrectly labelled as a one. There were 9 ones that we incorrectly predicted were zeros; and there were 13 ones that we correctly predicted were ones. Ideally only the diagonal line from the top-left to the bottom-right will have non-zero values.</p>\n<h4 id=\"should-i-be-worried-that-i-got-slightly-different-values-even-when-i-followed-the-same-steps-during-live-coding-and-used-setseed\">Should I be worried that I got slightly different values even when I followed the same steps during live coding and used <code>set.seed()</code>?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#should-i-be-worried-that-i-got-slightly-different-values-even-when-i-followed-the-same-steps-during-live-coding-and-used-setseed\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>I wouldn’t worry about it too much - it’s very possible I accidentally ran something twice in the workshop!</p>\n<h4 id=\"im-wondering-whether-using-tidymodels-has-any-advantagesdisadvantages-compared-to-using-scikit-learn\">I’m wondering whether using {tidymodels} has any advantages/disadvantages compared to using scikit-learn?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#im-wondering-whether-using-tidymodels-has-any-advantagesdisadvantages-compared-to-using-scikit-learn\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>The main benefit of {tidymodels} is that it bring machine learning capabilities to R in a very accessible, user-friendly way. This means that if you’re already doing exploratory data analysis, data preparation, and results visualisation in R you can continue doing so without having to export data and run models in Python instead. Multi-language workflows can be great, but single-language workflows tend to be easier to maintain and debug.</p>\n<p>I don’t think I would ever say one is better than the other - I’d choose the between them based on the language I (or the team) are already working in.</p>\n<h4 id=\"what-would-you-recommend-as-kind-of-the-next-step-in-learning-to-someone-who-is-new-to-this\">What would you recommend as kind of the next step in learning to someone who is new to this?\n  <a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/#what-would-you-recommend-as-kind-of-the-next-step-in-learning-to-someone-who-is-new-to-this\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>Any of the following resources are fantastic next steps:</p>\n<ul>\n<li>\n<p>\n<a href=\"https://www.tidymodels.org/\" rel=\"nofollow\" target=\"_blank\">{tidymodels} documentation</a>.</p>\n</li>\n<li>\n<p>\n<a href=\"https://www.tmwr.org/\" rel=\"nofollow\" target=\"_blank\">Tidy Modeling with R</a>. You can also join the Tidy Modelling with R book club in the \n<a href=\"https://rfordatasci.com/\" rel=\"nofollow\" target=\"_blank\">R4DS Online Learning Community</a> Slack channel.</p>\n</li>\n<li>\n<p>\n<a href=\"https://juliasilge.com/blog/\" rel=\"nofollow\" target=\"_blank\">Blog by Julia Silge</a>.</p>\n</li>\n</ul>\n<p>I’m hoping this has answered most of the remaining questions!</p>\n<p align=\"center\">\n<img alt=\"Gif of confused sausage dog with questions marks above its head\" data-lazy-src=\"https://i2.wp.com/raw.githubusercontent.com/nrennie/nrennie.rbind.io/main/content/blog/2023-10-23-tidymodels-questions/dog.gif?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" width=\"60%\"/><noscript><img alt=\"Gif of confused sausage dog with questions marks above its head\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/raw.githubusercontent.com/nrennie/nrennie.rbind.io/main/content/blog/2023-10-23-tidymodels-questions/dog.gif?w=578&amp;ssl=1\" width=\"60%\"/></noscript><br/>\n<small>Image: <a href=\"https://giphy.com/gifs/originals-doxie-maia-dachsund-ZXwdJuk172dQwAqMGv\" rel=\"nofollow\" target=\"_blank\">giphy.com</a></small>\n</p>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/\"> R on Nicola Rennie</a></strong>.</div>\n<hr>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</hr></div> </div>\n</article>",
    "main_text": "Answering some {tidymodels} questions\nPosted on\nOctober 22, 2023\nby\nR on Nicola Rennie\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nR on Nicola Rennie\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nLast week I had the pleasure of running the\nIntroduction to machine learning with {tidymodels}\nworkshop as part of the\nR/Pharma 2023 Conference\n. Thanks again to Phil Bowsher for the invitation, and to Eric Nantz for TA’ing the workshop and keeping an eye on all the questions coming in!\nDuring the workshop, we covered the pre-modelling steps with {tidymodels}, LASSO logistic regression, random forests, and support vector machines. The workshop materials can be found online:\nSlides:\nnrennie.github.io/r-pharma-2023-tidymodels\nGitHub:\ngithub.com/nrennie/r-pharma-2023-tidymodels\nThere were a few questions that we didn’t get the chance to answer. And in some cases, now that I’ve had a bit more time to think, I have better answers for some of the questions I did answer! So I’ve shared those answers here instead.\nPre-processing\nAll the binary (explanatory) variables are defined as numeric 0s and 1s\n<dbl>\n, would it be better to convert them to factors?\nWe don’t need to convert them to factors here, and actually you’ll get an error if you do.\nIs there a good standard range of proportions to use for the train vs test split of datasets?\nThis is one of those questions with no single answer. The\ninitial_split()\ndefault is 75% training data. 80% training data is also commonly given as a starting point. With less training data, the parameter estimates have a higher variance. With less testing data, the performance measures have a higher variance. It also depends on how many observations you have – there is a tendency to use smaller testing sets for data that is very large. In contrast, for small datasets you may use something closer to a 50:50 split.\nDoes the\ninitial_split()\nfunction account for class imbalance and maintain that proportion in the split?\nTo make sure that you have equivalent proportions of a particular variable in the resampled data as in the original data set, you can use the\nstrata\nargument in the\ninitial_split()\nfunction. By default, the\nstrata\nargument is\nNULL\n, but you can provide a column name e.g.\nhf_split <- initial_split(heart_failure, strata = death)\nto conduct stratified sampling. Remember that when you perform the initial split, you haven’t created\nrecipe\nto define what the response variable is yet. There’s a similar argument in\nvfold_cv()\nfor cross-validation samples.\nWhen you pre-process train and test, do you feed the parameters from train to process test. For example, when you normalise a variable in train does the normalised test have mean and standard deviation different from 0?\nThe\nstep_normalize()\nfunction creates a specification of a recipe step that will normalise numeric data to have a standard deviation of one and a mean of zero.\nstep_normalize()\nestimates the variable standard deviations and means from the data used in the training argument. If you’re applying the process to new data, you can use the\nbake()\nfunction to apply the scaling to the new data using these estimates.\nMore generally if you have a large enough sample size with a large imbalance in the outcome, would you recommend sub-sampling the larger class?\nIt depends! Most statistical models and machine learning algorithms are based on predicting the\naverage\n. If you want to find out what factors affect the average observation, then sub-sampling is probably not helpful. If you want to make sure you accurately predict minority classes, then sub-sampling may be beneficial.\nThis blog post from Matt Kaye provides a nice discussion:\nmatthewrkaye.com/posts/2023-03-25-balancing-classes/balancing-classes.htm\n.\nIn the scenario where you don’t want to do a cross validation split, is it possible to split your data into train, validation and test splits?\nYes, you can use the\ninitial_validation_split()\ninstead of\ninitial_split()\n. See here for more details:\nrsample.tidymodels.org/reference/initial_validation_split.html\n.\nIs there a component to add a sensitive analysis in the recipe (i.e. I want independent covariates A:E), then perform the whole workflow again to then add covariate F too?\nYes, there are a set of functions in {workflows} that help you to add or remove variables from workflows. Look at the help functions for\nworkflow_variables()\nby running\n?workflow_variables()\nto see examples of how it works.\nHow can I get a dataframe after the\nstep_dummy()\nfunction?\nTo see what the\nstep_*\nfunctions have done to the data, you can use\nprep()\nand\nbake()\non the training data. For example:\n1\n2\n3\n4\n5\n6\n7\n8\n9\n# make the recipe as in the examples\nhf_recipe <- recipe(death ~ ., data = hf_train) |> \n  step_dummy(sex) |> \n  step_normalize(age, serum_creatinine:time)\n\n# return a tibble of the transformed training data\nhf_recipe |> \n  prep(training = hf_train) |> \n  bake(new_data = NULL)\nLASSO logistic regression\nIs it necessary to add\nfamily = \"binary\"\nin\nlogistic_reg()\n?\nNo, the\nlogistic_reg()\nis specifically created for generalised linear models with binary outcomes - effectively the\nfamily\nargument is already defined. Unlike the\nglm()\nfunction in R which is for implementing multiple different types of generalised linear model - here, we need to be more specific and specify\nfamily = \"binary\"\n.\nWhy do you use\n\"glmnet\"\nin\nset_engine()\nfor LASSO logistic regression, rather than another one from the list?\nYou can see all of the available engines using\nshow_engines()\n. For example, for logistic regression we get:\n1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\nshow_engines(\"logistic_reg\")\n# A tibble: 7 × 2\n  engine    mode          \n  <chr>     <chr>         \n1 glm       classification\n2 glmnet    classification\n3 LiblineaR classification\n4 spark     classification\n5 keras     classification\n6 stan      classification\n7 brulee    classification\nThe\nlogistic_reg()\nfunction can actually fit different types of models including simple logistic regression models, LASSO regression models, ridge regression models, and a mixture of LASSO and ridge models. This means that there are multiple engines that fit each of these type of models -\nglmnet\nis used for LASSO regression.\nThe\nlogistic_reg()\nfunction has an\nengine\nparameter - does it matter whether the engine is set within the\nlogistic_reg()\nor outside using\nset_engine()\n?\nNo, you can use either. If you use both, it will use the last engine you specify last.\nWhat are the advantages and disadvantages of LASSO logistic regression opposed to ‘regular’ logistic regression?\nAdvantages\n: the main advantage, in my experience, has been automatic variable selection - no need to use stepwise procedures!. This is especially useful if you have a high number of candidate covariates. By pushing coefficients towards zero, LASSO regression also helps to avoid over-fitting - making the model more likely to perform better on unseen data.\nDisadvantages\n: By shrinking the coefficients towards zero, this means that the coefficients from a LASSO model don’t represent the true relationship between an explanatory variable and the response. This makes models harder to interpret, and it’s difficult to estimate uncertainty in these coefficients as they are biased towards zero. The introduction of the hyperparameter also adds an additional layer of complexity to fitting the model. LASSO regression doesn’t usually perform well if you have lots of correlated variables - try using a ridge regression (or mixture) model instead.\nCould you use LASSO to select the variables and then use those in a standard regression?\nIf your main aim is inference rather than prediction, then you’re right that LASSO is likely not the most appropriate final model. Instead you are best to perform feature selection and feed the selected features into something like a standard regression model. LASSO is one method of feature selection, so yes you could. You could of course also make use of a different feature selection method.\nWould using an Elastic Net (a trade off between LASSO and Ridge Regression) at this stage be appropriate?\nYes, it could definitely work, and it’s actually a very small code change to implement. In the\nmixture\nargument of\nlogistic_reg()\n, for LASSO regression we specify\nmixture = 1\n. If we specify\nmixture = 0\n, this implements a ridge regression model. Any value in between 0 and 1,⁠ specifies an elastic net model which mixes LASSO and ridge regression.\nHow did you take care of over-fitting the model?\nLASSO regression penalises the model coefficients, and therefore is itself a way of avoiding over-fitting models. It shrinks the coefficients of some explanatory variables towards zero and helps you to avoid including additional variables that contribute towards over-fitting.\nIs there variability around importance - similar to a confidence interval in OLS regression?\nThere are ways to measure the variability around the variable importance scores. For example, the {vip} package implements a permutation-based method. You can use this if you specify\nmethod = \"permute\"\nin the\nvip::vi()\nfunction. The permutation method allows you to compute standard errors (and other metrics) for the estimated variable importance scores. However, this isn’t similar to confidence intervals for coefficients in OLS regression.\nRead the {vip} package vignette for more details and examples:\nkoalaverse.github.io/vip/articles/vip.html#permutation-method\n.\nModel fitting in {tidymodels}\nFor each value of the hyperparameter, is its performance evaluated using CV? Or does each CV iteration use a different hyperparameter value?\nThe\nvfold_cv()\nhas two arguments that control the number of times it is fitted. The\nv\nargument controls how many folds, the default is 10. The\nrepeats\nargument controls how many times the v-fold partitioning is done. The default is 1.\nFor each cross-validation fold, the model is fitted to each element in the grid of penalty values. So if you have 10 cross validation folds, with 1 repeat, and 25 values of the hyperparameter, you’ll have 250 fitted models in the tuning step. Try looking at the output\nlasso_grid$.metrics\n.\nCan you elaborate what\nextract_fit_parsnip()\ndoes exactly ?\nAfter you fit a model e.g. using the\nfit()\nfunction, you can extract the fitted parsnip model object. The parsnip object wraps the underlying model object e.g. the model object returned by\nglmnet\n. The output of\nextract_fit_parsnip()\nisn’t usually very pretty so I’d recommend using\ntidy()\nto convert the output into a nice tibble. For example, from the LASSO fit in\nexample_01.R\n:\n1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\nfinal_lasso |>\n  fit(hf_train) |>\n  extract_fit_parsnip() |> \n  tidy()\n  \n# A tibble: 12 × 3\n   term                     estimate penalty\n   <chr>                       <dbl>   <dbl>\n 1 (Intercept)               -0.985   0.0596\n 2 age                        0.0836  0.0596\n 3 smoking                    0       0.0596\n 4 anaemia                    0       0.0596\n 5 diabetes                   0       0.0596\n 6 high_blood_pressure        0       0.0596\n 7 serum_creatinine           0.336   0.0596\n 8 creatinine_phosphokinase   0       0.0596\n 9 platelets                  0       0.0596\n10 ejection_fraction         -0.270   0.0596\n11 time                      -0.908   0.0596\n12 sex_M                      0       0.0596\nIf the model has already been fitted during the tuning step can we not just extract it directly rather than fitting it again with\nfinalize_workflow()\n?\nNot in the examples here, although the model has been fitted many times during the tuning process, we never fit it to the whole training set during the tuning process - only to each of the cross-validation folds which are each a subset of the training data. We still need to calculate the rest of (non-tuned) parameters e.g. the LASSO coefficients when the model is fitted to the training data.\nSo, now that the model is ready, how do we use it to make predictions for new data?\nAs an example, let’s assume we’re looking at the LASSO model and you’ve run all the code in\nexample_01.R\nand\nexample_02.R\n. Let’s also assume that you have some\nnew_data\nwith the same format and columns as the original data, but without the response variable column. You can use the\npredict()\nfunction to apply the model to new data:\n1\n2\n3\nfinal_lasso |> \n  fit(hf_train) |> \n  predict(new_data)\nIs\nlast_fit()\ntaking care of applying pre-processing steps to testing set?\nYes, this is the first (and only) time we’re actually using the testing data.\nDifferent types of models\nCan this be used for deep learning as well?\nYou can fit neural networks with {tidymodels}. There’s some nice examples in the {tidymodels} documentation here:\nhttps://www.tidymodels.org/learn/models/parsnip-nnet/\n. If you’re interested in deep learning in R, I’d also recommend having a look at\nDeep Learning and Scientific Computing with R\ntorch\n. It uses the R interface to PyTorch, for an alternative approach to deep learning in R.\nFor models fitted in Stan are these precompiled?\nI believe so. The Stan models in {tidymodels} using packages such as\n{rstanarm}\nto actually fit the models. Check the details of specific engines for more information.\nWhat about XGBoost?\nYes, you can fit\nXGBoost\nmodels with {tidymodels}. Julia Silge has a nice blog post on using XGBoost to predict beach volleyball matches:\njuliasilge.com/blog/xgboost-tune-volleyball/\nOther questions\nCan you show how to read a confusion matrix?\nYes, let’s say that the output of\nconf_mat()\nin\nexample_02.R\nlooks like this:\n1\n2\n3\n4\nTruth\nPrediction  0  1\n         0 37  9\n         1  1 13\nThis means that: there were 37 zeros that we correctly predicted were zeros; and there was 1 zero that we incorrectly labelled as a one. There were 9 ones that we incorrectly predicted were zeros; and there were 13 ones that we correctly predicted were ones. Ideally only the diagonal line from the top-left to the bottom-right will have non-zero values.\nShould I be worried that I got slightly different values even when I followed the same steps during live coding and used\nset.seed()\n?\nI wouldn’t worry about it too much - it’s very possible I accidentally ran something twice in the workshop!\nI’m wondering whether using {tidymodels} has any advantages/disadvantages compared to using scikit-learn?\nThe main benefit of {tidymodels} is that it bring machine learning capabilities to R in a very accessible, user-friendly way. This means that if you’re already doing exploratory data analysis, data preparation, and results visualisation in R you can continue doing so without having to export data and run models in Python instead. Multi-language workflows can be great, but single-language workflows tend to be easier to maintain and debug.\nI don’t think I would ever say one is better than the other - I’d choose the between them based on the language I (or the team) are already working in.\nWhat would you recommend as kind of the next step in learning to someone who is new to this?\nAny of the following resources are fantastic next steps:\n{tidymodels} documentation\n.\nTidy Modeling with R\n. You can also join the Tidy Modelling with R book club in the\nR4DS Online Learning Community\nSlack channel.\nBlog by Julia Silge\n.\nI’m hoping this has answered most of the remaining questions!\nImage:\ngiphy.com\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nR on Nicola Rennie\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "meta_description": "Last week I had the pleasure of running the Introduction to machine learning with {tidymodels} workshop as part of the R/Pharma 2023 Conference. Thanks again to Phil Bowsher for the invitation, and to Eric Nantz for TA’ing the workshop and keepi...",
    "meta_keywords": null,
    "og_description": "Last week I had the pleasure of running the Introduction to machine learning with {tidymodels} workshop as part of the R/Pharma 2023 Conference. Thanks again to Phil Bowsher for the invitation, and to Eric Nantz for TA’ing the workshop and keepi...",
    "og_image": "https://raw.githubusercontent.com/nrennie/nrennie.rbind.io/main/content/blog/2023-10-23-tidymodels-questions/dog.gif",
    "og_title": "Answering some {tidymodels} questions | R-bloggers",
    "raw_jsonld_article": null,
    "reading_time_min": 13.1,
    "sitemap_lastmod": "2023-10-23T00:00:00+00:00",
    "twitter_description": "Last week I had the pleasure of running the Introduction to machine learning with {tidymodels} workshop as part of the R/Pharma 2023 Conference. Thanks again to Phil Bowsher for the invitation, and to Eric Nantz for TA’ing the workshop and keepi...",
    "twitter_title": "Answering some {tidymodels} questions | R-bloggers",
    "url": "https://www.r-bloggers.com/2023/10/answering-some-tidymodels-questions/",
    "word_count": 2624
  }
}