{
  "id": "406c8c7d3aad6a84d1ad11bbc91893847d28262a",
  "url": "https://www.r-bloggers.com/2023/10/analyzing-the-runtime-performance-of-tidymodels-and-mlr3/",
  "created_at_utc": "2025-11-17T20:39:28Z",
  "data": null,
  "raw_original": {
    "uuid": "231739a9-b973-4488-b6ee-8e33327763d5",
    "created_at": "2025-11-17 20:39:28",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2023/10/analyzing-the-runtime-performance-of-tidymodels-and-mlr3/",
      "crawled_at": "2025-11-17T10:02:19.028156",
      "external_links": [
        {
          "href": "https://mlr-org.com/gallery/technical/2023-10-30-tidymodels/",
          "text": "mlr-org"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://cran.r-project.org/package=tidymodels",
          "text": "tidymodels"
        },
        {
          "href": "https://mlr3.mlr-org.com/",
          "text": "mlr3"
        },
        {
          "href": "https://www.rdocumentation.org/packages/rpart/topics/rpart",
          "text": "rpart::rpart()"
        },
        {
          "href": "https://www.rdocumentation.org/packages/ranger/topics/ranger",
          "text": "ranger::ranger()"
        },
        {
          "href": "https://mlr3.mlr-org.com/reference/mlr_tasks_sonar.html",
          "text": "Sonar"
        },
        {
          "href": "https://cran.r-project.org/package=microbenchmark",
          "text": "microbenchmark"
        },
        {
          "href": "https://github.com/mlr-org/mlr-benchmark/tree/main/tidymodels",
          "text": "mlr-org/mlr-benchmark"
        },
        {
          "href": "https://mlr-org.com/gallery/technical/2023-10-30-tidymodels/",
          "text": "mlr-org"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Analyzing the Runtime Performance of tidymodels and mlr3 | R-bloggers",
      "images": [
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/mlr-org.com/gallery/technical/2023-10-30-tidymodels/index_files/figure-html/fig-resample-sequential-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/mlr-org.com/gallery/technical/2023-10-30-tidymodels/index_files/figure-html/fig-resample-parallel-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/mlr-org.com/gallery/technical/2023-10-30-tidymodels/index_files/figure-html/fig-resample-parallel-2-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/mlr-org.com/gallery/technical/2023-10-30-tidymodels/index_files/figure-html/fig-tune-parallel-1.png?w=450&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/marc-becker/",
          "text": "Marc Becker"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-380300 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Analyzing the Runtime Performance of tidymodels and mlr3</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">October 29, 2023</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/marc-becker/\">Marc Becker</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://mlr-org.com/gallery/technical/2023-10-30-tidymodels/\"> mlr-org</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<section class=\"level1\" id=\"scope\">\n<h1>Scope</h1>\n<p>In the realm of data science, machine learning frameworks play an important role in streamlining and accelerating the development of analytical workflows. Among these, <a href=\"https://cran.r-project.org/package=tidymodels\" rel=\"nofollow\" target=\"_blank\">tidymodels</a> and <a href=\"https://mlr3.mlr-org.com/\" rel=\"nofollow\" target=\"_blank\">mlr3</a> stand out as prominent tools within the R community. They provide a unified interface for data preprocessing, model training, resampling and tuning. The streamlined and accelerated development process, while efficient, typically results in a trade-off concerning runtime performance. This article undertakes a detailed comparison of the runtime efficiency of <code>tidymodels</code> and <code>mlr3</code>, focusing on their performance in training, resampling, and tuning machine learning models. Specifically, we assess the time efficiency of these frameworks in running the <a href=\"https://www.rdocumentation.org/packages/rpart/topics/rpart\" rel=\"nofollow\" target=\"_blank\"><code>rpart::rpart()</code></a> and <a href=\"https://www.rdocumentation.org/packages/ranger/topics/ranger\" rel=\"nofollow\" target=\"_blank\"><code>ranger::ranger()</code></a> models, using the <a href=\"https://mlr3.mlr-org.com/reference/mlr_tasks_sonar.html\" rel=\"nofollow\" target=\"_blank\"><code>Sonar</code></a> dataset as a test case. Additionally, the study delves into analyzing the runtime overhead of these frameworks by comparing their performance against training the models without a framework. Through this comparative analysis, the article aims to provide valuable insights into the operational trade-offs of using these advanced machine learning frameworks in practical data science applications.</p>\n</section>\n<section class=\"level1\" id=\"setup\">\n<h1>Setup</h1>\n<p>We employ the <a href=\"https://cran.r-project.org/package=microbenchmark\" rel=\"nofollow\" target=\"_blank\">microbenchmark</a> package to measure the time required for training, resampling, and tuning models. This benchmarking process is applied to the <code>Sonar</code> dataset using the <code>rpart</code> and <code>ranger</code> algorithms.</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>library(\"mlr3verse\")\nlibrary(\"tidymodels\")\nlibrary(\"microbenchmark\")\n\ntask = tsk(\"sonar\")\ndata = task$data()\nformula = Class ~ .</pre>\n</div>\n<p>To ensure the robustness of our results, each function call within the benchmark is executed 100 times in a randomized sequence. The microbenchmark package then provides us with detailed insights, including the median, lower quartile, and upper quartile of the runtimes. To further enhance the reliability of our findings, we execute the benchmark on a cluster. Each run of <code>microbenchmark</code> is repeated 100 times, with different seeds applied for each iteration. Resulting in a total of 10,000 function calls of each command. The computing environment for each worker in the cluster consists of 3 cores and 12 GB of RAM. For transparency and reproducibility, the examples of the code used for this experiment are provided as snippets in the article. The complete code, along with all details of the experiment, is available in our public repository, <a href=\"https://github.com/mlr-org/mlr-benchmark/tree/main/tidymodels\" rel=\"nofollow\" target=\"_blank\">mlr-org/mlr-benchmark</a>.</p>\n<p>It’s important to note that our cluster setup is not specifically optimized for single-core performance. Consequently, executing the same benchmark on a local machine with might yield faster results.</p>\n</section>\n<section class=\"level1\" id=\"benchmark\">\n<h1>Benchmark</h1>\n<section class=\"level2\" id=\"train-the-models\">\n<h2 class=\"anchored\" data-anchor-id=\"train-the-models\">Train the Models</h2>\n<p>Our benchmark starts with the fundamental task of model training. To facilitate a direct comparison, we have structured our presentation into two distinct segments. On the left, we demonstrate the initialization of the <code>rpart</code> model, employing both <code>mlr3</code> and <code>tidymodels</code> frameworks. The <code>rpart</code> model is a decision tree classifier, which is a simple and fast-fitting algorithm for classification tasks. Simultaneously, on the right, we turn our attention to the initialization of the <code>ranger</code> model, known for its efficient implementation of the random forest algorithm. Our aim is to mirror the configuration as closely as possible across both frameworks, maintaining consistency in parameters and settings.</p>\n<pre># tidymodels\ntm_mod = decision_tree() %&gt;%\n  set_engine(\"rpart\",\n    xval = 0L) %&gt;%\n  set_mode(\"classification\")\n\n# mlr3\nlearner = lrn(\"classif.rpart\",\n  xval = 0L)\n# tidymodels\ntm_mod = rand_forest(trees = 1000L) %&gt;%\n  set_engine(\"ranger\",\n    num.threads = 1L,\n    seed = 1) %&gt;%\n  set_mode(\"classification\")\n\n# mlr3\nlearner = lrn(\"classif.ranger\",\n  num.trees = 1000L,\n  num.threads = 1L,\n  seed = 1,\n  verbose = FALSE,\n  predict_type = \"prob\")</pre>\n<div class=\"quarto-layout-panel\" data-layout-ncol=\"2\">\n<div class=\"quarto-layout-row quarto-layout-valign-top\">\n</div>\n</div>\n<p>We measure the runtime for the train functions within each framework. The result of the train function is a trained model in both frameworks. In addition, we invoke the <code>rpart()</code> and <code>ranger()</code> functions to establish a baseline for the minimum achievable runtime. This allows us to not only assess the efficiency of the train functions in each framework but also to understand how they perform relative to the base packages.</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre># tidymodels train\nfit(tm_mod, formula, data = data)\n\n# mlr3 train\nlearner$train(task)</pre>\n</div>\n<p>When training an <code>rpart</code> model, <code>tidymodels</code> demonstrates superior speed, outperforming <code>mlr3</code> (Table 1). Notably, the <code>mlr3</code> package requires approximately twice the time compared to the baseline.</p>\n<p>A key observation from our results is the significant relative overhead when using a framework for <code>rpart</code> model training. Given that <code>rpart</code> inherently requires a shorter training time, the additional processing time introduced by the frameworks becomes more pronounced. This aspect highlights the trade-off between the convenience offered by these frameworks and their impact on runtime for quicker tasks.</p>\n<p>Conversely, when we shift our focus to training a <code>ranger</code> model, the scenario changes (Table 2). Here, the runtime performance of <code>ranger</code> is strikingly similar across both <code>tidymodels</code> and <code>mlr3</code>. This equality in execution time can be attributed to the inherently longer training duration required by <code>ranger</code> models. As a result, the relative overhead introduced by either framework becomes minimal, effectively diminishing in the face of the more time-intensive training process. This pattern suggests that for more complex or time-consuming tasks, the choice of framework may have a less significant impact on overall runtime performance.</p>\n<div>\n</div>\n<div class=\"quarto-layout-panel\" data-layout-ncol=\"2\">\n<div class=\"quarto-layout-row quarto-layout-valign-top\">\n<div class=\"cell quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<div class=\"cell anchored\" data-layout-align=\"center\" id=\"tbl-train-rpart\">\n<figure class=\"quarto-float quarto-float-tbl figure\">\n<figcaption class=\"table quarto-float-caption quarto-float-tbl\" id=\"tbl-train-rpart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nTable 1: Average runtime in milliseconds of training <code>rpart</code> depending on the framework.\n</figcaption>\n<div aria-describedby=\"tbl-train-rpart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<div class=\"cell-output-display\">\n<table class=\"cell table table-sm table-striped small\">\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Framework</th>\n<th style=\"text-align: right;\">LQ</th>\n<th style=\"text-align: right;\">Median</th>\n<th style=\"text-align: right;\">UQ</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">base</td>\n<td style=\"text-align: right;\">11</td>\n<td style=\"text-align: right;\">11</td>\n<td style=\"text-align: right;\">12</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">mlr3</td>\n<td style=\"text-align: right;\">23</td>\n<td style=\"text-align: right;\">23</td>\n<td style=\"text-align: right;\">24</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: right;\">18</td>\n<td style=\"text-align: right;\">18</td>\n<td style=\"text-align: right;\">19</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</figure>\n</div>\n</div>\n<div class=\"cell quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<div class=\"cell anchored\" data-layout-align=\"center\" id=\"tbl-train-ranger\">\n<figure class=\"quarto-float quarto-float-tbl figure\">\n<figcaption class=\"table quarto-float-caption quarto-float-tbl\" id=\"tbl-train-ranger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nTable 2: Average runtime in milliseconds of training <code>ranger</code> depending on the framework.\n</figcaption>\n<div aria-describedby=\"tbl-train-ranger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<div class=\"cell-output-display\">\n<table class=\"cell table table-sm table-striped small\">\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Framework</th>\n<th style=\"text-align: right;\">LQ</th>\n<th style=\"text-align: right;\">Median</th>\n<th style=\"text-align: right;\">UQ</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">base</td>\n<td style=\"text-align: right;\">286</td>\n<td style=\"text-align: right;\">322</td>\n<td style=\"text-align: right;\">347</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">mlr3</td>\n<td style=\"text-align: right;\">301</td>\n<td style=\"text-align: right;\">335</td>\n<td style=\"text-align: right;\">357</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: right;\">310</td>\n<td style=\"text-align: right;\">342</td>\n<td style=\"text-align: right;\">362</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"resample-sequential\">\n<h2 class=\"anchored\" data-anchor-id=\"resample-sequential\">Resample Sequential</h2>\n<p>We proceed to evaluate the runtime performance of the resampling functions within both frameworks, specifically under conditions without parallelization. This step involves the generation of resampling splits, including 3-fold, 6-fold, and 9-fold cross-validation. Additionally, we run a 100 times repeated 3-fold cross-validation.</p>\n<p>We generate the same resampling splits for both frameworks. This consistency is key to ensuring that any observed differences in runtime are attributable to the frameworks themselves, rather than variations in the resampling process.</p>\n<p>In our pursuit of a fair and balanced comparison, we address certain inherent differences between the two frameworks. Notably, <code>tidymodels</code> inherently includes scoring of the resampling results as part of its process. To align the comparison, we replicate this scoring step in <code>mlr3</code>, thus maintaining a level field for evaluation. Furthermore, <code>mlr3</code> inherently saves predictions during the resampling process. To match this, we activate the saving of the predictions in <code>tidymodels</code>.</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre># tidymodels resample\ncontrol = control_grid(save_pred = TRUE)\nmetrics = metric_set(accuracy)\n\ntm_wf =\n  workflow() %&gt;%\n  add_model(tm_mod) %&gt;%\n  add_formula(formula)\n\nfit_resamples(tm_wf, folds, metrics = metrics, control = control)\n\n# mlr3 resample\nmeasure = msr(\"classif.acc\")\n\nrr = resample(task, learner, resampling)\nrr$score(measure)</pre>\n</div>\n<p>When resampling the fast-fitting <code>rpart</code> model, <code>mlr3</code> demonstrates a notable edge in speed, as detailed in Table 3. In contrast, when it comes to resampling the more computationally intensive <code>ranger</code> models, the performance of <code>tidymodels</code> and <code>mlr3</code> converges closely (Table 4). This parity in performance is particularly noteworthy, considering the differing internal mechanisms and optimizations of <code>tidymodels</code> and <code>mlr3</code>. A consistent trend observed across both frameworks is a linear increase in runtime proportional to the number of folds in cross-validation (Figure 1).</p>\n<div>\n</div>\n<div class=\"quarto-layout-panel\" data-layout-ncol=\"2\">\n<div class=\"quarto-layout-row quarto-layout-valign-top\">\n<div class=\"cell quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<div class=\"cell anchored\" data-layout-align=\"center\" id=\"tbl-resample-sequential-rpart\">\n<figure class=\"quarto-float quarto-float-tbl figure\">\n<figcaption class=\"table quarto-float-caption quarto-float-tbl\" id=\"tbl-resample-sequential-rpart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nTable 3: Average runtime in milliseconds of <code>rpart</code> depending on the framework and resampling strategy.\n</figcaption>\n<div aria-describedby=\"tbl-resample-sequential-rpart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<div class=\"cell-output-display\">\n<table class=\"cell table table-sm table-striped small\">\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Framework</th>\n<th style=\"text-align: left;\">Resampling</th>\n<th style=\"text-align: right;\">LQ</th>\n<th style=\"text-align: right;\">Median</th>\n<th style=\"text-align: right;\">UQ</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">mlr3</td>\n<td style=\"text-align: left;\">cv3</td>\n<td style=\"text-align: right;\">188</td>\n<td style=\"text-align: right;\">196</td>\n<td style=\"text-align: right;\">210</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: left;\">cv3</td>\n<td style=\"text-align: right;\">233</td>\n<td style=\"text-align: right;\">242</td>\n<td style=\"text-align: right;\">257</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">mlr3</td>\n<td style=\"text-align: left;\">cv6</td>\n<td style=\"text-align: right;\">343</td>\n<td style=\"text-align: right;\">357</td>\n<td style=\"text-align: right;\">379</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: left;\">cv6</td>\n<td style=\"text-align: right;\">401</td>\n<td style=\"text-align: right;\">415</td>\n<td style=\"text-align: right;\">436</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">mlr3</td>\n<td style=\"text-align: left;\">cv9</td>\n<td style=\"text-align: right;\">500</td>\n<td style=\"text-align: right;\">520</td>\n<td style=\"text-align: right;\">548</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: left;\">cv9</td>\n<td style=\"text-align: right;\">568</td>\n<td style=\"text-align: right;\">588</td>\n<td style=\"text-align: right;\">616</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">mlr3</td>\n<td style=\"text-align: left;\">rcv100</td>\n<td style=\"text-align: right;\">15526</td>\n<td style=\"text-align: right;\">16023</td>\n<td style=\"text-align: right;\">16777</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: left;\">rcv100</td>\n<td style=\"text-align: right;\">16409</td>\n<td style=\"text-align: right;\">16876</td>\n<td style=\"text-align: right;\">17527</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</figure>\n</div>\n</div>\n<div class=\"cell quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<div class=\"cell anchored\" data-layout-align=\"center\" id=\"tbl-resample-sequential-ranger\">\n<figure class=\"quarto-float quarto-float-tbl figure\">\n<figcaption class=\"table quarto-float-caption quarto-float-tbl\" id=\"tbl-resample-sequential-ranger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nTable 4: Average runtime in milliseconds of <code>ranger</code> depending on the framework and resampling strategy.\n</figcaption>\n<div aria-describedby=\"tbl-resample-sequential-ranger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<div class=\"cell-output-display\">\n<table class=\"cell table table-sm table-striped small\">\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Framework</th>\n<th style=\"text-align: left;\">Resampling</th>\n<th style=\"text-align: right;\">LQ</th>\n<th style=\"text-align: right;\">Median</th>\n<th style=\"text-align: right;\">UQ</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">mlr3</td>\n<td style=\"text-align: left;\">cv3</td>\n<td style=\"text-align: right;\">923</td>\n<td style=\"text-align: right;\">1004</td>\n<td style=\"text-align: right;\">1062</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: left;\">cv3</td>\n<td style=\"text-align: right;\">916</td>\n<td style=\"text-align: right;\">981</td>\n<td style=\"text-align: right;\">1023</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">mlr3</td>\n<td style=\"text-align: left;\">cv6</td>\n<td style=\"text-align: right;\">1990</td>\n<td style=\"text-align: right;\">2159</td>\n<td style=\"text-align: right;\">2272</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: left;\">cv6</td>\n<td style=\"text-align: right;\">2089</td>\n<td style=\"text-align: right;\">2176</td>\n<td style=\"text-align: right;\">2239</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">mlr3</td>\n<td style=\"text-align: left;\">cv9</td>\n<td style=\"text-align: right;\">3074</td>\n<td style=\"text-align: right;\">3279</td>\n<td style=\"text-align: right;\">3441</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: left;\">cv9</td>\n<td style=\"text-align: right;\">3260</td>\n<td style=\"text-align: right;\">3373</td>\n<td style=\"text-align: right;\">3453</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">mlr3</td>\n<td style=\"text-align: left;\">rcv100</td>\n<td style=\"text-align: right;\">85909</td>\n<td style=\"text-align: right;\">88642</td>\n<td style=\"text-align: right;\">91381</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: left;\">rcv100</td>\n<td style=\"text-align: right;\">87828</td>\n<td style=\"text-align: right;\">88822</td>\n<td style=\"text-align: right;\">89843</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</figure>\n</div>\n</div>\n</div>\n</div>\n<div class=\"cell\" data-layout-align=\"center\">\n<div class=\"cell-output-display\">\n<div class=\"quarto-figure quarto-figure-center anchored\" data-fig-align=\"center\" id=\"fig-resample-sequential\" width=\"450\">\n<figure class=\"quarto-float quarto-float-fig figure\">\n<div aria-describedby=\"fig-resample-sequential-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-lazy-src=\"https://i0.wp.com/mlr-org.com/gallery/technical/2023-10-30-tidymodels/index_files/figure-html/fig-resample-sequential-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/mlr-org.com/gallery/technical/2023-10-30-tidymodels/index_files/figure-html/fig-resample-sequential-1.png?w=450&amp;ssl=1\"/></noscript>\n</div>\n<figcaption class=\"figure quarto-float-caption quarto-float-fig\" id=\"fig-resample-sequential-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nFigure 1: Average runtime, measured in milliseconds, for cross-validations using <code>rpart</code> (displayed on the left) and <code>ranger</code> (on the right). The comparison encompasses variations across different frameworks and the number of folds in the cross-validation.\n</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"resample-parallel\">\n<h2 class=\"anchored\" data-anchor-id=\"resample-parallel\">Resample Parallel</h2>\n<p>We conducted a second set of resampling function tests, this time incorporating parallelization to explore its impact on runtime efficiency. In this phase, we utilized <code>doFuture</code> and <code>doParallel</code> as the primary parallelization packages for tidymodels, recognizing their robust support and compatibility. Meanwhile, for <code>mlr3</code>, the <code>future</code> package was employed to facilitate parallel processing.</p>\n<p>Our findings, as presented in the respective tables (Table 5 and Table 6), reveal interesting dynamics about parallelization within the frameworks. When the number of folds in the resampling process is doubled, we observe only a marginal increase in the average runtime. This pattern suggests a significant overhead associated with initializing the parallel workers, a factor that becomes particularly influential in the overall efficiency of the parallelization process.</p>\n<p>In the case of the <code>rpart</code> model, the parallelization overhead appears to outweigh the potential speedup benefits, as illustrated in the left section of Figure 2. This result indicates that for less complex models like <code>rpart</code>, where individual training times are relatively short, the initialization cost of parallel workers may not be sufficiently offset by the reduced processing time per fold.</p>\n<p>Conversely, for the <code>ranger</code> model, the utilization of parallelization demonstrates a clear advantage over the sequential version, as evidenced in the right section of Figure 2. This finding underscores that for more computationally intensive models like <code>ranger</code>, which have longer individual training times, the benefits of parallel processing significantly overcome the initial overhead of worker setup. This differentiation highlights the importance of considering the complexity and inherent processing time of models when deciding to implement parallelization strategies in these frameworks.</p>\n<div>\n</div>\n<div class=\"quarto-layout-panel\" data-layout-ncol=\"2\">\n<div class=\"quarto-layout-row quarto-layout-valign-top\">\n<div class=\"cell quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<div class=\"cell anchored\" data-layout-align=\"center\" id=\"tbl-resample-parallel-mlr3-future-rpart\">\n<figure class=\"quarto-float quarto-float-tbl figure\">\n<figcaption class=\"table quarto-float-caption quarto-float-tbl\" id=\"tbl-resample-parallel-mlr3-future-rpart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nTable 5: Average runtime in milliseconds of <code>mlr3</code> with <code>future</code> and <code>rpart</code> depending on the resampling strategy.\n</figcaption>\n<div aria-describedby=\"tbl-resample-parallel-mlr3-future-rpart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<div class=\"cell-output-display\">\n<table class=\"cell table table-sm table-striped small\">\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Resampling</th>\n<th style=\"text-align: right;\">LQ</th>\n<th style=\"text-align: right;\">Median</th>\n<th style=\"text-align: right;\">UQ</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">cv3</td>\n<td style=\"text-align: right;\">625</td>\n<td style=\"text-align: right;\">655</td>\n<td style=\"text-align: right;\">703</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">cv6</td>\n<td style=\"text-align: right;\">738</td>\n<td style=\"text-align: right;\">771</td>\n<td style=\"text-align: right;\">817</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">cv9</td>\n<td style=\"text-align: right;\">831</td>\n<td style=\"text-align: right;\">875</td>\n<td style=\"text-align: right;\">923</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">rcv100</td>\n<td style=\"text-align: right;\">8620</td>\n<td style=\"text-align: right;\">9043</td>\n<td style=\"text-align: right;\">9532</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</figure>\n</div>\n</div>\n<div class=\"cell quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<div class=\"cell anchored\" data-layout-align=\"center\" id=\"tbl-resample-parallel-mlr3-future-ranger\">\n<figure class=\"quarto-float quarto-float-tbl figure\">\n<figcaption class=\"table quarto-float-caption quarto-float-tbl\" id=\"tbl-resample-parallel-mlr3-future-ranger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nTable 6: Average runtime in milliseconds of <code>mlr3</code> with <code>future</code> and <code>ranger</code> depending on the resampling strategy.\n</figcaption>\n<div aria-describedby=\"tbl-resample-parallel-mlr3-future-ranger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<div class=\"cell-output-display\">\n<table class=\"cell table table-sm table-striped small\">\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Resampling</th>\n<th style=\"text-align: right;\">LQ</th>\n<th style=\"text-align: right;\">Median</th>\n<th style=\"text-align: right;\">UQ</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">cv3</td>\n<td style=\"text-align: right;\">836</td>\n<td style=\"text-align: right;\">884</td>\n<td style=\"text-align: right;\">943</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">cv6</td>\n<td style=\"text-align: right;\">1200</td>\n<td style=\"text-align: right;\">1249</td>\n<td style=\"text-align: right;\">1314</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">cv9</td>\n<td style=\"text-align: right;\">1577</td>\n<td style=\"text-align: right;\">1634</td>\n<td style=\"text-align: right;\">1706</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">rcv100</td>\n<td style=\"text-align: right;\">32047</td>\n<td style=\"text-align: right;\">32483</td>\n<td style=\"text-align: right;\">33022</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</figure>\n</div>\n</div>\n</div>\n</div>\n<p>When paired with doFuture, <code>tidymodels</code> exhibits significantly slower runtime compared to the <code>mlr3</code> package utilizing <code>future</code> (Table 7 and Table 8). We observed that <code>tidymodels</code> exports more data to the parallel workers, which notably exceeds that of <code>mlr3</code>. This substantial difference in data export could plausibly account for the observed slower runtime when using <code>tidymodels</code> on small tasks.</p>\n<div>\n</div>\n<div class=\"quarto-layout-panel\" data-layout-ncol=\"2\">\n<div class=\"quarto-layout-row quarto-layout-valign-top\">\n<div class=\"cell quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<div class=\"cell anchored\" data-layout-align=\"center\" id=\"tbl-resample-parallel-tidymodels-future-rpart\">\n<figure class=\"quarto-float quarto-float-tbl figure\">\n<figcaption class=\"table quarto-float-caption quarto-float-tbl\" id=\"tbl-resample-parallel-tidymodels-future-rpart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nTable 7: Average runtime in milliseconds of <code>tidymodels</code> with <code>doFuture</code> and <code>rpart</code> depending on the resampling strategy.\n</figcaption>\n<div aria-describedby=\"tbl-resample-parallel-tidymodels-future-rpart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<div class=\"cell-output-display\">\n<table class=\"cell table table-sm table-striped small\">\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Resampling</th>\n<th style=\"text-align: right;\">LQ</th>\n<th style=\"text-align: right;\">Median</th>\n<th style=\"text-align: right;\">UQ</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">cv3</td>\n<td style=\"text-align: right;\">2778</td>\n<td style=\"text-align: right;\">2817</td>\n<td style=\"text-align: right;\">3019</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">cv6</td>\n<td style=\"text-align: right;\">2808</td>\n<td style=\"text-align: right;\">2856</td>\n<td style=\"text-align: right;\">3033</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">cv9</td>\n<td style=\"text-align: right;\">2935</td>\n<td style=\"text-align: right;\">2975</td>\n<td style=\"text-align: right;\">3170</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">rcv100</td>\n<td style=\"text-align: right;\">9154</td>\n<td style=\"text-align: right;\">9302</td>\n<td style=\"text-align: right;\">9489</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</figure>\n</div>\n</div>\n<div class=\"cell quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<div class=\"cell anchored\" data-layout-align=\"center\" id=\"tbl-resample-parallel-tidymodels-future-ranger\">\n<figure class=\"quarto-float quarto-float-tbl figure\">\n<figcaption class=\"table quarto-float-caption quarto-float-tbl\" id=\"tbl-resample-parallel-tidymodels-future-ranger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nTable 8: Average runtime in milliseconds of <code>tidymodels</code> with <code>doFuture</code> and <code>ranger</code> depending on the resampling strategy.\n</figcaption>\n<div aria-describedby=\"tbl-resample-parallel-tidymodels-future-ranger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<div class=\"cell-output-display\">\n<table class=\"cell table table-sm table-striped small\">\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Resampling</th>\n<th style=\"text-align: right;\">LQ</th>\n<th style=\"text-align: right;\">Median</th>\n<th style=\"text-align: right;\">UQ</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">cv3</td>\n<td style=\"text-align: right;\">2982</td>\n<td style=\"text-align: right;\">3046</td>\n<td style=\"text-align: right;\">3234</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">cv6</td>\n<td style=\"text-align: right;\">3282</td>\n<td style=\"text-align: right;\">3366</td>\n<td style=\"text-align: right;\">3543</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">cv9</td>\n<td style=\"text-align: right;\">3568</td>\n<td style=\"text-align: right;\">3695</td>\n<td style=\"text-align: right;\">3869</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">rcv100</td>\n<td style=\"text-align: right;\">27546</td>\n<td style=\"text-align: right;\">27843</td>\n<td style=\"text-align: right;\">28166</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</figure>\n</div>\n</div>\n</div>\n</div>\n<p>The utilization of the <code>doParallel</code> package demonstrates a notable improvement in handling smaller resampling tasks. In these scenarios, the resampling process consistently outperforms the <code>mlr3</code> framework in terms of speed. However, it’s important to note that even with this enhanced performance, the <code>doParallel</code> package does not always surpass the efficiency of the sequential version, especially when working with the <code>rpart</code> model. This specific observation is illustrated in the left section of Figure 2.</p>\n<div>\n</div>\n<div class=\"quarto-layout-panel\" data-layout-ncol=\"2\">\n<div class=\"quarto-layout-row quarto-layout-valign-top\">\n<div class=\"cell quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<div class=\"cell anchored\" data-layout-align=\"center\" id=\"tbl-resample-parallel-tidymodels-parallel-rpart\">\n<figure class=\"quarto-float quarto-float-tbl figure\">\n<figcaption class=\"table quarto-float-caption quarto-float-tbl\" id=\"tbl-resample-parallel-tidymodels-parallel-rpart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nTable 9: Average runtime in milliseconds of <code>tidymodels</code> with <code>doParallel</code> and <code>rpart</code> depending on the resampling strategy.\n</figcaption>\n<div aria-describedby=\"tbl-resample-parallel-tidymodels-parallel-rpart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<div class=\"cell-output-display\">\n<table class=\"cell table table-sm table-striped small\">\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Resampling</th>\n<th style=\"text-align: right;\">LQ</th>\n<th style=\"text-align: right;\">Median</th>\n<th style=\"text-align: right;\">UQ</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">cv3</td>\n<td style=\"text-align: right;\">557</td>\n<td style=\"text-align: right;\">649</td>\n<td style=\"text-align: right;\">863</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">cv6</td>\n<td style=\"text-align: right;\">602</td>\n<td style=\"text-align: right;\">714</td>\n<td style=\"text-align: right;\">910</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">cv9</td>\n<td style=\"text-align: right;\">661</td>\n<td style=\"text-align: right;\">772</td>\n<td style=\"text-align: right;\">968</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">rcv100</td>\n<td style=\"text-align: right;\">10609</td>\n<td style=\"text-align: right;\">10820</td>\n<td style=\"text-align: right;\">11071</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</figure>\n</div>\n</div>\n<div class=\"cell quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<div class=\"cell anchored\" data-layout-align=\"center\" id=\"tbl-resample-parallel-tidymodels-parallel-ranger\">\n<figure class=\"quarto-float quarto-float-tbl figure\">\n<figcaption class=\"table quarto-float-caption quarto-float-tbl\" id=\"tbl-resample-parallel-tidymodels-parallel-ranger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nTable 10: Average runtime in milliseconds of <code>tidymodels</code> with <code>doParallel</code> and <code>ranger</code> depending on the resampling strategy.\n</figcaption>\n<div aria-describedby=\"tbl-resample-parallel-tidymodels-parallel-ranger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<div class=\"cell-output-display\">\n<table class=\"cell table table-sm table-striped small\">\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Resampling</th>\n<th style=\"text-align: right;\">LQ</th>\n<th style=\"text-align: right;\">Median</th>\n<th style=\"text-align: right;\">UQ</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">cv3</td>\n<td style=\"text-align: right;\">684</td>\n<td style=\"text-align: right;\">756</td>\n<td style=\"text-align: right;\">948</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">cv6</td>\n<td style=\"text-align: right;\">1007</td>\n<td style=\"text-align: right;\">1099</td>\n<td style=\"text-align: right;\">1272</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">cv9</td>\n<td style=\"text-align: right;\">1360</td>\n<td style=\"text-align: right;\">1461</td>\n<td style=\"text-align: right;\">1625</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">rcv100</td>\n<td style=\"text-align: right;\">31205</td>\n<td style=\"text-align: right;\">31486</td>\n<td style=\"text-align: right;\">31793</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</figure>\n</div>\n</div>\n</div>\n</div>\n<div class=\"cell\" data-layout-align=\"center\">\n<div class=\"cell-output-display\">\n<div class=\"quarto-figure quarto-figure-center anchored\" data-fig-align=\"center\" id=\"fig-resample-parallel\" width=\"450\">\n<figure class=\"quarto-float quarto-float-fig figure\">\n<div aria-describedby=\"fig-resample-parallel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-lazy-src=\"https://i2.wp.com/mlr-org.com/gallery/technical/2023-10-30-tidymodels/index_files/figure-html/fig-resample-parallel-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/mlr-org.com/gallery/technical/2023-10-30-tidymodels/index_files/figure-html/fig-resample-parallel-1.png?w=450&amp;ssl=1\"/></noscript>\n</div>\n<figcaption class=\"figure quarto-float-caption quarto-float-fig\" id=\"fig-resample-parallel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nFigure 2: Average runtime, measured in milliseconds, for cross-validations using <code>rpart</code> (displayed on the left) and <code>ranger</code> (on the right). The comparison encompasses variations across different frameworks, the number of folds in the cross-validation, and the implementation of parallelization.\n</figcaption>\n</figure>\n</div>\n</div>\n</div>\n<p>In the context of repeated cross-validation, our findings underscore the efficacy of parallelization (Figure 3). Across all frameworks tested, the adoption of parallel processing techniques yields a significant increase in speed. This enhancement is particularly noticeable in larger resampling tasks, where the demands on computational resources are more substantial.</p>\n<p>Interestingly, within these more extensive resampling scenarios, the <code>doFuture</code> package emerges as a more efficient option compared to <code>doParallel</code>. This distinction is important, as it highlights the relative strengths of different parallelization packages under varying workload conditions. While <code>doParallel</code> shows proficiency in smaller tasks, <code>doFuture</code> demonstrates its capability to handle larger, more complex resampling processes with greater speed and efficiency.</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<div class=\"cell-output-display\">\n<div class=\"quarto-figure quarto-figure-center anchored\" data-fig-align=\"center\" id=\"fig-resample-parallel-2\" width=\"450\">\n<figure class=\"quarto-float quarto-float-fig figure\">\n<div aria-describedby=\"fig-resample-parallel-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-lazy-src=\"https://i0.wp.com/mlr-org.com/gallery/technical/2023-10-30-tidymodels/index_files/figure-html/fig-resample-parallel-2-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/mlr-org.com/gallery/technical/2023-10-30-tidymodels/index_files/figure-html/fig-resample-parallel-2-1.png?w=450&amp;ssl=1\"/></noscript>\n</div>\n<figcaption class=\"figure quarto-float-caption quarto-float-fig\" id=\"fig-resample-parallel-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nFigure 3: Average runtime, measured in seconds, of a 100 times repeated 3-fold cross-validation using <code>rpart</code> (displayed on the left) and <code>ranger</code> (on the right). The comparison encompasses variations across different frameworks and the implementation of parallelization.\n</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"tune-sequential\">\n<h2 class=\"anchored\" data-anchor-id=\"tune-sequential\">Tune Sequential</h2>\n<p>We then shift our focus to assessing the runtime performance of the tuning functions. In this phase, the <code>tidymodels</code> package is utilized to evaluate a predefined grid, comprising a specific set of hyperparameter configurations. To ensure a balanced and comparable analysis, we employ the <code>\"design_points\"</code> tuner from the <code>mlr3tuning</code> package. This approach allows us to evaluate the same grid within the <code>mlr3</code> framework, maintaining consistency across both platforms. The grid used for this comparison contains 200 hyperparameter configurations each, for both the <code>rpart</code> and <code>ranger</code> models. This approach helps us to understand how each framework handles the optimization of model hyperparameters, a key aspect of building effective and efficient machine learning models.</p>\n<pre># tidymodels\ntm_mod = decision_tree(\n  cost_complexity = tune()) %&gt;%\n  set_engine(\"rpart\",\n    xval = 0) %&gt;%\n  set_mode(\"classification\")\n\ntm_design = data.table(\n  cost_complexity = seq(0.1, 0.2, length.out = 200))\n\n# mlr3\nlearner = lrn(\"classif.rpart\",\n  xval = 0,\n  cp = to_tune())\n\nmlr3_design = data.table(\n  cp = seq(0.1, 0.2, length.out = 200))\n# tidymodels\ntm_mod = rand_forest(\n  trees = tune()) %&gt;%\n  set_engine(\"ranger\",\n    num.threads = 1L,\n    seed = 1) %&gt;%\n  set_mode(\"classification\")\n\ntm_design = data.table(\n  trees = seq(1000, 1199))\n\n# mlr3\nlearner = lrn(\"classif.ranger\",\n  num.trees = to_tune(1, 10000),\n  num.threads = 1L,\n  seed = 1,\n  verbose = FALSE,\n  predict_type = \"prob\")\n\nmlr3_design = data.table(\n  num.trees = seq(1000, 1199))</pre>\n<div class=\"quarto-layout-panel\" data-layout-ncol=\"2\">\n<div class=\"quarto-layout-row quarto-layout-valign-top\">\n</div>\n</div>\n<p>We measure the runtime of the tune functions within each framework. Both the <code>tidymodels</code> and <code>mlr3</code> frameworks are tasked with identifying the optimal hyperparameter configuration.</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre># tidymodels tune\ntune::tune_grid(\n  tm_wf,\n  resamples = resamples,\n  grid = design,\n  metrics = metrics)\n\n# mlr3 tune\ntuner = tnr(\"design_points\", design = design, batch_size = nrow(design))\nmlr3tuning::tune(\n  tuner = tuner,\n  task = task,\n  learner = learner,\n  resampling = resampling,\n  measures = measure,\n  store_benchmark_result = FALSE)</pre>\n</div>\n<p>In our sequential tuning tests, <code>mlr3</code> demonstrates a notable advantage in terms of speed. This finding is clearly evidenced in our results, as shown in Table Table 11 for the <code>rpart</code> model and Table Table 12 for the <code>ranger</code> model. The faster performance of <code>mlr3</code> in these sequential runs highlights its efficiency in handling the tuning process without parallelization.</p>\n<div>\n</div>\n<div class=\"quarto-layout-panel\" data-layout-ncol=\"2\">\n<div class=\"quarto-layout-row quarto-layout-valign-top\">\n<div class=\"cell quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<div class=\"cell anchored\" data-layout-align=\"center\" id=\"tbl-tune-sequential-rpart\">\n<figure class=\"quarto-float quarto-float-tbl figure\">\n<figcaption class=\"table quarto-float-caption quarto-float-tbl\" id=\"tbl-tune-sequential-rpart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nTable 11: Average runtime in seconds of tuning 200 points of <code>rpart</code> depending on the framework.\n</figcaption>\n<div aria-describedby=\"tbl-tune-sequential-rpart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<div class=\"cell-output-display\">\n<table class=\"cell table table-sm table-striped small\">\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Framework</th>\n<th style=\"text-align: right;\">LQ</th>\n<th style=\"text-align: right;\">Median</th>\n<th style=\"text-align: right;\">UQ</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">mlr3</td>\n<td style=\"text-align: right;\">27</td>\n<td style=\"text-align: right;\">27</td>\n<td style=\"text-align: right;\">28</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: right;\">37</td>\n<td style=\"text-align: right;\">37</td>\n<td style=\"text-align: right;\">39</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</figure>\n</div>\n</div>\n<div class=\"cell quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<div class=\"cell anchored\" data-layout-align=\"center\" id=\"tbl-tune-sequential-ranger\">\n<figure class=\"quarto-float quarto-float-tbl figure\">\n<figcaption class=\"table quarto-float-caption quarto-float-tbl\" id=\"tbl-tune-sequential-ranger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nTable 12: Average runtime in seconds of tuning 200 points of <code>ranger</code> depending on the framework.\n</figcaption>\n<div aria-describedby=\"tbl-tune-sequential-ranger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<div class=\"cell-output-display\">\n<table class=\"cell table table-sm table-striped small\">\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Framework</th>\n<th style=\"text-align: right;\">LQ</th>\n<th style=\"text-align: right;\">Median</th>\n<th style=\"text-align: right;\">UQ</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">mlr3</td>\n<td style=\"text-align: right;\">167</td>\n<td style=\"text-align: right;\">171</td>\n<td style=\"text-align: right;\">175</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: right;\">194</td>\n<td style=\"text-align: right;\">195</td>\n<td style=\"text-align: right;\">196</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level2\" id=\"tune-parallel\">\n<h2 class=\"anchored\" data-anchor-id=\"tune-parallel\">Tune Parallel</h2>\n<p>Concluding our analysis, we proceed to evaluate the runtime performance of the tune functions, this time implementing parallelization to enhance efficiency. For these runs, parallelization is executed on 3 cores.</p>\n<p>In the case of <code>mlr3</code>, we opt for the largest possible chunk size. This strategic choice means that all points within the tuning grid are sent to the workers in a single batch, effectively minimizing the overhead typically associated with parallelization. This approach is crucial in reducing the time spent in distributing tasks across multiple cores, thereby streamlining the tuning process. On the other hand, the <code>tidymodels</code> package also operates with the same chunk size, but this setting is determined and managed internally within the framework.</p>\n<p>By conducting these parallelization tests, we aim to provide a deeper understanding of how each framework handles the distribution and management of computational tasks during the tuning process, particularly in a parallel computing environment. This final set of measurements is important in painting a complete picture of the runtime performance of the tune functions across both <code>tidymodels</code> and <code>mlr3</code> under different operational settings.</p>\n<div class=\"cell\" data-layout-align=\"center\">\n<pre>options(\"mlr3.exec_chunk_size\" = 200)</pre>\n</div>\n<p>Our analysis of the parallelized tuning functions reveals that the runtimes for <code>mlr3</code> and <code>tidymodels</code> are remarkably similar. However, subtle differences emerge upon closer inspection. For instance, the <code>mlr3</code> package exhibits a slightly faster performance when tuning the <code>rpart</code> model, as indicated in Table 13. In contrast, it falls marginally behind <code>tidymodels</code> in tuning the <code>ranger</code> model, as shown in Table 14.</p>\n<p>Interestingly, when considering the specific context of a 3-fold cross-validation, the <code>doParallel</code> package outperforms <code>doFuture</code> in terms of speed, as demonstrated in Figure 4. This outcome suggests that the choice of parallelization package can have a significant impact on tuning efficiency, particularly in scenarios with a smaller number of folds.</p>\n<p>A key takeaway from our study is the clear benefit of enabling parallelization, regardless of the chosen framework-backend combination. Activating parallelization consistently enhances performance, making it a highly recommended strategy for tuning machine learning models, especially in tasks involving extensive hyperparameter exploration or larger datasets. This conclusion underscores the value of parallel processing in modern machine learning workflows, offering a practical solution for accelerating model tuning across various computational settings.</p>\n<div>\n</div>\n<div class=\"quarto-layout-panel\" data-layout-ncol=\"2\">\n<div class=\"quarto-layout-row quarto-layout-valign-top\">\n<div class=\"cell quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<div class=\"cell anchored\" data-layout-align=\"center\" id=\"tbl-tune-parallel-mlr3-future-rpart\">\n<figure class=\"quarto-float quarto-float-tbl figure\">\n<figcaption class=\"table quarto-float-caption quarto-float-tbl\" id=\"tbl-tune-parallel-mlr3-future-rpart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nTable 13: Average runtime in seconds of tuning 200 points of <code>rpart</code> depending on the framework.\n</figcaption>\n<div aria-describedby=\"tbl-tune-parallel-mlr3-future-rpart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<div class=\"cell-output-display\">\n<table class=\"cell table table-sm table-striped small\">\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Framework</th>\n<th style=\"text-align: left;\">Backend</th>\n<th style=\"text-align: right;\">LQ</th>\n<th style=\"text-align: right;\">Median</th>\n<th style=\"text-align: right;\">UQ</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">mlr3</td>\n<td style=\"text-align: left;\">future</td>\n<td style=\"text-align: right;\">11</td>\n<td style=\"text-align: right;\">12</td>\n<td style=\"text-align: right;\">12</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: left;\">doFuture</td>\n<td style=\"text-align: right;\">17</td>\n<td style=\"text-align: right;\">17</td>\n<td style=\"text-align: right;\">17</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: left;\">doParallel</td>\n<td style=\"text-align: right;\">13</td>\n<td style=\"text-align: right;\">13</td>\n<td style=\"text-align: right;\">13</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</figure>\n</div>\n</div>\n<div class=\"cell quarto-layout-cell\" style=\"flex-basis: 50.0%;justify-content: center;\">\n<div class=\"cell anchored\" data-layout-align=\"center\" id=\"tbl-tune-parallel-mlr3-future-ranger\">\n<figure class=\"quarto-float quarto-float-tbl figure\">\n<figcaption class=\"table quarto-float-caption quarto-float-tbl\" id=\"tbl-tune-parallel-mlr3-future-ranger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nTable 14: Average runtime in seconds of tuning 200 points of <code>ranger</code> depending on the framework.\n</figcaption>\n<div aria-describedby=\"tbl-tune-parallel-mlr3-future-ranger-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<div class=\"cell-output-display\">\n<table class=\"cell table table-sm table-striped small\">\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Framework</th>\n<th style=\"text-align: left;\">Backend</th>\n<th style=\"text-align: right;\">LQ</th>\n<th style=\"text-align: right;\">Median</th>\n<th style=\"text-align: right;\">UQ</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">mlr3</td>\n<td style=\"text-align: left;\">future</td>\n<td style=\"text-align: right;\">54</td>\n<td style=\"text-align: right;\">55</td>\n<td style=\"text-align: right;\">55</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: left;\">doFuture</td>\n<td style=\"text-align: right;\">58</td>\n<td style=\"text-align: right;\">58</td>\n<td style=\"text-align: right;\">59</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">tidymodels</td>\n<td style=\"text-align: left;\">doParallel</td>\n<td style=\"text-align: right;\">54</td>\n<td style=\"text-align: right;\">54</td>\n<td style=\"text-align: right;\">55</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</figure>\n</div>\n</div>\n</div>\n</div>\n<div class=\"cell\" data-layout-align=\"center\">\n<div class=\"cell-output-display\">\n<div class=\"quarto-figure quarto-figure-center anchored\" data-fig-align=\"center\" id=\"fig-tune-parallel\" width=\"450\">\n<figure class=\"quarto-float quarto-float-fig figure\">\n<div aria-describedby=\"fig-tune-parallel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\n<img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-lazy-src=\"https://i1.wp.com/mlr-org.com/gallery/technical/2023-10-30-tidymodels/index_files/figure-html/fig-tune-parallel-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid quarto-figure quarto-figure-center figure-img\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/mlr-org.com/gallery/technical/2023-10-30-tidymodels/index_files/figure-html/fig-tune-parallel-1.png?w=450&amp;ssl=1\"/></noscript>\n</div>\n<figcaption class=\"figure quarto-float-caption quarto-float-fig\" id=\"fig-tune-parallel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca\">\nFigure 4: Average runtime, measured in seconds, of a tuning 200 hyperparameter configurations of <code>rpart</code> (displayed on the left) and <code>ranger</code> (on the right). The comparison encompasses variations across different frameworks and the implementation of parallelization.\n</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</section>\n</section>\n<section class=\"level1\" id=\"conclusion\">\n<h1>Conclusion</h1>\n<p>Our analysis reveals that both <code>tidymodels</code> and <code>mlr3</code> exhibit comparable runtimes across key processes such as training, resampling, and tuning, each displaying its own set of strengths and efficiencies.</p>\n<p>A notable observation is the relative overhead associated with using either framework, particularly when working with fast-fitting models like <code>rpart</code>. In these cases, the additional processing time introduced by the frameworks is more pronounced due to the inherently short training time of <code>rpart</code> models. This results in a higher relative overhead, reflecting the trade-offs between the convenience of a comprehensive framework and the directness of more basic approaches.</p>\n<p>Conversely, when dealing with slower-fitting models such as <code>ranger</code>, the scenario shifts. For these more time-intensive models, the relative overhead introduced by the frameworks diminishes significantly. In such instances, the extended training times of the models absorb much of the frameworks’ inherent overhead, rendering it relatively negligible.</p>\n<p>In summary, while there is no outright winner in terms of overall performance, the decision to use <code>tidymodels</code> or <code>mlr3</code> should be informed by the specific requirements of the task at hand.</p>\n</section>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://mlr-org.com/gallery/technical/2023-10-30-tidymodels/\"> mlr-org</a></strong>.</div>\n<hr>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</hr></div> </div>\n</article>",
      "main_text": "Analyzing the Runtime Performance of tidymodels and mlr3\nPosted on\nOctober 29, 2023\nby\nMarc Becker\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nmlr-org\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nScope\nIn the realm of data science, machine learning frameworks play an important role in streamlining and accelerating the development of analytical workflows. Among these,\ntidymodels\nand\nmlr3\nstand out as prominent tools within the R community. They provide a unified interface for data preprocessing, model training, resampling and tuning. The streamlined and accelerated development process, while efficient, typically results in a trade-off concerning runtime performance. This article undertakes a detailed comparison of the runtime efficiency of\ntidymodels\nand\nmlr3\n, focusing on their performance in training, resampling, and tuning machine learning models. Specifically, we assess the time efficiency of these frameworks in running the\nrpart::rpart()\nand\nranger::ranger()\nmodels, using the\nSonar\ndataset as a test case. Additionally, the study delves into analyzing the runtime overhead of these frameworks by comparing their performance against training the models without a framework. Through this comparative analysis, the article aims to provide valuable insights into the operational trade-offs of using these advanced machine learning frameworks in practical data science applications.\nSetup\nWe employ the\nmicrobenchmark\npackage to measure the time required for training, resampling, and tuning models. This benchmarking process is applied to the\nSonar\ndataset using the\nrpart\nand\nranger\nalgorithms.\nlibrary(\"mlr3verse\")\nlibrary(\"tidymodels\")\nlibrary(\"microbenchmark\")\n\ntask = tsk(\"sonar\")\ndata = task$data()\nformula = Class ~ .\nTo ensure the robustness of our results, each function call within the benchmark is executed 100 times in a randomized sequence. The microbenchmark package then provides us with detailed insights, including the median, lower quartile, and upper quartile of the runtimes. To further enhance the reliability of our findings, we execute the benchmark on a cluster. Each run of\nmicrobenchmark\nis repeated 100 times, with different seeds applied for each iteration. Resulting in a total of 10,000 function calls of each command. The computing environment for each worker in the cluster consists of 3 cores and 12 GB of RAM. For transparency and reproducibility, the examples of the code used for this experiment are provided as snippets in the article. The complete code, along with all details of the experiment, is available in our public repository,\nmlr-org/mlr-benchmark\n.\nIt’s important to note that our cluster setup is not specifically optimized for single-core performance. Consequently, executing the same benchmark on a local machine with might yield faster results.\nBenchmark\nTrain the Models\nOur benchmark starts with the fundamental task of model training. To facilitate a direct comparison, we have structured our presentation into two distinct segments. On the left, we demonstrate the initialization of the\nrpart\nmodel, employing both\nmlr3\nand\ntidymodels\nframeworks. The\nrpart\nmodel is a decision tree classifier, which is a simple and fast-fitting algorithm for classification tasks. Simultaneously, on the right, we turn our attention to the initialization of the\nranger\nmodel, known for its efficient implementation of the random forest algorithm. Our aim is to mirror the configuration as closely as possible across both frameworks, maintaining consistency in parameters and settings.\n# tidymodels\ntm_mod = decision_tree() %>%\n  set_engine(\"rpart\",\n    xval = 0L) %>%\n  set_mode(\"classification\")\n\n# mlr3\nlearner = lrn(\"classif.rpart\",\n  xval = 0L)\n# tidymodels\ntm_mod = rand_forest(trees = 1000L) %>%\n  set_engine(\"ranger\",\n    num.threads = 1L,\n    seed = 1) %>%\n  set_mode(\"classification\")\n\n# mlr3\nlearner = lrn(\"classif.ranger\",\n  num.trees = 1000L,\n  num.threads = 1L,\n  seed = 1,\n  verbose = FALSE,\n  predict_type = \"prob\")\nWe measure the runtime for the train functions within each framework. The result of the train function is a trained model in both frameworks. In addition, we invoke the\nrpart()\nand\nranger()\nfunctions to establish a baseline for the minimum achievable runtime. This allows us to not only assess the efficiency of the train functions in each framework but also to understand how they perform relative to the base packages.\n# tidymodels train\nfit(tm_mod, formula, data = data)\n\n# mlr3 train\nlearner$train(task)\nWhen training an\nrpart\nmodel,\ntidymodels\ndemonstrates superior speed, outperforming\nmlr3\n(Table 1). Notably, the\nmlr3\npackage requires approximately twice the time compared to the baseline.\nA key observation from our results is the significant relative overhead when using a framework for\nrpart\nmodel training. Given that\nrpart\ninherently requires a shorter training time, the additional processing time introduced by the frameworks becomes more pronounced. This aspect highlights the trade-off between the convenience offered by these frameworks and their impact on runtime for quicker tasks.\nConversely, when we shift our focus to training a\nranger\nmodel, the scenario changes (Table 2). Here, the runtime performance of\nranger\nis strikingly similar across both\ntidymodels\nand\nmlr3\n. This equality in execution time can be attributed to the inherently longer training duration required by\nranger\nmodels. As a result, the relative overhead introduced by either framework becomes minimal, effectively diminishing in the face of the more time-intensive training process. This pattern suggests that for more complex or time-consuming tasks, the choice of framework may have a less significant impact on overall runtime performance.\nTable 1: Average runtime in milliseconds of training\nrpart\ndepending on the framework.\nFramework\nLQ\nMedian\nUQ\nbase\n11\n11\n12\nmlr3\n23\n23\n24\ntidymodels\n18\n18\n19\nTable 2: Average runtime in milliseconds of training\nranger\ndepending on the framework.\nFramework\nLQ\nMedian\nUQ\nbase\n286\n322\n347\nmlr3\n301\n335\n357\ntidymodels\n310\n342\n362\nResample Sequential\nWe proceed to evaluate the runtime performance of the resampling functions within both frameworks, specifically under conditions without parallelization. This step involves the generation of resampling splits, including 3-fold, 6-fold, and 9-fold cross-validation. Additionally, we run a 100 times repeated 3-fold cross-validation.\nWe generate the same resampling splits for both frameworks. This consistency is key to ensuring that any observed differences in runtime are attributable to the frameworks themselves, rather than variations in the resampling process.\nIn our pursuit of a fair and balanced comparison, we address certain inherent differences between the two frameworks. Notably,\ntidymodels\ninherently includes scoring of the resampling results as part of its process. To align the comparison, we replicate this scoring step in\nmlr3\n, thus maintaining a level field for evaluation. Furthermore,\nmlr3\ninherently saves predictions during the resampling process. To match this, we activate the saving of the predictions in\ntidymodels\n.\n# tidymodels resample\ncontrol = control_grid(save_pred = TRUE)\nmetrics = metric_set(accuracy)\n\ntm_wf =\n  workflow() %>%\n  add_model(tm_mod) %>%\n  add_formula(formula)\n\nfit_resamples(tm_wf, folds, metrics = metrics, control = control)\n\n# mlr3 resample\nmeasure = msr(\"classif.acc\")\n\nrr = resample(task, learner, resampling)\nrr$score(measure)\nWhen resampling the fast-fitting\nrpart\nmodel,\nmlr3\ndemonstrates a notable edge in speed, as detailed in Table 3. In contrast, when it comes to resampling the more computationally intensive\nranger\nmodels, the performance of\ntidymodels\nand\nmlr3\nconverges closely (Table 4). This parity in performance is particularly noteworthy, considering the differing internal mechanisms and optimizations of\ntidymodels\nand\nmlr3\n. A consistent trend observed across both frameworks is a linear increase in runtime proportional to the number of folds in cross-validation (Figure 1).\nTable 3: Average runtime in milliseconds of\nrpart\ndepending on the framework and resampling strategy.\nFramework\nResampling\nLQ\nMedian\nUQ\nmlr3\ncv3\n188\n196\n210\ntidymodels\ncv3\n233\n242\n257\nmlr3\ncv6\n343\n357\n379\ntidymodels\ncv6\n401\n415\n436\nmlr3\ncv9\n500\n520\n548\ntidymodels\ncv9\n568\n588\n616\nmlr3\nrcv100\n15526\n16023\n16777\ntidymodels\nrcv100\n16409\n16876\n17527\nTable 4: Average runtime in milliseconds of\nranger\ndepending on the framework and resampling strategy.\nFramework\nResampling\nLQ\nMedian\nUQ\nmlr3\ncv3\n923\n1004\n1062\ntidymodels\ncv3\n916\n981\n1023\nmlr3\ncv6\n1990\n2159\n2272\ntidymodels\ncv6\n2089\n2176\n2239\nmlr3\ncv9\n3074\n3279\n3441\ntidymodels\ncv9\n3260\n3373\n3453\nmlr3\nrcv100\n85909\n88642\n91381\ntidymodels\nrcv100\n87828\n88822\n89843\nFigure 1: Average runtime, measured in milliseconds, for cross-validations using\nrpart\n(displayed on the left) and\nranger\n(on the right). The comparison encompasses variations across different frameworks and the number of folds in the cross-validation.\nResample Parallel\nWe conducted a second set of resampling function tests, this time incorporating parallelization to explore its impact on runtime efficiency. In this phase, we utilized\ndoFuture\nand\ndoParallel\nas the primary parallelization packages for tidymodels, recognizing their robust support and compatibility. Meanwhile, for\nmlr3\n, the\nfuture\npackage was employed to facilitate parallel processing.\nOur findings, as presented in the respective tables (Table 5 and Table 6), reveal interesting dynamics about parallelization within the frameworks. When the number of folds in the resampling process is doubled, we observe only a marginal increase in the average runtime. This pattern suggests a significant overhead associated with initializing the parallel workers, a factor that becomes particularly influential in the overall efficiency of the parallelization process.\nIn the case of the\nrpart\nmodel, the parallelization overhead appears to outweigh the potential speedup benefits, as illustrated in the left section of Figure 2. This result indicates that for less complex models like\nrpart\n, where individual training times are relatively short, the initialization cost of parallel workers may not be sufficiently offset by the reduced processing time per fold.\nConversely, for the\nranger\nmodel, the utilization of parallelization demonstrates a clear advantage over the sequential version, as evidenced in the right section of Figure 2. This finding underscores that for more computationally intensive models like\nranger\n, which have longer individual training times, the benefits of parallel processing significantly overcome the initial overhead of worker setup. This differentiation highlights the importance of considering the complexity and inherent processing time of models when deciding to implement parallelization strategies in these frameworks.\nTable 5: Average runtime in milliseconds of\nmlr3\nwith\nfuture\nand\nrpart\ndepending on the resampling strategy.\nResampling\nLQ\nMedian\nUQ\ncv3\n625\n655\n703\ncv6\n738\n771\n817\ncv9\n831\n875\n923\nrcv100\n8620\n9043\n9532\nTable 6: Average runtime in milliseconds of\nmlr3\nwith\nfuture\nand\nranger\ndepending on the resampling strategy.\nResampling\nLQ\nMedian\nUQ\ncv3\n836\n884\n943\ncv6\n1200\n1249\n1314\ncv9\n1577\n1634\n1706\nrcv100\n32047\n32483\n33022\nWhen paired with doFuture,\ntidymodels\nexhibits significantly slower runtime compared to the\nmlr3\npackage utilizing\nfuture\n(Table 7 and Table 8). We observed that\ntidymodels\nexports more data to the parallel workers, which notably exceeds that of\nmlr3\n. This substantial difference in data export could plausibly account for the observed slower runtime when using\ntidymodels\non small tasks.\nTable 7: Average runtime in milliseconds of\ntidymodels\nwith\ndoFuture\nand\nrpart\ndepending on the resampling strategy.\nResampling\nLQ\nMedian\nUQ\ncv3\n2778\n2817\n3019\ncv6\n2808\n2856\n3033\ncv9\n2935\n2975\n3170\nrcv100\n9154\n9302\n9489\nTable 8: Average runtime in milliseconds of\ntidymodels\nwith\ndoFuture\nand\nranger\ndepending on the resampling strategy.\nResampling\nLQ\nMedian\nUQ\ncv3\n2982\n3046\n3234\ncv6\n3282\n3366\n3543\ncv9\n3568\n3695\n3869\nrcv100\n27546\n27843\n28166\nThe utilization of the\ndoParallel\npackage demonstrates a notable improvement in handling smaller resampling tasks. In these scenarios, the resampling process consistently outperforms the\nmlr3\nframework in terms of speed. However, it’s important to note that even with this enhanced performance, the\ndoParallel\npackage does not always surpass the efficiency of the sequential version, especially when working with the\nrpart\nmodel. This specific observation is illustrated in the left section of Figure 2.\nTable 9: Average runtime in milliseconds of\ntidymodels\nwith\ndoParallel\nand\nrpart\ndepending on the resampling strategy.\nResampling\nLQ\nMedian\nUQ\ncv3\n557\n649\n863\ncv6\n602\n714\n910\ncv9\n661\n772\n968\nrcv100\n10609\n10820\n11071\nTable 10: Average runtime in milliseconds of\ntidymodels\nwith\ndoParallel\nand\nranger\ndepending on the resampling strategy.\nResampling\nLQ\nMedian\nUQ\ncv3\n684\n756\n948\ncv6\n1007\n1099\n1272\ncv9\n1360\n1461\n1625\nrcv100\n31205\n31486\n31793\nFigure 2: Average runtime, measured in milliseconds, for cross-validations using\nrpart\n(displayed on the left) and\nranger\n(on the right). The comparison encompasses variations across different frameworks, the number of folds in the cross-validation, and the implementation of parallelization.\nIn the context of repeated cross-validation, our findings underscore the efficacy of parallelization (Figure 3). Across all frameworks tested, the adoption of parallel processing techniques yields a significant increase in speed. This enhancement is particularly noticeable in larger resampling tasks, where the demands on computational resources are more substantial.\nInterestingly, within these more extensive resampling scenarios, the\ndoFuture\npackage emerges as a more efficient option compared to\ndoParallel\n. This distinction is important, as it highlights the relative strengths of different parallelization packages under varying workload conditions. While\ndoParallel\nshows proficiency in smaller tasks,\ndoFuture\ndemonstrates its capability to handle larger, more complex resampling processes with greater speed and efficiency.\nFigure 3: Average runtime, measured in seconds, of a 100 times repeated 3-fold cross-validation using\nrpart\n(displayed on the left) and\nranger\n(on the right). The comparison encompasses variations across different frameworks and the implementation of parallelization.\nTune Sequential\nWe then shift our focus to assessing the runtime performance of the tuning functions. In this phase, the\ntidymodels\npackage is utilized to evaluate a predefined grid, comprising a specific set of hyperparameter configurations. To ensure a balanced and comparable analysis, we employ the\n\"design_points\"\ntuner from the\nmlr3tuning\npackage. This approach allows us to evaluate the same grid within the\nmlr3\nframework, maintaining consistency across both platforms. The grid used for this comparison contains 200 hyperparameter configurations each, for both the\nrpart\nand\nranger\nmodels. This approach helps us to understand how each framework handles the optimization of model hyperparameters, a key aspect of building effective and efficient machine learning models.\n# tidymodels\ntm_mod = decision_tree(\n  cost_complexity = tune()) %>%\n  set_engine(\"rpart\",\n    xval = 0) %>%\n  set_mode(\"classification\")\n\ntm_design = data.table(\n  cost_complexity = seq(0.1, 0.2, length.out = 200))\n\n# mlr3\nlearner = lrn(\"classif.rpart\",\n  xval = 0,\n  cp = to_tune())\n\nmlr3_design = data.table(\n  cp = seq(0.1, 0.2, length.out = 200))\n# tidymodels\ntm_mod = rand_forest(\n  trees = tune()) %>%\n  set_engine(\"ranger\",\n    num.threads = 1L,\n    seed = 1) %>%\n  set_mode(\"classification\")\n\ntm_design = data.table(\n  trees = seq(1000, 1199))\n\n# mlr3\nlearner = lrn(\"classif.ranger\",\n  num.trees = to_tune(1, 10000),\n  num.threads = 1L,\n  seed = 1,\n  verbose = FALSE,\n  predict_type = \"prob\")\n\nmlr3_design = data.table(\n  num.trees = seq(1000, 1199))\nWe measure the runtime of the tune functions within each framework. Both the\ntidymodels\nand\nmlr3\nframeworks are tasked with identifying the optimal hyperparameter configuration.\n# tidymodels tune\ntune::tune_grid(\n  tm_wf,\n  resamples = resamples,\n  grid = design,\n  metrics = metrics)\n\n# mlr3 tune\ntuner = tnr(\"design_points\", design = design, batch_size = nrow(design))\nmlr3tuning::tune(\n  tuner = tuner,\n  task = task,\n  learner = learner,\n  resampling = resampling,\n  measures = measure,\n  store_benchmark_result = FALSE)\nIn our sequential tuning tests,\nmlr3\ndemonstrates a notable advantage in terms of speed. This finding is clearly evidenced in our results, as shown in Table Table 11 for the\nrpart\nmodel and Table Table 12 for the\nranger\nmodel. The faster performance of\nmlr3\nin these sequential runs highlights its efficiency in handling the tuning process without parallelization.\nTable 11: Average runtime in seconds of tuning 200 points of\nrpart\ndepending on the framework.\nFramework\nLQ\nMedian\nUQ\nmlr3\n27\n27\n28\ntidymodels\n37\n37\n39\nTable 12: Average runtime in seconds of tuning 200 points of\nranger\ndepending on the framework.\nFramework\nLQ\nMedian\nUQ\nmlr3\n167\n171\n175\ntidymodels\n194\n195\n196\nTune Parallel\nConcluding our analysis, we proceed to evaluate the runtime performance of the tune functions, this time implementing parallelization to enhance efficiency. For these runs, parallelization is executed on 3 cores.\nIn the case of\nmlr3\n, we opt for the largest possible chunk size. This strategic choice means that all points within the tuning grid are sent to the workers in a single batch, effectively minimizing the overhead typically associated with parallelization. This approach is crucial in reducing the time spent in distributing tasks across multiple cores, thereby streamlining the tuning process. On the other hand, the\ntidymodels\npackage also operates with the same chunk size, but this setting is determined and managed internally within the framework.\nBy conducting these parallelization tests, we aim to provide a deeper understanding of how each framework handles the distribution and management of computational tasks during the tuning process, particularly in a parallel computing environment. This final set of measurements is important in painting a complete picture of the runtime performance of the tune functions across both\ntidymodels\nand\nmlr3\nunder different operational settings.\noptions(\"mlr3.exec_chunk_size\" = 200)\nOur analysis of the parallelized tuning functions reveals that the runtimes for\nmlr3\nand\ntidymodels\nare remarkably similar. However, subtle differences emerge upon closer inspection. For instance, the\nmlr3\npackage exhibits a slightly faster performance when tuning the\nrpart\nmodel, as indicated in Table 13. In contrast, it falls marginally behind\ntidymodels\nin tuning the\nranger\nmodel, as shown in Table 14.\nInterestingly, when considering the specific context of a 3-fold cross-validation, the\ndoParallel\npackage outperforms\ndoFuture\nin terms of speed, as demonstrated in Figure 4. This outcome suggests that the choice of parallelization package can have a significant impact on tuning efficiency, particularly in scenarios with a smaller number of folds.\nA key takeaway from our study is the clear benefit of enabling parallelization, regardless of the chosen framework-backend combination. Activating parallelization consistently enhances performance, making it a highly recommended strategy for tuning machine learning models, especially in tasks involving extensive hyperparameter exploration or larger datasets. This conclusion underscores the value of parallel processing in modern machine learning workflows, offering a practical solution for accelerating model tuning across various computational settings.\nTable 13: Average runtime in seconds of tuning 200 points of\nrpart\ndepending on the framework.\nFramework\nBackend\nLQ\nMedian\nUQ\nmlr3\nfuture\n11\n12\n12\ntidymodels\ndoFuture\n17\n17\n17\ntidymodels\ndoParallel\n13\n13\n13\nTable 14: Average runtime in seconds of tuning 200 points of\nranger\ndepending on the framework.\nFramework\nBackend\nLQ\nMedian\nUQ\nmlr3\nfuture\n54\n55\n55\ntidymodels\ndoFuture\n58\n58\n59\ntidymodels\ndoParallel\n54\n54\n55\nFigure 4: Average runtime, measured in seconds, of a tuning 200 hyperparameter configurations of\nrpart\n(displayed on the left) and\nranger\n(on the right). The comparison encompasses variations across different frameworks and the implementation of parallelization.\nConclusion\nOur analysis reveals that both\ntidymodels\nand\nmlr3\nexhibit comparable runtimes across key processes such as training, resampling, and tuning, each displaying its own set of strengths and efficiencies.\nA notable observation is the relative overhead associated with using either framework, particularly when working with fast-fitting models like\nrpart\n. In these cases, the additional processing time introduced by the frameworks is more pronounced due to the inherently short training time of\nrpart\nmodels. This results in a higher relative overhead, reflecting the trade-offs between the convenience of a comprehensive framework and the directness of more basic approaches.\nConversely, when dealing with slower-fitting models such as\nranger\n, the scenario shifts. For these more time-intensive models, the relative overhead introduced by the frameworks diminishes significantly. In such instances, the extended training times of the models absorb much of the frameworks’ inherent overhead, rendering it relatively negligible.\nIn summary, while there is no outright winner in terms of overall performance, the decision to use\ntidymodels\nor\nmlr3\nshould be informed by the specific requirements of the task at hand.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nmlr-org\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "Scope In the realm of data science, machine learning frameworks play an important role in streamlining and accelerating the development of analytical workflows. Among these, tidymodels and mlr3 stand out as prominent tools within the R community...",
      "meta_keywords": null,
      "og_description": "Scope In the realm of data science, machine learning frameworks play an important role in streamlining and accelerating the development of analytical workflows. Among these, tidymodels and mlr3 stand out as prominent tools within the R community...",
      "og_image": "https://mlr-org.com/gallery/technical/2023-10-30-tidymodels/index_files/figure-html/fig-resample-sequential-1.png",
      "og_title": "Analyzing the Runtime Performance of tidymodels and mlr3 | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 16.4,
      "sitemap_lastmod": "2023-10-30T00:00:00+00:00",
      "twitter_description": "Scope In the realm of data science, machine learning frameworks play an important role in streamlining and accelerating the development of analytical workflows. Among these, tidymodels and mlr3 stand out as prominent tools within the R community...",
      "twitter_title": "Analyzing the Runtime Performance of tidymodels and mlr3 | R-bloggers",
      "url": "https://www.r-bloggers.com/2023/10/analyzing-the-runtime-performance-of-tidymodels-and-mlr3/",
      "word_count": 3289
    }
  }
}