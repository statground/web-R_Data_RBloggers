{
  "id": "74546dc007d1ce80d57d31092b34a1645e71ae14",
  "url": "https://www.r-bloggers.com/2024/01/statistical-computing-on-a-shoestring-stan-in-the-azure-cloud-using-cloud-init/",
  "created_at_utc": "2025-11-17T20:38:34Z",
  "data": null,
  "raw_original": {
    "uuid": "3c65dcda-aafd-4eab-9a8f-6e584b4fc317",
    "created_at": "2025-11-17 20:38:34",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2024/01/statistical-computing-on-a-shoestring-stan-in-the-azure-cloud-using-cloud-init/",
      "crawled_at": "2025-11-17T09:18:08.438171",
      "external_links": [
        {
          "href": "https://gsverhoeven.github.io/post/azure-stan-linux/",
          "text": "Statistics | Gertjan Verhoeven"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://unsplash.com/@taylorvanriper925",
          "text": "https://unsplash.com/@taylorvanriper925"
        },
        {
          "href": "https://github.com/stan-dev/propaganda/tree/master/moore-sloan_sell_sheet/figures",
          "text": "stan-dev/propaganda"
        },
        {
          "href": "https://github.com/gsverhoeven/azure_cli_scripts",
          "text": "gsverhoeven/azure_cli_scripts"
        },
        {
          "href": "https://cloudinit.readthedocs.io/en/23.3.3/tutorial/qemu.html",
          "text": "how to work with QEMU"
        },
        {
          "href": "https://16shuklarahul.medium.com/how-to-fix-kvm-permission-denied-error-on-ubuntu-18-04-16-04-14-04-f04a6e23c0cd",
          "text": "after reading this explanation"
        },
        {
          "href": "https://learn.microsoft.com/en-us/azure/virtual-machines/linux/create-cli-complete",
          "text": "here"
        },
        {
          "href": "https://raw.githubusercontent.com/gsverhoeven/azure_cli_scripts/main/azure_config_ubuntu.sh",
          "text": "gsverhoeven/azure_cli_scripts/main/azure_config_ubuntu.sh"
        },
        {
          "href": "https://learn.microsoft.com/en-us/cli/azure/azure-cli-vm-tutorial-2",
          "text": "the Azure documentation"
        },
        {
          "href": "https://powersj.io/posts/ubuntu-images-azure/",
          "text": "this blog post by Joshua Powers"
        },
        {
          "href": "https://azure.microsoft.com/en-us/pricing/details/virtual-machines/series/",
          "text": "different types of VMs offered by Microsoft"
        },
        {
          "href": "https://azureprice.net/vm/Standard_D2s_v3?currency=EUR&timeoption=day&paymentType=payasyougo",
          "text": "https://azureprice.net/vm/Standard_D2s_v3?currency=EUR&timeoption=day&paymentType=payasyougo"
        },
        {
          "href": "https://learn.microsoft.com/en-us/azure/virtual-machines/linux/expand-disks?tabs=ubuntu",
          "text": "default OS disk size for Linux VMs"
        },
        {
          "href": "https://www.cloudelicious.net/azure-vms-and-their-temporary-storage/",
          "text": "here"
        },
        {
          "href": "https://learn.microsoft.com/en-us/azure/virtual-machines/disks-types",
          "text": "Azure disk types"
        },
        {
          "href": "https://cloud-init.io/",
          "text": "Cloud-init"
        },
        {
          "href": "https://cloudinit.readthedocs.io/en/latest/explanation/introduction.html#introduction",
          "text": "Here"
        },
        {
          "href": "https://raw.githubusercontent.com/gsverhoeven/azure_cli_scripts/main/cloud_init_cfg.yaml",
          "text": "here"
        },
        {
          "href": "https://www.qemu.org/",
          "text": "here"
        },
        {
          "href": "https://cloudinit.readthedocs.io/en/23.4.1/reference/datasources/nocloud.html#nocloud",
          "text": "special data source ‚Äúnocloud‚Äù"
        },
        {
          "href": "https://github.com/canonical/cloud-init/issues/3133",
          "text": "hack"
        },
        {
          "href": "https://raw.githubusercontent.com/gsverhoeven/azure_cli_scripts/main/qemu/do_qemu.sh",
          "text": "do_qemu.sh"
        },
        {
          "href": "https://superuser.com/questions/1112092/hacking-attempts-to-linux-vm-in-azure",
          "text": "post on superuser.com"
        },
        {
          "href": "https://github.com/stamparm/ipsum",
          "text": "IPsum Github repository"
        },
        {
          "href": "https://www.abuseipdb.com/",
          "text": "AbuseIPDB"
        },
        {
          "href": "https://stackoverflow.com/questions/75915624/xrdp-filter-setting-for-fail2ban",
          "text": "https://stackoverflow.com/questions/75915624/xrdp-filter-setting-for-fail2ban"
        },
        {
          "href": "https://github.com/ansible/ansible",
          "text": "Ansible"
        },
        {
          "href": "https://en.wikipedia.org/wiki/Containerization_(computing)",
          "text": "Container thing"
        },
        {
          "href": "https://en.wikipedia.org/wiki/Docker_(software)",
          "text": "Docker"
        },
        {
          "href": "https://en.wikipedia.org/wiki/Kubernetes",
          "text": "Kubernetes"
        },
        {
          "href": "https://gsverhoeven.github.io/post/azure-stan-linux/",
          "text": "Statistics | Gertjan Verhoeven"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Statistical computing on a shoestring: Stan in the Azure cloud using Cloud-init | R-bloggers",
      "images": [
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/gsverhoeven.github.io/post/stan_in_azure/azure_scope-levels.png?w=578&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/gsverhoeven.github.io/post/stan_in_azure/rdp_rstudio_stan.png?w=578&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/statistics-gertjan-verhoeven/",
          "text": "Statistics | Gertjan Verhoeven"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/cdn-cgi/l/email-protection",
          "text": "[email¬†protected]"
        },
        {
          "href": "https://www.r-bloggers.com/cdn-cgi/l/email-protection",
          "text": "[email¬†protected]"
        },
        {
          "href": "https://www.r-bloggers.com/cdn-cgi/l/email-protection",
          "text": "[email¬†protected]"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-381517 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Statistical computing on a shoestring: Stan in the Azure cloud using Cloud-init</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">January 14, 2024</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/statistics-gertjan-verhoeven/\">Statistics | Gertjan Verhoeven</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://gsverhoeven.github.io/post/azure-stan-linux/\"> Statistics | Gertjan Verhoeven</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<p><small>\n<em>Photo source: cropped from original by Taylor van Riper <a class=\"uri\" href=\"https://unsplash.com/@taylorvanriper925\" rel=\"nofollow\" target=\"_blank\">https://unsplash.com/@taylorvanriper925</a></em></small></p>\n<p><em>Graphics source: Michael Betancourt at <a href=\"https://github.com/stan-dev/propaganda/tree/master/moore-sloan_sell_sheet/figures\" rel=\"nofollow\" target=\"_blank\">stan-dev/propaganda</a></em>\n</p>\n<p>Time to explore what the public cloud is all about.\nOur goal is to write code (i.e.¬†scripts) using open-source tools to automatically set up cloud infrastructure. In short, we want <strong>Infrastructure as code</strong>.</p>\n<p>For this I chose a specific use case, which is <strong>spinning up a low cost data analysis development environment with R, Rstudio and Stan tools</strong> installed and configured.</p>\n<p>This has two big advantages, <strong>reproducibility</strong> and <strong>lower switching cost</strong>:</p>\n<ul>\n<li>Scripting the compute resources that made a data analysis possible is the next level in reproducibility.</li>\n<li>Ideally, we want our scripts to be independent of a particular cloud provider. This would allow us to easily change from e.g.¬†Azure to Amazon AWS if things stagnate or we can get a better deal elsewhere.</li>\n</ul>\n<p>I ended up writing Linux shell scripts that use the <strong>Azure command-line interface (Azure CLI)</strong> to deploy a Linux VM configured using <strong>Cloud-init</strong>. While doing so I discovered that being able to test changes locally first before deploying to the cloud speeds up development significantly.</p>\n<p>To summarize and motivate the tech choices I made:</p>\n<ul>\n<li>I chose <strong>Azure</strong> since my employer recently moved to Azure and me learning it would be beneficial for work.</li>\n<li>I chose <strong>Azure CLI</strong> to write simple shell scripts without the additional abstraction layer introduced by more generic tools like Terraform/OpenTofu or Ansible</li>\n<li>I chose <strong>Linux Ubuntu OS</strong> to keep cost down, as it is free and needs less resources than <strong>Windows 10/11</strong></li>\n<li>I chose <strong>Cloud-init</strong> as it has emerged as the standard way to configure Linux cloud images across all cloud platforms</li>\n<li>I chose the <strong>QEMU Quick Emulator</strong> to run VMs locally to speed up development</li>\n</ul>\n<p>The blog uses Linux throughout, but the Azure CLI commands should work for Windows as well.\nAll scripts mentioned in this blog are available in a separate Github repository, <a href=\"https://github.com/gsverhoeven/azure_cli_scripts\" rel=\"nofollow\" target=\"_blank\">gsverhoeven/azure_cli_scripts</a>.</p>\n<div class=\"section level1\" id=\"cloud-computing-in-azure-on-a-shoestring\">\n<h1>Cloud computing in Azure on a shoestring</h1>\n<p>So what do we need to pay for this low cost cloud computing data analytics VM?</p>\n<p>For a single VM the main cost driver is the VM itself. We need at least 8GB of RAM and a minimum of 2 CPU, so we end up with a <code>Standard D2s</code> VM. At the time of writing, monthly cost, assuming 24/7 usage is 73 euro.</p>\n<p>(To find out about these prices in the first place: Azure shows them when you select ‚Äúcreate new VM‚Äù in the portal)</p>\n<p>We have two additional small cost drivers, the associated disk (‚Äústorage‚Äù), and we need to pay for a public IP address, each roughly 0.1 euro per day.</p>\n<p>If we would bring the VM up and keep it on for a whole day we pay around 2.5 euro a day.\nIf we only use it for 8 hours, cost is reduced to an estimated 1 euro per day.\nIf we stop the VM such that the resources are released (deallocated), we only need to pay for the IP and disk storage, which is 0.2 euro per day, or 6 euro on a monthly basis. This allows us a ‚Äúfast resume‚Äù option that avoids waiting 30 min to install and configure all the software. I tried this, it is a feasible strategy, it takes a minute or so to boot up.</p>\n<p>Ok let‚Äôs do it!</p>\n</div>\n<div class=\"section level1\" id=\"setting-up-our-local-iaas-dev-environment\">\n<h1>Setting up our local IaaS dev environment</h1>\n<p>As mentioned above, we use both <strong>Azure CLI</strong> and <strong>QEMU virtual emulator</strong> for local VM development.</p>\n<p>I started with creating a free account on Azure. This comes with 200 Euro free credit to spent within a month.</p>\n<p>Then I installed <code>azure-cli</code> on my local system (Ubuntu 18.04 LTS):</p>\n<pre>#downloads the signing key from Microsoft\ncurl -sL https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/microsoft.gpg &gt; /dev/null \n## creates a file called microsoft.gpg in the folder where keys are stored\n\nAZ_REPO=$(lsb_release -cs) ## outputs the codename for the linux distribution i.e. Ubuntu 18.04 = bionic\necho \"deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ $AZ_REPO main\" | sudo tee /etc/apt/sources.list.d/azure-cli.list \n## writes that URL to the package resource list\nsudo apt-get update\nsudo apt-get install azure-cli</pre>\n<p>First time we use <code>azure-cli</code> locally we need authenticate:</p>\n<pre># Log in interactively using the browser.\naz login</pre>\n<p>Test if it works by creating and deleting a new resource group:</p>\n<pre>az group create --location westeurope --resource-group MyCoolRG -o table\r\nLocation    Name\n----------  --------\nwesteurope  MyCoolRG\n</pre>\n<p>Great! that worked. Now let‚Äôs get rid of it.</p>\n<pre>az group delete --resource-group MyCoolRG</pre>\n<p>Next we install <strong>QEMU</strong>, which stands for Quick Emulator. The documentation for Cloud-init contains a section on <a href=\"https://cloudinit.readthedocs.io/en/23.3.3/tutorial/qemu.html\" rel=\"nofollow\" target=\"_blank\">how to work with QEMU</a>. This will be our local development environment to test Cloud-init scripts before launching them on the cloud.</p>\n<p>Install QEMU:</p>\n<pre>sudo apt install qemu-kvm</pre>\n<p>This installs QEMU 2.11 (2018) that plays well with Ubuntu 18.04.</p>\n<p>QEMU on Ubuntu works with hypervisor KVM to run virtual machines locally. Each virtual machine has private virtualized hardware: a network card, disk, graphics adapter, etc. For windows VMware is a popular alternative.</p>\n<p>QEMU upon first use threw an error ‚Äú/dev/kvm device: permission denied‚Äù that I fixed by adding my own user account to the <code>kvm</code> group <a href=\"https://16shuklarahul.medium.com/how-to-fix-kvm-permission-denied-error-on-ubuntu-18-04-16-04-14-04-f04a6e23c0cd\" rel=\"nofollow\" target=\"_blank\">after reading this explanation</a>:</p>\n<pre>sudo adduser gertjan kvm</pre>\n<p>On my machine, all users in group <code>kvm</code> have <code>rw</code> access for <code>/dev/kvm</code>, thereby fixing the permission error.</p>\n<pre>(base) gertjan:~$ qemu-system-x86_64 --version\nQEMU emulator version 2.11.1(Debian 1:2.11+dfsg-1ubuntu7.41)\nCopyright (c) 2003-2017 Fabrice Bellard and the QEMU Project developers</pre>\n</div>\n<div class=\"section level1\" id=\"creating-the-azure-infrastucture\">\n<h1>Creating the Azure infrastucture</h1>\n<p>Azure is organized as a hierarchical structure. See the schematic below.\nAll the components that make up the infrastructure are called <em>resources</em>. Traversing upwards through the hierarchy:</p>\n<ul>\n<li><strong>Resources</strong> are contained within <strong>resource groups</strong>.</li>\n<li><strong>Resource groups</strong> exist within a <strong>subscription</strong>.</li>\n<li>Finally, <strong>subscriptions</strong> exist within <strong>management groups</strong>.</li>\n</ul>\n<p><img data-lazy-src=\"https://i0.wp.com/gsverhoeven.github.io/post/stan_in_azure/azure_scope-levels.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i0.wp.com/gsverhoeven.github.io/post/stan_in_azure/azure_scope-levels.png?w=578&amp;ssl=1\"/></noscript></p>\n<p>In this blog post, we will create the infrastructure we need from scratch.\nOur desired infrastructure consists of a single virtual network that contains a single virtual machine (VM)\nThe VM will be configured to be accessible through the internet using SSH and ‚ÄúMicrosoft Remote Desktop‚Äù (RDP).</p>\n<p>To quickly create a VM in Azure, it is possible to use a single Azure CLI command with default values that automatically creates any required supporting resources.\nHowever, to really understand the Azure building blocks and their dependencies, it is better to create each Azure resource separately.\nIn doing so we gradually build up the infrastructure step by step.\n(An official Azure tutorial by Cynthia Nottingham and others that takes a similar approach can be found <a href=\"https://learn.microsoft.com/en-us/azure/virtual-machines/linux/create-cli-complete\" rel=\"nofollow\" target=\"_blank\">here</a>)</p>\n<p>Special attention is given to secure our network and VM, because it is exposed to the public internet.\nHackers are continuously scanning the Azure network IP address ranges for vulnerable systems, so we need to defend ourselves.\nWe use a basic Firewall called ‚ÄúNetwork Security Group‚Äù that works with <strong>Security Rules</strong>.\nMore on our security measures below. I chose not to use an ‚ÄúAvailability Set‚Äù as this only makes sense for groups of VMs.</p>\n<p>I use Linux shell Environment Variables to separate the <strong>Azure configuration parameters</strong> (which image, which VM type etc) from the actual Azure CLI commands that create the resources.\nTo view my current configuration file containing all Azure parameters: <a href=\"https://raw.githubusercontent.com/gsverhoeven/azure_cli_scripts/main/azure_config_ubuntu.sh\" rel=\"nofollow\" target=\"_blank\">gsverhoeven/azure_cli_scripts/main/azure_config_ubuntu.sh</a></p>\n</div>\n<div class=\"section level1\" id=\"step-by-step-guide-to-set-up-the-vm\">\n<h1>Step-by-step guide to set up the VM</h1>\n<ul>\n<li>First we create a new <strong>Resource group</strong></li>\n<li>Then we create a <strong>Virtual Network</strong> with a <strong>Subnet</strong></li>\n<li>Then we create a <strong>Public IP</strong></li>\n<li>Then we create a <strong>Network Security Group</strong> &amp; Rules</li>\n<li>Then we create a <strong>Network Interface Card (NIC)</strong></li>\n<li>Then we choose the <strong>VM image</strong>, <strong>VM size</strong> and <strong>VM storage type</strong></li>\n<li>Then we write a <strong>Cloud-init script</strong> to initialize the VM</li>\n<li>Finally we <strong>create the VM</strong> and enjoy the show</li>\n</ul>\n<div class=\"section level2\" id=\"create-resource-group\">\n<h2>Create resource Group</h2>\n<p>First we create a new <em>Resource Group</em>, <code>myRGtest</code>.\nThis needs a location. Since I am in West Europe, let‚Äôs choose <code>westeurope</code>.</p>\n<pre># create shell variables\nresourceGroup=myRGtest\nlocation=westeurope\naz group create --name $resourceGroup --location $location\naz group show --resource-group $resourceGroup</pre>\n</div>\n<div class=\"section level2\" id=\"create-virtual-network\">\n<h2>Create Virtual Network</h2>\n<p>Next we create a <em>Virtual Network</em> and a <em>Subnet</em>, as explained in <a href=\"https://learn.microsoft.com/en-us/cli/azure/azure-cli-vm-tutorial-2\" rel=\"nofollow\" target=\"_blank\">the Azure documentation</a>:</p>\n<pre># create shell variables\nvnetName=StanDEV-VNet1\nsubnetName=StanDEV-Subnet1\nvnetAddressPrefix=10.0.0.0/16\nsubnetAddressPrefix=10.0.0.0/24\n\naz network vnet create \\\n  --name $vnetName \\\n  --resource-group $resourceGroup \\\n  --address-prefixes $vnetAddressPrefix \\\n  --subnet-name $subnetName \\\n  --subnet-prefixes $subnetAddressPrefix</pre>\n</div>\n<div class=\"section level2\" id=\"create-public-ip-address\">\n<h2>Create Public IP address</h2>\n<p>Now let‚Äôs create a public IP address with <code>az network public-ip create</code>.</p>\n<pre>publicIP=TEST-public-ip\nmypublicdns=gsverhoeven\n\necho \"creating public IP address ..\"\naz network public-ip create \\\n    --resource-group $resourceGroup \\\n    --name $publicIP \\\n    --sku standard \\\n    --dns-name $mypublicdns \\\n    --output $azOutput \\\n    --zone 1 # non-zonal IP</pre>\n<p>This public IP address enables us to connect to the VM from the Internet.</p>\n<p>This command results in an IP address with a Fully qualified domain name (FQDN) of <code>gsverhoeven.westeurope.cloudapp.azure.com</code></p>\n<pre>nslookup  gsverhoeven.westeurope.cloudapp.azure.com\n#Server:        127.0.0.53\n#Address:   127.0.0.53#53\n\n#Non-authoritative answer:\n#Name:  gsverhoeven.westeurope.cloudapp.azure.com\n#Address: 68.219.248.112\r\naz network public-ip list -o table\r\nName            ResourceGroup    Location    Zones    Address        IdleTimeoutInMinutes    ProvisioningState\n--------------  ---------------  ----------  -------  -------------  ----------------------  -------------------\nTEST-public-ip  myRGtest         westeurope           104.46.41.142  4                       Succeeded\n</pre>\n</div>\n<div class=\"section level2\" id=\"create-network-security-group-rules\">\n<h2>Create network security group &amp; Rules</h2>\n<p>To control the flow of traffic in and out of our VM, we use a so-called <strong>network security group</strong>. The following example uses <code>az network nsg create</code> to create a network security group named <code>myNSG</code>:</p>\n<pre>NetworkSecurityGroup=myNSG\n\naz network nsg create \\\n    --resource-group $resourceGroup \\\n    --name $NetworkSecurityGroup</pre>\n<p>This works by defining rules that allow or deny specific traffic.\nA new NSG starts with a set of default rules, among which is the rule that all inbound traffic is blocked.\nRules are processed in priority order, with lower numbers processed before higher numbers, because lower numbers have higher priority. Once traffic matches a rule, processing stops.</p>\n<p><strong>To allow inbound connections on port 22 (to enable SSH access)</strong>, create an inbound rule with <code>az network nsg rule create</code>. The following example creates a rule named <code>myNetworkSecurityGroupRuleSSH</code>:</p>\n<pre>echo \"create SSH rule ..\"\naz network nsg rule create \\\n    --resource-group $resourceGroup \\\n    --nsg-name $NetworkSecurityGroup \\\n    --name myNetworkSecurityGroupRuleSSH \\\n    --description \"Allow SSH at port 22\" \\\n    --protocol tcp \\\n    --priority 1000 \\\n    --destination-port-range 22 \\\n    --access allow \\\n    --output $azOutput</pre>\n<p>To allow <strong>Remote Desktop traffic</strong> to reach your Linux VM, add another network security group rule.\nThe following example creates a rule named <code>myNetworkSecurityGroupRuleRDP</code>:</p>\n<pre>echo \"create RDP rule ..\"\naz network nsg rule create \\\n    --resource-group $resourceGroup \\\n    --nsg-name $NetworkSecurityGroup \\\n    --name myNetworkSecurityGroupRuleRDP \\\n    --description \"Allow RDP at port 3389\" \\\n    --direction Inbound \\\n    --protocol tcp \\\n    --priority 1001 \\\n    --destination-port-range 3389 \\\n    --access allow \\\n    --output $azOutput \\\n    --source-address-prefixes $trustedIPAdress</pre>\n<p>Examine the network security group and rules with <code>az network nsg rule list</code>:</p>\n<pre>echo \"check NSG rules ..\"\naz network nsg rule list \\\n    --resource-group $resourceGroup \\\n    --nsg-name $NetworkSecurityGroup \\\n    --output table</pre>\n</div>\n<div class=\"section level2\" id=\"create-nic\">\n<h2>Create NIC</h2>\n<p>Virtual network interface cards (NICs) are programmatically available because you can apply rules to their use.\nIn the following <code>az network nic create</code> command, we create a NIC named <code>myNic</code> and associate it with our network security group. The public IP address we created above is also associated with the virtual NIC.</p>\n<pre>echo \"create NIC ..\"\naz network nic create \\\n    --resource-group $resourceGroup \\\n    --name $NICName \\\n    --vnet-name $vnetName \\\n    --subnet $subnetName \\\n    --public-ip-address $publicIP \\\n    --output $azOutput \\\n    --network-security-group $NetworkSecurityGroup</pre>\n<p>From the dependencies, we can see that a NIC ties together:</p>\n<ul>\n<li>A Network Security Group,</li>\n<li>A public IP,</li>\n<li>A VNet &amp; subnet,</li>\n</ul>\n<p>all within a resource group. Later on, when we create the VM, we only need to specify the NIC to bring up the VM in the virtual network with the desired NSG.</p>\n</div>\n<div class=\"section level2\" id=\"vm-image-choice\">\n<h2>VM Image choice</h2>\n<p>As VM image I chose <strong>Ubuntu Server 22.04 LTS</strong> for reasons already mentioned above.\nBut which one, how do we find the image we need?</p>\n<p>Canonical, the company behind Ubuntu Linux, offers various preconfigured Ubuntu images in the Azure Marketplace.\nAzure CLI can be used to programmatically interact with Azure Marketplace. I used <a href=\"https://powersj.io/posts/ubuntu-images-azure/\" rel=\"nofollow\" target=\"_blank\">this blog post by Joshua Powers</a> to learn how this works.</p>\n<p>All images published by Canonical are discoverable using the following command:</p>\n<pre>az vm image list-skus \\\n--publisher Canonical \\\n--offer Ubuntu \\\n--location westeurope \\\n-o table\r\nLocation    Name\n----------  ----------------------\nwesteurope  18_04-lts\nwesteurope  18_04-lts-gen2\nwesteurope  18_04-lts-minimal\nwesteurope  18_04-lts-minimal-gen2\n...\nwesteurope  22_04-lts\nwesteurope  22_04-lts-gen2\nwesteurope  22_04-lts-minimal\nwesteurope  22_04-lts-minimal-gen2\n...\n</pre>\n<p>I went with <code>22_04-lts</code>.</p>\n</div>\n<div class=\"section level2\" id=\"vm-size-choice\">\n<h2>VM Size choice</h2>\n<p>There is a bewildering amount of choice regarding <a href=\"https://azure.microsoft.com/en-us/pricing/details/virtual-machines/series/\" rel=\"nofollow\" target=\"_blank\">different types of VMs offered by Microsoft</a>. As my focus is on cheap, general purpose compute, I ended up with D-series VMs.</p>\n<p>Azureprice.net shows regional price variation, however without subscription it only shows the extent of the price variation.\nMy current heuristic is taking the median (i.e.¬†middle) price, so far it seems to give a good estimate of monthly pay-as-you-go prices for west-europe.</p>\n<p><a class=\"uri\" href=\"https://azureprice.net/vm/Standard_D2s_v3?currency=EUR&amp;timeoption=day&amp;paymentType=payasyougo\" rel=\"nofollow\" target=\"_blank\">https://azureprice.net/vm/Standard_D2s_v3?currency=EUR&amp;timeoption=day&amp;paymentType=payasyougo</a></p>\n<p>To have a reasonable fast software install I found we need at least 8GB of mem and 2 vCPUs, this corresponds to <code>Standard_D2s_v3</code>. With this VM, cloud-init installation finishes after 23 min, after which the VM is fully operational.\nThis has a monthly cost of 78 euro (based on 24/7 usage).</p>\n<pre>`Standard` is recommended tier.\nD ‚Äì General purpose compute\n2 ‚Äì VM Size\ns ‚Äì Premium Storage capable\nv3 ‚Äì version</pre>\n</div>\n<div class=\"section level2\" id=\"disk-storage-associated-with-the-vm\">\n<h2>Disk storage associated with the VM</h2>\n<p>When an Azure virtual machine is created, two disks are automatically attached to the virtual machine.</p>\n<p>The disk that holds the VM image (in our case Ubuntu 22) is called the <strong>OS disk</strong>. In Azure, the <a href=\"https://learn.microsoft.com/en-us/azure/virtual-machines/linux/expand-disks?tabs=ubuntu\" rel=\"nofollow\" target=\"_blank\">default OS disk size for Linux VMs</a> is currently at 30 GB. This appears to also be the minimum OS disk size, there is only the option to expand them. The OS disk is labeled <code>/dev/sda</code> by default.</p>\n<p>In addition, there is a <strong>temp disk</strong> mounted that is physically located on the Azure host where the VM is running. This can only be used for temporary data processing, and its size is given. It does not incur any extra cost. Temporary disks are labeled <code>/dev/sdb</code> and have a mountpoint of <code>/mnt</code>. More info on temp disks <a href=\"https://www.cloudelicious.net/azure-vms-and-their-temporary-storage/\" rel=\"nofollow\" target=\"_blank\">here</a></p>\n<p><strong>N.b.</strong> I did not go so far as to attach a <strong>data disk</strong>. So we need to make sure that work we do on the VM is pushed to e.g.¬†Github, because if we tear the VM down, the user data is lost as well.</p>\n<p>The Disk types are controlled by the <code>-storage-sku</code> option when we create the VM.\nAllowed values for this option include <code>Standard_LRS</code> for traditional hard disks (HDD), <code>StandardSSD_LRS</code> and <code>Premium_LRS</code> both consists of SSD disks but with differing performance characteristics. Locally redundant storage (LRS) replicates your data three times within a single data center in the selected region. More info at <a href=\"https://learn.microsoft.com/en-us/azure/virtual-machines/disks-types\" rel=\"nofollow\" target=\"_blank\">Azure disk types</a></p>\n<p>We want the cheapest SSD option, this seems to be <code>StandardSSD_LRS</code>.</p>\n</div>\n</div>\n<div class=\"section level1\" id=\"cloud-init-to-automate-software-installation-and-vm-configuration\">\n<h1>Cloud-init to automate software installation and VM configuration</h1>\n<p>At this point we could stop, and create the VM. However, it would just be a plain out-of-the-box Linux installation.\nAnd our goal is to use the VM for data science, Bayesian modelling in particular!</p>\n<p>So directly after creating the VM, we want to install additional software on it.\nFor this we use the open source tool <a href=\"https://cloud-init.io/\" rel=\"nofollow\" target=\"_blank\">Cloud-init</a>. It typically runs directly after a cloud instance is created.\nCloud-init is cross-platform across the public cloud, so in theory we should be able to easily move our instance from one cloud provider to another.</p>\n<p>Already in the early days of cloud computing (2007), people recognized the need to automatically configure cloud instances using user defined scripts. Around that time Cloud-init was born (it was called <code>ec2-init</code> at that time, because at that time AWS EC2 basically WAS the complete public cloud).</p>\n<p>According to the documentation:</p>\n<p><em>Cloud-init is an open source initialisation tool that was designed to make it easier to get your systems up and running with a minimum of effort, already configured according to your needs. [‚Ä¶] During boot, cloud-init identifies the cloud it is running on and initialises the system accordingly. Cloud instances will automatically be provisioned during first boot with networking, storage, SSH keys, packages and various other system aspects already configured.</em></p>\n<p><a href=\"https://cloudinit.readthedocs.io/en/latest/explanation/introduction.html#introduction\" rel=\"nofollow\" target=\"_blank\">Here</a> is a nice overview introduction.</p>\n<p><strong>Cloud-init</strong> needs a script or cloud config that will be run directly after provisioning the VM.\nThis is called ‚ÄúUser data‚Äù by most cloud providers, M$ calls it <code>custom-data</code>.\nAlthough it can run any shell script, there is also a declarative YAML based configuration file that works with modules to perform common tasks like adding users, updating and installing linux software packages etc.\nFor this blog I went with a YAML file called <code>cloud_init_cfg.yaml</code>.\nThe content of this file can be inspected <a href=\"https://raw.githubusercontent.com/gsverhoeven/azure_cli_scripts/main/cloud_init_cfg.yaml\" rel=\"nofollow\" target=\"_blank\">here</a>.</p>\n<div class=\"section level2\" id=\"testing-cloud-init-on-the-local-file-system-using-qemu\">\n<h2>Testing cloud-init on the local file system using QEMU</h2>\n<p>As we are developing our cloud config script, we want to test it locally before deploying the whole shabam to the Azure cloud, as this is slow (you don‚Äôt want to wait 10 minutes to discover you made a typo .. AGAIN!!).\nEnter the <strong>QEMU virtualizer</strong> (website <a href=\"https://www.qemu.org/\" rel=\"nofollow\" target=\"_blank\">here</a>), that can act as a virtualization host to run the instance locally.\nAs the Cloud-init enabled instance is booted up inside QEMU, it needs a data source to fetch the cloud config script from.\nCloud-init supports the <a href=\"https://cloudinit.readthedocs.io/en/23.4.1/reference/datasources/nocloud.html#nocloud\" rel=\"nofollow\" target=\"_blank\">special data source ‚Äúnocloud‚Äù</a> that allows us to use the local file system to offer the data source to the instance in three variants. I use the variant with a local HTTP server running using the python built-in webserver at local port 8000:</p>\n<pre>gnome-terminal -- python3 -m http.server --directory .</pre>\n<p>The url of the webserver is communicated to the instance by <strong>Qemu</strong> using a <a href=\"https://github.com/canonical/cloud-init/issues/3133\" rel=\"nofollow\" target=\"_blank\">hack</a>, which is putting it into the serial number field of the SMBIOS:</p>\n<pre>-smbios type=1,serial=ds='nocloud;s=http://10.0.2.2:8000/'</pre>\n<p>Here is example code that downloads a Cloud-init enabled Ubuntu 22.04 image (<code>jammy</code>) for local testing.\nThe initial (virtual) disk size of the image is 2.2 GB, which is too small to install all the software we need to run Rstudio.\nSo we increase the image size to 30GB. After that we fire up the instance with QEMU:</p>\n<pre>wget https://cloud-images.ubuntu.com/jammy/current/jammy-server-cloudimg-amd64.img\nqemu-img info jammy-server-cloudimg-amd64.img \n# 2.2 GB\nqemu-img resize jammy-server-cloudimg-amd64.img 30G\n\nqemu-system-x86_64                                            \\\n    -net nic                                                    \\\n    -net user\n    -machine accel=kvm                                          \\ # use hardware acceleration\n    -cpu host                                                   \\ # emulate host processor\n    -m 1024                                                      \\ # use 1 GB RAM\n    -nographic                                                  \\ # graphic window disabled\n    -hda jammy-server-cloudimg-amd64.img                        \\ # Set a virtual hard drive and use the specified image file \n    -smbios type=1,serial=ds='nocloud;s=http://10.0.2.2:8000/'\r\nubuntu@jammy:~$ sudo lsblk -d | grep disk\nfd0     2:0    1     4K  0 disk \nsda     8:0    0    30G  0 disk </pre>\n<p>I ended up writing a script <a href=\"https://raw.githubusercontent.com/gsverhoeven/azure_cli_scripts/main/qemu/do_qemu.sh\" rel=\"nofollow\" target=\"_blank\">do_qemu.sh</a> that starts a local VM using the same cloud-config YAML file that is also used to configure the actual Azure VM. This allowed for fast development and seamless switching between local and cloud testing.</p>\n</div>\n<div class=\"section level2\" id=\"using-cloud-init-to-install-additional-packages\">\n<h2>Using cloud-init to install additional packages</h2>\n<p>Using Cloud-init‚Äôs <code>packages</code> module, we install the following software:</p>\n<ul>\n<li>inxi (system information tool)</li>\n<li>Firefox</li>\n<li>Fail2ban (Blocking of bad IP addresses)</li>\n<li>XFCE4 desktop (default ubuntu image comes without a desktop)</li>\n<li>xRDP (to use the VM as a remote desktop)</li>\n<li>GNU make and g++ compiler (to compile R packages as well as Stan programs)</li>\n<li>various dependencies for R packages, notably tidyverse</li>\n</ul>\n</div>\n<div class=\"section level2\" id=\"using-cloud-init-to-run-scripts-on-the-vm-during-late-boot\">\n<h2>Using cloud-init to run scripts on the VM during late boot</h2>\n<p>To configure Fail2ban, xRDP, install R and Rstudio, I wrote separate scripts that perform the necessary steps.\nThese scripts are contained within the <code>cloud_init_cfg.yaml</code> file to be written to disk within the instance during early init. At late init, the scripts are then executed one after another.</p>\n<ul>\n<li><ul>\n<li>[bash, /enable_fail2ban.sh ]</li>\n</ul></li>\n<li><ul>\n<li>[bash, /install_xrdp.sh ]</li>\n</ul></li>\n<li><ul>\n<li>[bash, /install_r.sh ]</li>\n</ul></li>\n<li><ul>\n<li>[bash, /install_rstudio.sh ]</li>\n</ul></li>\n</ul>\n</div>\n</div>\n<div class=\"section level1\" id=\"securing-our-vm\">\n<h1>Securing our VM</h1>\n<p>For a VM with a public IP on the hostile internet, we need some security measures in place.\n‚ÄúHackers‚Äù will be using a list of azure IPs and will attempt brute force SSH to gain access.\nSee for example this <a href=\"https://superuser.com/questions/1112092/hacking-attempts-to-linux-vm-in-azure\" rel=\"nofollow\" target=\"_blank\">post on superuser.com</a>.\nThere are sites that document so called ‚Äúbad IPs‚Äù, known culprits of e.g.¬†unauthorized scanning for open ports:</p>\n<ul>\n<li><a href=\"https://github.com/stamparm/ipsum\" rel=\"nofollow\" target=\"_blank\">IPsum Github repository</a> list with bad IPs, including a Wall of Shame</li>\n<li><a href=\"https://www.abuseipdb.com/\" rel=\"nofollow\" target=\"_blank\">AbuseIPDB</a>, a database of abusive IP addresses.</li>\n</ul>\n<p>Some of these were indeed scanning my VM as well.\nWe take the following steps to secure our VM from outside attacks:</p>\n<ul>\n<li>SSH password authentication is disabled, access only through SSH keys</li>\n<li>We generate an password (needed for RDP logon) on the fly from keyboard input when creating the VM</li>\n<li>Only RDP connections from a single trusted IP address are allowed</li>\n<li>All other ports are closed for inbound traffic using Azure NSG</li>\n<li>Use <strong>Fail2ban</strong> to ban IPs that have multiple unsuccessful SSH login attempts</li>\n</ul>\n<p>NSG is a basic type of firewall, that is relatively dumb.\nIt does not know about applications, it just filters network packets based on rules.\nSo we use it to block all incoming connections from the internet, except SSH and RDP.</p>\n<ul>\n<li><p>To connect using SSH, a private key is needed that is only available on my local desktop system. When someone tries to brute force the SSH connection, their IP is banned after a few unsuccessful login attempts.</p></li>\n<li><p>To connect using RDP, it only accepts connections from the IP address attached to my local desktop system via my ISP. It would be nice to add RDP to fail2ban, however this apparently is not easy.</p></li>\n</ul>\n<p>Hopefully this is enough security for a single VM without important secrets, and I did not make any mistake here üôÇ</p>\n<p>(Microsoft has created a product ‚ÄúAzure Bastion‚Äù for our use case, when we want to use RDP / remote desktop into a VM on Azure, but do not want to use a VPN or expose the VM using a public IP address. It seems expensive though ..)</p>\n<p>To explain and document I will now describe my security measures in more detail, starting with SSH access.</p>\n<div class=\"section level2\" id=\"ssh-access\">\n<h2>SSH access</h2>\n<p>A common, secure way of connecting to a VM is through a ‚Äúsecure shell‚Äù aka SSH connection.\nIt is secure because all traffic is encrypted. We can either use passwords or work with ‚Äúkey pairs‚Äù. We choose SSH keys because it is safer, since passwords can be guessed or brute-force discovered.</p>\n<p>SSH works with so-called ‚Äúkey pairs‚Äù, that consist of a public and private key. The private key is kept secret and is stored on our local system. The public key is passed to the VM when it is created. The VM uses this public key to encrypt all communication. To decrypt this communication, the private key is needed. Since nobody else has this key except we ourselves on our local system in a safe place, the connection is safeguarded.</p>\n<p>We need to generate a public and private key for ourselves, and get it on the new VM.\nWe use the <code>--generate-ssh-keys</code> parameter to create them the first time we create the VM. After that, since we already have a key pair, this parameter uses existing keys in <code>~/.ssh</code>.</p>\n<p>Since SSH communication goes back and forth between our local system and the VM, we also need to encrypt the information we send to the VM. For that we need to use the <strong>VM‚Äôs public</strong> key that it hands out to whoever wants to communicate with it. We fetch after VM creation using <code>ssh-keyscan</code>:</p>\n<pre>ssh-keyscan -H $mypublicdns.westeurope.cloudapp.azure.com &gt;&gt; ~/.ssh/known_hosts</pre>\n<p>After all this, we can connect to the VM using SSH without the need to supply a password, the key-pairs in the background take care of the authentication process.</p>\n<pre>(base) gertjan:~$ ssh <a class=\"__cf_email__\" data-cfemail=\"7d0e091c13080e180f3d1a0e0b180f1512180b1813530a180e0918080f120d18531e111208191c0d0d531c07080f18531e1210\" href=\"/cdn-cgi/l/email-protection\">[email¬†protected]</a>\nWelcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.2.0-1018-azure x86_64)\n\n[...]\n\nLast login: Sun Jan 14 22:02:30 2024 from 77.248.168.82\nstanuser@standev:~$ </pre>\n</div>\n<div class=\"section level2\" id=\"interactive-password-generation-for-rdp-access\">\n<h2>Interactive password generation for RDP access</h2>\n<p>For remote desktop access with sufficient performance (no lags) we still need to set a password on the VM when we create it.\nSince we want a fully scripted process of VM creation, I needed a secure way to generate and set a password during VM creation. In the end, I figured out a way to accomplish this using a shell script with an interactive prompt, that dynamically inserts the hashed password into the Cloud-init config file. This config file is then used to set the password on the VM upon creation, after which the copy of the config file containing the hashed password is deleted.</p>\n<pre>echo \"generate cloud-config with encrypted password ..\"\nread -sp 'Enter password for Cloud-config: ' SECRET\nHASHEDPW=$(mkpasswd $SECRET --method=SHA-512 --rounds=4096)\ncp $customDataScript $customDataScript.tmp\nsed -i -e \"/password:/ s@:.*@: $HASHEDPW@\" $customDataScript.tmp</pre>\n<p>This way, I do not have to store a hashed password, not in the Github code repository, or on my local computer.\nI have the password stored in my Keepass password manager in case I forget it.</p>\n</div>\n<div class=\"section level2\" id=\"remote-desktop-access-using-rdp\">\n<h2>Remote desktop access using RDP</h2>\n<p>Since we want to use the VM as a remote desktop, we need a connection that supports graphics.\nBoth RDP and VNC are popular protocols for remote desktop access. I went with RDP as it appears the faster of the two, and because RDP is natively supported in Windows.</p>\n<p>I did not explore tunneling RDP over SSH or VPN because it would reduce performance too much, and it requires too much configuration on the client side, which is often not possible with company restricted laptops.</p>\n<p>To be able to use RDP with Linux we need to install <code>xrdp</code>. To be able to login to <code>xrdp</code> requires setting a password for the user that logs in, introducing a security risk. To mitigate this risk, Azure NSG (our firewall) only accepts RDP connections from the IP address attached to my local desktop system via my ISP.</p>\n</div>\n<div class=\"section level2\" id=\"fail2ban-for-ssh\">\n<h2>Fail2ban for SSH</h2>\n<p>fail2ban will dynamically block brute force attacks on the remote system. It is pre-configured for the default ssh port 22/tcp. As I am writing this blog, the VM is up and running, and every few hours an IP address get banned.\nIt is configured to ban an IP after 5 login attempts. A ban lasts for 10 min, after which the ban is released again.\nApparently this is for performance reasons, as we do not want to gather a very long list of IP addresses that needs to be scanned every time a new login attempt is made.</p>\n<pre>sudo apt install fail2ban</pre>\n<p>It is not enabled by default.</p>\n<pre>sudo cp jail.conf jail.local\nsudo systemctl enable fail2ban\nsudo systemctl start fail2ban\n\nsudo systemctl status fail2ban.service\r\n‚óè fail2ban.service - Fail2Ban Service\n     Loaded: loaded (/lib/systemd/system/fail2ban.service; enabled; vendor preset: enabled)\n     Active: active (running) since Sun 2024-01-14 21:21:40 UTC; 1min 48s ago\n       Docs: man:fail2ban(1)\n   Main PID: 563 (fail2ban-server)\n      Tasks: 5 (limit: 9510)\n     Memory: 17.7M\n        CPU: 298ms\n     CGroup: /system.slice/fail2ban.service\n             ‚îî‚îÄ563 /usr/bin/python3 /usr/bin/fail2ban-server -xf start\n\nJan 14 21:21:40 standev systemd[1]: Started Fail2Ban Service.\nJan 14 21:21:42 standev fail2ban-server[563]: Server ready</pre>\n<p>It should be possibly to have fail2ban also monitor failed RDP login attempts, that would improve security even more.\n<a class=\"uri\" href=\"https://stackoverflow.com/questions/75915624/xrdp-filter-setting-for-fail2ban\" rel=\"nofollow\" target=\"_blank\">https://stackoverflow.com/questions/75915624/xrdp-filter-setting-for-fail2ban</a></p>\n</div>\n</div>\n<div class=\"section level1\" id=\"create-the-vm\">\n<h1>Create the VM</h1>\n<p>We now are ready to bring it all together and create the VM. For this Azure CLI has the <code>az vm create</code> command.\nThe following example creates a VM that automatically starts up and runs our Cloud-init script:</p>\n<pre>az vm create \\\n  --resource-group $resourceGroup \\\n  --name $vmName \\\n  --nics $NICName \\\n  --image $vmImage \\\n  --storage-sku $storagetype \\\n  --size $vmSize \\\n  --admin-username $AdminUsername \\\n  --custom-data $customDataScript.tmp \\\n  --generate-ssh-keys \\\n  --output $azOutput \\\n  --security-type Standard # no trusted launch</pre>\n<p>Most options we already discussed above, except two:</p>\n<ul>\n<li><code>--custom-data</code>, this specifies the <strong>Cloud-init</strong> script that will passed on to the cloud-init enabled VM image and contains instructions to create user accounts, install packages etc.</li>\n<li><code>--generate-ssh-keys</code>, this was described under ‚ÄúSecuring the VM‚Äù.</li>\n</ul>\n<p>Although there are Azure CLI commands to stop, start and deallocate the VM, I typically use a shell script <code>deploy_vm_ubuntu.sh</code> to bring it up, leave it running while I need it, use the Azure Portal to manually stop and start the VM, and when no longer needed, tear it down using another script <code>delete_vm_ubuntu.sh</code>. This script simply uses <code>az group delete</code> to remove the Resource group containing the VM and related resources.</p>\n<p>After running the deploy script, we can ssh into the VM and verify that cloud-init is still running in the background:</p>\n<pre>(base) gertjan:~/azure_cli_scripts$ ssh <a class=\"__cf_email__\" data-cfemail=\"394a4d58574c4a5c4b795e4a4f5c4b51565c4f5c57174e5c4a4d5c4c4b56495c175a55564c5d5849491758434c4b5c175a5654\" href=\"/cdn-cgi/l/email-protection\">[email¬†protected]</a>\nWelcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.2.0-1018-azure x86_64)\n\n[....]\n\n\n*** System restart required ***\nTo run a command as administrator (user \"root\"), use \"sudo &lt;command&gt;\".\nSee \"man sudo_root\" for details.\n\nstanuser@standev:~$ cloud-init status\nstatus: running\nstanuser@standev:~$ exit</pre>\n<p>After some 25 minutes of installing software, the VM is ready for use.</p>\n<pre>Cloud-init v. 23.3.3-0ubuntu0~22.04.1 finished at Mon, 01 Jan 2024 18:09:08 +0000. \\\nDatasource DataSourceAzure [seed=/dev/sr0].  Up 1453.38 seconds</pre>\n<p>For the finishing touch, we (manually) do all upgrades to get the latest security updates, and reboot the system.</p>\n<pre>(base) gertjan:~/Werk/Github/gsverhoeven/azure_cli_scripts$  ssh <a class=\"__cf_email__\" data-cfemail=\"81f2f5e0eff4f2e4f3c1e6f2f7e4f3e9eee4f7e4efaff6e4f2f5e4f4f3eef1e4afe2edeef4e5e0f1f1afe0fbf4f3e4afe2eeec\" href=\"/cdn-cgi/l/email-protection\">[email¬†protected]</a>\n[...]\nsudo apt upgrade\nsudo reboot</pre>\n<p>After this, we are in business, let the Bayesian modelling commence!\n<img data-lazy-src=\"https://i0.wp.com/gsverhoeven.github.io/post/stan_in_azure/rdp_rstudio_stan.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i0.wp.com/gsverhoeven.github.io/post/stan_in_azure/rdp_rstudio_stan.png?w=578&amp;ssl=1\"/></noscript></p>\n</div>\n<div class=\"section level1\" id=\"lessons-learned\">\n<h1>Lessons learned</h1>\n<p>I learned several things from doing this.</p>\n<p>First, infrastructure as code is a form of software development, and as such needs a suitable development environment.\nThis means being able to rapidly test changes in e.g.¬†configuration scripts, and to be able to debug stuff by stripping things to the core.</p>\n<p>I improved the workflow by using QEMU, that allows me to work with Cloud-init enabled instances locally. This allowed me to figure out how cloud-init works without the overhead of doing a full cloud rollout, creating all the resources etc.</p>\n<p>However, as my local machine is quite dated (4 GB mem, 2 core CPU, so even worse than the cheap D-compute from Azure) executing the full init takes even longer than in the cloud, and I ran into memory problems as I can only run QEMU with 2 GB mem.\nSo repeating the full process every time we make a small change is not the way.</p>\n<p>Ultimately we need a build tool that breaks down the whole image building process into a pipeline of steps, saving intermediate results. Basically a <code>make</code> tool for VM (golden) image building. Then if we change some code, it could use graph dependencies to figure out which parts are affected and need to be rebuild. My next step here would be to look at <a href=\"https://github.com/ansible/ansible\" rel=\"nofollow\" target=\"_blank\">Ansible</a> or an open source alternative to HashiCorp Packer.</p>\n<p>In addition, there is this <a href=\"https://en.wikipedia.org/wiki/Containerization_(computing)\" rel=\"nofollow\" target=\"_blank\">Container thing</a>, with Docker etc. This might offer a different way of ‚Äúdesktop computing‚Äù where I develop locally and run analyses in <a href=\"https://en.wikipedia.org/wiki/Docker_(software)\" rel=\"nofollow\" target=\"_blank\">Docker</a> containers in the cloud, managed by <a href=\"https://en.wikipedia.org/wiki/Kubernetes\" rel=\"nofollow\" target=\"_blank\">Kubernetes</a>. This is completely uncharted territory for me.</p>\n<p>Another thing I found that Cloud computing is expensive. Even with the most low cost options, for a 24/7 desktop solution in the cloud we still end up paying around a 100 euro per month. And that‚Äôs with a 2 core 8GB RAM machine! This is the price we pay for the flexibility of renting without any long term commitment, the hardware already being there, it just works etc.</p>\n<p>Finally, I am used to the relatively safe computing environment at home behind an ISP‚Äôs firewall. In the public cloud, we are fully exposed, and one can actually see the continuous break-in attempts occurring by the hour. That somehow feels a bit.. chilly.</p>\n<p>To be continued ‚Ä¶</p>\n</div>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://gsverhoeven.github.io/post/azure-stan-linux/\"> Statistics | Gertjan Verhoeven</a></strong>.</div>\n<hr>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</hr></div> </div>\n</article>",
      "main_text": "Statistical computing on a shoestring: Stan in the Azure cloud using Cloud-init\nPosted on\nJanuary 14, 2024\nby\nStatistics | Gertjan Verhoeven\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nStatistics | Gertjan Verhoeven\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nPhoto source: cropped from original by Taylor van Riper\nhttps://unsplash.com/@taylorvanriper925\nGraphics source: Michael Betancourt at\nstan-dev/propaganda\nTime to explore what the public cloud is all about.\nOur goal is to write code (i.e.¬†scripts) using open-source tools to automatically set up cloud infrastructure. In short, we want\nInfrastructure as code\n.\nFor this I chose a specific use case, which is\nspinning up a low cost data analysis development environment with R, Rstudio and Stan tools\ninstalled and configured.\nThis has two big advantages,\nreproducibility\nand\nlower switching cost\n:\nScripting the compute resources that made a data analysis possible is the next level in reproducibility.\nIdeally, we want our scripts to be independent of a particular cloud provider. This would allow us to easily change from e.g.¬†Azure to Amazon AWS if things stagnate or we can get a better deal elsewhere.\nI ended up writing Linux shell scripts that use the\nAzure command-line interface (Azure CLI)\nto deploy a Linux VM configured using\nCloud-init\n. While doing so I discovered that being able to test changes locally first before deploying to the cloud speeds up development significantly.\nTo summarize and motivate the tech choices I made:\nI chose\nAzure\nsince my employer recently moved to Azure and me learning it would be beneficial for work.\nI chose\nAzure CLI\nto write simple shell scripts without the additional abstraction layer introduced by more generic tools like Terraform/OpenTofu or Ansible\nI chose\nLinux Ubuntu OS\nto keep cost down, as it is free and needs less resources than\nWindows 10/11\nI chose\nCloud-init\nas it has emerged as the standard way to configure Linux cloud images across all cloud platforms\nI chose the\nQEMU Quick Emulator\nto run VMs locally to speed up development\nThe blog uses Linux throughout, but the Azure CLI commands should work for Windows as well.\nAll scripts mentioned in this blog are available in a separate Github repository,\ngsverhoeven/azure_cli_scripts\n.\nCloud computing in Azure on a shoestring\nSo what do we need to pay for this low cost cloud computing data analytics VM?\nFor a single VM the main cost driver is the VM itself. We need at least 8GB of RAM and a minimum of 2 CPU, so we end up with a\nStandard D2s\nVM. At the time of writing, monthly cost, assuming 24/7 usage is 73 euro.\n(To find out about these prices in the first place: Azure shows them when you select ‚Äúcreate new VM‚Äù in the portal)\nWe have two additional small cost drivers, the associated disk (‚Äústorage‚Äù), and we need to pay for a public IP address, each roughly 0.1 euro per day.\nIf we would bring the VM up and keep it on for a whole day we pay around 2.5 euro a day.\nIf we only use it for 8 hours, cost is reduced to an estimated 1 euro per day.\nIf we stop the VM such that the resources are released (deallocated), we only need to pay for the IP and disk storage, which is 0.2 euro per day, or 6 euro on a monthly basis. This allows us a ‚Äúfast resume‚Äù option that avoids waiting 30 min to install and configure all the software. I tried this, it is a feasible strategy, it takes a minute or so to boot up.\nOk let‚Äôs do it!\nSetting up our local IaaS dev environment\nAs mentioned above, we use both\nAzure CLI\nand\nQEMU virtual emulator\nfor local VM development.\nI started with creating a free account on Azure. This comes with 200 Euro free credit to spent within a month.\nThen I installed\nazure-cli\non my local system (Ubuntu 18.04 LTS):\n#downloads the signing key from Microsoft\ncurl -sL https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/microsoft.gpg > /dev/null \n## creates a file called microsoft.gpg in the folder where keys are stored\n\nAZ_REPO=$(lsb_release -cs) ## outputs the codename for the linux distribution i.e. Ubuntu 18.04 = bionic\necho \"deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ $AZ_REPO main\" | sudo tee /etc/apt/sources.list.d/azure-cli.list \n## writes that URL to the package resource list\nsudo apt-get update\nsudo apt-get install azure-cli\nFirst time we use\nazure-cli\nlocally we need authenticate:\n# Log in interactively using the browser.\naz login\nTest if it works by creating and deleting a new resource group:\naz group create --location westeurope --resource-group MyCoolRG -o table\nLocation    Name\n----------  --------\nwesteurope  MyCoolRG\nGreat! that worked. Now let‚Äôs get rid of it.\naz group delete --resource-group MyCoolRG\nNext we install\nQEMU\n, which stands for Quick Emulator. The documentation for Cloud-init contains a section on\nhow to work with QEMU\n. This will be our local development environment to test Cloud-init scripts before launching them on the cloud.\nInstall QEMU:\nsudo apt install qemu-kvm\nThis installs QEMU 2.11 (2018) that plays well with Ubuntu 18.04.\nQEMU on Ubuntu works with hypervisor KVM to run virtual machines locally. Each virtual machine has private virtualized hardware: a network card, disk, graphics adapter, etc. For windows VMware is a popular alternative.\nQEMU upon first use threw an error ‚Äú/dev/kvm device: permission denied‚Äù that I fixed by adding my own user account to the\nkvm\ngroup\nafter reading this explanation\n:\nsudo adduser gertjan kvm\nOn my machine, all users in group\nkvm\nhave\nrw\naccess for\n/dev/kvm\n, thereby fixing the permission error.\n(base) gertjan:~$ qemu-system-x86_64 --version\nQEMU emulator version 2.11.1(Debian 1:2.11+dfsg-1ubuntu7.41)\nCopyright (c) 2003-2017 Fabrice Bellard and the QEMU Project developers\nCreating the Azure infrastucture\nAzure is organized as a hierarchical structure. See the schematic below.\nAll the components that make up the infrastructure are called\nresources\n. Traversing upwards through the hierarchy:\nResources\nare contained within\nresource groups\n.\nResource groups\nexist within a\nsubscription\n.\nFinally,\nsubscriptions\nexist within\nmanagement groups\n.\nIn this blog post, we will create the infrastructure we need from scratch.\nOur desired infrastructure consists of a single virtual network that contains a single virtual machine (VM)\nThe VM will be configured to be accessible through the internet using SSH and ‚ÄúMicrosoft Remote Desktop‚Äù (RDP).\nTo quickly create a VM in Azure, it is possible to use a single Azure CLI command with default values that automatically creates any required supporting resources.\nHowever, to really understand the Azure building blocks and their dependencies, it is better to create each Azure resource separately.\nIn doing so we gradually build up the infrastructure step by step.\n(An official Azure tutorial by Cynthia Nottingham and others that takes a similar approach can be found\nhere\n)\nSpecial attention is given to secure our network and VM, because it is exposed to the public internet.\nHackers are continuously scanning the Azure network IP address ranges for vulnerable systems, so we need to defend ourselves.\nWe use a basic Firewall called ‚ÄúNetwork Security Group‚Äù that works with\nSecurity Rules\n.\nMore on our security measures below. I chose not to use an ‚ÄúAvailability Set‚Äù as this only makes sense for groups of VMs.\nI use Linux shell Environment Variables to separate the\nAzure configuration parameters\n(which image, which VM type etc) from the actual Azure CLI commands that create the resources.\nTo view my current configuration file containing all Azure parameters:\ngsverhoeven/azure_cli_scripts/main/azure_config_ubuntu.sh\nStep-by-step guide to set up the VM\nFirst we create a new\nResource group\nThen we create a\nVirtual Network\nwith a\nSubnet\nThen we create a\nPublic IP\nThen we create a\nNetwork Security Group\n& Rules\nThen we create a\nNetwork Interface Card (NIC)\nThen we choose the\nVM image\n,\nVM size\nand\nVM storage type\nThen we write a\nCloud-init script\nto initialize the VM\nFinally we\ncreate the VM\nand enjoy the show\nCreate resource Group\nFirst we create a new\nResource Group\n,\nmyRGtest\n.\nThis needs a location. Since I am in West Europe, let‚Äôs choose\nwesteurope\n.\n# create shell variables\nresourceGroup=myRGtest\nlocation=westeurope\naz group create --name $resourceGroup --location $location\naz group show --resource-group $resourceGroup\nCreate Virtual Network\nNext we create a\nVirtual Network\nand a\nSubnet\n, as explained in\nthe Azure documentation\n:\n# create shell variables\nvnetName=StanDEV-VNet1\nsubnetName=StanDEV-Subnet1\nvnetAddressPrefix=10.0.0.0/16\nsubnetAddressPrefix=10.0.0.0/24\n\naz network vnet create \\\n  --name $vnetName \\\n  --resource-group $resourceGroup \\\n  --address-prefixes $vnetAddressPrefix \\\n  --subnet-name $subnetName \\\n  --subnet-prefixes $subnetAddressPrefix\nCreate Public IP address\nNow let‚Äôs create a public IP address with\naz network public-ip create\n.\npublicIP=TEST-public-ip\nmypublicdns=gsverhoeven\n\necho \"creating public IP address ..\"\naz network public-ip create \\\n    --resource-group $resourceGroup \\\n    --name $publicIP \\\n    --sku standard \\\n    --dns-name $mypublicdns \\\n    --output $azOutput \\\n    --zone 1 # non-zonal IP\nThis public IP address enables us to connect to the VM from the Internet.\nThis command results in an IP address with a Fully qualified domain name (FQDN) of\ngsverhoeven.westeurope.cloudapp.azure.com\nnslookup  gsverhoeven.westeurope.cloudapp.azure.com\n#Server:        127.0.0.53\n#Address:   127.0.0.53#53\n\n#Non-authoritative answer:\n#Name:  gsverhoeven.westeurope.cloudapp.azure.com\n#Address: 68.219.248.112\naz network public-ip list -o table\nName            ResourceGroup    Location    Zones    Address        IdleTimeoutInMinutes    ProvisioningState\n--------------  ---------------  ----------  -------  -------------  ----------------------  -------------------\nTEST-public-ip  myRGtest         westeurope           104.46.41.142  4                       Succeeded\nCreate network security group & Rules\nTo control the flow of traffic in and out of our VM, we use a so-called\nnetwork security group\n. The following example uses\naz network nsg create\nto create a network security group named\nmyNSG\n:\nNetworkSecurityGroup=myNSG\n\naz network nsg create \\\n    --resource-group $resourceGroup \\\n    --name $NetworkSecurityGroup\nThis works by defining rules that allow or deny specific traffic.\nA new NSG starts with a set of default rules, among which is the rule that all inbound traffic is blocked.\nRules are processed in priority order, with lower numbers processed before higher numbers, because lower numbers have higher priority. Once traffic matches a rule, processing stops.\nTo allow inbound connections on port 22 (to enable SSH access)\n, create an inbound rule with\naz network nsg rule create\n. The following example creates a rule named\nmyNetworkSecurityGroupRuleSSH\n:\necho \"create SSH rule ..\"\naz network nsg rule create \\\n    --resource-group $resourceGroup \\\n    --nsg-name $NetworkSecurityGroup \\\n    --name myNetworkSecurityGroupRuleSSH \\\n    --description \"Allow SSH at port 22\" \\\n    --protocol tcp \\\n    --priority 1000 \\\n    --destination-port-range 22 \\\n    --access allow \\\n    --output $azOutput\nTo allow\nRemote Desktop traffic\nto reach your Linux VM, add another network security group rule.\nThe following example creates a rule named\nmyNetworkSecurityGroupRuleRDP\n:\necho \"create RDP rule ..\"\naz network nsg rule create \\\n    --resource-group $resourceGroup \\\n    --nsg-name $NetworkSecurityGroup \\\n    --name myNetworkSecurityGroupRuleRDP \\\n    --description \"Allow RDP at port 3389\" \\\n    --direction Inbound \\\n    --protocol tcp \\\n    --priority 1001 \\\n    --destination-port-range 3389 \\\n    --access allow \\\n    --output $azOutput \\\n    --source-address-prefixes $trustedIPAdress\nExamine the network security group and rules with\naz network nsg rule list\n:\necho \"check NSG rules ..\"\naz network nsg rule list \\\n    --resource-group $resourceGroup \\\n    --nsg-name $NetworkSecurityGroup \\\n    --output table\nCreate NIC\nVirtual network interface cards (NICs) are programmatically available because you can apply rules to their use.\nIn the following\naz network nic create\ncommand, we create a NIC named\nmyNic\nand associate it with our network security group. The public IP address we created above is also associated with the virtual NIC.\necho \"create NIC ..\"\naz network nic create \\\n    --resource-group $resourceGroup \\\n    --name $NICName \\\n    --vnet-name $vnetName \\\n    --subnet $subnetName \\\n    --public-ip-address $publicIP \\\n    --output $azOutput \\\n    --network-security-group $NetworkSecurityGroup\nFrom the dependencies, we can see that a NIC ties together:\nA Network Security Group,\nA public IP,\nA VNet & subnet,\nall within a resource group. Later on, when we create the VM, we only need to specify the NIC to bring up the VM in the virtual network with the desired NSG.\nVM Image choice\nAs VM image I chose\nUbuntu Server 22.04 LTS\nfor reasons already mentioned above.\nBut which one, how do we find the image we need?\nCanonical, the company behind Ubuntu Linux, offers various preconfigured Ubuntu images in the Azure Marketplace.\nAzure CLI can be used to programmatically interact with Azure Marketplace. I used\nthis blog post by Joshua Powers\nto learn how this works.\nAll images published by Canonical are discoverable using the following command:\naz vm image list-skus \\\n--publisher Canonical \\\n--offer Ubuntu \\\n--location westeurope \\\n-o table\nLocation    Name\n----------  ----------------------\nwesteurope  18_04-lts\nwesteurope  18_04-lts-gen2\nwesteurope  18_04-lts-minimal\nwesteurope  18_04-lts-minimal-gen2\n...\nwesteurope  22_04-lts\nwesteurope  22_04-lts-gen2\nwesteurope  22_04-lts-minimal\nwesteurope  22_04-lts-minimal-gen2\n...\nI went with\n22_04-lts\n.\nVM Size choice\nThere is a bewildering amount of choice regarding\ndifferent types of VMs offered by Microsoft\n. As my focus is on cheap, general purpose compute, I ended up with D-series VMs.\nAzureprice.net shows regional price variation, however without subscription it only shows the extent of the price variation.\nMy current heuristic is taking the median (i.e.¬†middle) price, so far it seems to give a good estimate of monthly pay-as-you-go prices for west-europe.\nhttps://azureprice.net/vm/Standard_D2s_v3?currency=EUR&timeoption=day&paymentType=payasyougo\nTo have a reasonable fast software install I found we need at least 8GB of mem and 2 vCPUs, this corresponds to\nStandard_D2s_v3\n. With this VM, cloud-init installation finishes after 23 min, after which the VM is fully operational.\nThis has a monthly cost of 78 euro (based on 24/7 usage).\n`Standard` is recommended tier.\nD ‚Äì General purpose compute\n2 ‚Äì VM Size\ns ‚Äì Premium Storage capable\nv3 ‚Äì version\nDisk storage associated with the VM\nWhen an Azure virtual machine is created, two disks are automatically attached to the virtual machine.\nThe disk that holds the VM image (in our case Ubuntu 22) is called the\nOS disk\n. In Azure, the\ndefault OS disk size for Linux VMs\nis currently at 30 GB. This appears to also be the minimum OS disk size, there is only the option to expand them. The OS disk is labeled\n/dev/sda\nby default.\nIn addition, there is a\ntemp disk\nmounted that is physically located on the Azure host where the VM is running. This can only be used for temporary data processing, and its size is given. It does not incur any extra cost. Temporary disks are labeled\n/dev/sdb\nand have a mountpoint of\n/mnt\n. More info on temp disks\nhere\nN.b.\nI did not go so far as to attach a\ndata disk\n. So we need to make sure that work we do on the VM is pushed to e.g.¬†Github, because if we tear the VM down, the user data is lost as well.\nThe Disk types are controlled by the\n-storage-sku\noption when we create the VM.\nAllowed values for this option include\nStandard_LRS\nfor traditional hard disks (HDD),\nStandardSSD_LRS\nand\nPremium_LRS\nboth consists of SSD disks but with differing performance characteristics. Locally redundant storage (LRS) replicates your data three times within a single data center in the selected region. More info at\nAzure disk types\nWe want the cheapest SSD option, this seems to be\nStandardSSD_LRS\n.\nCloud-init to automate software installation and VM configuration\nAt this point we could stop, and create the VM. However, it would just be a plain out-of-the-box Linux installation.\nAnd our goal is to use the VM for data science, Bayesian modelling in particular!\nSo directly after creating the VM, we want to install additional software on it.\nFor this we use the open source tool\nCloud-init\n. It typically runs directly after a cloud instance is created.\nCloud-init is cross-platform across the public cloud, so in theory we should be able to easily move our instance from one cloud provider to another.\nAlready in the early days of cloud computing (2007), people recognized the need to automatically configure cloud instances using user defined scripts. Around that time Cloud-init was born (it was called\nec2-init\nat that time, because at that time AWS EC2 basically WAS the complete public cloud).\nAccording to the documentation:\nCloud-init is an open source initialisation tool that was designed to make it easier to get your systems up and running with a minimum of effort, already configured according to your needs. [‚Ä¶] During boot, cloud-init identifies the cloud it is running on and initialises the system accordingly. Cloud instances will automatically be provisioned during first boot with networking, storage, SSH keys, packages and various other system aspects already configured.\nHere\nis a nice overview introduction.\nCloud-init\nneeds a script or cloud config that will be run directly after provisioning the VM.\nThis is called ‚ÄúUser data‚Äù by most cloud providers, M$ calls it\ncustom-data\n.\nAlthough it can run any shell script, there is also a declarative YAML based configuration file that works with modules to perform common tasks like adding users, updating and installing linux software packages etc.\nFor this blog I went with a YAML file called\ncloud_init_cfg.yaml\n.\nThe content of this file can be inspected\nhere\n.\nTesting cloud-init on the local file system using QEMU\nAs we are developing our cloud config script, we want to test it locally before deploying the whole shabam to the Azure cloud, as this is slow (you don‚Äôt want to wait 10 minutes to discover you made a typo .. AGAIN!!).\nEnter the\nQEMU virtualizer\n(website\nhere\n), that can act as a virtualization host to run the instance locally.\nAs the Cloud-init enabled instance is booted up inside QEMU, it needs a data source to fetch the cloud config script from.\nCloud-init supports the\nspecial data source ‚Äúnocloud‚Äù\nthat allows us to use the local file system to offer the data source to the instance in three variants. I use the variant with a local HTTP server running using the python built-in webserver at local port 8000:\ngnome-terminal -- python3 -m http.server --directory .\nThe url of the webserver is communicated to the instance by\nQemu\nusing a\nhack\n, which is putting it into the serial number field of the SMBIOS:\n-smbios type=1,serial=ds='nocloud;s=http://10.0.2.2:8000/'\nHere is example code that downloads a Cloud-init enabled Ubuntu 22.04 image (\njammy\n) for local testing.\nThe initial (virtual) disk size of the image is 2.2 GB, which is too small to install all the software we need to run Rstudio.\nSo we increase the image size to 30GB. After that we fire up the instance with QEMU:\nwget https://cloud-images.ubuntu.com/jammy/current/jammy-server-cloudimg-amd64.img\nqemu-img info jammy-server-cloudimg-amd64.img \n# 2.2 GB\nqemu-img resize jammy-server-cloudimg-amd64.img 30G\n\nqemu-system-x86_64                                            \\\n    -net nic                                                    \\\n    -net user\n    -machine accel=kvm                                          \\ # use hardware acceleration\n    -cpu host                                                   \\ # emulate host processor\n    -m 1024                                                      \\ # use 1 GB RAM\n    -nographic                                                  \\ # graphic window disabled\n    -hda jammy-server-cloudimg-amd64.img                        \\ # Set a virtual hard drive and use the specified image file \n    -smbios type=1,serial=ds='nocloud;s=http://10.0.2.2:8000/'\nubuntu@jammy:~$ sudo lsblk -d | grep disk\nfd0     2:0    1     4K  0 disk \nsda     8:0    0    30G  0 disk\nI ended up writing a script\ndo_qemu.sh\nthat starts a local VM using the same cloud-config YAML file that is also used to configure the actual Azure VM. This allowed for fast development and seamless switching between local and cloud testing.\nUsing cloud-init to install additional packages\nUsing Cloud-init‚Äôs\npackages\nmodule, we install the following software:\ninxi (system information tool)\nFirefox\nFail2ban (Blocking of bad IP addresses)\nXFCE4 desktop (default ubuntu image comes without a desktop)\nxRDP (to use the VM as a remote desktop)\nGNU make and g++ compiler (to compile R packages as well as Stan programs)\nvarious dependencies for R packages, notably tidyverse\nUsing cloud-init to run scripts on the VM during late boot\nTo configure Fail2ban, xRDP, install R and Rstudio, I wrote separate scripts that perform the necessary steps.\nThese scripts are contained within the\ncloud_init_cfg.yaml\nfile to be written to disk within the instance during early init. At late init, the scripts are then executed one after another.\n[bash, /enable_fail2ban.sh ]\n[bash, /install_xrdp.sh ]\n[bash, /install_r.sh ]\n[bash, /install_rstudio.sh ]\nSecuring our VM\nFor a VM with a public IP on the hostile internet, we need some security measures in place.\n‚ÄúHackers‚Äù will be using a list of azure IPs and will attempt brute force SSH to gain access.\nSee for example this\npost on superuser.com\n.\nThere are sites that document so called ‚Äúbad IPs‚Äù, known culprits of e.g.¬†unauthorized scanning for open ports:\nIPsum Github repository\nlist with bad IPs, including a Wall of Shame\nAbuseIPDB\n, a database of abusive IP addresses.\nSome of these were indeed scanning my VM as well.\nWe take the following steps to secure our VM from outside attacks:\nSSH password authentication is disabled, access only through SSH keys\nWe generate an password (needed for RDP logon) on the fly from keyboard input when creating the VM\nOnly RDP connections from a single trusted IP address are allowed\nAll other ports are closed for inbound traffic using Azure NSG\nUse\nFail2ban\nto ban IPs that have multiple unsuccessful SSH login attempts\nNSG is a basic type of firewall, that is relatively dumb.\nIt does not know about applications, it just filters network packets based on rules.\nSo we use it to block all incoming connections from the internet, except SSH and RDP.\nTo connect using SSH, a private key is needed that is only available on my local desktop system. When someone tries to brute force the SSH connection, their IP is banned after a few unsuccessful login attempts.\nTo connect using RDP, it only accepts connections from the IP address attached to my local desktop system via my ISP. It would be nice to add RDP to fail2ban, however this apparently is not easy.\nHopefully this is enough security for a single VM without important secrets, and I did not make any mistake here üôÇ\n(Microsoft has created a product ‚ÄúAzure Bastion‚Äù for our use case, when we want to use RDP / remote desktop into a VM on Azure, but do not want to use a VPN or expose the VM using a public IP address. It seems expensive though ..)\nTo explain and document I will now describe my security measures in more detail, starting with SSH access.\nSSH access\nA common, secure way of connecting to a VM is through a ‚Äúsecure shell‚Äù aka SSH connection.\nIt is secure because all traffic is encrypted. We can either use passwords or work with ‚Äúkey pairs‚Äù. We choose SSH keys because it is safer, since passwords can be guessed or brute-force discovered.\nSSH works with so-called ‚Äúkey pairs‚Äù, that consist of a public and private key. The private key is kept secret and is stored on our local system. The public key is passed to the VM when it is created. The VM uses this public key to encrypt all communication. To decrypt this communication, the private key is needed. Since nobody else has this key except we ourselves on our local system in a safe place, the connection is safeguarded.\nWe need to generate a public and private key for ourselves, and get it on the new VM.\nWe use the\n--generate-ssh-keys\nparameter to create them the first time we create the VM. After that, since we already have a key pair, this parameter uses existing keys in\n~/.ssh\n.\nSince SSH communication goes back and forth between our local system and the VM, we also need to encrypt the information we send to the VM. For that we need to use the\nVM‚Äôs public\nkey that it hands out to whoever wants to communicate with it. We fetch after VM creation using\nssh-keyscan\n:\nssh-keyscan -H $mypublicdns.westeurope.cloudapp.azure.com >> ~/.ssh/known_hosts\nAfter all this, we can connect to the VM using SSH without the need to supply a password, the key-pairs in the background take care of the authentication process.\n(base) gertjan:~$ ssh\n[email¬†protected]\nWelcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.2.0-1018-azure x86_64)\n\n[...]\n\nLast login: Sun Jan 14 22:02:30 2024 from 77.248.168.82\nstanuser@standev:~$\nInteractive password generation for RDP access\nFor remote desktop access with sufficient performance (no lags) we still need to set a password on the VM when we create it.\nSince we want a fully scripted process of VM creation, I needed a secure way to generate and set a password during VM creation. In the end, I figured out a way to accomplish this using a shell script with an interactive prompt, that dynamically inserts the hashed password into the Cloud-init config file. This config file is then used to set the password on the VM upon creation, after which the copy of the config file containing the hashed password is deleted.\necho \"generate cloud-config with encrypted password ..\"\nread -sp 'Enter password for Cloud-config: ' SECRET\nHASHEDPW=$(mkpasswd $SECRET --method=SHA-512 --rounds=4096)\ncp $customDataScript $customDataScript.tmp\nsed -i -e \"/password:/ s@:.*@: $HASHEDPW@\" $customDataScript.tmp\nThis way, I do not have to store a hashed password, not in the Github code repository, or on my local computer.\nI have the password stored in my Keepass password manager in case I forget it.\nRemote desktop access using RDP\nSince we want to use the VM as a remote desktop, we need a connection that supports graphics.\nBoth RDP and VNC are popular protocols for remote desktop access. I went with RDP as it appears the faster of the two, and because RDP is natively supported in Windows.\nI did not explore tunneling RDP over SSH or VPN because it would reduce performance too much, and it requires too much configuration on the client side, which is often not possible with company restricted laptops.\nTo be able to use RDP with Linux we need to install\nxrdp\n. To be able to login to\nxrdp\nrequires setting a password for the user that logs in, introducing a security risk. To mitigate this risk, Azure NSG (our firewall) only accepts RDP connections from the IP address attached to my local desktop system via my ISP.\nFail2ban for SSH\nfail2ban will dynamically block brute force attacks on the remote system. It is pre-configured for the default ssh port 22/tcp. As I am writing this blog, the VM is up and running, and every few hours an IP address get banned.\nIt is configured to ban an IP after 5 login attempts. A ban lasts for 10 min, after which the ban is released again.\nApparently this is for performance reasons, as we do not want to gather a very long list of IP addresses that needs to be scanned every time a new login attempt is made.\nsudo apt install fail2ban\nIt is not enabled by default.\nsudo cp jail.conf jail.local\nsudo systemctl enable fail2ban\nsudo systemctl start fail2ban\n\nsudo systemctl status fail2ban.service\n‚óè fail2ban.service - Fail2Ban Service\n     Loaded: loaded (/lib/systemd/system/fail2ban.service; enabled; vendor preset: enabled)\n     Active: active (running) since Sun 2024-01-14 21:21:40 UTC; 1min 48s ago\n       Docs: man:fail2ban(1)\n   Main PID: 563 (fail2ban-server)\n      Tasks: 5 (limit: 9510)\n     Memory: 17.7M\n        CPU: 298ms\n     CGroup: /system.slice/fail2ban.service\n             ‚îî‚îÄ563 /usr/bin/python3 /usr/bin/fail2ban-server -xf start\n\nJan 14 21:21:40 standev systemd[1]: Started Fail2Ban Service.\nJan 14 21:21:42 standev fail2ban-server[563]: Server ready\nIt should be possibly to have fail2ban also monitor failed RDP login attempts, that would improve security even more.\nhttps://stackoverflow.com/questions/75915624/xrdp-filter-setting-for-fail2ban\nCreate the VM\nWe now are ready to bring it all together and create the VM. For this Azure CLI has the\naz vm create\ncommand.\nThe following example creates a VM that automatically starts up and runs our Cloud-init script:\naz vm create \\\n  --resource-group $resourceGroup \\\n  --name $vmName \\\n  --nics $NICName \\\n  --image $vmImage \\\n  --storage-sku $storagetype \\\n  --size $vmSize \\\n  --admin-username $AdminUsername \\\n  --custom-data $customDataScript.tmp \\\n  --generate-ssh-keys \\\n  --output $azOutput \\\n  --security-type Standard # no trusted launch\nMost options we already discussed above, except two:\n--custom-data\n, this specifies the\nCloud-init\nscript that will passed on to the cloud-init enabled VM image and contains instructions to create user accounts, install packages etc.\n--generate-ssh-keys\n, this was described under ‚ÄúSecuring the VM‚Äù.\nAlthough there are Azure CLI commands to stop, start and deallocate the VM, I typically use a shell script\ndeploy_vm_ubuntu.sh\nto bring it up, leave it running while I need it, use the Azure Portal to manually stop and start the VM, and when no longer needed, tear it down using another script\ndelete_vm_ubuntu.sh\n. This script simply uses\naz group delete\nto remove the Resource group containing the VM and related resources.\nAfter running the deploy script, we can ssh into the VM and verify that cloud-init is still running in the background:\n(base) gertjan:~/azure_cli_scripts$ ssh\n[email¬†protected]\nWelcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.2.0-1018-azure x86_64)\n\n[....]\n\n*** System restart required ***\nTo run a command as administrator (user \"root\"), use \"sudo <command>\".\nSee \"man sudo_root\" for details.\n\nstanuser@standev:~$ cloud-init status\nstatus: running\nstanuser@standev:~$ exit\nAfter some 25 minutes of installing software, the VM is ready for use.\nCloud-init v. 23.3.3-0ubuntu0~22.04.1 finished at Mon, 01 Jan 2024 18:09:08 +0000. \\\nDatasource DataSourceAzure [seed=/dev/sr0].  Up 1453.38 seconds\nFor the finishing touch, we (manually) do all upgrades to get the latest security updates, and reboot the system.\n(base) gertjan:~/Werk/Github/gsverhoeven/azure_cli_scripts$  ssh\n[email¬†protected]\n[...]\nsudo apt upgrade\nsudo reboot\nAfter this, we are in business, let the Bayesian modelling commence!\nLessons learned\nI learned several things from doing this.\nFirst, infrastructure as code is a form of software development, and as such needs a suitable development environment.\nThis means being able to rapidly test changes in e.g.¬†configuration scripts, and to be able to debug stuff by stripping things to the core.\nI improved the workflow by using QEMU, that allows me to work with Cloud-init enabled instances locally. This allowed me to figure out how cloud-init works without the overhead of doing a full cloud rollout, creating all the resources etc.\nHowever, as my local machine is quite dated (4 GB mem, 2 core CPU, so even worse than the cheap D-compute from Azure) executing the full init takes even longer than in the cloud, and I ran into memory problems as I can only run QEMU with 2 GB mem.\nSo repeating the full process every time we make a small change is not the way.\nUltimately we need a build tool that breaks down the whole image building process into a pipeline of steps, saving intermediate results. Basically a\nmake\ntool for VM (golden) image building. Then if we change some code, it could use graph dependencies to figure out which parts are affected and need to be rebuild. My next step here would be to look at\nAnsible\nor an open source alternative to HashiCorp Packer.\nIn addition, there is this\nContainer thing\n, with Docker etc. This might offer a different way of ‚Äúdesktop computing‚Äù where I develop locally and run analyses in\nDocker\ncontainers in the cloud, managed by\nKubernetes\n. This is completely uncharted territory for me.\nAnother thing I found that Cloud computing is expensive. Even with the most low cost options, for a 24/7 desktop solution in the cloud we still end up paying around a 100 euro per month. And that‚Äôs with a 2 core 8GB RAM machine! This is the price we pay for the flexibility of renting without any long term commitment, the hardware already being there, it just works etc.\nFinally, I am used to the relatively safe computing environment at home behind an ISP‚Äôs firewall. In the public cloud, we are fully exposed, and one can actually see the continuous break-in attempts occurring by the hour. That somehow feels a bit.. chilly.\nTo be continued ‚Ä¶\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nStatistics | Gertjan Verhoeven\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "Photo source: cropped from original by Taylor van Riper https://unsplash.com/@taylorvanriper925 Graphics source: Michael Betancourt at stan-dev/propaganda Time to explore what the public cloud is all about. Our goal is to write code (i.e. scripts) using open-source tools to automatically set up cloud infrastructure. In short, we want Infrastructure as code. For this I chose a specific use case, which is spinning up a low cost data analysis development environment with R, Rstudio and Stan tools installed and configured. This has two big advantages, reproducibility and lower switching cost: Scripting the compute resources that made a data analysis possible is the next level in reproducibility. Ideally, we want our scripts to be independent of a particular cloud provider. This would allow us to easily change from e.g. Azure to Amazon AWS if things stagnate or we can get a better deal elsewhere. I ended up writing Linux shell scripts that use the Azure command-line interface (Azure CLI) to deploy a Linux VM configured using Cloud-init. While doing so I discovered that being able to test changes locally first before deploying to the cloud speeds up development significantly. To summarize and motivate the tech choices I made: I chose Azure since my employer recently moved to Azure and me learning it would be beneficial for work. I chose Azure CLI to write simple shell scripts without the additional abstraction layer introduced by more generic tools like Terraform/OpenTofu or Ansible I chose Linux Ubuntu OS to keep cost down, as it is free and needs less resources than Windows 10/11 I chose Cloud-init as it has emerged as the standard way to configure Linux cloud images across all cloud platforms I chose the QEMU Quick Emulator to run VMs locally to speed up development The blog uses Linux throughout, but the Azure CLI commands should work for Windows as well. All scripts mentioned in this blog are available in a separate Github repository, gsverhoeven/azure_cli_scripts. Cloud computing in Azure on a shoestring So what do we need to pay for this low cost cloud computing data analytics VM? For a single VM the main cost driver is the VM itself. We need at least 8GB of RAM and a minimum of 2 CPU, so we end up with a Standard D2s VM. At the time of writing, monthly cost, assuming 24/7 usage is 73 euro. (To find out about these prices in the first place: Azure shows them when you select ‚Äúcreate new VM‚Äù in the portal) We have two additional small cost drivers, the associated disk (‚Äústorage‚Äù), and we need to pay for a public IP address, each roughly 0.1 euro per day. If we would bring the VM up and keep it on for a whole day we pay around 2.5 euro a day. If we only use it for 8 hours, cost is reduced to an estimated 1 euro per day. If we stop the VM such that the resources are released (deallocated), we only need to pay for the IP and disk storage, which is 0.2 euro per day, or 6 euro on a monthly basis. This allows us a ‚Äúfast resume‚Äù option that avoids waiting 30 min to install and configure all the software. I tried this, it is a feasible strategy, it takes a minute or so to boot up. Ok let‚Äôs do it! Setting up our local IaaS dev environment As mentioned above, we use both Azure CLI and QEMU virtual emulator for local VM development. I started with creating a free account on Azure. This comes with 200 Euro free credit to spent within a month. Then I installed azure-cli on my local system (Ubuntu 18.04 LTS): #downloads the signing key from Microsoft curl -sL https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/microsoft.gpg > /dev/null ## creates a file called microsoft.gpg in the folder where keys are stored AZ_REPO=$(lsb_release -cs) ## outputs the codename for the linux distribution i.e. Ubuntu 18.04 = bionic echo \"deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ $AZ_REPO main\" | sudo tee /etc/apt/sources.list.d/azure-cli.list ## writes that URL to the package resource list sudo apt-get update sudo apt-get install azure-cli First time we use azure-cli locally we need authenticate: # Log in interactively using the browser. az login Test if it works by creating and deleting a new resource group: az group create --location westeurope --resource-group MyCoolRG -o table Location Name ---------- -------- westeurope MyCoolRG Great! that worked. Now let‚Äôs get rid of it. az group delete --resource-group MyCoolRG Next we install QEMU, which stands for Quick Emulator. The documentation for Cloud-init contains a section on how to work with QEMU. This will be our local development environment to test Cloud-init scripts before launching them on the cloud. Install QEMU: sudo apt install qemu-kvm This installs QEMU 2.11 (2018) that plays well with Ubuntu 18.04. QEMU on Ubuntu works with hypervisor KVM to run virtual machines locally. Each virtual machine has private virtualized hardware: a network card, disk, graphics adapter, etc. For windows VMware is a popular alternative. QEMU upon first use threw an error ‚Äú/dev/kvm device: permission denied‚Äù that I fixed by adding my own user account to the kvm group after reading this explanation: sudo adduser gertjan kvm On my machine, all users in group kvm have rw access for /dev/kvm, thereby fixing the permission error. (base) gertjan:~$ qemu-system-x86_64 --version QEMU emulator version 2.11.1(Debian 1:2.11+dfsg-1ubuntu7.41) Copyright (c) 2003-2017 Fabrice Bellard and the QEMU Project developers Creating the Azure infrastucture Azure is organized as a hierarchical structure. See the schematic below. All the components that make up the infrastructure are called resources. Traversing upwards through the hierarchy: Resources are contained within resource groups. Resource groups exist within a subscription. Finally, subscriptions exist within management groups. In this blog post, we will create the infrastructure we need from scratch. Our desired infrastructure consists of a single virtual network that contains a single virtual machine (VM) The VM will be configured to be accessible through the internet using SSH and ‚ÄúMicrosoft Remote Desktop‚Äù (RDP). To quickly create a VM in Azure, it is possible to use a single Azure CLI command with default values that automatically creates any required supporting resources. However, to really understand the Azure building blocks and their dependencies, it is better to create each Azure resource separately. In doing so we gradually build up the infrastructure step by step. (An official Azure tutorial by Cynthia Nottingham and others that takes a similar approach can be found here) Special attention is given to secure our network and VM, because it is exposed to the public internet. Hackers are continuously scanning the Azure network IP address ranges for vulnerable systems, so we need to defend ourselves. We use a basic Firewall called ‚ÄúNetwork Security Group‚Äù that works with Security Rules. More on our security measures below. I chose not to use an ‚ÄúAvailability Set‚Äù as this only makes sense for groups of VMs. I use Linux shell Environment Variables to separate the Azure configuration parameters (which image, which VM type etc) from the actual Azure CLI commands that create the resources. To view my current configuration file containing all Azure parameters: gsverhoeven/azure_cli_scripts/main/azure_config_ubuntu.sh Step-by-step guide to set up the VM First we create a new Resource group Then we create a Virtual Network with a Subnet Then we create a Public IP Then we create a Network Security Group & Rules Then we create a Network Interface Card (NIC) Then we choose the VM image, VM size and VM storage type Then we write a Cloud-init script to initialize the VM Finally we create the VM and enjoy the show Create resource Group First we create a new Resource Group, myRGtest. This needs a location. Since I am in West Europe, let‚Äôs choose westeurope. # create shell variables resourceGroup=myRGtest location=westeurope az group create --name $resourceGroup --location $location az group show --resource-group $resourceGroup Create Virtual Network Next we create a Virtual Network and a Subnet, as explained in the Azure documentation: # create shell variables vnetName=StanDEV-VNet1 subnetName=StanDEV-Subnet1 vnetAddressPrefix=10.0.0.0/16 subnetAddressPrefix=10.0.0.0/24 az network vnet create \\ --name $vnetName \\ --resource-group $resourceGroup \\ --address-prefixes $vnetAddressPrefix \\ --subnet-name $subnetName \\ --subnet-prefixes $subnetAddressPrefix Create Public IP address Now let‚Äôs create a public IP address with az network public-ip create. publicIP=TEST-public-ip mypublicdns=gsverhoeven echo \"creating public IP address ..\" az network public-ip create \\ --resource-group $resourceGroup \\ --name $publicIP \\ --sku standard \\ --dns-name $mypublicdns \\ --output $azOutput \\ --zone 1 # non-zonal IP This public IP address enables us to connect to the VM from the Internet. This command results in an IP address with a Fully qualified domain name (FQDN) of gsverhoeven.westeurope.cloudapp.azure.com nslookup gsverhoeven.westeurope.cloudapp.azure.com #Server: 127.0.0.53 #Address: 127.0.0.53#53 #Non-authoritative answer: #Name: gsverhoeven.westeurope.cloudapp.azure.com #Address: 68.219.248.112 az network public-ip list -o table Name ResourceGroup Location Zones Address IdleTimeoutInMinutes ProvisioningState -------------- --------------- ---------- ------- ------------- ---------------------- ------------------- TEST-public-ip myRGtest westeurope 104.46.41.142 4 Succeeded Create network security group & Rules To control the flow of traffic in and out of our VM, we use a so-called network security group. The following example uses az network nsg create to create a network security group named myNSG: NetworkSecurityGroup=myNSG az network nsg create \\ --resource-group $resourceGroup \\ --name $NetworkSecurityGroup This works by defining rules that allow or deny specific traffic. A new NSG starts with a set of default rules, among which is the rule that all inbound traffic is blocked. Rules are processed in priority order, with lower numbers processed before higher numbers, because lower numbers have higher priority. Once traffic matches a rule, processing stops. To allow inbound connections on port 22 (to enable SSH access), create an inbound rule with az network nsg rule create. The following example creates a rule named myNetworkSecurityGroupRuleSSH: echo \"create SSH rule ..\" az network nsg rule create \\ --resource-group $resourceGroup \\ --nsg-name $NetworkSecurityGroup \\ --name myNetworkSecurityGroupRuleSSH \\ --description \"Allow SSH at port 22\" \\ --protocol tcp \\ --priority 1000 \\ --destination-port-range 22 \\ --access allow \\ --output $azOutput To allow Remote Desktop traffic to reach your Linux VM, add another network security group rule. The following example creates a rule named myNetworkSecurityGroupRuleRDP: echo \"create RDP rule ..\" az network nsg rule create \\ --resource-group $resourceGroup \\ --nsg-name $NetworkSecurityGroup \\ --name myNetworkSecurityGroupRuleRDP \\ --description \"Allow RDP at port 3389\" \\ --direction Inbound \\ --protocol tcp \\ --priority 1001 \\ --destination-port-range 3389 \\ --access allow \\ --output $azOutput \\ --source-address-prefixes $trustedIPAdress Examine the network security group and rules with az network nsg rule list: echo \"check NSG rules ..\" az network nsg rule list \\ --resource-group $resourceGroup \\ --nsg-name $NetworkSecurityGroup \\ --output table Create NIC Virtual network interface cards (NICs) are programmatically available because you can apply rules to their use. In the following az network nic create command, we create a NIC named myNic and associate it with our network security group. The public IP address we created above is also associated with the virtual NIC. echo \"create NIC ..\" az network nic create \\ --resource-group $resourceGroup \\ --name $NICName \\ --vnet-name $vnetName \\ --subnet $subnetName \\ --public-ip-address $publicIP \\ --output $azOutput \\ --network-security-group $NetworkSecurityGroup From the dependencies, we can see that a NIC ties together: A Network Security Group, A public IP, A VNet & subnet, all within a resource group. Later on, when we create the VM, we only need to specify the NIC to bring up the VM in the virtual network with the desired NSG. VM Image choice As VM image I chose Ubuntu Server 22.04 LTS for reasons already mentioned above. But which one, how do we find the image we need? Canonical, the company behind Ubuntu Linux, offers various preconfigured Ubuntu images in the Azure Marketplace. Azure CLI can be used to programmatically interact with Azure Marketplace. I used this blog post by Joshua Powers to learn how this works. All images published by Canonical are discoverable using the following command: az vm image list-skus \\ --publisher Canonical \\ --offer Ubuntu \\ --location westeurope \\ -o table Location Name ---------- ---------------------- westeurope 18_04-lts westeurope 18_04-lts-gen2 westeurope 18_04-lts-minimal westeurope 18_04-lts-minimal-gen2 ... westeurope 22_04-lts westeurope 22_04-lts-gen2 westeurope 22_04-lts-minimal westeurope 22_04-lts-minimal-gen2 ... I went with 22_04-lts. VM Size choice There is a bewildering amount of choice regarding different types of VMs offered by Microsoft. As my focus is on cheap, general purpose compute, I ended up with D-series VMs. Azureprice.net shows regional price variation, however without subscription it only shows the extent of the price variation. My current heuristic is taking the median (i.e. middle) price, so far it seems to give a good estimate of monthly pay-as-you-go prices for west-europe. https://azureprice.net/vm/Standard_D2s_v3?currency=EUR&timeoption=day&paymentType=payasyougo To have a reasonable fast software install I found we need at least 8GB of mem and 2 vCPUs, this corresponds to Standard_D2s_v3. With this VM, cloud-init installation finishes after 23 min, after which the VM is fully operational. This has a monthly cost of 78 euro (based on 24/7 usage). `Standard` is recommended tier. D ‚Äì General purpose compute 2 ‚Äì VM Size s ‚Äì Premium Storage capable v3 ‚Äì version Disk storage associated with the VM When an Azure virtual machine is created, two disks are automatically attached to the virtual machine. The disk that holds the VM image (in our case Ubuntu 22) is called the OS disk. In Azure, the default OS disk size for Linux VMs is currently at 30 GB. This appears to also be the minimum OS disk size, there is only the option to expand them. The OS disk is labeled /dev/sda by default. In addition, there is a temp disk mounted that is physically located on the Azure host where the VM is running. This can only be used for temporary data processing, and its size is given. It does not incur any extra cost. Temporary disks are labeled /dev/sdb and have a mountpoint of /mnt. More info on temp disks here N.b. I did not go so far as to attach a data disk. So we need to make sure that work we do on the VM is pushed to e.g. Github, because if we tear the VM down, the user data is lost as well. The Disk types are controlled by the -storage-sku option when we create the VM. Allowed values for this option include Standard_LRS for traditional hard disks (HDD), StandardSSD_LRS and Premium_LRS both consists of SSD disks but with differing performance characteristics. Locally redundant storage (LRS) replicates your data three times within a single data center in the selected region. More info at Azure disk types We want the cheapest SSD option, this seems to be StandardSSD_LRS. Cloud-init to automate software installation and VM configuration At this point we could stop, and create the VM. However, it would just be a plain out-of-the-box Linux installation. And our goal is to use the VM for data science, Bayesian modelling in particular! So directly after creating the VM, we want to install additional software on it. For this we use the open source tool Cloud-init. It typically runs directly after a cloud instance is created. Cloud-init is cross-platform across the public cloud, so in theory we should be able to easily move our instance from one cloud provider to another. Already in the early days of cloud computing (2007), people recognized the need to automatically configure cloud instances using user defined scripts. Around that time Cloud-init was born (it was called ec2-init at that time, because at that time AWS EC2 basically WAS the complete public cloud). According to the documentation: Cloud-init is an open source initialisation tool that was designed to make it easier to get your systems up and running with a minimum of effort, already configured according to your needs. [‚Ä¶] During boot, cloud-init identifies the cloud it is running on and initialises the system accordingly. Cloud instances will automatically be provisioned during first boot with networking, storage, SSH keys, packages and various other system aspects already configured. Here is a nice overview introduction. Cloud-init needs a script or cloud config that will be run directly after provisioning the VM. This is called ‚ÄúUser data‚Äù by most cloud providers, M$ calls it custom-data. Although it can run any shell script, there is also a declarative YAML based configuration file that works with modules to perform common tasks like adding users, updating and installing linux software packages etc. For this blog I went with a YAML file called cloud_init_cfg.yaml. The content of this file can be inspected here. Testing cloud-init on the local file system using QEMU As we are developing our cloud config script, we want to test it locally before deploying the whole shabam to the Azure cloud, as this is slow (you don‚Äôt want to wait 10 minutes to discover you made a typo .. AGAIN!!). Enter the QEMU virtualizer (website here), that can act as a virtualization host to run the instance locally. As the Cloud-init enabled instance is booted up inside QEMU, it needs a data source to fetch the cloud config script from. Cloud-init supports the special data source ‚Äúnocloud‚Äù that allows us to use the local file system to offer the data source to the instance in three variants. I use the variant with a local HTTP server running using the python built-in webserver at local port 8000: gnome-terminal -- python3 -m http.server --directory . The url of the webserver is communicated to the instance by Qemu using a hack, which is putting it into the serial number field of the SMBIOS: -smbios type=1,serial=ds='nocloud;s=http://10.0.2.2:8000/' Here is example code that downloads a Cloud-init enabled Ubuntu 22.04 image (jammy) for local testing. The initial (virtual) disk size of the image is 2.2 GB, which is too small to install all the software we need to run Rstudio. So we increase the image size to 30GB. After that we fire up the instance with QEMU: wget https://cloud-images.ubuntu.com/jammy/current/jammy-server-cloudimg-amd64.img qemu-img info jammy-server-cloudimg-amd64.img # 2.2 GB qemu-img resize jammy-server-cloudimg-amd64.img 30G qemu-system-x86_64 \\ -net nic \\ -net user -machine accel=kvm \\ # use hardware acceleration -cpu host \\ # emulate host processor -m 1024 \\ # use 1 GB RAM -nographic \\ # graphic window disabled -hda jammy-server-cloudimg-amd64.img \\ # Set a virtual hard drive and use the specified image file -smbios type=1,serial=ds='nocloud;s=http://10.0.2.2:8000/' ubuntu@jammy:~$ sudo lsblk -d | grep disk fd0 2:0 1 4K 0 disk sda 8:0 0 30G 0 disk I ended up writing a script do_qemu.sh that starts a local VM using the same cloud-config YAML file that is also used to configure the actual Azure VM. This allowed for fast development and seamless switching between local and cloud testing. Using cloud-init to install additional packages Using Cloud-init‚Äôs packages module, we install the following software: inxi (system information tool) Firefox Fail2ban (Blocking of bad IP addresses) XFCE4 desktop (default ubuntu image comes without a desktop) xRDP (to use the VM as a remote desktop) GNU make and g++ compiler (to compile R packages as well as Stan programs) various dependencies for R packages, notably tidyverse Using cloud-init to run scripts on the VM during late boot To configure Fail2ban, xRDP, install R and Rstudio, I wrote separate scripts that perform the necessary steps. These scripts are contained within the cloud_init_cfg.yaml file to be written to disk within the instance during early init. At late init, the scripts are then executed one after another. [bash, /enable_fail2ban.sh ] [bash, /install_xrdp.sh ] [bash, /install_r.sh ] [bash, /install_rstudio.sh ] Securing our VM For a VM with a public IP on the hostile internet, we need some security measures in place. ‚ÄúHackers‚Äù will be using a list of azure IPs and will attempt brute force SSH to gain access. See for example this post on superuser.com. There are sites that document so called ‚Äúbad IPs‚Äù, known culprits of e.g. unauthorized scanning for open ports: IPsum Github repository list with bad IPs, including a Wall of Shame AbuseIPDB, a database of abusive IP addresses. Some of these were indeed scanning my VM as well. We take the following steps to secure our VM from outside attacks: SSH password authentication is disabled, access only through SSH keys We generate an password (needed for RDP logon) on the fly from keyboard input when creating the VM Only RDP connections from a single trusted IP address are allowed All other ports are closed for inbound traffic using Azure NSG Use Fail2ban to ban IPs that have multiple unsuccessful SSH login attempts NSG is a basic type of firewall, that is relatively dumb. It does not know about applications, it just filters network packets based on rules. So we use it to block all incoming connections from the internet, except SSH and RDP. To connect using SSH, a private key is needed that is only available on my local desktop system. When someone tries to brute force the SSH connection, their IP is banned after a few unsuccessful login attempts. To connect using RDP, it only accepts connections from the IP address attached to my local desktop system via my ISP. It would be nice to add RDP to fail2ban, however this apparently is not easy. Hopefully this is enough security for a single VM without important secrets, and I did not make any mistake here :) (Microsoft has created a product ‚ÄúAzure Bastion‚Äù for our use case, when we want to use RDP / remote desktop into a VM on Azure, but do not want to use a VPN or expose the VM using a public IP address. It seems expensive though ..) To explain and document I will now describe my security measures in more detail, starting with SSH access. SSH access A common, secure way of connecting to a VM is through a ‚Äúsecure shell‚Äù aka SSH connection. It is secure because all traffic is encrypted. We can either use passwords or work with ‚Äúkey pairs‚Äù. We choose SSH keys because it is safer, since passwords can be guessed or brute-force discovered. SSH works with so-called ‚Äúkey pairs‚Äù, that consist of a public and private key. The private key is kept secret and is stored on our local system. The public key is passed to the VM when it is created. The VM uses this public key to encrypt all communication. To decrypt this communication, the private key is needed. Since nobody else has this key except we ourselves on our local system in a safe place, the connection is safeguarded. We need to generate a public and private key for ourselves, and get it on the new VM. We use the --generate-ssh-keys parameter to create them the first time we create the VM. After that, since we already have a key pair, this parameter uses existing keys in ~/.ssh. Since SSH communication goes back and forth between our local system and the VM, we also need to encrypt the information we send to the VM. For that we need to use the VM‚Äôs public key that it hands out to whoever wants to communicate with it. We fetch after VM creation using ssh-keyscan: ssh-keyscan -H $mypublicdns.westeurope.cloudapp.azure.com >> ~/.ssh/known_hosts After all this, we can connect to the VM using SSH without the need to supply a password, the key-pairs in the background take care of the authentication process. (base) gertjan:~$ ssh stanuser@gsverhoeven.westeurope.cloudapp.azure.com Welcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.2.0-1018-azure x86_64) [...] Last login: Sun Jan 14 22:02:30 2024 from 77.248.168.82 stanuser@standev:~$ Interactive password generation for RDP access For remote desktop access with sufficient performance (no lags) we still need to set a password on the VM when we create it. Since we want a fully scripted process of VM creation, I needed a secure way to generate and set a password during VM creation. In the end, I figured out a way to accomplish this using a shell script with an interactive prompt, that dynamically inserts the hashed password into the Cloud-init config file. This config file is then used to set the password on the VM upon creation, after which the copy of the config file containing the hashed password is deleted. echo \"generate cloud-config with encrypted password ..\" read -sp 'Enter password for Cloud-config: ' SECRET HASHEDPW=$(mkpasswd $SECRET --method=SHA-512 --rounds=4096) cp $customDataScript $customDataScript.tmp sed -i -e \"/password:/ s@:.*@: $HASHEDPW@\" $customDataScript.tmp This way, I do not have to store a hashed password, not in the Github code repository, or on my local computer. I have the password stored in my Keepass password manager in case I forget it. Remote desktop access using RDP Since we want to use the VM as a remote desktop, we need a connection that supports graphics. Both RDP and VNC are popular protocols for remote desktop access. I went with RDP as it appears the faster of the two, and because RDP is natively supported in Windows. I did not explore tunneling RDP over SSH or VPN because it would reduce performance too much, and it requires too much configuration on the client side, which is often not possible with company restricted laptops. To be able to use RDP with Linux we need to install xrdp. To be able to login to xrdp requires setting a password for the user that logs in, introducing a security risk. To mitigate this risk, Azure NSG (our firewall) only accepts RDP connections from the IP address attached to my local desktop system via my ISP. Fail2ban for SSH fail2ban will dynamically block brute force attacks on the remote system. It is pre-configured for the default ssh port 22/tcp. As I am writing this blog, the VM is up and running, and every few hours an IP address get banned. It is configured to ban an IP after 5 login attempts. A ban lasts for 10 min, after which the ban is released again. Apparently this is for performance reasons, as we do not want to gather a very long list of IP addresses that needs to be scanned every time a new login attempt is made. sudo apt install fail2ban It is not enabled by default. sudo cp jail.conf jail.local sudo systemctl enable fail2ban sudo systemctl start fail2ban sudo systemctl status fail2ban.service ‚óè fail2ban.service - Fail2Ban Service Loaded: loaded (/lib/systemd/system/fail2ban.service; enabled; vendor preset: enabled) Active: active (running) since Sun 2024-01-14 21:21:40 UTC; 1min 48s ago Docs: man:fail2ban(1) Main PID: 563 (fail2ban-server) Tasks: 5 (limit: 9510) Memory: 17.7M CPU: 298ms CGroup: /system.slice/fail2ban.service ‚îî‚îÄ563 /usr/bin/python3 /usr/bin/fail2ban-server -xf start Jan 14 21:21:40 standev systemd[1]: Started Fail2Ban Service. Jan 14 21:21:42 standev fail2ban-server[563]: Server ready It should be possibly to have fail2ban also monitor failed RDP login attempts, that would improve security even more. https://stackoverflow.com/questions/75915624/xrdp-filter-setting-for-fail2ban Create the VM We now are ready to bring it all together and create the VM. For this Azure CLI has the az vm create command. The following example creates a VM that automatically starts up and runs our Cloud-init script: az vm create \\ --resource-group $resourceGroup \\ --name $vmName \\ --nics $NICName \\ --image $vmImage \\ --storage-sku $storagetype \\ --size $vmSize \\ --admin-username $AdminUsername \\ --custom-data $customDataScript.tmp \\ --generate-ssh-keys \\ --output $azOutput \\ --security-type Standard # no trusted launch Most options we already discussed above, except two: --custom-data, this specifies the Cloud-init script that will passed on to the cloud-init enabled VM image and contains instructions to create user accounts, install packages etc. --generate-ssh-keys, this was described under ‚ÄúSecuring the VM‚Äù. Although there are Azure CLI commands to stop, start and deallocate the VM, I typically use a shell script deploy_vm_ubuntu.sh to bring it up, leave it running while I need it, use the Azure Portal to manually stop and start the VM, and when no longer needed, tear it down using another script delete_vm_ubuntu.sh. This script simply uses az group delete to remove the Resource group containing the VM and related resources. After running the deploy script, we can ssh into the VM and verify that cloud-init is still running in the background: (base) gertjan:~/azure_cli_scripts$ ssh stanuser@gsverhoeven.westeurope.cloudapp.azure.com Welcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.2.0-1018-azure x86_64) [....] *** System restart required *** To run a command as administrator (user \"root\"), use \"sudo \". See \"man sudo_root\" for details. stanuser@standev:~$ cloud-init status status: running stanuser@standev:~$ exit After some 25 minutes of installing software, the VM is ready for use. Cloud-init v. 23.3.3-0ubuntu0~22.04.1 finished at Mon, 01 Jan 2024 18:09:08 +0000. \\ Datasource DataSourceAzure [seed=/dev/sr0]. Up 1453.38 seconds For the finishing touch, we (manually) do all upgrades to get the latest security updates, and reboot the system. (base) gertjan:~/Werk/Github/gsverhoeven/azure_cli_scripts$ ssh stanuser@gsverhoeven.westeurope.cloudapp.azure.com [...] sudo apt upgrade sudo reboot After this, we are in business, let the Bayesian modelling commence! Lessons learned I learned several things from doing this. First, infrastructure as code is a form of software development, and as such needs a suitable development environment. This means being able to rapidly test changes in e.g. configuration scripts, and to be able to debug stuff by stripping things to the core. I improved the workflow by using QEMU, that allows me to work with Cloud-init enabled instances locally. This allowed me to figure out how cloud-init works without the overhead of doing a full cloud rollout, creating all the resources etc. However, as my local machine is quite dated (4 GB mem, 2 core CPU, so even worse than the cheap D-compute from Azure) executing the full init takes even longer than in the cloud, and I ran into memory problems as I can only run QEMU with 2 GB mem. So repeating the full process every time we make a small change is not the way. Ultimately we need a build tool that breaks down the whole image building process into a pipeline of steps, saving intermediate results. Basically a make tool for VM (golden) image building. Then if we change some code, it could use graph dependencies to figure out which parts are affected and need to be rebuild. My next step here would be to look at Ansible or an open source alternative to HashiCorp Packer. In addition, there is this Container thing, with Docker etc. This might offer a different way of ‚Äúdesktop computing‚Äù where I develop locally and run analyses in Docker containers in the cloud, managed by Kubernetes. This is completely uncharted territory for me. Another thing I found that Cloud computing is expensive. Even with the most low cost options, for a 24/7 desktop solution in the cloud we still end up paying around a 100 euro per month. And that‚Äôs with a 2 core 8GB RAM machine! This is the price we pay for the flexibility of renting without any long term commitment, the hardware already being there, it just works etc. Finally, I am used to the relatively safe computing environment at home behind an ISP‚Äôs firewall. In the public cloud, we are fully exposed, and one can actually see the continuous break-in attempts occurring by the hour. That somehow feels a bit.. chilly. To be continued ‚Ä¶",
      "meta_keywords": null,
      "og_description": "Photo source: cropped from original by Taylor van Riper https://unsplash.com/@taylorvanriper925 Graphics source: Michael Betancourt at stan-dev/propaganda Time to explore what the public cloud is all about. Our goal is to write code (i.e. scripts) using open-source tools to automatically set up cloud infrastructure. In short, we want Infrastructure as code. For this I chose a specific use case, which is spinning up a low cost data analysis development environment with R, Rstudio and Stan tools installed and configured. This has two big advantages, reproducibility and lower switching cost: Scripting the compute resources that made a data analysis possible is the next level in reproducibility. Ideally, we want our scripts to be independent of a particular cloud provider. This would allow us to easily change from e.g. Azure to Amazon AWS if things stagnate or we can get a better deal elsewhere. I ended up writing Linux shell scripts that use the Azure command-line interface (Azure CLI) to deploy a Linux VM configured using Cloud-init. While doing so I discovered that being able to test changes locally first before deploying to the cloud speeds up development significantly. To summarize and motivate the tech choices I made: I chose Azure since my employer recently moved to Azure and me learning it would be beneficial for work. I chose Azure CLI to write simple shell scripts without the additional abstraction layer introduced by more generic tools like Terraform/OpenTofu or Ansible I chose Linux Ubuntu OS to keep cost down, as it is free and needs less resources than Windows 10/11 I chose Cloud-init as it has emerged as the standard way to configure Linux cloud images across all cloud platforms I chose the QEMU Quick Emulator to run VMs locally to speed up development The blog uses Linux throughout, but the Azure CLI commands should work for Windows as well. All scripts mentioned in this blog are available in a separate Github repository, gsverhoeven/azure_cli_scripts. Cloud computing in Azure on a shoestring So what do we need to pay for this low cost cloud computing data analytics VM? For a single VM the main cost driver is the VM itself. We need at least 8GB of RAM and a minimum of 2 CPU, so we end up with a Standard D2s VM. At the time of writing, monthly cost, assuming 24/7 usage is 73 euro. (To find out about these prices in the first place: Azure shows them when you select ‚Äúcreate new VM‚Äù in the portal) We have two additional small cost drivers, the associated disk (‚Äústorage‚Äù), and we need to pay for a public IP address, each roughly 0.1 euro per day. If we would bring the VM up and keep it on for a whole day we pay around 2.5 euro a day. If we only use it for 8 hours, cost is reduced to an estimated 1 euro per day. If we stop the VM such that the resources are released (deallocated), we only need to pay for the IP and disk storage, which is 0.2 euro per day, or 6 euro on a monthly basis. This allows us a ‚Äúfast resume‚Äù option that avoids waiting 30 min to install and configure all the software. I tried this, it is a feasible strategy, it takes a minute or so to boot up. Ok let‚Äôs do it! Setting up our local IaaS dev environment As mentioned above, we use both Azure CLI and QEMU virtual emulator for local VM development. I started with creating a free account on Azure. This comes with 200 Euro free credit to spent within a month. Then I installed azure-cli on my local system (Ubuntu 18.04 LTS): #downloads the signing key from Microsoft curl -sL https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/microsoft.gpg > /dev/null ## creates a file called microsoft.gpg in the folder where keys are stored AZ_REPO=$(lsb_release -cs) ## outputs the codename for the linux distribution i.e. Ubuntu 18.04 = bionic echo \"deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ $AZ_REPO main\" | sudo tee /etc/apt/sources.list.d/azure-cli.list ## writes that URL to the package resource list sudo apt-get update sudo apt-get install azure-cli First time we use azure-cli locally we need authenticate: # Log in interactively using the browser. az login Test if it works by creating and deleting a new resource group: az group create --location westeurope --resource-group MyCoolRG -o table Location Name ---------- -------- westeurope MyCoolRG Great! that worked. Now let‚Äôs get rid of it. az group delete --resource-group MyCoolRG Next we install QEMU, which stands for Quick Emulator. The documentation for Cloud-init contains a section on how to work with QEMU. This will be our local development environment to test Cloud-init scripts before launching them on the cloud. Install QEMU: sudo apt install qemu-kvm This installs QEMU 2.11 (2018) that plays well with Ubuntu 18.04. QEMU on Ubuntu works with hypervisor KVM to run virtual machines locally. Each virtual machine has private virtualized hardware: a network card, disk, graphics adapter, etc. For windows VMware is a popular alternative. QEMU upon first use threw an error ‚Äú/dev/kvm device: permission denied‚Äù that I fixed by adding my own user account to the kvm group after reading this explanation: sudo adduser gertjan kvm On my machine, all users in group kvm have rw access for /dev/kvm, thereby fixing the permission error. (base) gertjan:~$ qemu-system-x86_64 --version QEMU emulator version 2.11.1(Debian 1:2.11+dfsg-1ubuntu7.41) Copyright (c) 2003-2017 Fabrice Bellard and the QEMU Project developers Creating the Azure infrastucture Azure is organized as a hierarchical structure. See the schematic below. All the components that make up the infrastructure are called resources. Traversing upwards through the hierarchy: Resources are contained within resource groups. Resource groups exist within a subscription. Finally, subscriptions exist within management groups. In this blog post, we will create the infrastructure we need from scratch. Our desired infrastructure consists of a single virtual network that contains a single virtual machine (VM) The VM will be configured to be accessible through the internet using SSH and ‚ÄúMicrosoft Remote Desktop‚Äù (RDP). To quickly create a VM in Azure, it is possible to use a single Azure CLI command with default values that automatically creates any required supporting resources. However, to really understand the Azure building blocks and their dependencies, it is better to create each Azure resource separately. In doing so we gradually build up the infrastructure step by step. (An official Azure tutorial by Cynthia Nottingham and others that takes a similar approach can be found here) Special attention is given to secure our network and VM, because it is exposed to the public internet. Hackers are continuously scanning the Azure network IP address ranges for vulnerable systems, so we need to defend ourselves. We use a basic Firewall called ‚ÄúNetwork Security Group‚Äù that works with Security Rules. More on our security measures below. I chose not to use an ‚ÄúAvailability Set‚Äù as this only makes sense for groups of VMs. I use Linux shell Environment Variables to separate the Azure configuration parameters (which image, which VM type etc) from the actual Azure CLI commands that create the resources. To view my current configuration file containing all Azure parameters: gsverhoeven/azure_cli_scripts/main/azure_config_ubuntu.sh Step-by-step guide to set up the VM First we create a new Resource group Then we create a Virtual Network with a Subnet Then we create a Public IP Then we create a Network Security Group & Rules Then we create a Network Interface Card (NIC) Then we choose the VM image, VM size and VM storage type Then we write a Cloud-init script to initialize the VM Finally we create the VM and enjoy the show Create resource Group First we create a new Resource Group, myRGtest. This needs a location. Since I am in West Europe, let‚Äôs choose westeurope. # create shell variables resourceGroup=myRGtest location=westeurope az group create --name $resourceGroup --location $location az group show --resource-group $resourceGroup Create Virtual Network Next we create a Virtual Network and a Subnet, as explained in the Azure documentation: # create shell variables vnetName=StanDEV-VNet1 subnetName=StanDEV-Subnet1 vnetAddressPrefix=10.0.0.0/16 subnetAddressPrefix=10.0.0.0/24 az network vnet create \\ --name $vnetName \\ --resource-group $resourceGroup \\ --address-prefixes $vnetAddressPrefix \\ --subnet-name $subnetName \\ --subnet-prefixes $subnetAddressPrefix Create Public IP address Now let‚Äôs create a public IP address with az network public-ip create. publicIP=TEST-public-ip mypublicdns=gsverhoeven echo \"creating public IP address ..\" az network public-ip create \\ --resource-group $resourceGroup \\ --name $publicIP \\ --sku standard \\ --dns-name $mypublicdns \\ --output $azOutput \\ --zone 1 # non-zonal IP This public IP address enables us to connect to the VM from the Internet. This command results in an IP address with a Fully qualified domain name (FQDN) of gsverhoeven.westeurope.cloudapp.azure.com nslookup gsverhoeven.westeurope.cloudapp.azure.com #Server: 127.0.0.53 #Address: 127.0.0.53#53 #Non-authoritative answer: #Name: gsverhoeven.westeurope.cloudapp.azure.com #Address: 68.219.248.112 az network public-ip list -o table Name ResourceGroup Location Zones Address IdleTimeoutInMinutes ProvisioningState -------------- --------------- ---------- ------- ------------- ---------------------- ------------------- TEST-public-ip myRGtest westeurope 104.46.41.142 4 Succeeded Create network security group & Rules To control the flow of traffic in and out of our VM, we use a so-called network security group. The following example uses az network nsg create to create a network security group named myNSG: NetworkSecurityGroup=myNSG az network nsg create \\ --resource-group $resourceGroup \\ --name $NetworkSecurityGroup This works by defining rules that allow or deny specific traffic. A new NSG starts with a set of default rules, among which is the rule that all inbound traffic is blocked. Rules are processed in priority order, with lower numbers processed before higher numbers, because lower numbers have higher priority. Once traffic matches a rule, processing stops. To allow inbound connections on port 22 (to enable SSH access), create an inbound rule with az network nsg rule create. The following example creates a rule named myNetworkSecurityGroupRuleSSH: echo \"create SSH rule ..\" az network nsg rule create \\ --resource-group $resourceGroup \\ --nsg-name $NetworkSecurityGroup \\ --name myNetworkSecurityGroupRuleSSH \\ --description \"Allow SSH at port 22\" \\ --protocol tcp \\ --priority 1000 \\ --destination-port-range 22 \\ --access allow \\ --output $azOutput To allow Remote Desktop traffic to reach your Linux VM, add another network security group rule. The following example creates a rule named myNetworkSecurityGroupRuleRDP: echo \"create RDP rule ..\" az network nsg rule create \\ --resource-group $resourceGroup \\ --nsg-name $NetworkSecurityGroup \\ --name myNetworkSecurityGroupRuleRDP \\ --description \"Allow RDP at port 3389\" \\ --direction Inbound \\ --protocol tcp \\ --priority 1001 \\ --destination-port-range 3389 \\ --access allow \\ --output $azOutput \\ --source-address-prefixes $trustedIPAdress Examine the network security group and rules with az network nsg rule list: echo \"check NSG rules ..\" az network nsg rule list \\ --resource-group $resourceGroup \\ --nsg-name $NetworkSecurityGroup \\ --output table Create NIC Virtual network interface cards (NICs) are programmatically available because you can apply rules to their use. In the following az network nic create command, we create a NIC named myNic and associate it with our network security group. The public IP address we created above is also associated with the virtual NIC. echo \"create NIC ..\" az network nic create \\ --resource-group $resourceGroup \\ --name $NICName \\ --vnet-name $vnetName \\ --subnet $subnetName \\ --public-ip-address $publicIP \\ --output $azOutput \\ --network-security-group $NetworkSecurityGroup From the dependencies, we can see that a NIC ties together: A Network Security Group, A public IP, A VNet & subnet, all within a resource group. Later on, when we create the VM, we only need to specify the NIC to bring up the VM in the virtual network with the desired NSG. VM Image choice As VM image I chose Ubuntu Server 22.04 LTS for reasons already mentioned above. But which one, how do we find the image we need? Canonical, the company behind Ubuntu Linux, offers various preconfigured Ubuntu images in the Azure Marketplace. Azure CLI can be used to programmatically interact with Azure Marketplace. I used this blog post by Joshua Powers to learn how this works. All images published by Canonical are discoverable using the following command: az vm image list-skus \\ --publisher Canonical \\ --offer Ubuntu \\ --location westeurope \\ -o table Location Name ---------- ---------------------- westeurope 18_04-lts westeurope 18_04-lts-gen2 westeurope 18_04-lts-minimal westeurope 18_04-lts-minimal-gen2 ... westeurope 22_04-lts westeurope 22_04-lts-gen2 westeurope 22_04-lts-minimal westeurope 22_04-lts-minimal-gen2 ... I went with 22_04-lts. VM Size choice There is a bewildering amount of choice regarding different types of VMs offered by Microsoft. As my focus is on cheap, general purpose compute, I ended up with D-series VMs. Azureprice.net shows regional price variation, however without subscription it only shows the extent of the price variation. My current heuristic is taking the median (i.e. middle) price, so far it seems to give a good estimate of monthly pay-as-you-go prices for west-europe. https://azureprice.net/vm/Standard_D2s_v3?currency=EUR&timeoption=day&paymentType=payasyougo To have a reasonable fast software install I found we need at least 8GB of mem and 2 vCPUs, this corresponds to Standard_D2s_v3. With this VM, cloud-init installation finishes after 23 min, after which the VM is fully operational. This has a monthly cost of 78 euro (based on 24/7 usage). `Standard` is recommended tier. D ‚Äì General purpose compute 2 ‚Äì VM Size s ‚Äì Premium Storage capable v3 ‚Äì version Disk storage associated with the VM When an Azure virtual machine is created, two disks are automatically attached to the virtual machine. The disk that holds the VM image (in our case Ubuntu 22) is called the OS disk. In Azure, the default OS disk size for Linux VMs is currently at 30 GB. This appears to also be the minimum OS disk size, there is only the option to expand them. The OS disk is labeled /dev/sda by default. In addition, there is a temp disk mounted that is physically located on the Azure host where the VM is running. This can only be used for temporary data processing, and its size is given. It does not incur any extra cost. Temporary disks are labeled /dev/sdb and have a mountpoint of /mnt. More info on temp disks here N.b. I did not go so far as to attach a data disk. So we need to make sure that work we do on the VM is pushed to e.g. Github, because if we tear the VM down, the user data is lost as well. The Disk types are controlled by the -storage-sku option when we create the VM. Allowed values for this option include Standard_LRS for traditional hard disks (HDD), StandardSSD_LRS and Premium_LRS both consists of SSD disks but with differing performance characteristics. Locally redundant storage (LRS) replicates your data three times within a single data center in the selected region. More info at Azure disk types We want the cheapest SSD option, this seems to be StandardSSD_LRS. Cloud-init to automate software installation and VM configuration At this point we could stop, and create the VM. However, it would just be a plain out-of-the-box Linux installation. And our goal is to use the VM for data science, Bayesian modelling in particular! So directly after creating the VM, we want to install additional software on it. For this we use the open source tool Cloud-init. It typically runs directly after a cloud instance is created. Cloud-init is cross-platform across the public cloud, so in theory we should be able to easily move our instance from one cloud provider to another. Already in the early days of cloud computing (2007), people recognized the need to automatically configure cloud instances using user defined scripts. Around that time Cloud-init was born (it was called ec2-init at that time, because at that time AWS EC2 basically WAS the complete public cloud). According to the documentation: Cloud-init is an open source initialisation tool that was designed to make it easier to get your systems up and running with a minimum of effort, already configured according to your needs. [‚Ä¶] During boot, cloud-init identifies the cloud it is running on and initialises the system accordingly. Cloud instances will automatically be provisioned during first boot with networking, storage, SSH keys, packages and various other system aspects already configured. Here is a nice overview introduction. Cloud-init needs a script or cloud config that will be run directly after provisioning the VM. This is called ‚ÄúUser data‚Äù by most cloud providers, M$ calls it custom-data. Although it can run any shell script, there is also a declarative YAML based configuration file that works with modules to perform common tasks like adding users, updating and installing linux software packages etc. For this blog I went with a YAML file called cloud_init_cfg.yaml. The content of this file can be inspected here. Testing cloud-init on the local file system using QEMU As we are developing our cloud config script, we want to test it locally before deploying the whole shabam to the Azure cloud, as this is slow (you don‚Äôt want to wait 10 minutes to discover you made a typo .. AGAIN!!). Enter the QEMU virtualizer (website here), that can act as a virtualization host to run the instance locally. As the Cloud-init enabled instance is booted up inside QEMU, it needs a data source to fetch the cloud config script from. Cloud-init supports the special data source ‚Äúnocloud‚Äù that allows us to use the local file system to offer the data source to the instance in three variants. I use the variant with a local HTTP server running using the python built-in webserver at local port 8000: gnome-terminal -- python3 -m http.server --directory . The url of the webserver is communicated to the instance by Qemu using a hack, which is putting it into the serial number field of the SMBIOS: -smbios type=1,serial=ds='nocloud;s=http://10.0.2.2:8000/' Here is example code that downloads a Cloud-init enabled Ubuntu 22.04 image (jammy) for local testing. The initial (virtual) disk size of the image is 2.2 GB, which is too small to install all the software we need to run Rstudio. So we increase the image size to 30GB. After that we fire up the instance with QEMU: wget https://cloud-images.ubuntu.com/jammy/current/jammy-server-cloudimg-amd64.img qemu-img info jammy-server-cloudimg-amd64.img # 2.2 GB qemu-img resize jammy-server-cloudimg-amd64.img 30G qemu-system-x86_64 \\ -net nic \\ -net user -machine accel=kvm \\ # use hardware acceleration -cpu host \\ # emulate host processor -m 1024 \\ # use 1 GB RAM -nographic \\ # graphic window disabled -hda jammy-server-cloudimg-amd64.img \\ # Set a virtual hard drive and use the specified image file -smbios type=1,serial=ds='nocloud;s=http://10.0.2.2:8000/' ubuntu@jammy:~$ sudo lsblk -d | grep disk fd0 2:0 1 4K 0 disk sda 8:0 0 30G 0 disk I ended up writing a script do_qemu.sh that starts a local VM using the same cloud-config YAML file that is also used to configure the actual Azure VM. This allowed for fast development and seamless switching between local and cloud testing. Using cloud-init to install additional packages Using Cloud-init‚Äôs packages module, we install the following software: inxi (system information tool) Firefox Fail2ban (Blocking of bad IP addresses) XFCE4 desktop (default ubuntu image comes without a desktop) xRDP (to use the VM as a remote desktop) GNU make and g++ compiler (to compile R packages as well as Stan programs) various dependencies for R packages, notably tidyverse Using cloud-init to run scripts on the VM during late boot To configure Fail2ban, xRDP, install R and Rstudio, I wrote separate scripts that perform the necessary steps. These scripts are contained within the cloud_init_cfg.yaml file to be written to disk within the instance during early init. At late init, the scripts are then executed one after another. [bash, /enable_fail2ban.sh ] [bash, /install_xrdp.sh ] [bash, /install_r.sh ] [bash, /install_rstudio.sh ] Securing our VM For a VM with a public IP on the hostile internet, we need some security measures in place. ‚ÄúHackers‚Äù will be using a list of azure IPs and will attempt brute force SSH to gain access. See for example this post on superuser.com. There are sites that document so called ‚Äúbad IPs‚Äù, known culprits of e.g. unauthorized scanning for open ports: IPsum Github repository list with bad IPs, including a Wall of Shame AbuseIPDB, a database of abusive IP addresses. Some of these were indeed scanning my VM as well. We take the following steps to secure our VM from outside attacks: SSH password authentication is disabled, access only through SSH keys We generate an password (needed for RDP logon) on the fly from keyboard input when creating the VM Only RDP connections from a single trusted IP address are allowed All other ports are closed for inbound traffic using Azure NSG Use Fail2ban to ban IPs that have multiple unsuccessful SSH login attempts NSG is a basic type of firewall, that is relatively dumb. It does not know about applications, it just filters network packets based on rules. So we use it to block all incoming connections from the internet, except SSH and RDP. To connect using SSH, a private key is needed that is only available on my local desktop system. When someone tries to brute force the SSH connection, their IP is banned after a few unsuccessful login attempts. To connect using RDP, it only accepts connections from the IP address attached to my local desktop system via my ISP. It would be nice to add RDP to fail2ban, however this apparently is not easy. Hopefully this is enough security for a single VM without important secrets, and I did not make any mistake here :) (Microsoft has created a product ‚ÄúAzure Bastion‚Äù for our use case, when we want to use RDP / remote desktop into a VM on Azure, but do not want to use a VPN or expose the VM using a public IP address. It seems expensive though ..) To explain and document I will now describe my security measures in more detail, starting with SSH access. SSH access A common, secure way of connecting to a VM is through a ‚Äúsecure shell‚Äù aka SSH connection. It is secure because all traffic is encrypted. We can either use passwords or work with ‚Äúkey pairs‚Äù. We choose SSH keys because it is safer, since passwords can be guessed or brute-force discovered. SSH works with so-called ‚Äúkey pairs‚Äù, that consist of a public and private key. The private key is kept secret and is stored on our local system. The public key is passed to the VM when it is created. The VM uses this public key to encrypt all communication. To decrypt this communication, the private key is needed. Since nobody else has this key except we ourselves on our local system in a safe place, the connection is safeguarded. We need to generate a public and private key for ourselves, and get it on the new VM. We use the --generate-ssh-keys parameter to create them the first time we create the VM. After that, since we already have a key pair, this parameter uses existing keys in ~/.ssh. Since SSH communication goes back and forth between our local system and the VM, we also need to encrypt the information we send to the VM. For that we need to use the VM‚Äôs public key that it hands out to whoever wants to communicate with it. We fetch after VM creation using ssh-keyscan: ssh-keyscan -H $mypublicdns.westeurope.cloudapp.azure.com >> ~/.ssh/known_hosts After all this, we can connect to the VM using SSH without the need to supply a password, the key-pairs in the background take care of the authentication process. (base) gertjan:~$ ssh stanuser@gsverhoeven.westeurope.cloudapp.azure.com Welcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.2.0-1018-azure x86_64) [...] Last login: Sun Jan 14 22:02:30 2024 from 77.248.168.82 stanuser@standev:~$ Interactive password generation for RDP access For remote desktop access with sufficient performance (no lags) we still need to set a password on the VM when we create it. Since we want a fully scripted process of VM creation, I needed a secure way to generate and set a password during VM creation. In the end, I figured out a way to accomplish this using a shell script with an interactive prompt, that dynamically inserts the hashed password into the Cloud-init config file. This config file is then used to set the password on the VM upon creation, after which the copy of the config file containing the hashed password is deleted. echo \"generate cloud-config with encrypted password ..\" read -sp 'Enter password for Cloud-config: ' SECRET HASHEDPW=$(mkpasswd $SECRET --method=SHA-512 --rounds=4096) cp $customDataScript $customDataScript.tmp sed -i -e \"/password:/ s@:.*@: $HASHEDPW@\" $customDataScript.tmp This way, I do not have to store a hashed password, not in the Github code repository, or on my local computer. I have the password stored in my Keepass password manager in case I forget it. Remote desktop access using RDP Since we want to use the VM as a remote desktop, we need a connection that supports graphics. Both RDP and VNC are popular protocols for remote desktop access. I went with RDP as it appears the faster of the two, and because RDP is natively supported in Windows. I did not explore tunneling RDP over SSH or VPN because it would reduce performance too much, and it requires too much configuration on the client side, which is often not possible with company restricted laptops. To be able to use RDP with Linux we need to install xrdp. To be able to login to xrdp requires setting a password for the user that logs in, introducing a security risk. To mitigate this risk, Azure NSG (our firewall) only accepts RDP connections from the IP address attached to my local desktop system via my ISP. Fail2ban for SSH fail2ban will dynamically block brute force attacks on the remote system. It is pre-configured for the default ssh port 22/tcp. As I am writing this blog, the VM is up and running, and every few hours an IP address get banned. It is configured to ban an IP after 5 login attempts. A ban lasts for 10 min, after which the ban is released again. Apparently this is for performance reasons, as we do not want to gather a very long list of IP addresses that needs to be scanned every time a new login attempt is made. sudo apt install fail2ban It is not enabled by default. sudo cp jail.conf jail.local sudo systemctl enable fail2ban sudo systemctl start fail2ban sudo systemctl status fail2ban.service ‚óè fail2ban.service - Fail2Ban Service Loaded: loaded (/lib/systemd/system/fail2ban.service; enabled; vendor preset: enabled) Active: active (running) since Sun 2024-01-14 21:21:40 UTC; 1min 48s ago Docs: man:fail2ban(1) Main PID: 563 (fail2ban-server) Tasks: 5 (limit: 9510) Memory: 17.7M CPU: 298ms CGroup: /system.slice/fail2ban.service ‚îî‚îÄ563 /usr/bin/python3 /usr/bin/fail2ban-server -xf start Jan 14 21:21:40 standev systemd[1]: Started Fail2Ban Service. Jan 14 21:21:42 standev fail2ban-server[563]: Server ready It should be possibly to have fail2ban also monitor failed RDP login attempts, that would improve security even more. https://stackoverflow.com/questions/75915624/xrdp-filter-setting-for-fail2ban Create the VM We now are ready to bring it all together and create the VM. For this Azure CLI has the az vm create command. The following example creates a VM that automatically starts up and runs our Cloud-init script: az vm create \\ --resource-group $resourceGroup \\ --name $vmName \\ --nics $NICName \\ --image $vmImage \\ --storage-sku $storagetype \\ --size $vmSize \\ --admin-username $AdminUsername \\ --custom-data $customDataScript.tmp \\ --generate-ssh-keys \\ --output $azOutput \\ --security-type Standard # no trusted launch Most options we already discussed above, except two: --custom-data, this specifies the Cloud-init script that will passed on to the cloud-init enabled VM image and contains instructions to create user accounts, install packages etc. --generate-ssh-keys, this was described under ‚ÄúSecuring the VM‚Äù. Although there are Azure CLI commands to stop, start and deallocate the VM, I typically use a shell script deploy_vm_ubuntu.sh to bring it up, leave it running while I need it, use the Azure Portal to manually stop and start the VM, and when no longer needed, tear it down using another script delete_vm_ubuntu.sh. This script simply uses az group delete to remove the Resource group containing the VM and related resources. After running the deploy script, we can ssh into the VM and verify that cloud-init is still running in the background: (base) gertjan:~/azure_cli_scripts$ ssh stanuser@gsverhoeven.westeurope.cloudapp.azure.com Welcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.2.0-1018-azure x86_64) [....] *** System restart required *** To run a command as administrator (user \"root\"), use \"sudo \". See \"man sudo_root\" for details. stanuser@standev:~$ cloud-init status status: running stanuser@standev:~$ exit After some 25 minutes of installing software, the VM is ready for use. Cloud-init v. 23.3.3-0ubuntu0~22.04.1 finished at Mon, 01 Jan 2024 18:09:08 +0000. \\ Datasource DataSourceAzure [seed=/dev/sr0]. Up 1453.38 seconds For the finishing touch, we (manually) do all upgrades to get the latest security updates, and reboot the system. (base) gertjan:~/Werk/Github/gsverhoeven/azure_cli_scripts$ ssh stanuser@gsverhoeven.westeurope.cloudapp.azure.com [...] sudo apt upgrade sudo reboot After this, we are in business, let the Bayesian modelling commence! Lessons learned I learned several things from doing this. First, infrastructure as code is a form of software development, and as such needs a suitable development environment. This means being able to rapidly test changes in e.g. configuration scripts, and to be able to debug stuff by stripping things to the core. I improved the workflow by using QEMU, that allows me to work with Cloud-init enabled instances locally. This allowed me to figure out how cloud-init works without the overhead of doing a full cloud rollout, creating all the resources etc. However, as my local machine is quite dated (4 GB mem, 2 core CPU, so even worse than the cheap D-compute from Azure) executing the full init takes even longer than in the cloud, and I ran into memory problems as I can only run QEMU with 2 GB mem. So repeating the full process every time we make a small change is not the way. Ultimately we need a build tool that breaks down the whole image building process into a pipeline of steps, saving intermediate results. Basically a make tool for VM (golden) image building. Then if we change some code, it could use graph dependencies to figure out which parts are affected and need to be rebuild. My next step here would be to look at Ansible or an open source alternative to HashiCorp Packer. In addition, there is this Container thing, with Docker etc. This might offer a different way of ‚Äúdesktop computing‚Äù where I develop locally and run analyses in Docker containers in the cloud, managed by Kubernetes. This is completely uncharted territory for me. Another thing I found that Cloud computing is expensive. Even with the most low cost options, for a 24/7 desktop solution in the cloud we still end up paying around a 100 euro per month. And that‚Äôs with a 2 core 8GB RAM machine! This is the price we pay for the flexibility of renting without any long term commitment, the hardware already being there, it just works etc. Finally, I am used to the relatively safe computing environment at home behind an ISP‚Äôs firewall. In the public cloud, we are fully exposed, and one can actually see the continuous break-in attempts occurring by the hour. That somehow feels a bit.. chilly. To be continued ‚Ä¶",
      "og_image": "https://gsverhoeven.github.io/post/stan_in_azure/azure_scope-levels.png",
      "og_title": "Statistical computing on a shoestring: Stan in the Azure cloud using Cloud-init | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 27.9,
      "sitemap_lastmod": "2024-01-15T00:00:00+00:00",
      "twitter_description": "Photo source: cropped from original by Taylor van Riper https://unsplash.com/@taylorvanriper925 Graphics source: Michael Betancourt at stan-dev/propaganda Time to explore what the public cloud is all about. Our goal is to write code (i.e. scripts) using open-source tools to automatically set up cloud infrastructure. In short, we want Infrastructure as code. For this I chose a specific use case, which is spinning up a low cost data analysis development environment with R, Rstudio and Stan tools installed and configured. This has two big advantages, reproducibility and lower switching cost: Scripting the compute resources that made a data analysis possible is the next level in reproducibility. Ideally, we want our scripts to be independent of a particular cloud provider. This would allow us to easily change from e.g. Azure to Amazon AWS if things stagnate or we can get a better deal elsewhere. I ended up writing Linux shell scripts that use the Azure command-line interface (Azure CLI) to deploy a Linux VM configured using Cloud-init. While doing so I discovered that being able to test changes locally first before deploying to the cloud speeds up development significantly. To summarize and motivate the tech choices I made: I chose Azure since my employer recently moved to Azure and me learning it would be beneficial for work. I chose Azure CLI to write simple shell scripts without the additional abstraction layer introduced by more generic tools like Terraform/OpenTofu or Ansible I chose Linux Ubuntu OS to keep cost down, as it is free and needs less resources than Windows 10/11 I chose Cloud-init as it has emerged as the standard way to configure Linux cloud images across all cloud platforms I chose the QEMU Quick Emulator to run VMs locally to speed up development The blog uses Linux throughout, but the Azure CLI commands should work for Windows as well. All scripts mentioned in this blog are available in a separate Github repository, gsverhoeven/azure_cli_scripts. Cloud computing in Azure on a shoestring So what do we need to pay for this low cost cloud computing data analytics VM? For a single VM the main cost driver is the VM itself. We need at least 8GB of RAM and a minimum of 2 CPU, so we end up with a Standard D2s VM. At the time of writing, monthly cost, assuming 24/7 usage is 73 euro. (To find out about these prices in the first place: Azure shows them when you select ‚Äúcreate new VM‚Äù in the portal) We have two additional small cost drivers, the associated disk (‚Äústorage‚Äù), and we need to pay for a public IP address, each roughly 0.1 euro per day. If we would bring the VM up and keep it on for a whole day we pay around 2.5 euro a day. If we only use it for 8 hours, cost is reduced to an estimated 1 euro per day. If we stop the VM such that the resources are released (deallocated), we only need to pay for the IP and disk storage, which is 0.2 euro per day, or 6 euro on a monthly basis. This allows us a ‚Äúfast resume‚Äù option that avoids waiting 30 min to install and configure all the software. I tried this, it is a feasible strategy, it takes a minute or so to boot up. Ok let‚Äôs do it! Setting up our local IaaS dev environment As mentioned above, we use both Azure CLI and QEMU virtual emulator for local VM development. I started with creating a free account on Azure. This comes with 200 Euro free credit to spent within a month. Then I installed azure-cli on my local system (Ubuntu 18.04 LTS): #downloads the signing key from Microsoft curl -sL https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/microsoft.gpg > /dev/null ## creates a file called microsoft.gpg in the folder where keys are stored AZ_REPO=$(lsb_release -cs) ## outputs the codename for the linux distribution i.e. Ubuntu 18.04 = bionic echo \"deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ $AZ_REPO main\" | sudo tee /etc/apt/sources.list.d/azure-cli.list ## writes that URL to the package resource list sudo apt-get update sudo apt-get install azure-cli First time we use azure-cli locally we need authenticate: # Log in interactively using the browser. az login Test if it works by creating and deleting a new resource group: az group create --location westeurope --resource-group MyCoolRG -o table Location Name ---------- -------- westeurope MyCoolRG Great! that worked. Now let‚Äôs get rid of it. az group delete --resource-group MyCoolRG Next we install QEMU, which stands for Quick Emulator. The documentation for Cloud-init contains a section on how to work with QEMU. This will be our local development environment to test Cloud-init scripts before launching them on the cloud. Install QEMU: sudo apt install qemu-kvm This installs QEMU 2.11 (2018) that plays well with Ubuntu 18.04. QEMU on Ubuntu works with hypervisor KVM to run virtual machines locally. Each virtual machine has private virtualized hardware: a network card, disk, graphics adapter, etc. For windows VMware is a popular alternative. QEMU upon first use threw an error ‚Äú/dev/kvm device: permission denied‚Äù that I fixed by adding my own user account to the kvm group after reading this explanation: sudo adduser gertjan kvm On my machine, all users in group kvm have rw access for /dev/kvm, thereby fixing the permission error. (base) gertjan:~$ qemu-system-x86_64 --version QEMU emulator version 2.11.1(Debian 1:2.11+dfsg-1ubuntu7.41) Copyright (c) 2003-2017 Fabrice Bellard and the QEMU Project developers Creating the Azure infrastucture Azure is organized as a hierarchical structure. See the schematic below. All the components that make up the infrastructure are called resources. Traversing upwards through the hierarchy: Resources are contained within resource groups. Resource groups exist within a subscription. Finally, subscriptions exist within management groups. In this blog post, we will create the infrastructure we need from scratch. Our desired infrastructure consists of a single virtual network that contains a single virtual machine (VM) The VM will be configured to be accessible through the internet using SSH and ‚ÄúMicrosoft Remote Desktop‚Äù (RDP). To quickly create a VM in Azure, it is possible to use a single Azure CLI command with default values that automatically creates any required supporting resources. However, to really understand the Azure building blocks and their dependencies, it is better to create each Azure resource separately. In doing so we gradually build up the infrastructure step by step. (An official Azure tutorial by Cynthia Nottingham and others that takes a similar approach can be found here) Special attention is given to secure our network and VM, because it is exposed to the public internet. Hackers are continuously scanning the Azure network IP address ranges for vulnerable systems, so we need to defend ourselves. We use a basic Firewall called ‚ÄúNetwork Security Group‚Äù that works with Security Rules. More on our security measures below. I chose not to use an ‚ÄúAvailability Set‚Äù as this only makes sense for groups of VMs. I use Linux shell Environment Variables to separate the Azure configuration parameters (which image, which VM type etc) from the actual Azure CLI commands that create the resources. To view my current configuration file containing all Azure parameters: gsverhoeven/azure_cli_scripts/main/azure_config_ubuntu.sh Step-by-step guide to set up the VM First we create a new Resource group Then we create a Virtual Network with a Subnet Then we create a Public IP Then we create a Network Security Group & Rules Then we create a Network Interface Card (NIC) Then we choose the VM image, VM size and VM storage type Then we write a Cloud-init script to initialize the VM Finally we create the VM and enjoy the show Create resource Group First we create a new Resource Group, myRGtest. This needs a location. Since I am in West Europe, let‚Äôs choose westeurope. # create shell variables resourceGroup=myRGtest location=westeurope az group create --name $resourceGroup --location $location az group show --resource-group $resourceGroup Create Virtual Network Next we create a Virtual Network and a Subnet, as explained in the Azure documentation: # create shell variables vnetName=StanDEV-VNet1 subnetName=StanDEV-Subnet1 vnetAddressPrefix=10.0.0.0/16 subnetAddressPrefix=10.0.0.0/24 az network vnet create \\ --name $vnetName \\ --resource-group $resourceGroup \\ --address-prefixes $vnetAddressPrefix \\ --subnet-name $subnetName \\ --subnet-prefixes $subnetAddressPrefix Create Public IP address Now let‚Äôs create a public IP address with az network public-ip create. publicIP=TEST-public-ip mypublicdns=gsverhoeven echo \"creating public IP address ..\" az network public-ip create \\ --resource-group $resourceGroup \\ --name $publicIP \\ --sku standard \\ --dns-name $mypublicdns \\ --output $azOutput \\ --zone 1 # non-zonal IP This public IP address enables us to connect to the VM from the Internet. This command results in an IP address with a Fully qualified domain name (FQDN) of gsverhoeven.westeurope.cloudapp.azure.com nslookup gsverhoeven.westeurope.cloudapp.azure.com #Server: 127.0.0.53 #Address: 127.0.0.53#53 #Non-authoritative answer: #Name: gsverhoeven.westeurope.cloudapp.azure.com #Address: 68.219.248.112 az network public-ip list -o table Name ResourceGroup Location Zones Address IdleTimeoutInMinutes ProvisioningState -------------- --------------- ---------- ------- ------------- ---------------------- ------------------- TEST-public-ip myRGtest westeurope 104.46.41.142 4 Succeeded Create network security group & Rules To control the flow of traffic in and out of our VM, we use a so-called network security group. The following example uses az network nsg create to create a network security group named myNSG: NetworkSecurityGroup=myNSG az network nsg create \\ --resource-group $resourceGroup \\ --name $NetworkSecurityGroup This works by defining rules that allow or deny specific traffic. A new NSG starts with a set of default rules, among which is the rule that all inbound traffic is blocked. Rules are processed in priority order, with lower numbers processed before higher numbers, because lower numbers have higher priority. Once traffic matches a rule, processing stops. To allow inbound connections on port 22 (to enable SSH access), create an inbound rule with az network nsg rule create. The following example creates a rule named myNetworkSecurityGroupRuleSSH: echo \"create SSH rule ..\" az network nsg rule create \\ --resource-group $resourceGroup \\ --nsg-name $NetworkSecurityGroup \\ --name myNetworkSecurityGroupRuleSSH \\ --description \"Allow SSH at port 22\" \\ --protocol tcp \\ --priority 1000 \\ --destination-port-range 22 \\ --access allow \\ --output $azOutput To allow Remote Desktop traffic to reach your Linux VM, add another network security group rule. The following example creates a rule named myNetworkSecurityGroupRuleRDP: echo \"create RDP rule ..\" az network nsg rule create \\ --resource-group $resourceGroup \\ --nsg-name $NetworkSecurityGroup \\ --name myNetworkSecurityGroupRuleRDP \\ --description \"Allow RDP at port 3389\" \\ --direction Inbound \\ --protocol tcp \\ --priority 1001 \\ --destination-port-range 3389 \\ --access allow \\ --output $azOutput \\ --source-address-prefixes $trustedIPAdress Examine the network security group and rules with az network nsg rule list: echo \"check NSG rules ..\" az network nsg rule list \\ --resource-group $resourceGroup \\ --nsg-name $NetworkSecurityGroup \\ --output table Create NIC Virtual network interface cards (NICs) are programmatically available because you can apply rules to their use. In the following az network nic create command, we create a NIC named myNic and associate it with our network security group. The public IP address we created above is also associated with the virtual NIC. echo \"create NIC ..\" az network nic create \\ --resource-group $resourceGroup \\ --name $NICName \\ --vnet-name $vnetName \\ --subnet $subnetName \\ --public-ip-address $publicIP \\ --output $azOutput \\ --network-security-group $NetworkSecurityGroup From the dependencies, we can see that a NIC ties together: A Network Security Group, A public IP, A VNet & subnet, all within a resource group. Later on, when we create the VM, we only need to specify the NIC to bring up the VM in the virtual network with the desired NSG. VM Image choice As VM image I chose Ubuntu Server 22.04 LTS for reasons already mentioned above. But which one, how do we find the image we need? Canonical, the company behind Ubuntu Linux, offers various preconfigured Ubuntu images in the Azure Marketplace. Azure CLI can be used to programmatically interact with Azure Marketplace. I used this blog post by Joshua Powers to learn how this works. All images published by Canonical are discoverable using the following command: az vm image list-skus \\ --publisher Canonical \\ --offer Ubuntu \\ --location westeurope \\ -o table Location Name ---------- ---------------------- westeurope 18_04-lts westeurope 18_04-lts-gen2 westeurope 18_04-lts-minimal westeurope 18_04-lts-minimal-gen2 ... westeurope 22_04-lts westeurope 22_04-lts-gen2 westeurope 22_04-lts-minimal westeurope 22_04-lts-minimal-gen2 ... I went with 22_04-lts. VM Size choice There is a bewildering amount of choice regarding different types of VMs offered by Microsoft. As my focus is on cheap, general purpose compute, I ended up with D-series VMs. Azureprice.net shows regional price variation, however without subscription it only shows the extent of the price variation. My current heuristic is taking the median (i.e. middle) price, so far it seems to give a good estimate of monthly pay-as-you-go prices for west-europe. https://azureprice.net/vm/Standard_D2s_v3?currency=EUR&timeoption=day&paymentType=payasyougo To have a reasonable fast software install I found we need at least 8GB of mem and 2 vCPUs, this corresponds to Standard_D2s_v3. With this VM, cloud-init installation finishes after 23 min, after which the VM is fully operational. This has a monthly cost of 78 euro (based on 24/7 usage). `Standard` is recommended tier. D ‚Äì General purpose compute 2 ‚Äì VM Size s ‚Äì Premium Storage capable v3 ‚Äì version Disk storage associated with the VM When an Azure virtual machine is created, two disks are automatically attached to the virtual machine. The disk that holds the VM image (in our case Ubuntu 22) is called the OS disk. In Azure, the default OS disk size for Linux VMs is currently at 30 GB. This appears to also be the minimum OS disk size, there is only the option to expand them. The OS disk is labeled /dev/sda by default. In addition, there is a temp disk mounted that is physically located on the Azure host where the VM is running. This can only be used for temporary data processing, and its size is given. It does not incur any extra cost. Temporary disks are labeled /dev/sdb and have a mountpoint of /mnt. More info on temp disks here N.b. I did not go so far as to attach a data disk. So we need to make sure that work we do on the VM is pushed to e.g. Github, because if we tear the VM down, the user data is lost as well. The Disk types are controlled by the -storage-sku option when we create the VM. Allowed values for this option include Standard_LRS for traditional hard disks (HDD), StandardSSD_LRS and Premium_LRS both consists of SSD disks but with differing performance characteristics. Locally redundant storage (LRS) replicates your data three times within a single data center in the selected region. More info at Azure disk types We want the cheapest SSD option, this seems to be StandardSSD_LRS. Cloud-init to automate software installation and VM configuration At this point we could stop, and create the VM. However, it would just be a plain out-of-the-box Linux installation. And our goal is to use the VM for data science, Bayesian modelling in particular! So directly after creating the VM, we want to install additional software on it. For this we use the open source tool Cloud-init. It typically runs directly after a cloud instance is created. Cloud-init is cross-platform across the public cloud, so in theory we should be able to easily move our instance from one cloud provider to another. Already in the early days of cloud computing (2007), people recognized the need to automatically configure cloud instances using user defined scripts. Around that time Cloud-init was born (it was called ec2-init at that time, because at that time AWS EC2 basically WAS the complete public cloud). According to the documentation: Cloud-init is an open source initialisation tool that was designed to make it easier to get your systems up and running with a minimum of effort, already configured according to your needs. [‚Ä¶] During boot, cloud-init identifies the cloud it is running on and initialises the system accordingly. Cloud instances will automatically be provisioned during first boot with networking, storage, SSH keys, packages and various other system aspects already configured. Here is a nice overview introduction. Cloud-init needs a script or cloud config that will be run directly after provisioning the VM. This is called ‚ÄúUser data‚Äù by most cloud providers, M$ calls it custom-data. Although it can run any shell script, there is also a declarative YAML based configuration file that works with modules to perform common tasks like adding users, updating and installing linux software packages etc. For this blog I went with a YAML file called cloud_init_cfg.yaml. The content of this file can be inspected here. Testing cloud-init on the local file system using QEMU As we are developing our cloud config script, we want to test it locally before deploying the whole shabam to the Azure cloud, as this is slow (you don‚Äôt want to wait 10 minutes to discover you made a typo .. AGAIN!!). Enter the QEMU virtualizer (website here), that can act as a virtualization host to run the instance locally. As the Cloud-init enabled instance is booted up inside QEMU, it needs a data source to fetch the cloud config script from. Cloud-init supports the special data source ‚Äúnocloud‚Äù that allows us to use the local file system to offer the data source to the instance in three variants. I use the variant with a local HTTP server running using the python built-in webserver at local port 8000: gnome-terminal -- python3 -m http.server --directory . The url of the webserver is communicated to the instance by Qemu using a hack, which is putting it into the serial number field of the SMBIOS: -smbios type=1,serial=ds='nocloud;s=http://10.0.2.2:8000/' Here is example code that downloads a Cloud-init enabled Ubuntu 22.04 image (jammy) for local testing. The initial (virtual) disk size of the image is 2.2 GB, which is too small to install all the software we need to run Rstudio. So we increase the image size to 30GB. After that we fire up the instance with QEMU: wget https://cloud-images.ubuntu.com/jammy/current/jammy-server-cloudimg-amd64.img qemu-img info jammy-server-cloudimg-amd64.img # 2.2 GB qemu-img resize jammy-server-cloudimg-amd64.img 30G qemu-system-x86_64 \\ -net nic \\ -net user -machine accel=kvm \\ # use hardware acceleration -cpu host \\ # emulate host processor -m 1024 \\ # use 1 GB RAM -nographic \\ # graphic window disabled -hda jammy-server-cloudimg-amd64.img \\ # Set a virtual hard drive and use the specified image file -smbios type=1,serial=ds='nocloud;s=http://10.0.2.2:8000/' ubuntu@jammy:~$ sudo lsblk -d | grep disk fd0 2:0 1 4K 0 disk sda 8:0 0 30G 0 disk I ended up writing a script do_qemu.sh that starts a local VM using the same cloud-config YAML file that is also used to configure the actual Azure VM. This allowed for fast development and seamless switching between local and cloud testing. Using cloud-init to install additional packages Using Cloud-init‚Äôs packages module, we install the following software: inxi (system information tool) Firefox Fail2ban (Blocking of bad IP addresses) XFCE4 desktop (default ubuntu image comes without a desktop) xRDP (to use the VM as a remote desktop) GNU make and g++ compiler (to compile R packages as well as Stan programs) various dependencies for R packages, notably tidyverse Using cloud-init to run scripts on the VM during late boot To configure Fail2ban, xRDP, install R and Rstudio, I wrote separate scripts that perform the necessary steps. These scripts are contained within the cloud_init_cfg.yaml file to be written to disk within the instance during early init. At late init, the scripts are then executed one after another. [bash, /enable_fail2ban.sh ] [bash, /install_xrdp.sh ] [bash, /install_r.sh ] [bash, /install_rstudio.sh ] Securing our VM For a VM with a public IP on the hostile internet, we need some security measures in place. ‚ÄúHackers‚Äù will be using a list of azure IPs and will attempt brute force SSH to gain access. See for example this post on superuser.com. There are sites that document so called ‚Äúbad IPs‚Äù, known culprits of e.g. unauthorized scanning for open ports: IPsum Github repository list with bad IPs, including a Wall of Shame AbuseIPDB, a database of abusive IP addresses. Some of these were indeed scanning my VM as well. We take the following steps to secure our VM from outside attacks: SSH password authentication is disabled, access only through SSH keys We generate an password (needed for RDP logon) on the fly from keyboard input when creating the VM Only RDP connections from a single trusted IP address are allowed All other ports are closed for inbound traffic using Azure NSG Use Fail2ban to ban IPs that have multiple unsuccessful SSH login attempts NSG is a basic type of firewall, that is relatively dumb. It does not know about applications, it just filters network packets based on rules. So we use it to block all incoming connections from the internet, except SSH and RDP. To connect using SSH, a private key is needed that is only available on my local desktop system. When someone tries to brute force the SSH connection, their IP is banned after a few unsuccessful login attempts. To connect using RDP, it only accepts connections from the IP address attached to my local desktop system via my ISP. It would be nice to add RDP to fail2ban, however this apparently is not easy. Hopefully this is enough security for a single VM without important secrets, and I did not make any mistake here :) (Microsoft has created a product ‚ÄúAzure Bastion‚Äù for our use case, when we want to use RDP / remote desktop into a VM on Azure, but do not want to use a VPN or expose the VM using a public IP address. It seems expensive though ..) To explain and document I will now describe my security measures in more detail, starting with SSH access. SSH access A common, secure way of connecting to a VM is through a ‚Äúsecure shell‚Äù aka SSH connection. It is secure because all traffic is encrypted. We can either use passwords or work with ‚Äúkey pairs‚Äù. We choose SSH keys because it is safer, since passwords can be guessed or brute-force discovered. SSH works with so-called ‚Äúkey pairs‚Äù, that consist of a public and private key. The private key is kept secret and is stored on our local system. The public key is passed to the VM when it is created. The VM uses this public key to encrypt all communication. To decrypt this communication, the private key is needed. Since nobody else has this key except we ourselves on our local system in a safe place, the connection is safeguarded. We need to generate a public and private key for ourselves, and get it on the new VM. We use the --generate-ssh-keys parameter to create them the first time we create the VM. After that, since we already have a key pair, this parameter uses existing keys in ~/.ssh. Since SSH communication goes back and forth between our local system and the VM, we also need to encrypt the information we send to the VM. For that we need to use the VM‚Äôs public key that it hands out to whoever wants to communicate with it. We fetch after VM creation using ssh-keyscan: ssh-keyscan -H $mypublicdns.westeurope.cloudapp.azure.com >> ~/.ssh/known_hosts After all this, we can connect to the VM using SSH without the need to supply a password, the key-pairs in the background take care of the authentication process. (base) gertjan:~$ ssh stanuser@gsverhoeven.westeurope.cloudapp.azure.com Welcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.2.0-1018-azure x86_64) [...] Last login: Sun Jan 14 22:02:30 2024 from 77.248.168.82 stanuser@standev:~$ Interactive password generation for RDP access For remote desktop access with sufficient performance (no lags) we still need to set a password on the VM when we create it. Since we want a fully scripted process of VM creation, I needed a secure way to generate and set a password during VM creation. In the end, I figured out a way to accomplish this using a shell script with an interactive prompt, that dynamically inserts the hashed password into the Cloud-init config file. This config file is then used to set the password on the VM upon creation, after which the copy of the config file containing the hashed password is deleted. echo \"generate cloud-config with encrypted password ..\" read -sp 'Enter password for Cloud-config: ' SECRET HASHEDPW=$(mkpasswd $SECRET --method=SHA-512 --rounds=4096) cp $customDataScript $customDataScript.tmp sed -i -e \"/password:/ s@:.*@: $HASHEDPW@\" $customDataScript.tmp This way, I do not have to store a hashed password, not in the Github code repository, or on my local computer. I have the password stored in my Keepass password manager in case I forget it. Remote desktop access using RDP Since we want to use the VM as a remote desktop, we need a connection that supports graphics. Both RDP and VNC are popular protocols for remote desktop access. I went with RDP as it appears the faster of the two, and because RDP is natively supported in Windows. I did not explore tunneling RDP over SSH or VPN because it would reduce performance too much, and it requires too much configuration on the client side, which is often not possible with company restricted laptops. To be able to use RDP with Linux we need to install xrdp. To be able to login to xrdp requires setting a password for the user that logs in, introducing a security risk. To mitigate this risk, Azure NSG (our firewall) only accepts RDP connections from the IP address attached to my local desktop system via my ISP. Fail2ban for SSH fail2ban will dynamically block brute force attacks on the remote system. It is pre-configured for the default ssh port 22/tcp. As I am writing this blog, the VM is up and running, and every few hours an IP address get banned. It is configured to ban an IP after 5 login attempts. A ban lasts for 10 min, after which the ban is released again. Apparently this is for performance reasons, as we do not want to gather a very long list of IP addresses that needs to be scanned every time a new login attempt is made. sudo apt install fail2ban It is not enabled by default. sudo cp jail.conf jail.local sudo systemctl enable fail2ban sudo systemctl start fail2ban sudo systemctl status fail2ban.service ‚óè fail2ban.service - Fail2Ban Service Loaded: loaded (/lib/systemd/system/fail2ban.service; enabled; vendor preset: enabled) Active: active (running) since Sun 2024-01-14 21:21:40 UTC; 1min 48s ago Docs: man:fail2ban(1) Main PID: 563 (fail2ban-server) Tasks: 5 (limit: 9510) Memory: 17.7M CPU: 298ms CGroup: /system.slice/fail2ban.service ‚îî‚îÄ563 /usr/bin/python3 /usr/bin/fail2ban-server -xf start Jan 14 21:21:40 standev systemd[1]: Started Fail2Ban Service. Jan 14 21:21:42 standev fail2ban-server[563]: Server ready It should be possibly to have fail2ban also monitor failed RDP login attempts, that would improve security even more. https://stackoverflow.com/questions/75915624/xrdp-filter-setting-for-fail2ban Create the VM We now are ready to bring it all together and create the VM. For this Azure CLI has the az vm create command. The following example creates a VM that automatically starts up and runs our Cloud-init script: az vm create \\ --resource-group $resourceGroup \\ --name $vmName \\ --nics $NICName \\ --image $vmImage \\ --storage-sku $storagetype \\ --size $vmSize \\ --admin-username $AdminUsername \\ --custom-data $customDataScript.tmp \\ --generate-ssh-keys \\ --output $azOutput \\ --security-type Standard # no trusted launch Most options we already discussed above, except two: --custom-data, this specifies the Cloud-init script that will passed on to the cloud-init enabled VM image and contains instructions to create user accounts, install packages etc. --generate-ssh-keys, this was described under ‚ÄúSecuring the VM‚Äù. Although there are Azure CLI commands to stop, start and deallocate the VM, I typically use a shell script deploy_vm_ubuntu.sh to bring it up, leave it running while I need it, use the Azure Portal to manually stop and start the VM, and when no longer needed, tear it down using another script delete_vm_ubuntu.sh. This script simply uses az group delete to remove the Resource group containing the VM and related resources. After running the deploy script, we can ssh into the VM and verify that cloud-init is still running in the background: (base) gertjan:~/azure_cli_scripts$ ssh stanuser@gsverhoeven.westeurope.cloudapp.azure.com Welcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.2.0-1018-azure x86_64) [....] *** System restart required *** To run a command as administrator (user \"root\"), use \"sudo \". See \"man sudo_root\" for details. stanuser@standev:~$ cloud-init status status: running stanuser@standev:~$ exit After some 25 minutes of installing software, the VM is ready for use. Cloud-init v. 23.3.3-0ubuntu0~22.04.1 finished at Mon, 01 Jan 2024 18:09:08 +0000. \\ Datasource DataSourceAzure [seed=/dev/sr0]. Up 1453.38 seconds For the finishing touch, we (manually) do all upgrades to get the latest security updates, and reboot the system. (base) gertjan:~/Werk/Github/gsverhoeven/azure_cli_scripts$ ssh stanuser@gsverhoeven.westeurope.cloudapp.azure.com [...] sudo apt upgrade sudo reboot After this, we are in business, let the Bayesian modelling commence! Lessons learned I learned several things from doing this. First, infrastructure as code is a form of software development, and as such needs a suitable development environment. This means being able to rapidly test changes in e.g. configuration scripts, and to be able to debug stuff by stripping things to the core. I improved the workflow by using QEMU, that allows me to work with Cloud-init enabled instances locally. This allowed me to figure out how cloud-init works without the overhead of doing a full cloud rollout, creating all the resources etc. However, as my local machine is quite dated (4 GB mem, 2 core CPU, so even worse than the cheap D-compute from Azure) executing the full init takes even longer than in the cloud, and I ran into memory problems as I can only run QEMU with 2 GB mem. So repeating the full process every time we make a small change is not the way. Ultimately we need a build tool that breaks down the whole image building process into a pipeline of steps, saving intermediate results. Basically a make tool for VM (golden) image building. Then if we change some code, it could use graph dependencies to figure out which parts are affected and need to be rebuild. My next step here would be to look at Ansible or an open source alternative to HashiCorp Packer. In addition, there is this Container thing, with Docker etc. This might offer a different way of ‚Äúdesktop computing‚Äù where I develop locally and run analyses in Docker containers in the cloud, managed by Kubernetes. This is completely uncharted territory for me. Another thing I found that Cloud computing is expensive. Even with the most low cost options, for a 24/7 desktop solution in the cloud we still end up paying around a 100 euro per month. And that‚Äôs with a 2 core 8GB RAM machine! This is the price we pay for the flexibility of renting without any long term commitment, the hardware already being there, it just works etc. Finally, I am used to the relatively safe computing environment at home behind an ISP‚Äôs firewall. In the public cloud, we are fully exposed, and one can actually see the continuous break-in attempts occurring by the hour. That somehow feels a bit.. chilly. To be continued ‚Ä¶",
      "twitter_title": "Statistical computing on a shoestring: Stan in the Azure cloud using Cloud-init | R-bloggers",
      "url": "https://www.r-bloggers.com/2024/01/statistical-computing-on-a-shoestring-stan-in-the-azure-cloud-using-cloud-init/",
      "word_count": 5570
    }
  }
}