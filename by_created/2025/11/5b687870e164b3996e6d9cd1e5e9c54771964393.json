{
  "id": "5b687870e164b3996e6d9cd1e5e9c54771964393",
  "url": "https://www.r-bloggers.com/2023/11/original-text/",
  "created_at_utc": "2025-11-17T20:39:21Z",
  "data": null,
  "raw_original": {
    "uuid": "2e48bc28-e814-4a09-81d3-a14359865887",
    "created_at": "2025-11-17 20:39:21",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2023/11/original-text/",
      "crawled_at": "2025-11-17T09:59:45.515564",
      "external_links": [
        {
          "href": "https://matiasandina.com/posts/2023-11-07-original-text/index.html",
          "text": "Matias Andina"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://matiasandina.github.io/ggethos/",
          "text": "here"
        },
        {
          "href": "https://creativecommons.org/licenses/by/4.0/",
          "text": "https://creativecommons.org/licenses/by/4.0/"
        },
        {
          "href": "https://matiasandina.com/posts/2023-11-07-original-text",
          "text": "https://matiasandina.com/posts/2023-11-07-original-text"
        },
        {
          "href": "https://matiasandina.com/posts/2023-11-07-original-text/index.html",
          "text": "Matias Andina"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Original Text | R-bloggers",
      "images": [
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/matiasandina.com/posts/2023-11-07-original-text/index_files/figure-html/unnamed-chunk-9-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/matiasandina.com/posts/2023-11-07-original-text/index_files/figure-html/unnamed-chunk-10-1.png?w=450&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/matias-andina/",
          "text": "Matias Andina"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-379977 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Original Text</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">November 6, 2023</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/matias-andina/\">Matias Andina</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://matiasandina.com/posts/2023-11-07-original-text/index.html\"> Matias Andina</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<p>I have been lately noticing a glaring trend in some of the non-fiction books that I read: the use and abuse of verbatim quotes. They come in the shape of:</p>\n<blockquote class=\"blockquote\">\n<p>‚ÄúAs such and such said: INSERT LONG VERBATIM TEXT HERE‚Äù</p>\n</blockquote>\n<p>Of course, there are no rules regarding the use of verbatim text<sup>1</sup>. But, if I can get a sense of overuse only from reading the book, it makes me curious to go get look at the data.</p>\n<p>How much of the book is actually a verbatim text dump? Would I bet is 10%? Maybe 20%? Would lower percentages make me go easier on the author or is this a lost cause (i.e., if I notice the overuse by reading, all hope is lost)?</p>\n<section class=\"level2\" id=\"example-book\">\n<h2 class=\"anchored\" data-anchor-id=\"example-book\">Example Book</h2>\n<p>Enough of chatter. Let‚Äôs try to answer this by analyzing one of the books in question: ‚ÄúDo Nothing‚Äù by Celeste Headlee. Reading the book in R using the <code>epubr</code> package gives us this table:</p>\n<div class=\"cell\">\n<details>\n<summary>Code</summary>\n<pre># read the epub\nbook_text &lt;- epubr::epub(\"Do Nothing - Celeste Headlee.epub\")\nbook_text$data[[1]] %&gt;% \n  mutate(text = str_sub(text, 0, 20),\n         text = paste(text, \"...\")) %&gt;% \n  gt::gt() # needs to get the text stings truncated</pre>\n</details>\n<div class=\"cell-output-display\">\n<div id=\"mderspzntz\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n\n<table class=\"gt_table\" data-quarto-bootstrap=\"false\" data-quarto-disable-processing=\"false\">\n<thead>\n<tr class=\"gt_col_headings\">\n<th class=\"gt_col_heading gt_columns_bottom_border gt_left\" colspan=\"1\" id=\"section\" rowspan=\"1\" scope=\"col\">section</th>\n<th class=\"gt_col_heading gt_columns_bottom_border gt_left\" colspan=\"1\" id=\"text\" rowspan=\"1\" scope=\"col\">text</th>\n<th class=\"gt_col_heading gt_columns_bottom_border gt_right\" colspan=\"1\" id=\"nword\" rowspan=\"1\" scope=\"col\">nword</th>\n<th class=\"gt_col_heading gt_columns_bottom_border gt_right\" colspan=\"1\" id=\"nchar\" rowspan=\"1\" scope=\"col\">nchar</th>\n</tr>\n</thead>\n<tbody class=\"gt_table_body\">\n<tr><td class=\"gt_row gt_left\" headers=\"section\">titlepage</td>\n<td class=\"gt_row gt_left\" headers=\"text\"> ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">0</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">0</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0001.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\"> ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">0</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">0</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0002.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\"> ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">0</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">0</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0003.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Copyright ¬© 2020 by  ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">111</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">1014</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0004.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">CONTENTSCoverTitle P ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">93</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">685</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0005.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">INTRODUCTIONIt will  ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">3242</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">18783</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0006.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">PART IThe Cult of Ef ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">5</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">28</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0007.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Chapter 1MIND THE GA ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">3270</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">18268</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0008.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Chapter 2IT STARTS W ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">4880</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">28878</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0009.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Chapter 3WORK ETHICI ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">3812</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">22815</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0010.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Chapter 4TIME BECOME ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">8804</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">52065</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0011.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Chapter 5WORK COMES  ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">4271</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">25298</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0012.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Chapter 6THE BUSIEST ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">4773</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">28006</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0013.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Chapter 7DO WE LIVE  ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">5022</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">28949</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0014.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Chapter 8UNIVERSAL H ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">5930</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">35332</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0015.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Chapter 9IS TECH TO  ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">6036</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">35402</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0016.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">PART IILeaving the C ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">12</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">61</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0017.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Life-Back OneCHALLEN ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">2345</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">13558</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0018.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Life-Back TwoTAKE TH ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">2570</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">15330</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0019.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Life-Back ThreeSTEP  ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">3933</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">22790</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0020.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Life-Back FourINVEST ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">1925</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">10856</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0021.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Life-Back FiveMAKE R ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">2857</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">16804</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0022.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">Life-Back SixTAKE TH ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">2161</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">12337</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0023.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">CONCLUSIONWe have ch ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">2084</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">12378</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0024.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">For Theresa, who has ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">14</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">72</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0025.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">ACKNOWLEDGMENTSI WOR ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">355</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">1995</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0026.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">NOTESIntroduction‚ÄùOu ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">4067</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">28683</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0027.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">ABOUT THE AUTHORCELE ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">318</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">1971</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"section\">part0028.xhtml</td>\n<td class=\"gt_row gt_left\" headers=\"text\">What‚Äôs next onyour r ‚Ä¶</td>\n<td class=\"gt_row gt_right\" headers=\"nword\">19</td>\n<td class=\"gt_row gt_right\" headers=\"nchar\">139</td></tr>\n</tbody>\n</table>\n</div>\n</div>\n</div>\n<p>We can get rid of the legal stuff that normally goes before the text and everything that comes after the content (i.e., acknowledgements and references).</p>\n<div class=\"cell\">\n<details>\n<summary>Code</summary>\n<pre># A simple slice operation would do\nbook_txt &lt;- book_text$data[[1]] %&gt;% \n  slice(6:24)</pre>\n</details>\n</div>\n<p>We can also get some metadata from the text (will come useful for later).<br/>\n</p>\n<div class=\"cell\">\n<details>\n<summary>Code</summary>\n<pre># bind previous word and character counts\nmeta &lt;- book_txt %&gt;% \n  select(section, nword, nchar) %&gt;% \n  mutate(part = paste0(\"part\", 5:23)) %&gt;% \n  select(-section)</pre>\n</details>\n</div>\n<p>Now that we have the text, we can find all the instances of <code>\"something in between these quotes here\"</code> using <code>stringr::str_locate_all():</code></p>\n<div class=\"cell\">\n<details>\n<summary>Code</summary>\n<pre># extract the text\nmatch_df &lt;- stringr::str_locate_all(book_txt$text, '\"(.*?)\"') %&gt;% \n  # give names for future binding\n  # parts go from 5 to 23 (idx goes 6:24)\n  set_names(nm = paste0(\"part\", 5:23)) %&gt;% \n  # convert into tibble for easy binding\n  map(as_tibble) %&gt;% \n  bind_rows(.id =  \"part\")</pre>\n</details>\n</div>\n<p>Below, I‚Äôm showing a slice with an example of matched character positions and how they would look like in the text. I want to direct your attention to the second and third row. I hope you notice that these two quotes are, in fact, one single quote that was split into two.</p>\n<div class=\"cell\">\n<details>\n<summary>Code</summary>\n<pre># This is an example\nmatch_df %&gt;% \n  slice(8:10) %&gt;% \n  mutate(quote = map2_chr(\n    start, end,  \n    function(.x, .y) str_sub(book_txt$text[[1]], .x, .y)\n  )) %&gt;% \n  gt::gt() %&gt;%\n  gt::tab_style(\n    style = gt::cell_text(weight = \"bold\"),\n    locations = gt::cells_column_labels()\n        )</pre>\n</details>\n<div class=\"cell-output-display\">\n<div id=\"wgroahpbhl\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n\n<table class=\"gt_table\" data-quarto-bootstrap=\"false\" data-quarto-disable-processing=\"false\">\n<thead>\n<tr class=\"gt_col_headings\">\n<th class=\"gt_col_heading gt_columns_bottom_border gt_left\" colspan=\"1\" id=\"part\" rowspan=\"1\" scope=\"col\" style=\"font-weight: bold;\">part</th>\n<th class=\"gt_col_heading gt_columns_bottom_border gt_right\" colspan=\"1\" id=\"start\" rowspan=\"1\" scope=\"col\" style=\"font-weight: bold;\">start</th>\n<th class=\"gt_col_heading gt_columns_bottom_border gt_right\" colspan=\"1\" id=\"end\" rowspan=\"1\" scope=\"col\" style=\"font-weight: bold;\">end</th>\n<th class=\"gt_col_heading gt_columns_bottom_border gt_left\" colspan=\"1\" id=\"quote\" rowspan=\"1\" scope=\"col\" style=\"font-weight: bold;\">quote</th>\n</tr>\n</thead>\n<tbody class=\"gt_table_body\">\n<tr><td class=\"gt_row gt_left\" headers=\"part\">part5</td>\n<td class=\"gt_row gt_right\" headers=\"start\">14893</td>\n<td class=\"gt_row gt_right\" headers=\"end\">14905</td>\n<td class=\"gt_row gt_left\" headers=\"quote\">‚Äúinefficient‚Äù</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"part\">part5</td>\n<td class=\"gt_row gt_right\" headers=\"start\">16002</td>\n<td class=\"gt_row gt_right\" headers=\"end\">16132</td>\n<td class=\"gt_row gt_left\" headers=\"quote\">‚ÄúI can hunch over my computer screen for half the day churning frenetically through emails without getting much of substance done,‚Äù</td></tr>\n<tr><td class=\"gt_row gt_left\" headers=\"part\">part5</td>\n<td class=\"gt_row gt_right\" headers=\"start\">16186</td>\n<td class=\"gt_row gt_right\" headers=\"end\">16336</td>\n<td class=\"gt_row gt_left\" headers=\"quote\">‚Äúall the while telling myself what a loser I am, and leave at 6:00 p.m. feeling like I put in a full day. And given my level of mental fatigue, I did!‚Äù</td></tr>\n</tbody>\n</table>\n</div>\n</div>\n</div>\n<section class=\"level3\" id=\"merging-quotes\">\n<h3 class=\"anchored\" data-anchor-id=\"merging-quotes\">Merging Quotes</h3>\n<p>The issue of quotes being split arises not because of a bug in code, but because the author writes in this way. She would do something like:</p>\n<blockquote class=\"blockquote\">\n<p>‚ÄúA palm tree‚Äù, somebody said, ‚Äúbelongs to the Plant Kingdom.‚Äù</p>\n</blockquote>\n<p>These stylistic choices will modify the statistics for the direct quotes (e.g., the average length of a quote will be much lesser than if these quotes were kept verbatim). I decided that I want to merge quotes if they are too close to each other (I will try 100 characters<sup>2</sup>). This will slightly inflate my % counts, since I‚Äôm attributing characters that are not direct quotes to actual quotes. Thus, when I calculate percentages, I will do so without merging (see <span class=\"citation\" data-cites=\"percentages-with-no-merging\">@percentages-with-no-merging</span>).</p>\n<p>There‚Äôs one neat trick using <code>lag</code> and <code>cumsum</code> with a condition to achieve conditional grouping. We can see that rows 9 and 10 are marked as belonging to the same group now üéâ.</p>\n<div class=\"cell\">\n<details>\n<summary>Code</summary>\n<pre>threshold &lt;- 100  # Define your threshold\n\nmerged_quotes &lt;- match_df %&gt;%\n  mutate(\n    .by = part, \n    prev_end = lag(end),\n    distance = start - prev_end,\n    merge_group = cumsum(ifelse(is.na(distance) | distance &gt; threshold, 1, 0))\n  ) \n\n# \nhead(merged_quotes, n = 10)</pre>\n</details>\n<div class=\"cell-output cell-output-stdout\">\n<pre># A tibble: 10 √ó 6\n   part  start   end prev_end distance merge_group\n   &lt;chr&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;    &lt;int&gt;       &lt;dbl&gt;\n 1 part5   574   597       NA       NA           1\n 2 part5  1342  1361      597      745           2\n 3 part5  1876  1904     1361      515           3\n 4 part5  6036  6051     1904     4132           4\n 5 part5  8751  8944     6051     2700           5\n 6 part5  9276  9373     8944      332           6\n 7 part5 13258 13265     9373     3885           7\n 8 part5 14893 14905    13265     1628           8\n 9 part5 16002 16132    14905     1097           9\n10 part5 16186 16336    16132       54           9</pre>\n</div>\n</div>\n<p>This intermediate step also gives us the answer to a new question:</p>\n<blockquote class=\"blockquote\">\n<p>What is the average distance between quotes?</p>\n</blockquote>\n<p>The answer is xÃÑ= 740 ¬± sd = 970 . On average, you start a new qoute after 130 words of original content. Is that a lot? Is that too little?</p>\n<p>To be honest, it feels true to the reading experience. My sensation was that the author was using the verbatim quotes with high frequency, and the data seems to align with that. But don‚Äôt take my word for it, let‚Äôs try to visualize it.</p>\n<p>We are two steps away from the viz.</p>\n<ol type=\"1\">\n<li>Do the actual merge</li>\n<li>Add the end of each chapter</li>\n</ol>\n<p>We can do <code>Step 1</code> using the code below:</p>\n<div class=\"cell\">\n<details>\n<summary>Code</summary>\n<pre>merged_quotes &lt;- merged_quotes %&gt;%\n  summarize(\n    .by = c(merge_group, part),\n    part = first(part),\n    start = first(start),\n    end = last(end)\n  ) %&gt;% \n  # add the lag again to see where the original text starts\n  mutate(text_start = lag(end, default = 0), .by = part)</pre>\n</details>\n</div>\n<p>Right now, we have the start of the original text in <code>text_start</code> and the <code>start</code> and <code>end</code> of each verbatim quote. We need to make use of the metadata stored in <code>meta</code> to add the end of the original content for of each chapter. This only matters for the very last portion that we are going to plot, so I will make a new data set that contains those values instead of merging everything together. To visualize it, I‚Äôm going to make use of a package I developed called <code>ggethos</code>. You can check it out <a href=\"https://matiasandina.github.io/ggethos/\" rel=\"nofollow\" target=\"_blank\">here</a> or adapt the code to work with <code>geom_segment()</code>.</p>\n<div class=\"cell\">\n<details>\n<summary>Code</summary>\n<pre># pad parts  for plotting\nformat_part &lt;- function(part_name) {\n  # Extract the numeric part\n  part_number &lt;- as.integer(str_extract(part_name, \"\\\\d+\"))\n\n  # Pad the number with zeros and prepend 'part'\n  formatted_part &lt;- str_c(\"part\", str_pad(part_number, width = 2, pad = \"0\"))\n  \n  return(formatted_part)\n}\n\n# make tail end segments\ntail_data &lt;- merged_quotes %&gt;% \n  summarise(.by = part, last_quote_end = max(end)) %&gt;% \n  left_join(meta, by='part') %&gt;% \n  # fix the padding after merging\n  mutate(part = format_part(part))\n\n# fix the padding here too\nmerged_quotes &lt;- merged_quotes  %&gt;% mutate(part = format_part(part))\n\n\nggplot(data=merged_quotes) + \n  geom_ethogram(aes(x=text_start, xend=start, y = part), color =\"gray30\") +\n  geom_ethogram(data=tail_data, aes(x=last_quote_end, \n                                    xend=nchar, y = part), color =\"gray30\") +\n  geom_ethogram(aes(x=start, xend=end, y = part), color = \"red\")+\n  cowplot::theme_nothing() +\n  labs(title = \"'Do Nothing' is Peppered by Quotes\",\n       subtitle = \"&lt;span style = 'color:gray30'&gt;Original Text&lt;/span&gt; and &lt;span style = 'color:red'&gt;Verbatim quotes&lt;/span&gt;\",\n       caption = \"Viz: Matias Andina\",\n       y = \"Chapter\") +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    plot.subtitle = ggtext::element_markdown(hjust = 0.5),\n    plot.background = element_rect(fill = \"black\"),\n    text = element_text(color = 'gray80'),\n    axis.title.y = element_text(angle = 90),\n    plot.caption = element_text(size = 8, hjust = .95))</pre>\n</details>\n<div class=\"cell-output-display\">\n<p><img class=\"img-fluid\" data-lazy-src=\"https://i1.wp.com/matiasandina.com/posts/2023-11-07-original-text/index_files/figure-html/unnamed-chunk-9-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/matiasandina.com/posts/2023-11-07-original-text/index_files/figure-html/unnamed-chunk-9-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</div>\n</div>\n<p>I believe this plot conveys a good mental image of what reading the book feels like in terms of verbatim text usage.</p>\n</section>\n<section class=\"level3\" id=\"percentages-with-no-merges\">\n<h3 class=\"anchored\" data-anchor-id=\"percentages-with-no-merges\">Percentages with no merges</h3>\n<p>As mentioned in the beginning of the article, I was curious about <em>how much</em> verbatim text there was. Again, using the number of characters in each chapter stored in the <code>meta</code> object, we can easily calculate the percentage of all characters that are directly quoted:</p>\n<div class=\"cell\">\n<details>\n<summary>Code</summary>\n<pre>match_df %&gt;% \n  mutate(quote_chars = end - start) %&gt;% \n  summarise(.by = part, \n            quote_chars = sum(quote_chars)) %&gt;% \n  left_join(meta, by = \"part\") %&gt;% \n  mutate(quote_frac = quote_chars / nchar,\n         part = fct_reorder(part, quote_frac)) %&gt;% \n  ggplot() +\n  geom_hline(aes(yintercept = mean(quote_frac)), lty = 4) +\n  geom_point(aes(as.numeric(part), quote_frac), \n             size = 4, alpha = 0.9, color = \"darkred\") +\n  geom_label(aes(x = 15.5, y = 0.17,\n                 label = paste(part[which.max(quote_frac)],\n                               scales::percent(max(quote_frac)),\n                               sep=\"\\n\"\n                 ))) +\n  scale_y_continuous(labels = scales::label_percent(),\n                     expand = expansion(add = c(0.01, 0.05)))+\n  labs(y = \"Verbatim Quotes\",\n       x = \"Book Part\\n(ascending quote % order)\",\n       title = \"'Do Nothing' contains ~10% verbatim quoted text\",\n       subtitle = \"Some parts are as high as 17%!\")+\n  cowplot::theme_minimal_hgrid()</pre>\n</details>\n<div class=\"cell-output-display\">\n<p><img class=\"img-fluid\" data-lazy-src=\"https://i1.wp.com/matiasandina.com/posts/2023-11-07-original-text/index_files/figure-html/unnamed-chunk-10-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/matiasandina.com/posts/2023-11-07-original-text/index_files/figure-html/unnamed-chunk-10-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</div>\n</div>\n</section>\n</section>\n<section class=\"level2\" id=\"a-silver-lining\">\n<h2 class=\"anchored\" data-anchor-id=\"a-silver-lining\">A silver lining</h2>\n<p>Most non-fiction books are a regurgitation of something somebody else said a long time ago (there‚Äôs nothing new under the sun). In a sense then, it‚Äôs more truthful for an author to quote verbatim from the original source than to paraphrase whatever they took out of it and hide the initial message under a footnote<sup>3</sup>.</p>\n</section>\n<div class=\"default\" id=\"quarto-appendix\"><section class=\"footnotes footnotes-end-of-document\" id=\"footnotes\"><h2 class=\"anchored quarto-appendix-heading\">Footnotes</h2>\n<ol>\n<li id=\"fn1\"><p>But I‚Äôm sure a copyright lawyer would know much more than I do regarding how much verbatim text you can include and still claim ownership of your work.‚Ü©Ô∏é</p></li>\n<li id=\"fn2\"><p>Of course, this threshold is arbitrary. How did I come up with it? I asked ChatGPT to come up with 10 interjections that were a bit longer than ‚Äúthey said‚Äù and phrases where sitting comfortably around 50. I doubled it to be super sure that we were not missing instances.‚Ü©Ô∏é</p></li>\n<li id=\"fn3\"><p>This paragraph was indeed a paraphrase of my editor‚Äôs (read wife‚Äôs) reaction to my article. Talking to her is a great exercise in positive reframing.‚Ü©Ô∏é</p></li>\n</ol>\n</section><section class=\"quarto-appendix-contents\"><h2 class=\"anchored quarto-appendix-heading\">Reuse</h2><div class=\"quarto-appendix-contents\" id=\"quarto-reuse\"><div><a href=\"https://creativecommons.org/licenses/by/4.0/\" rel=\"nofollow\" target=\"_blank\">https://creativecommons.org/licenses/by/4.0/</a></div></div></section><section class=\"quarto-appendix-contents\"><h2 class=\"anchored quarto-appendix-heading\">Citation</h2><div><div class=\"quarto-appendix-secondary-label\">BibTeX citation:</div><pre>@online{andina2023,\n  author = {Andina, Matias},\n  title = {Original {Text}},\n  date = {2023-11-07},\n  url = {https://matiasandina.com/posts/2023-11-07-original-text},\n  langid = {en}\n}\n</pre><div class=\"quarto-appendix-secondary-label\">For attribution, please cite this work as:</div><div class=\"csl-entry quarto-appendix-citeas\" id=\"ref-andina2023\">\nAndina, Matias. 2023. <span>‚ÄúOriginal Text.‚Äù</span> November 7, 2023. <a href=\"https://matiasandina.com/posts/2023-11-07-original-text\" rel=\"nofollow\" target=\"_blank\">https://matiasandina.com/posts/2023-11-07-original-text</a>.\n</div></div></section></div>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://matiasandina.com/posts/2023-11-07-original-text/index.html\"> Matias Andina</a></strong>.</div>\n<hr>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</hr></div> </div>\n</article>",
      "main_text": "Original Text\nPosted on\nNovember 6, 2023\nby\nMatias Andina\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nMatias Andina\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nI have been lately noticing a glaring trend in some of the non-fiction books that I read: the use and abuse of verbatim quotes. They come in the shape of:\n‚ÄúAs such and such said: INSERT LONG VERBATIM TEXT HERE‚Äù\nOf course, there are no rules regarding the use of verbatim text\n1\n. But, if I can get a sense of overuse only from reading the book, it makes me curious to go get look at the data.\nHow much of the book is actually a verbatim text dump? Would I bet is 10%? Maybe 20%? Would lower percentages make me go easier on the author or is this a lost cause (i.e., if I notice the overuse by reading, all hope is lost)?\nExample Book\nEnough of chatter. Let‚Äôs try to answer this by analyzing one of the books in question: ‚ÄúDo Nothing‚Äù by Celeste Headlee. Reading the book in R using the\nepubr\npackage gives us this table:\nCode\n# read the epub\nbook_text <- epubr::epub(\"Do Nothing - Celeste Headlee.epub\")\nbook_text$data[[1]] %>% \n  mutate(text = str_sub(text, 0, 20),\n         text = paste(text, \"...\")) %>% \n  gt::gt() # needs to get the text stings truncated\nsection\ntext\nnword\nnchar\ntitlepage\n‚Ä¶\n0\n0\npart0001.xhtml\n‚Ä¶\n0\n0\npart0002.xhtml\n‚Ä¶\n0\n0\npart0003.xhtml\nCopyright ¬© 2020 by  ‚Ä¶\n111\n1014\npart0004.xhtml\nCONTENTSCoverTitle P ‚Ä¶\n93\n685\npart0005.xhtml\nINTRODUCTIONIt will  ‚Ä¶\n3242\n18783\npart0006.xhtml\nPART IThe Cult of Ef ‚Ä¶\n5\n28\npart0007.xhtml\nChapter 1MIND THE GA ‚Ä¶\n3270\n18268\npart0008.xhtml\nChapter 2IT STARTS W ‚Ä¶\n4880\n28878\npart0009.xhtml\nChapter 3WORK ETHICI ‚Ä¶\n3812\n22815\npart0010.xhtml\nChapter 4TIME BECOME ‚Ä¶\n8804\n52065\npart0011.xhtml\nChapter 5WORK COMES  ‚Ä¶\n4271\n25298\npart0012.xhtml\nChapter 6THE BUSIEST ‚Ä¶\n4773\n28006\npart0013.xhtml\nChapter 7DO WE LIVE  ‚Ä¶\n5022\n28949\npart0014.xhtml\nChapter 8UNIVERSAL H ‚Ä¶\n5930\n35332\npart0015.xhtml\nChapter 9IS TECH TO  ‚Ä¶\n6036\n35402\npart0016.xhtml\nPART IILeaving the C ‚Ä¶\n12\n61\npart0017.xhtml\nLife-Back OneCHALLEN ‚Ä¶\n2345\n13558\npart0018.xhtml\nLife-Back TwoTAKE TH ‚Ä¶\n2570\n15330\npart0019.xhtml\nLife-Back ThreeSTEP  ‚Ä¶\n3933\n22790\npart0020.xhtml\nLife-Back FourINVEST ‚Ä¶\n1925\n10856\npart0021.xhtml\nLife-Back FiveMAKE R ‚Ä¶\n2857\n16804\npart0022.xhtml\nLife-Back SixTAKE TH ‚Ä¶\n2161\n12337\npart0023.xhtml\nCONCLUSIONWe have ch ‚Ä¶\n2084\n12378\npart0024.xhtml\nFor Theresa, who has ‚Ä¶\n14\n72\npart0025.xhtml\nACKNOWLEDGMENTSI WOR ‚Ä¶\n355\n1995\npart0026.xhtml\nNOTESIntroduction‚ÄùOu ‚Ä¶\n4067\n28683\npart0027.xhtml\nABOUT THE AUTHORCELE ‚Ä¶\n318\n1971\npart0028.xhtml\nWhat‚Äôs next onyour r ‚Ä¶\n19\n139\nWe can get rid of the legal stuff that normally goes before the text and everything that comes after the content (i.e., acknowledgements and references).\nCode\n# A simple slice operation would do\nbook_txt <- book_text$data[[1]] %>% \n  slice(6:24)\nWe can also get some metadata from the text (will come useful for later).\nCode\n# bind previous word and character counts\nmeta <- book_txt %>% \n  select(section, nword, nchar) %>% \n  mutate(part = paste0(\"part\", 5:23)) %>% \n  select(-section)\nNow that we have the text, we can find all the instances of\n\"something in between these quotes here\"\nusing\nstringr::str_locate_all():\nCode\n# extract the text\nmatch_df <- stringr::str_locate_all(book_txt$text, '\"(.*?)\"') %>% \n  # give names for future binding\n  # parts go from 5 to 23 (idx goes 6:24)\n  set_names(nm = paste0(\"part\", 5:23)) %>% \n  # convert into tibble for easy binding\n  map(as_tibble) %>% \n  bind_rows(.id =  \"part\")\nBelow, I‚Äôm showing a slice with an example of matched character positions and how they would look like in the text. I want to direct your attention to the second and third row. I hope you notice that these two quotes are, in fact, one single quote that was split into two.\nCode\n# This is an example\nmatch_df %>% \n  slice(8:10) %>% \n  mutate(quote = map2_chr(\n    start, end,  \n    function(.x, .y) str_sub(book_txt$text[[1]], .x, .y)\n  )) %>% \n  gt::gt() %>%\n  gt::tab_style(\n    style = gt::cell_text(weight = \"bold\"),\n    locations = gt::cells_column_labels()\n        )\npart\nstart\nend\nquote\npart5\n14893\n14905\n‚Äúinefficient‚Äù\npart5\n16002\n16132\n‚ÄúI can hunch over my computer screen for half the day churning frenetically through emails without getting much of substance done,‚Äù\npart5\n16186\n16336\n‚Äúall the while telling myself what a loser I am, and leave at 6:00 p.m. feeling like I put in a full day. And given my level of mental fatigue, I did!‚Äù\nMerging Quotes\nThe issue of quotes being split arises not because of a bug in code, but because the author writes in this way. She would do something like:\n‚ÄúA palm tree‚Äù, somebody said, ‚Äúbelongs to the Plant Kingdom.‚Äù\nThese stylistic choices will modify the statistics for the direct quotes (e.g., the average length of a quote will be much lesser than if these quotes were kept verbatim). I decided that I want to merge quotes if they are too close to each other (I will try 100 characters\n2\n). This will slightly inflate my % counts, since I‚Äôm attributing characters that are not direct quotes to actual quotes. Thus, when I calculate percentages, I will do so without merging (see\n@percentages-with-no-merging\n).\nThere‚Äôs one neat trick using\nlag\nand\ncumsum\nwith a condition to achieve conditional grouping. We can see that rows 9 and 10 are marked as belonging to the same group now üéâ.\nCode\nthreshold <- 100  # Define your threshold\n\nmerged_quotes <- match_df %>%\n  mutate(\n    .by = part, \n    prev_end = lag(end),\n    distance = start - prev_end,\n    merge_group = cumsum(ifelse(is.na(distance) | distance > threshold, 1, 0))\n  ) \n\n# \nhead(merged_quotes, n = 10)\n# A tibble: 10 √ó 6\n   part  start   end prev_end distance merge_group\n   <chr> <int> <int>    <int>    <int>       <dbl>\n 1 part5   574   597       NA       NA           1\n 2 part5  1342  1361      597      745           2\n 3 part5  1876  1904     1361      515           3\n 4 part5  6036  6051     1904     4132           4\n 5 part5  8751  8944     6051     2700           5\n 6 part5  9276  9373     8944      332           6\n 7 part5 13258 13265     9373     3885           7\n 8 part5 14893 14905    13265     1628           8\n 9 part5 16002 16132    14905     1097           9\n10 part5 16186 16336    16132       54           9\nThis intermediate step also gives us the answer to a new question:\nWhat is the average distance between quotes?\nThe answer is xÃÑ= 740 ¬± sd = 970 . On average, you start a new qoute after 130 words of original content. Is that a lot? Is that too little?\nTo be honest, it feels true to the reading experience. My sensation was that the author was using the verbatim quotes with high frequency, and the data seems to align with that. But don‚Äôt take my word for it, let‚Äôs try to visualize it.\nWe are two steps away from the viz.\nDo the actual merge\nAdd the end of each chapter\nWe can do\nStep 1\nusing the code below:\nCode\nmerged_quotes <- merged_quotes %>%\n  summarize(\n    .by = c(merge_group, part),\n    part = first(part),\n    start = first(start),\n    end = last(end)\n  ) %>% \n  # add the lag again to see where the original text starts\n  mutate(text_start = lag(end, default = 0), .by = part)\nRight now, we have the start of the original text in\ntext_start\nand the\nstart\nand\nend\nof each verbatim quote. We need to make use of the metadata stored in\nmeta\nto add the end of the original content for of each chapter. This only matters for the very last portion that we are going to plot, so I will make a new data set that contains those values instead of merging everything together. To visualize it, I‚Äôm going to make use of a package I developed called\nggethos\n. You can check it out\nhere\nor adapt the code to work with\ngeom_segment()\n.\nCode\n# pad parts  for plotting\nformat_part <- function(part_name) {\n  # Extract the numeric part\n  part_number <- as.integer(str_extract(part_name, \"\\\\d+\"))\n\n  # Pad the number with zeros and prepend 'part'\n  formatted_part <- str_c(\"part\", str_pad(part_number, width = 2, pad = \"0\"))\n  \n  return(formatted_part)\n}\n\n# make tail end segments\ntail_data <- merged_quotes %>% \n  summarise(.by = part, last_quote_end = max(end)) %>% \n  left_join(meta, by='part') %>% \n  # fix the padding after merging\n  mutate(part = format_part(part))\n\n# fix the padding here too\nmerged_quotes <- merged_quotes  %>% mutate(part = format_part(part))\n\nggplot(data=merged_quotes) + \n  geom_ethogram(aes(x=text_start, xend=start, y = part), color =\"gray30\") +\n  geom_ethogram(data=tail_data, aes(x=last_quote_end, \n                                    xend=nchar, y = part), color =\"gray30\") +\n  geom_ethogram(aes(x=start, xend=end, y = part), color = \"red\")+\n  cowplot::theme_nothing() +\n  labs(title = \"'Do Nothing' is Peppered by Quotes\",\n       subtitle = \"<span style = 'color:gray30'>Original Text</span> and <span style = 'color:red'>Verbatim quotes</span>\",\n       caption = \"Viz: Matias Andina\",\n       y = \"Chapter\") +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    plot.subtitle = ggtext::element_markdown(hjust = 0.5),\n    plot.background = element_rect(fill = \"black\"),\n    text = element_text(color = 'gray80'),\n    axis.title.y = element_text(angle = 90),\n    plot.caption = element_text(size = 8, hjust = .95))\nI believe this plot conveys a good mental image of what reading the book feels like in terms of verbatim text usage.\nPercentages with no merges\nAs mentioned in the beginning of the article, I was curious about\nhow much\nverbatim text there was. Again, using the number of characters in each chapter stored in the\nmeta\nobject, we can easily calculate the percentage of all characters that are directly quoted:\nCode\nmatch_df %>% \n  mutate(quote_chars = end - start) %>% \n  summarise(.by = part, \n            quote_chars = sum(quote_chars)) %>% \n  left_join(meta, by = \"part\") %>% \n  mutate(quote_frac = quote_chars / nchar,\n         part = fct_reorder(part, quote_frac)) %>% \n  ggplot() +\n  geom_hline(aes(yintercept = mean(quote_frac)), lty = 4) +\n  geom_point(aes(as.numeric(part), quote_frac), \n             size = 4, alpha = 0.9, color = \"darkred\") +\n  geom_label(aes(x = 15.5, y = 0.17,\n                 label = paste(part[which.max(quote_frac)],\n                               scales::percent(max(quote_frac)),\n                               sep=\"\\n\"\n                 ))) +\n  scale_y_continuous(labels = scales::label_percent(),\n                     expand = expansion(add = c(0.01, 0.05)))+\n  labs(y = \"Verbatim Quotes\",\n       x = \"Book Part\\n(ascending quote % order)\",\n       title = \"'Do Nothing' contains ~10% verbatim quoted text\",\n       subtitle = \"Some parts are as high as 17%!\")+\n  cowplot::theme_minimal_hgrid()\nA silver lining\nMost non-fiction books are a regurgitation of something somebody else said a long time ago (there‚Äôs nothing new under the sun). In a sense then, it‚Äôs more truthful for an author to quote verbatim from the original source than to paraphrase whatever they took out of it and hide the initial message under a footnote\n3\n.\nFootnotes\nBut I‚Äôm sure a copyright lawyer would know much more than I do regarding how much verbatim text you can include and still claim ownership of your work.‚Ü©Ô∏é\nOf course, this threshold is arbitrary. How did I come up with it? I asked ChatGPT to come up with 10 interjections that were a bit longer than ‚Äúthey said‚Äù and phrases where sitting comfortably around 50. I doubled it to be super sure that we were not missing instances.‚Ü©Ô∏é\nThis paragraph was indeed a paraphrase of my editor‚Äôs (read wife‚Äôs) reaction to my article. Talking to her is a great exercise in positive reframing.‚Ü©Ô∏é\nReuse\nhttps://creativecommons.org/licenses/by/4.0/\nCitation\nBibTeX citation:\n@online{andina2023,\n  author = {Andina, Matias},\n  title = {Original {Text}},\n  date = {2023-11-07},\n  url = {https://matiasandina.com/posts/2023-11-07-original-text},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAndina, Matias. 2023.\n‚ÄúOriginal Text.‚Äù\nNovember 7, 2023.\nhttps://matiasandina.com/posts/2023-11-07-original-text\n.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nMatias Andina\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "I have been lately noticing a glaring trend in some of the non-fiction books that I read: the use and abuse of verbatim quotes. They come in the shape of: ‚ÄúAs such and such said: INSERT LONG VERBATIM TEXT HERE‚Äù Of course, there are no rules regarding the use of verbatim text1. But, if I can get a sense of overuse only from reading the book, it makes me curious to go get look at the data. How much of the book is actually a verbatim text dump? Would I bet is 10%? Maybe 20%? Would lower percentages make me go easier on the author or is this a lost cause (i.e., if I notice the overuse by reading, all hope is lost)? Example Book Enough of chatter. Let‚Äôs try to answer this by analyzing one of the books in question: ‚ÄúDo Nothing‚Äù by Celeste Headlee. Reading the book in R using the epubr package gives us this table: Code # read the epub book_text % mutate(text = str_sub(text, 0, 20), text = paste(text, \"...\")) %>% gt::gt() # needs to get the text stings truncated section text nword nchar titlepage ... 0 0 part0001.xhtml ... 0 0 part0002.xhtml ... 0 0 part0003.xhtml Copyright ¬© 2020 by ... 111 1014 part0004.xhtml CONTENTSCoverTitle P ... 93 685 part0005.xhtml INTRODUCTIONIt will ... 3242 18783 part0006.xhtml PART IThe Cult of Ef ... 5 28 part0007.xhtml Chapter 1MIND THE GA ... 3270 18268 part0008.xhtml Chapter 2IT STARTS W ... 4880 28878 part0009.xhtml Chapter 3WORK ETHICI ... 3812 22815 part0010.xhtml Chapter 4TIME BECOME ... 8804 52065 part0011.xhtml Chapter 5WORK COMES ... 4271 25298 part0012.xhtml Chapter 6THE BUSIEST ... 4773 28006 part0013.xhtml Chapter 7DO WE LIVE ... 5022 28949 part0014.xhtml Chapter 8UNIVERSAL H ... 5930 35332 part0015.xhtml Chapter 9IS TECH TO ... 6036 35402 part0016.xhtml PART IILeaving the C ... 12 61 part0017.xhtml Life-Back OneCHALLEN ... 2345 13558 part0018.xhtml Life-Back TwoTAKE TH ... 2570 15330 part0019.xhtml Life-Back ThreeSTEP ... 3933 22790 part0020.xhtml Life-Back FourINVEST ... 1925 10856 part0021.xhtml Life-Back FiveMAKE R ... 2857 16804 part0022.xhtml Life-Back SixTAKE TH ... 2161 12337 part0023.xhtml CONCLUSIONWe have ch ... 2084 12378 part0024.xhtml For Theresa, who has ... 14 72 part0025.xhtml ACKNOWLEDGMENTSI WOR ... 355 1995 part0026.xhtml NOTESIntroduction\"Ou ... 4067 28683 part0027.xhtml ABOUT THE AUTHORCELE ... 318 1971 part0028.xhtml What's next onyour r ... 19 139 We can get rid of the legal stuff that normally goes before the text and everything that comes after the content (i.e., acknowledgements and references). Code # A simple slice operation would do book_txt % slice(6:24) We can also get some metadata from the text (will come useful for later). Code # bind previous word and character counts meta % select(section, nword, nchar) %>% mutate(part = paste0(\"part\", 5:23)) %>% select(-section) Now that we have the text, we can find all the instances of \"something in between these quotes here\" using stringr::str_locate_all(): Code # extract the text match_df % # give names for future binding # parts go from 5 to 23 (idx goes 6:24) set_names(nm = paste0(\"part\", 5:23)) %>% # convert into tibble for easy binding map(as_tibble) %>% bind_rows(.id = \"part\") Below, I‚Äôm showing a slice with an example of matched character positions and how they would look like in the text. I want to direct your attention to the second and third row. I hope you notice that these two quotes are, in fact, one single quote that was split into two. Code # This is an example match_df %>% slice(8:10) %>% mutate(quote = map2_chr( start, end, function(.x, .y) str_sub(book_txt$text[[1]], .x, .y) )) %>% gt::gt() %>% gt::tab_style( style = gt::cell_text(weight = \"bold\"), locations = gt::cells_column_labels() ) part start end quote part5 14893 14905 \"inefficient\" part5 16002 16132 \"I can hunch over my computer screen for half the day churning frenetically through emails without getting much of substance done,\" part5 16186 16336 \"all the while telling myself what a loser I am, and leave at 6:00 p.m. feeling like I put in a full day. And given my level of mental fatigue, I did!\" Merging Quotes The issue of quotes being split arises not because of a bug in code, but because the author writes in this way. She would do something like: ‚ÄúA palm tree‚Äù, somebody said, ‚Äúbelongs to the Plant Kingdom.‚Äù These stylistic choices will modify the statistics for the direct quotes (e.g., the average length of a quote will be much lesser than if these quotes were kept verbatim). I decided that I want to merge quotes if they are too close to each other (I will try 100 characters2). This will slightly inflate my % counts, since I‚Äôm attributing characters that are not direct quotes to actual quotes. Thus, when I calculate percentages, I will do so without merging (see @percentages-with-no-merging). There‚Äôs one neat trick using lag and cumsum with a condition to achieve conditional grouping. We can see that rows 9 and 10 are marked as belonging to the same group now üéâ. Code threshold threshold, 1, 0)) ) # head(merged_quotes, n = 10) # A tibble: 10 √ó 6 part start end prev_end distance merge_group 1 part5 574 597 NA NA 1 2 part5 1342 1361 597 745 2 3 part5 1876 1904 1361 515 3 4 part5 6036 6051 1904 4132 4 5 part5 8751 8944 6051 2700 5 6 part5 9276 9373 8944 332 6 7 part5 13258 13265 9373 3885 7 8 part5 14893 14905 13265 1628 8 9 part5 16002 16132 14905 1097 9 10 part5 16186 16336 16132 54 9 This intermediate step also gives us the answer to a new question: What is the average distance between quotes? The answer is xÃÑ= 740 ¬± sd = 970 . On average, you start a new qoute after 130 words of original content. Is that a lot? Is that too little? To be honest, it feels true to the reading experience. My sensation was that the author was using the verbatim quotes with high frequency, and the data seems to align with that. But don‚Äôt take my word for it, let‚Äôs try to visualize it. We are two steps away from the viz. Do the actual merge Add the end of each chapter We can do Step 1 using the code below: Code merged_quotes % summarize( .by = c(merge_group, part), part = first(part), start = first(start), end = last(end) ) %>% # add the lag again to see where the original text starts mutate(text_start = lag(end, default = 0), .by = part) Right now, we have the start of the original text in text_start and the start and end of each verbatim quote. We need to make use of the metadata stored in meta to add the end of the original content for of each chapter. This only matters for the very last portion that we are going to plot, so I will make a new data set that contains those values instead of merging everything together. To visualize it, I‚Äôm going to make use of a package I developed called ggethos. You can check it out here or adapt the code to work with geom_segment(). Code # pad parts for plotting format_part % # fix the padding after merging mutate(part = format_part(part)) # fix the padding here too merged_quotes % mutate(part = format_part(part)) ggplot(data=merged_quotes) + geom_ethogram(aes(x=text_start, xend=start, y = part), color =\"gray30\") + geom_ethogram(data=tail_data, aes(x=last_quote_end, xend=nchar, y = part), color =\"gray30\") + geom_ethogram(aes(x=start, xend=end, y = part), color = \"red\")+ cowplot::theme_nothing() + labs(title = \"'Do Nothing' is Peppered by Quotes\", subtitle = \"Original Text and Verbatim quotes\", caption = \"Viz: Matias Andina\", y = \"Chapter\") + theme( plot.title = element_text(hjust = 0.5), plot.subtitle = ggtext::element_markdown(hjust = 0.5), plot.background = element_rect(fill = \"black\"), text = element_text(color = 'gray80'), axis.title.y = element_text(angle = 90), plot.caption = element_text(size = 8, hjust = .95)) I believe this plot conveys a good mental image of what reading the book feels like in terms of verbatim text usage. Percentages with no merges As mentioned in the beginning of the article, I was curious about how much verbatim text there was. Again, using the number of characters in each chapter stored in the meta object, we can easily calculate the percentage of all characters that are directly quoted: Code match_df %>% mutate(quote_chars = end - start) %>% summarise(.by = part, quote_chars = sum(quote_chars)) %>% left_join(meta, by = \"part\") %>% mutate(quote_frac = quote_chars / nchar, part = fct_reorder(part, quote_frac)) %>% ggplot() + geom_hline(aes(yintercept = mean(quote_frac)), lty = 4) + geom_point(aes(as.numeric(part), quote_frac), size = 4, alpha = 0.9, color = \"darkred\") + geom_label(aes(x = 15.5, y = 0.17, label = paste(part[which.max(quote_frac)], scales::percent(max(quote_frac)), sep=\"\\n\" ))) + scale_y_continuous(labels = scales::label_percent(), expand = expansion(add = c(0.01, 0.05)))+ labs(y = \"Verbatim Quotes\", x = \"Book Part\\n(ascending quote % order)\", title = \"'Do Nothing' contains ~10% verbatim quoted text\", subtitle = \"Some parts are as high as 17%!\")+ cowplot::theme_minimal_hgrid() A silver lining Most non-fiction books are a regurgitation of something somebody else said a long time ago (there‚Äôs nothing new under the sun). In a sense then, it‚Äôs more truthful for an author to quote verbatim from the original source than to paraphrase whatever they took out of it and hide the initial message under a footnote3. Footnotes But I‚Äôm sure a copyright lawyer would know much more than I do regarding how much verbatim text you can include and still claim ownership of your work.‚Ü©Ô∏é Of course, this threshold is arbitrary. How did I come up with it? I asked ChatGPT to come up with 10 interjections that were a bit longer than ‚Äúthey said‚Äù and phrases where sitting comfortably around 50. I doubled it to be super sure that we were not missing instances.‚Ü©Ô∏é This paragraph was indeed a paraphrase of my editor‚Äôs (read wife‚Äôs) reaction to my article. Talking to her is a great exercise in positive reframing.‚Ü©Ô∏é Reusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{andina2023, author = {Andina, Matias}, title = {Original {Text}}, date = {2023-11-07}, url = {https://matiasandina.com/posts/2023-11-07-original-text}, langid = {en} } For attribution, please cite this work as: Andina, Matias. 2023. ‚ÄúOriginal Text.‚Äù November 7, 2023. https://matiasandina.com/posts/2023-11-07-original-text.",
      "meta_keywords": null,
      "og_description": "I have been lately noticing a glaring trend in some of the non-fiction books that I read: the use and abuse of verbatim quotes. They come in the shape of: ‚ÄúAs such and such said: INSERT LONG VERBATIM TEXT HERE‚Äù Of course, there are no rules regarding the use of verbatim text1. But, if I can get a sense of overuse only from reading the book, it makes me curious to go get look at the data. How much of the book is actually a verbatim text dump? Would I bet is 10%? Maybe 20%? Would lower percentages make me go easier on the author or is this a lost cause (i.e., if I notice the overuse by reading, all hope is lost)? Example Book Enough of chatter. Let‚Äôs try to answer this by analyzing one of the books in question: ‚ÄúDo Nothing‚Äù by Celeste Headlee. Reading the book in R using the epubr package gives us this table: Code # read the epub book_text % mutate(text = str_sub(text, 0, 20), text = paste(text, \"...\")) %>% gt::gt() # needs to get the text stings truncated section text nword nchar titlepage ... 0 0 part0001.xhtml ... 0 0 part0002.xhtml ... 0 0 part0003.xhtml Copyright ¬© 2020 by ... 111 1014 part0004.xhtml CONTENTSCoverTitle P ... 93 685 part0005.xhtml INTRODUCTIONIt will ... 3242 18783 part0006.xhtml PART IThe Cult of Ef ... 5 28 part0007.xhtml Chapter 1MIND THE GA ... 3270 18268 part0008.xhtml Chapter 2IT STARTS W ... 4880 28878 part0009.xhtml Chapter 3WORK ETHICI ... 3812 22815 part0010.xhtml Chapter 4TIME BECOME ... 8804 52065 part0011.xhtml Chapter 5WORK COMES ... 4271 25298 part0012.xhtml Chapter 6THE BUSIEST ... 4773 28006 part0013.xhtml Chapter 7DO WE LIVE ... 5022 28949 part0014.xhtml Chapter 8UNIVERSAL H ... 5930 35332 part0015.xhtml Chapter 9IS TECH TO ... 6036 35402 part0016.xhtml PART IILeaving the C ... 12 61 part0017.xhtml Life-Back OneCHALLEN ... 2345 13558 part0018.xhtml Life-Back TwoTAKE TH ... 2570 15330 part0019.xhtml Life-Back ThreeSTEP ... 3933 22790 part0020.xhtml Life-Back FourINVEST ... 1925 10856 part0021.xhtml Life-Back FiveMAKE R ... 2857 16804 part0022.xhtml Life-Back SixTAKE TH ... 2161 12337 part0023.xhtml CONCLUSIONWe have ch ... 2084 12378 part0024.xhtml For Theresa, who has ... 14 72 part0025.xhtml ACKNOWLEDGMENTSI WOR ... 355 1995 part0026.xhtml NOTESIntroduction\"Ou ... 4067 28683 part0027.xhtml ABOUT THE AUTHORCELE ... 318 1971 part0028.xhtml What's next onyour r ... 19 139 We can get rid of the legal stuff that normally goes before the text and everything that comes after the content (i.e., acknowledgements and references). Code # A simple slice operation would do book_txt % slice(6:24) We can also get some metadata from the text (will come useful for later). Code # bind previous word and character counts meta % select(section, nword, nchar) %>% mutate(part = paste0(\"part\", 5:23)) %>% select(-section) Now that we have the text, we can find all the instances of \"something in between these quotes here\" using stringr::str_locate_all(): Code # extract the text match_df % # give names for future binding # parts go from 5 to 23 (idx goes 6:24) set_names(nm = paste0(\"part\", 5:23)) %>% # convert into tibble for easy binding map(as_tibble) %>% bind_rows(.id = \"part\") Below, I‚Äôm showing a slice with an example of matched character positions and how they would look like in the text. I want to direct your attention to the second and third row. I hope you notice that these two quotes are, in fact, one single quote that was split into two. Code # This is an example match_df %>% slice(8:10) %>% mutate(quote = map2_chr( start, end, function(.x, .y) str_sub(book_txt$text[[1]], .x, .y) )) %>% gt::gt() %>% gt::tab_style( style = gt::cell_text(weight = \"bold\"), locations = gt::cells_column_labels() ) part start end quote part5 14893 14905 \"inefficient\" part5 16002 16132 \"I can hunch over my computer screen for half the day churning frenetically through emails without getting much of substance done,\" part5 16186 16336 \"all the while telling myself what a loser I am, and leave at 6:00 p.m. feeling like I put in a full day. And given my level of mental fatigue, I did!\" Merging Quotes The issue of quotes being split arises not because of a bug in code, but because the author writes in this way. She would do something like: ‚ÄúA palm tree‚Äù, somebody said, ‚Äúbelongs to the Plant Kingdom.‚Äù These stylistic choices will modify the statistics for the direct quotes (e.g., the average length of a quote will be much lesser than if these quotes were kept verbatim). I decided that I want to merge quotes if they are too close to each other (I will try 100 characters2). This will slightly inflate my % counts, since I‚Äôm attributing characters that are not direct quotes to actual quotes. Thus, when I calculate percentages, I will do so without merging (see @percentages-with-no-merging). There‚Äôs one neat trick using lag and cumsum with a condition to achieve conditional grouping. We can see that rows 9 and 10 are marked as belonging to the same group now üéâ. Code threshold threshold, 1, 0)) ) # head(merged_quotes, n = 10) # A tibble: 10 √ó 6 part start end prev_end distance merge_group 1 part5 574 597 NA NA 1 2 part5 1342 1361 597 745 2 3 part5 1876 1904 1361 515 3 4 part5 6036 6051 1904 4132 4 5 part5 8751 8944 6051 2700 5 6 part5 9276 9373 8944 332 6 7 part5 13258 13265 9373 3885 7 8 part5 14893 14905 13265 1628 8 9 part5 16002 16132 14905 1097 9 10 part5 16186 16336 16132 54 9 This intermediate step also gives us the answer to a new question: What is the average distance between quotes? The answer is xÃÑ= 740 ¬± sd = 970 . On average, you start a new qoute after 130 words of original content. Is that a lot? Is that too little? To be honest, it feels true to the reading experience. My sensation was that the author was using the verbatim quotes with high frequency, and the data seems to align with that. But don‚Äôt take my word for it, let‚Äôs try to visualize it. We are two steps away from the viz. Do the actual merge Add the end of each chapter We can do Step 1 using the code below: Code merged_quotes % summarize( .by = c(merge_group, part), part = first(part), start = first(start), end = last(end) ) %>% # add the lag again to see where the original text starts mutate(text_start = lag(end, default = 0), .by = part) Right now, we have the start of the original text in text_start and the start and end of each verbatim quote. We need to make use of the metadata stored in meta to add the end of the original content for of each chapter. This only matters for the very last portion that we are going to plot, so I will make a new data set that contains those values instead of merging everything together. To visualize it, I‚Äôm going to make use of a package I developed called ggethos. You can check it out here or adapt the code to work with geom_segment(). Code # pad parts for plotting format_part % # fix the padding after merging mutate(part = format_part(part)) # fix the padding here too merged_quotes % mutate(part = format_part(part)) ggplot(data=merged_quotes) + geom_ethogram(aes(x=text_start, xend=start, y = part), color =\"gray30\") + geom_ethogram(data=tail_data, aes(x=last_quote_end, xend=nchar, y = part), color =\"gray30\") + geom_ethogram(aes(x=start, xend=end, y = part), color = \"red\")+ cowplot::theme_nothing() + labs(title = \"'Do Nothing' is Peppered by Quotes\", subtitle = \"Original Text and Verbatim quotes\", caption = \"Viz: Matias Andina\", y = \"Chapter\") + theme( plot.title = element_text(hjust = 0.5), plot.subtitle = ggtext::element_markdown(hjust = 0.5), plot.background = element_rect(fill = \"black\"), text = element_text(color = 'gray80'), axis.title.y = element_text(angle = 90), plot.caption = element_text(size = 8, hjust = .95)) I believe this plot conveys a good mental image of what reading the book feels like in terms of verbatim text usage. Percentages with no merges As mentioned in the beginning of the article, I was curious about how much verbatim text there was. Again, using the number of characters in each chapter stored in the meta object, we can easily calculate the percentage of all characters that are directly quoted: Code match_df %>% mutate(quote_chars = end - start) %>% summarise(.by = part, quote_chars = sum(quote_chars)) %>% left_join(meta, by = \"part\") %>% mutate(quote_frac = quote_chars / nchar, part = fct_reorder(part, quote_frac)) %>% ggplot() + geom_hline(aes(yintercept = mean(quote_frac)), lty = 4) + geom_point(aes(as.numeric(part), quote_frac), size = 4, alpha = 0.9, color = \"darkred\") + geom_label(aes(x = 15.5, y = 0.17, label = paste(part[which.max(quote_frac)], scales::percent(max(quote_frac)), sep=\"\\n\" ))) + scale_y_continuous(labels = scales::label_percent(), expand = expansion(add = c(0.01, 0.05)))+ labs(y = \"Verbatim Quotes\", x = \"Book Part\\n(ascending quote % order)\", title = \"'Do Nothing' contains ~10% verbatim quoted text\", subtitle = \"Some parts are as high as 17%!\")+ cowplot::theme_minimal_hgrid() A silver lining Most non-fiction books are a regurgitation of something somebody else said a long time ago (there‚Äôs nothing new under the sun). In a sense then, it‚Äôs more truthful for an author to quote verbatim from the original source than to paraphrase whatever they took out of it and hide the initial message under a footnote3. Footnotes But I‚Äôm sure a copyright lawyer would know much more than I do regarding how much verbatim text you can include and still claim ownership of your work.‚Ü©Ô∏é Of course, this threshold is arbitrary. How did I come up with it? I asked ChatGPT to come up with 10 interjections that were a bit longer than ‚Äúthey said‚Äù and phrases where sitting comfortably around 50. I doubled it to be super sure that we were not missing instances.‚Ü©Ô∏é This paragraph was indeed a paraphrase of my editor‚Äôs (read wife‚Äôs) reaction to my article. Talking to her is a great exercise in positive reframing.‚Ü©Ô∏é Reusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{andina2023, author = {Andina, Matias}, title = {Original {Text}}, date = {2023-11-07}, url = {https://matiasandina.com/posts/2023-11-07-original-text}, langid = {en} } For attribution, please cite this work as: Andina, Matias. 2023. ‚ÄúOriginal Text.‚Äù November 7, 2023. https://matiasandina.com/posts/2023-11-07-original-text.",
      "og_image": "https://matiasandina.com/posts/2023-11-07-original-text/index_files/figure-html/unnamed-chunk-9-1.png",
      "og_title": "Original Text | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 9.8,
      "sitemap_lastmod": "2023-11-07T05:00:00+00:00",
      "twitter_description": "I have been lately noticing a glaring trend in some of the non-fiction books that I read: the use and abuse of verbatim quotes. They come in the shape of: ‚ÄúAs such and such said: INSERT LONG VERBATIM TEXT HERE‚Äù Of course, there are no rules regarding the use of verbatim text1. But, if I can get a sense of overuse only from reading the book, it makes me curious to go get look at the data. How much of the book is actually a verbatim text dump? Would I bet is 10%? Maybe 20%? Would lower percentages make me go easier on the author or is this a lost cause (i.e., if I notice the overuse by reading, all hope is lost)? Example Book Enough of chatter. Let‚Äôs try to answer this by analyzing one of the books in question: ‚ÄúDo Nothing‚Äù by Celeste Headlee. Reading the book in R using the epubr package gives us this table: Code # read the epub book_text % mutate(text = str_sub(text, 0, 20), text = paste(text, \"...\")) %>% gt::gt() # needs to get the text stings truncated section text nword nchar titlepage ... 0 0 part0001.xhtml ... 0 0 part0002.xhtml ... 0 0 part0003.xhtml Copyright ¬© 2020 by ... 111 1014 part0004.xhtml CONTENTSCoverTitle P ... 93 685 part0005.xhtml INTRODUCTIONIt will ... 3242 18783 part0006.xhtml PART IThe Cult of Ef ... 5 28 part0007.xhtml Chapter 1MIND THE GA ... 3270 18268 part0008.xhtml Chapter 2IT STARTS W ... 4880 28878 part0009.xhtml Chapter 3WORK ETHICI ... 3812 22815 part0010.xhtml Chapter 4TIME BECOME ... 8804 52065 part0011.xhtml Chapter 5WORK COMES ... 4271 25298 part0012.xhtml Chapter 6THE BUSIEST ... 4773 28006 part0013.xhtml Chapter 7DO WE LIVE ... 5022 28949 part0014.xhtml Chapter 8UNIVERSAL H ... 5930 35332 part0015.xhtml Chapter 9IS TECH TO ... 6036 35402 part0016.xhtml PART IILeaving the C ... 12 61 part0017.xhtml Life-Back OneCHALLEN ... 2345 13558 part0018.xhtml Life-Back TwoTAKE TH ... 2570 15330 part0019.xhtml Life-Back ThreeSTEP ... 3933 22790 part0020.xhtml Life-Back FourINVEST ... 1925 10856 part0021.xhtml Life-Back FiveMAKE R ... 2857 16804 part0022.xhtml Life-Back SixTAKE TH ... 2161 12337 part0023.xhtml CONCLUSIONWe have ch ... 2084 12378 part0024.xhtml For Theresa, who has ... 14 72 part0025.xhtml ACKNOWLEDGMENTSI WOR ... 355 1995 part0026.xhtml NOTESIntroduction\"Ou ... 4067 28683 part0027.xhtml ABOUT THE AUTHORCELE ... 318 1971 part0028.xhtml What's next onyour r ... 19 139 We can get rid of the legal stuff that normally goes before the text and everything that comes after the content (i.e., acknowledgements and references). Code # A simple slice operation would do book_txt % slice(6:24) We can also get some metadata from the text (will come useful for later). Code # bind previous word and character counts meta % select(section, nword, nchar) %>% mutate(part = paste0(\"part\", 5:23)) %>% select(-section) Now that we have the text, we can find all the instances of \"something in between these quotes here\" using stringr::str_locate_all(): Code # extract the text match_df % # give names for future binding # parts go from 5 to 23 (idx goes 6:24) set_names(nm = paste0(\"part\", 5:23)) %>% # convert into tibble for easy binding map(as_tibble) %>% bind_rows(.id = \"part\") Below, I‚Äôm showing a slice with an example of matched character positions and how they would look like in the text. I want to direct your attention to the second and third row. I hope you notice that these two quotes are, in fact, one single quote that was split into two. Code # This is an example match_df %>% slice(8:10) %>% mutate(quote = map2_chr( start, end, function(.x, .y) str_sub(book_txt$text[[1]], .x, .y) )) %>% gt::gt() %>% gt::tab_style( style = gt::cell_text(weight = \"bold\"), locations = gt::cells_column_labels() ) part start end quote part5 14893 14905 \"inefficient\" part5 16002 16132 \"I can hunch over my computer screen for half the day churning frenetically through emails without getting much of substance done,\" part5 16186 16336 \"all the while telling myself what a loser I am, and leave at 6:00 p.m. feeling like I put in a full day. And given my level of mental fatigue, I did!\" Merging Quotes The issue of quotes being split arises not because of a bug in code, but because the author writes in this way. She would do something like: ‚ÄúA palm tree‚Äù, somebody said, ‚Äúbelongs to the Plant Kingdom.‚Äù These stylistic choices will modify the statistics for the direct quotes (e.g., the average length of a quote will be much lesser than if these quotes were kept verbatim). I decided that I want to merge quotes if they are too close to each other (I will try 100 characters2). This will slightly inflate my % counts, since I‚Äôm attributing characters that are not direct quotes to actual quotes. Thus, when I calculate percentages, I will do so without merging (see @percentages-with-no-merging). There‚Äôs one neat trick using lag and cumsum with a condition to achieve conditional grouping. We can see that rows 9 and 10 are marked as belonging to the same group now üéâ. Code threshold threshold, 1, 0)) ) # head(merged_quotes, n = 10) # A tibble: 10 √ó 6 part start end prev_end distance merge_group 1 part5 574 597 NA NA 1 2 part5 1342 1361 597 745 2 3 part5 1876 1904 1361 515 3 4 part5 6036 6051 1904 4132 4 5 part5 8751 8944 6051 2700 5 6 part5 9276 9373 8944 332 6 7 part5 13258 13265 9373 3885 7 8 part5 14893 14905 13265 1628 8 9 part5 16002 16132 14905 1097 9 10 part5 16186 16336 16132 54 9 This intermediate step also gives us the answer to a new question: What is the average distance between quotes? The answer is xÃÑ= 740 ¬± sd = 970 . On average, you start a new qoute after 130 words of original content. Is that a lot? Is that too little? To be honest, it feels true to the reading experience. My sensation was that the author was using the verbatim quotes with high frequency, and the data seems to align with that. But don‚Äôt take my word for it, let‚Äôs try to visualize it. We are two steps away from the viz. Do the actual merge Add the end of each chapter We can do Step 1 using the code below: Code merged_quotes % summarize( .by = c(merge_group, part), part = first(part), start = first(start), end = last(end) ) %>% # add the lag again to see where the original text starts mutate(text_start = lag(end, default = 0), .by = part) Right now, we have the start of the original text in text_start and the start and end of each verbatim quote. We need to make use of the metadata stored in meta to add the end of the original content for of each chapter. This only matters for the very last portion that we are going to plot, so I will make a new data set that contains those values instead of merging everything together. To visualize it, I‚Äôm going to make use of a package I developed called ggethos. You can check it out here or adapt the code to work with geom_segment(). Code # pad parts for plotting format_part % # fix the padding after merging mutate(part = format_part(part)) # fix the padding here too merged_quotes % mutate(part = format_part(part)) ggplot(data=merged_quotes) + geom_ethogram(aes(x=text_start, xend=start, y = part), color =\"gray30\") + geom_ethogram(data=tail_data, aes(x=last_quote_end, xend=nchar, y = part), color =\"gray30\") + geom_ethogram(aes(x=start, xend=end, y = part), color = \"red\")+ cowplot::theme_nothing() + labs(title = \"'Do Nothing' is Peppered by Quotes\", subtitle = \"Original Text and Verbatim quotes\", caption = \"Viz: Matias Andina\", y = \"Chapter\") + theme( plot.title = element_text(hjust = 0.5), plot.subtitle = ggtext::element_markdown(hjust = 0.5), plot.background = element_rect(fill = \"black\"), text = element_text(color = 'gray80'), axis.title.y = element_text(angle = 90), plot.caption = element_text(size = 8, hjust = .95)) I believe this plot conveys a good mental image of what reading the book feels like in terms of verbatim text usage. Percentages with no merges As mentioned in the beginning of the article, I was curious about how much verbatim text there was. Again, using the number of characters in each chapter stored in the meta object, we can easily calculate the percentage of all characters that are directly quoted: Code match_df %>% mutate(quote_chars = end - start) %>% summarise(.by = part, quote_chars = sum(quote_chars)) %>% left_join(meta, by = \"part\") %>% mutate(quote_frac = quote_chars / nchar, part = fct_reorder(part, quote_frac)) %>% ggplot() + geom_hline(aes(yintercept = mean(quote_frac)), lty = 4) + geom_point(aes(as.numeric(part), quote_frac), size = 4, alpha = 0.9, color = \"darkred\") + geom_label(aes(x = 15.5, y = 0.17, label = paste(part[which.max(quote_frac)], scales::percent(max(quote_frac)), sep=\"\\n\" ))) + scale_y_continuous(labels = scales::label_percent(), expand = expansion(add = c(0.01, 0.05)))+ labs(y = \"Verbatim Quotes\", x = \"Book Part\\n(ascending quote % order)\", title = \"'Do Nothing' contains ~10% verbatim quoted text\", subtitle = \"Some parts are as high as 17%!\")+ cowplot::theme_minimal_hgrid() A silver lining Most non-fiction books are a regurgitation of something somebody else said a long time ago (there‚Äôs nothing new under the sun). In a sense then, it‚Äôs more truthful for an author to quote verbatim from the original source than to paraphrase whatever they took out of it and hide the initial message under a footnote3. Footnotes But I‚Äôm sure a copyright lawyer would know much more than I do regarding how much verbatim text you can include and still claim ownership of your work.‚Ü©Ô∏é Of course, this threshold is arbitrary. How did I come up with it? I asked ChatGPT to come up with 10 interjections that were a bit longer than ‚Äúthey said‚Äù and phrases where sitting comfortably around 50. I doubled it to be super sure that we were not missing instances.‚Ü©Ô∏é This paragraph was indeed a paraphrase of my editor‚Äôs (read wife‚Äôs) reaction to my article. Talking to her is a great exercise in positive reframing.‚Ü©Ô∏é Reusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{andina2023, author = {Andina, Matias}, title = {Original {Text}}, date = {2023-11-07}, url = {https://matiasandina.com/posts/2023-11-07-original-text}, langid = {en} } For attribution, please cite this work as: Andina, Matias. 2023. ‚ÄúOriginal Text.‚Äù November 7, 2023. https://matiasandina.com/posts/2023-11-07-original-text.",
      "twitter_title": "Original Text | R-bloggers",
      "url": "https://www.r-bloggers.com/2023/11/original-text/",
      "word_count": 1951
    }
  }
}