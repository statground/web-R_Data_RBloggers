{
  "uuid": "44edde1c-ebbb-43eb-a92d-2be68bb8b9fd",
  "created_at": "2025-11-22 19:59:24",
  "raw_json": {
    "article_author": null,
    "article_headline": null,
    "article_modified": null,
    "article_published": null,
    "article_section": null,
    "article_tags": null,
    "canonical_url": "https://www.r-bloggers.com/2025/01/a-trip-from-variance-covariance-to-correlation-and-back/",
    "crawled_at": "2025-11-22T10:55:15.743376",
    "external_links": [
      {
        "href": "https://www.statforbiology.com/2025/stat_general_correlationcovariance/",
        "text": "R on Fixing the bridge between biologists and statisticians"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://twitter.com/onofriandreapg?ref_src=twsrc%5Etfw",
        "text": "Follow@onofriandreapg"
      },
      {
        "href": "https://www.statforbiology.com/2025/stat_general_correlationcovariance/",
        "text": "R on Fixing the bridge between biologists and statisticians"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "h1_title": "R-bloggers",
    "html_title": "A trip from variance-covariance to correlation and back | R-bloggers",
    "images": [
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i2.wp.com/www.casaonofri.it/_Figures/CovarianceCorrelation.png?w=578&ssl=1"
      }
    ],
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/r-on-fixing-the-bridge-between-biologists-and-stat/",
        "text": "R on Fixing the bridge between biologists and statisticians"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/cdn-cgi/l/email-protection#e7868983958286c988898881958ea792898e9780c98e93",
        "text": "[email protected]"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "lang": "en-US",
    "main_html": "<article class=\"post-390130 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">A trip from variance-covariance to correlation and back</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">January 23, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/r-on-fixing-the-bridge-between-biologists-and-stat/\">R on Fixing the bridge between biologists and statisticians</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://www.statforbiology.com/2025/stat_general_correlationcovariance/\"> R on Fixing the bridge between biologists and statisticians</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<p>The variance-covariance and the correlation matrices are two entities that describe the association between the columns of a two-way data matrix. They are very much used, e.g., in agriculture, biology and ecology and they can be easily calculated with base R, as shown in the box below.</p>\n<pre>data(mtcars)\nmatr &lt;- mtcars[,1:4]\n\n# Covariances\nSigma &lt;- cov(matr)\n\n# Correlations\nR &lt;- cor(matr)\n\nSigma\n##              mpg        cyl       disp        hp\n## mpg    36.324103  -9.172379  -633.0972 -320.7321\n## cyl    -9.172379   3.189516   199.6603  101.9315\n## disp -633.097208 199.660282 15360.7998 6721.1587\n## hp   -320.732056 101.931452  6721.1587 4700.8669\nR\n##             mpg        cyl       disp         hp\n## mpg   1.0000000 -0.8521620 -0.8475514 -0.7761684\n## cyl  -0.8521620  1.0000000  0.9020329  0.8324475\n## disp -0.8475514  0.9020329  1.0000000  0.7909486\n## hp   -0.7761684  0.8324475  0.7909486  1.0000000</pre>\n<p>It is useful to be able to go back and forth from variance-covariance to correlation, without going back to the original data matrix. Let’s consider that the variance-covariance of the two variables X and Y is:</p>\n<p><span class=\"math display\">\\[\\textrm{cov}(X, Y) = \\sum\\limits_{i=1}^{n} {(X_i - \\hat{X})(Y_i - \\hat{Y})}\\]</span></p>\n<p>where <span class=\"math inline\">\\(\\hat{Y}\\)</span> and <span class=\"math inline\">\\(\\hat{X}\\)</span> are the means for each variable. The correlation is:</p>\n<p><span class=\"math display\">\\[\\textrm{cor}(X, Y) = \\frac{\\textrm{cov}(X, Y)}{\\sigma_x \\sigma_y} \\]</span></p>\n<p>where <span class=\"math inline\">\\(\\sigma_x\\)</span> and <span class=\"math inline\">\\(\\sigma_y\\)</span> are the standard deviations for X and Y.</p>\n<p>The opposite relationship is clear:</p>\n<p><span class=\"math display\">\\[ \\textrm{cov}(X, Y) = \\textrm{cor}(X, Y) \\sigma_x \\sigma_y\\]</span></p>\n<p>Therefore, converting from covariance to correlation is pretty easy. For example, take the covariance between ‘cyl’ and ‘mpg’ above (-9.172379), the correlation is:</p>\n<pre>-633.097208 / (sqrt(36.324103) * sqrt(15360.7998))\n## [1] -0.8475514</pre>\n<p>On the reverse, if we have the correlation (-0.8521620), the covariance is</p>\n<pre>-0.8475514 * sqrt(36.324103) * sqrt(15360.7998)\n## [1] -633.0972</pre>\n<p>If we consider the whole covariance matrix, we have to take each element in this matrix and divide it by the square roots of the diagonal elements in the same column and in the same row (see figure below).</p>\n<p><img data-lazy-src=\"https://i2.wp.com/www.casaonofri.it/_Figures/CovarianceCorrelation.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" style=\"width:95.0%\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.casaonofri.it/_Figures/CovarianceCorrelation.png?w=578&amp;ssl=1\" style=\"width:95.0%\"/></noscript></p>\n<p>The question is: how can we do all these calculations in one single step, for all elements in the covariance matrix, to calculate the corresponding correlation matrix?</p>\n<p>If we have some memories of matrix algebra, we might remember that if we take a diagonal matrix of order <span class=\"math inline\">\\(n \\times n\\)</span> and multiply it by a square matrix with the same order, all elements in each column are multiplied by the diagonal element in the corresponding column:</p>\n<p><span class=\"math display\">\\[\\begin{pmatrix}\n1 &amp; 1 &amp; 1 &amp; 1 \\\\\n1 &amp; 1 &amp; 1 &amp; 1 \\\\\n1 &amp; 1 &amp; 1 &amp; 1 \\\\\n1 &amp; 1 &amp; 1 &amp; 1\n\\end{pmatrix}\n\\times\n\\begin{pmatrix}\n1 &amp; 0 &amp; 0 &amp; 0 \\\\\n0 &amp; 2 &amp; 0 &amp; 0 \\\\\n0 &amp; 0 &amp; 3 &amp; 0 \\\\\n0 &amp; 0 &amp; 0 &amp; 4\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 &amp; 2 &amp; 3 &amp; 4 \\\\\n1 &amp; 2 &amp; 3 &amp; 4 \\\\\n1 &amp; 2 &amp; 3 &amp; 4 \\\\\n1 &amp; 2 &amp; 3 &amp; 4\n\\end{pmatrix}\\]</span></p>\n<p>If we reverse the order of factors, all elements in each row are multiplied by the diagonal element in the corresponding row:</p>\n<p><span class=\"math display\">\\[\n\\begin{pmatrix}\n1 &amp; 0 &amp; 0 &amp; 0 \\\\\n0 &amp; 2 &amp; 0 &amp; 0 \\\\\n0 &amp; 0 &amp; 3 &amp; 0 \\\\\n0 &amp; 0 &amp; 0 &amp; 4\n\\end{pmatrix}\n\\times\n\\begin{pmatrix}\n1 &amp; 1 &amp; 1 &amp; 1 \\\\\n1 &amp; 1 &amp; 1 &amp; 1 \\\\\n1 &amp; 1 &amp; 1 &amp; 1 \\\\\n1 &amp; 1 &amp; 1 &amp; 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 &amp; 1 &amp; 1 &amp; 1 \\\\\n2 &amp; 2 &amp; 2 &amp; 2 \\\\\n3 &amp; 3 &amp; 3 &amp; 3 \\\\\n4 &amp; 4 &amp; 4 &amp; 4\n\\end{pmatrix}\n\\]</span></p>\n<p>Therefore, if we take a covariance matrix <span class=\"math inline\">\\(\\Sigma\\)</span> of order <span class=\"math inline\">\\(n \\times n\\)</span> and pre-multiply and post-multiply it for the same diagonal matrix of order <span class=\"math inline\">\\(n \\times n\\)</span>, each element in <span class=\"math inline\">\\(\\Sigma\\)</span> is multiplied by both the diagonal elements in the same row and same column, which is exactly what we are looking for.</p>\n<p>In the code below, we:</p>\n<ol style=\"list-style-type: decimal\">\n<li>Create a covariance matrix</li>\n<li>Take the square roots of the diagonal element (standard deviations) and load them in a diagonal matrix</li>\n<li>Invert this diagonal matrix</li>\n<li>Pre-multiply and post-multiply the covariance matrix for this diagonal matrix of inverse standard deviations</li>\n</ol>\n<pre>StDev &lt;- sqrt(diag(Sigma))\nStDevMat &lt;- diag(StDev)\nInvStDev &lt;- solve(StDevMat)\nInvStDev %*% Sigma %*% InvStDev\n##            [,1]       [,2]       [,3]       [,4]\n## [1,]  1.0000000 -0.8521620 -0.8475514 -0.7761684\n## [2,] -0.8521620  1.0000000  0.9020329  0.8324475\n## [3,] -0.8475514  0.9020329  1.0000000  0.7909486\n## [4,] -0.7761684  0.8324475  0.7909486  1.0000000</pre>\n<p>Going from correlation to covariance can be done similarly, although, in this case, together with the correlation matrix we also need to have the standard deviations of the original variables, because they are not included in the matrix under transformation:</p>\n<pre>StDevMat %*% R %*% StDevMat\n##             [,1]       [,2]       [,3]      [,4]\n## [1,]   36.324103  -9.172379  -633.0972 -320.7321\n## [2,]   -9.172379   3.189516   199.6603  101.9315\n## [3,] -633.097208 199.660282 15360.7998 6721.1587\n## [4,] -320.732056 101.931452  6721.1587 4700.8669</pre>\n<div class=\"section level1\" id=\"solutions-with-r\">\n<h1>Solutions with R</h1>\n<p>Is there any other solutions for those who are not accustomed to matrix algebra? The easiest way to go from covariance to correlation is to use the <code>cov2cor()</code> function in the ‘nlme’ package.</p>\n<pre># From covariance to correlation\nlibrary(nlme)\ncov2cor(Sigma)\n##             mpg        cyl       disp         hp\n## mpg   1.0000000 -0.8521620 -0.8475514 -0.7761684\n## cyl  -0.8521620  1.0000000  0.9020329  0.8324475\n## disp -0.8475514  0.9020329  1.0000000  0.7909486\n## hp   -0.7761684  0.8324475  0.7909486  1.0000000</pre>\n<p>With base R, we can <code>sweep()</code> twice:</p>\n<pre># From covariance to correlation\nsweep(sweep(Sigma, 1, StDev, FUN = \"/\"), 2, StDev, FUN = \"/\")\n##             mpg        cyl       disp         hp\n## mpg   1.0000000 -0.8521620 -0.8475514 -0.7761684\n## cyl  -0.8521620  1.0000000  0.9020329  0.8324475\n## disp -0.8475514  0.9020329  1.0000000  0.7909486\n## hp   -0.7761684  0.8324475  0.7909486  1.0000000\n# From correlation to covariance\nsweep(sweep(R, 1, StDev, FUN = \"*\"), 2, StDev, FUN = \"*\")\n##              mpg        cyl       disp        hp\n## mpg    36.324103  -9.172379  -633.0972 -320.7321\n## cyl    -9.172379   3.189516   199.6603  101.9315\n## disp -633.097208 199.660282 15360.7998 6721.1587\n## hp   -320.732056 101.931452  6721.1587 4700.8669</pre>\n<p>We can also <code>scale()</code> and <code>t()</code> twice, but it looks far less neat:</p>\n<pre># From covariance to correlation\nscale(t(scale(t(Sigma), center = F, scale = StDev)), \n      center = F, scale = StDev)\n##             mpg        cyl       disp         hp\n## mpg   1.0000000 -0.8521620 -0.8475514 -0.7761684\n## cyl  -0.8521620  1.0000000  0.9020329  0.8324475\n## disp -0.8475514  0.9020329  1.0000000  0.7909486\n## hp   -0.7761684  0.8324475  0.7909486  1.0000000\n## attr(,\"scaled:scale\")\n##        mpg        cyl       disp         hp \n##   6.026948   1.785922 123.938694  68.562868\n# From correlation to covariance\nscale(t(scale(t(R), center = F, scale = 1/StDev)), \n      center = F, scale = 1/StDev)\n##              mpg        cyl       disp        hp\n## mpg    36.324103  -9.172379  -633.0972 -320.7321\n## cyl    -9.172379   3.189516   199.6603  101.9315\n## disp -633.097208 199.660282 15360.7998 6721.1587\n## hp   -320.732056 101.931452  6721.1587 4700.8669\n## attr(,\"scaled:scale\")\n##         mpg         cyl        disp          hp \n## 0.165921457 0.559934979 0.008068505 0.014585154</pre>\n<p>Just curious whether you young students have some better solution; I am sure you have one! Please, drop me a line!</p>\n<p>Happy coding!</p>\n<hr/>\n<p>Prof. Andrea Onofri<br/>\nDepartment of Agricultural, Food and Environmental Sciences<br/>\nUniversity of Perugia (Italy)<br/>\nSend comments to: <a href=\"/cdn-cgi/l/email-protection#e7868983958286c988898881958ea792898e9780c98e93\" rel=\"nofollow\" target=\"_blank\"><span class=\"__cf_email__\" data-cfemail=\"04656a607661652a6b6a6b62766d44716a6d74632a6d70\">[email protected]</span></a></p>\n<a class=\"twitter-follow-button\" data-show-count=\"false\" href=\"https://twitter.com/onofriandreapg?ref_src=twsrc%5Etfw\" rel=\"nofollow\" target=\"_blank\">Follow <span class=\"citation\">@onofriandreapg</span></a>\n\n</div>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://www.statforbiology.com/2025/stat_general_correlationcovariance/\"> R on Fixing the bridge between biologists and statisticians</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
    "main_text": "A trip from variance-covariance to correlation and back\nPosted on\nJanuary 23, 2025\nby\nR on Fixing the bridge between biologists and statisticians\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nR on Fixing the bridge between biologists and statisticians\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nThe variance-covariance and the correlation matrices are two entities that describe the association between the columns of a two-way data matrix. They are very much used, e.g., in agriculture, biology and ecology and they can be easily calculated with base R, as shown in the box below.\ndata(mtcars)\nmatr <- mtcars[,1:4]\n\n# Covariances\nSigma <- cov(matr)\n\n# Correlations\nR <- cor(matr)\n\nSigma\n##              mpg        cyl       disp        hp\n## mpg    36.324103  -9.172379  -633.0972 -320.7321\n## cyl    -9.172379   3.189516   199.6603  101.9315\n## disp -633.097208 199.660282 15360.7998 6721.1587\n## hp   -320.732056 101.931452  6721.1587 4700.8669\nR\n##             mpg        cyl       disp         hp\n## mpg   1.0000000 -0.8521620 -0.8475514 -0.7761684\n## cyl  -0.8521620  1.0000000  0.9020329  0.8324475\n## disp -0.8475514  0.9020329  1.0000000  0.7909486\n## hp   -0.7761684  0.8324475  0.7909486  1.0000000\nIt is useful to be able to go back and forth from variance-covariance to correlation, without going back to the original data matrix. Let’s consider that the variance-covariance of the two variables X and Y is:\n\\[\\textrm{cov}(X, Y) = \\sum\\limits_{i=1}^{n} {(X_i - \\hat{X})(Y_i - \\hat{Y})}\\]\nwhere\n\\(\\hat{Y}\\)\nand\n\\(\\hat{X}\\)\nare the means for each variable. The correlation is:\n\\[\\textrm{cor}(X, Y) = \\frac{\\textrm{cov}(X, Y)}{\\sigma_x \\sigma_y} \\]\nwhere\n\\(\\sigma_x\\)\nand\n\\(\\sigma_y\\)\nare the standard deviations for X and Y.\nThe opposite relationship is clear:\n\\[ \\textrm{cov}(X, Y) = \\textrm{cor}(X, Y) \\sigma_x \\sigma_y\\]\nTherefore, converting from covariance to correlation is pretty easy. For example, take the covariance between ‘cyl’ and ‘mpg’ above (-9.172379), the correlation is:\n-633.097208 / (sqrt(36.324103) * sqrt(15360.7998))\n## [1] -0.8475514\nOn the reverse, if we have the correlation (-0.8521620), the covariance is\n-0.8475514 * sqrt(36.324103) * sqrt(15360.7998)\n## [1] -633.0972\nIf we consider the whole covariance matrix, we have to take each element in this matrix and divide it by the square roots of the diagonal elements in the same column and in the same row (see figure below).\nThe question is: how can we do all these calculations in one single step, for all elements in the covariance matrix, to calculate the corresponding correlation matrix?\nIf we have some memories of matrix algebra, we might remember that if we take a diagonal matrix of order\n\\(n \\times n\\)\nand multiply it by a square matrix with the same order, all elements in each column are multiplied by the diagonal element in the corresponding column:\n\\[\\begin{pmatrix}\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1\n\\end{pmatrix}\n\\times\n\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 2 & 0 & 0 \\\\\n0 & 0 & 3 & 0 \\\\\n0 & 0 & 0 & 4\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 & 2 & 3 & 4 \\\\\n1 & 2 & 3 & 4 \\\\\n1 & 2 & 3 & 4 \\\\\n1 & 2 & 3 & 4\n\\end{pmatrix}\\]\nIf we reverse the order of factors, all elements in each row are multiplied by the diagonal element in the corresponding row:\n\\[\n\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 2 & 0 & 0 \\\\\n0 & 0 & 3 & 0 \\\\\n0 & 0 & 0 & 4\n\\end{pmatrix}\n\\times\n\\begin{pmatrix}\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 & 1 & 1 & 1 \\\\\n2 & 2 & 2 & 2 \\\\\n3 & 3 & 3 & 3 \\\\\n4 & 4 & 4 & 4\n\\end{pmatrix}\n\\]\nTherefore, if we take a covariance matrix\n\\(\\Sigma\\)\nof order\n\\(n \\times n\\)\nand pre-multiply and post-multiply it for the same diagonal matrix of order\n\\(n \\times n\\)\n, each element in\n\\(\\Sigma\\)\nis multiplied by both the diagonal elements in the same row and same column, which is exactly what we are looking for.\nIn the code below, we:\nCreate a covariance matrix\nTake the square roots of the diagonal element (standard deviations) and load them in a diagonal matrix\nInvert this diagonal matrix\nPre-multiply and post-multiply the covariance matrix for this diagonal matrix of inverse standard deviations\nStDev <- sqrt(diag(Sigma))\nStDevMat <- diag(StDev)\nInvStDev <- solve(StDevMat)\nInvStDev %*% Sigma %*% InvStDev\n##            [,1]       [,2]       [,3]       [,4]\n## [1,]  1.0000000 -0.8521620 -0.8475514 -0.7761684\n## [2,] -0.8521620  1.0000000  0.9020329  0.8324475\n## [3,] -0.8475514  0.9020329  1.0000000  0.7909486\n## [4,] -0.7761684  0.8324475  0.7909486  1.0000000\nGoing from correlation to covariance can be done similarly, although, in this case, together with the correlation matrix we also need to have the standard deviations of the original variables, because they are not included in the matrix under transformation:\nStDevMat %*% R %*% StDevMat\n##             [,1]       [,2]       [,3]      [,4]\n## [1,]   36.324103  -9.172379  -633.0972 -320.7321\n## [2,]   -9.172379   3.189516   199.6603  101.9315\n## [3,] -633.097208 199.660282 15360.7998 6721.1587\n## [4,] -320.732056 101.931452  6721.1587 4700.8669\nSolutions with R\nIs there any other solutions for those who are not accustomed to matrix algebra? The easiest way to go from covariance to correlation is to use the\ncov2cor()\nfunction in the ‘nlme’ package.\n# From covariance to correlation\nlibrary(nlme)\ncov2cor(Sigma)\n##             mpg        cyl       disp         hp\n## mpg   1.0000000 -0.8521620 -0.8475514 -0.7761684\n## cyl  -0.8521620  1.0000000  0.9020329  0.8324475\n## disp -0.8475514  0.9020329  1.0000000  0.7909486\n## hp   -0.7761684  0.8324475  0.7909486  1.0000000\nWith base R, we can\nsweep()\ntwice:\n# From covariance to correlation\nsweep(sweep(Sigma, 1, StDev, FUN = \"/\"), 2, StDev, FUN = \"/\")\n##             mpg        cyl       disp         hp\n## mpg   1.0000000 -0.8521620 -0.8475514 -0.7761684\n## cyl  -0.8521620  1.0000000  0.9020329  0.8324475\n## disp -0.8475514  0.9020329  1.0000000  0.7909486\n## hp   -0.7761684  0.8324475  0.7909486  1.0000000\n# From correlation to covariance\nsweep(sweep(R, 1, StDev, FUN = \"*\"), 2, StDev, FUN = \"*\")\n##              mpg        cyl       disp        hp\n## mpg    36.324103  -9.172379  -633.0972 -320.7321\n## cyl    -9.172379   3.189516   199.6603  101.9315\n## disp -633.097208 199.660282 15360.7998 6721.1587\n## hp   -320.732056 101.931452  6721.1587 4700.8669\nWe can also\nscale()\nand\nt()\ntwice, but it looks far less neat:\n# From covariance to correlation\nscale(t(scale(t(Sigma), center = F, scale = StDev)), \n      center = F, scale = StDev)\n##             mpg        cyl       disp         hp\n## mpg   1.0000000 -0.8521620 -0.8475514 -0.7761684\n## cyl  -0.8521620  1.0000000  0.9020329  0.8324475\n## disp -0.8475514  0.9020329  1.0000000  0.7909486\n## hp   -0.7761684  0.8324475  0.7909486  1.0000000\n## attr(,\"scaled:scale\")\n##        mpg        cyl       disp         hp \n##   6.026948   1.785922 123.938694  68.562868\n# From correlation to covariance\nscale(t(scale(t(R), center = F, scale = 1/StDev)), \n      center = F, scale = 1/StDev)\n##              mpg        cyl       disp        hp\n## mpg    36.324103  -9.172379  -633.0972 -320.7321\n## cyl    -9.172379   3.189516   199.6603  101.9315\n## disp -633.097208 199.660282 15360.7998 6721.1587\n## hp   -320.732056 101.931452  6721.1587 4700.8669\n## attr(,\"scaled:scale\")\n##         mpg         cyl        disp          hp \n## 0.165921457 0.559934979 0.008068505 0.014585154\nJust curious whether you young students have some better solution; I am sure you have one! Please, drop me a line!\nHappy coding!\nProf. Andrea Onofri\nDepartment of Agricultural, Food and Environmental Sciences\nUniversity of Perugia (Italy)\nSend comments to:\n[email protected]\nFollow\n@onofriandreapg\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nR on Fixing the bridge between biologists and statisticians\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "meta_description": "The variance-covariance and the correlation matrices are two entities that describe the association between the columns of a two-way data matrix. They are very much used, e.g., in agriculture, biology and ecology and they can be easily calculated wi...",
    "meta_keywords": null,
    "og_description": "The variance-covariance and the correlation matrices are two entities that describe the association between the columns of a two-way data matrix. They are very much used, e.g., in agriculture, biology and ecology and they can be easily calculated wi...",
    "og_image": "https://www.casaonofri.it/_Figures/CovarianceCorrelation.png",
    "og_title": "A trip from variance-covariance to correlation and back | R-bloggers",
    "raw_jsonld_article": null,
    "reading_time_min": 6.9,
    "sitemap_lastmod": null,
    "twitter_description": "The variance-covariance and the correlation matrices are two entities that describe the association between the columns of a two-way data matrix. They are very much used, e.g., in agriculture, biology and ecology and they can be easily calculated wi...",
    "twitter_title": "A trip from variance-covariance to correlation and back | R-bloggers",
    "url": "https://www.r-bloggers.com/2025/01/a-trip-from-variance-covariance-to-correlation-and-back/",
    "word_count": 1373
  }
}