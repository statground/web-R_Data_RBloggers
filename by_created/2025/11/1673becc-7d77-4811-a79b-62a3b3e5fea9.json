{
  "uuid": "1673becc-7d77-4811-a79b-62a3b3e5fea9",
  "created_at": "2025-11-17 20:38:49",
  "raw_json": {
    "article_author": null,
    "article_headline": null,
    "article_modified": null,
    "article_published": null,
    "article_section": null,
    "article_tags": null,
    "canonical_url": "https://www.r-bloggers.com/2023/12/a-three-arm-trial-using-two-step-randomization/",
    "crawled_at": "2025-11-17T09:31:54.407293",
    "external_links": [
      {
        "href": "https://www.rdatagen.net/post/2023-12-19-a-three-arm-trial-using-two-step-randomization/",
        "text": "ouR data generation"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://bartshealth-nhs.libguides.com/CDS",
        "text": "Clinical Decision Support"
      },
      {
        "href": "https://www.rdatagen.net/post/2023-12-19-a-three-arm-trial-using-two-step-randomization/",
        "text": "ouR data generation"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "h1_title": "R-bloggers",
    "html_title": "A three-arm trial using two-step randomization | R-bloggers",
    "images": [
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i1.wp.com/www.rdatagen.net/post/2023-12-19-a-three-arm-trial-using-two-step-randomization/index.en_files/figure-html/unnamed-chunk-4-1.png?w=450&ssl=1"
      },
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i1.wp.com/www.rdatagen.net/post/2023-12-19-a-three-arm-trial-using-two-step-randomization/index.en_files/figure-html/unnamed-chunk-11-1.png?w=450&ssl=1"
      }
    ],
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/keith-goldfeld/",
        "text": "Keith Goldfeld"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "lang": "en-US",
    "main_html": "<article class=\"post-380962 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">A three-arm trial using two-step randomization</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">December 18, 2023</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/keith-goldfeld/\">Keith Goldfeld</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://www.rdatagen.net/post/2023-12-19-a-three-arm-trial-using-two-step-randomization/\"> ouR data generation</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<link href=\"https://www.rdatagen.net/post/2023-12-19-a-three-arm-trial-using-two-step-randomization/index.en_files/tabwid/tabwid.css\" rel=\"stylesheet\">\n\n<p><a href=\"https://bartshealth-nhs.libguides.com/CDS\" rel=\"nofollow\" target=\"_blank\">Clinical Decision Support</a> (CDS) tools are systems created to support clinical decision-making. Health care professionals using these tools can get guidance about diagnostic and treatment options when providing care to a patient. I’m currently involved with designing a trial focused on comparing a standard CDS tool with an enhanced version (CDS+). The main goal is to directly compare patient-level outcomes for those who have been exposed to the different versions of the CDS. However, we might also be interested in comparing the basic CDS with a control arm, which would suggest some type of three-arm trial.</p>\n<p>A key question is the unit of randomization – should it be at the provider or patient level? If we can assume that CDS and CDS+ can be implemented at the patient level without any contamination, a trial comparing the two CDS versions could take advantage of patient-level randomization. However, once you turn on CDS or CDS+ at the provider level, it may not be possible to have an uncontaminated control arm, suggesting a less efficient cluster randomized trial. One of my colleagues came up with a design that takes advantage of patient-level randomization while acknowledging the need to address potential contamination of the patients in the control arm. This would be accomplished by randomizing providers to either the control or CDS arms, and then randomizing patients within the CDS arm (stratified by provider) to either CDS or CDS+ intervention.</p>\n<p>It should be fairly obvious that two-step approach with at least some patient-level randomization would be better (with respect to statistical power) than a more standard three-arm cluster randomized trial that could provide the same effect estimates (though my initial reaction was that it wasn’t so obvious). My goal here is to simulate data (and provide code) using each design and estimate power under each.</p>\n<div class=\"section level3\" id=\"preliminaries\">\n<h3>Preliminaries</h3>\n<p>Before we get started, here are the libraries that will be need for the simulations, model fitting, and outputting the results:</p>\n<pre>library(simstudy)\nlibrary(ggplot2)\nlibrary(lmerTest)\nlibrary(data.table)\nlibrary(multcomp)\nlibrary(parallel)\nlibrary(flextable)\n\nRNGkind(\"L'Ecuyer-CMRG\")  # to set seed for parallel process</pre>\n</div>\n<div class=\"section level3\" id=\"three-arm-cluster-randomized-trial\">\n<h3>Three-arm cluster randomized trial</h3>\n<p>We’ll start with the three-arm cluster randomized trial, where providers would be randomized in a 1:1:1 ratio to either <span class=\"math inline\">\\(Control\\)</span>, <span class=\"math inline\">\\(CDS\\)</span>, or <span class=\"math inline\">\\(CDS+\\)</span>. The data definitions for the cluster-level data includes a random effect <span class=\"math inline\">\\(b\\)</span> and a three-level treatment indicator <span class=\"math inline\">\\(A\\)</span>. The individual-level outcome is a continuous variable centered around 0 for patients in the control arm (offset by the provider-specific random effect). The effect of CDS (compared to Control) is 1.5, and the incremental effect of CDS+ (compared to CDS) is 0.75.</p>\n<pre>defs &lt;- \n  defData(varname = \"b\", formula = 0, variance = 1) |&gt;\n  defData(varname = \"A\", formula = \"1;1;1\", dist = \"trtAssign\") \n\ndefy &lt;- \n  defDataAdd(varname = \"y\", formula = \"1.50 * (A==2) + 2.25 * (A==3) + b\", variance = 8)</pre>\n<p>To generate a single data set, we generate the provider level data, add the patient-level records and generate the patient-level outcomes.</p>\n<pre>set.seed(9612)\n\ndc &lt;- genData(30, defs, id = \"provider\")\ndd &lt;- genCluster(dc, \"provider\", 40, \"id\")\ndd &lt;- addColumns(defy, dd)</pre>\n<p><img data-lazy-src=\"https://i1.wp.com/www.rdatagen.net/post/2023-12-19-a-three-arm-trial-using-two-step-randomization/index.en_files/figure-html/unnamed-chunk-4-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.rdatagen.net/post/2023-12-19-a-three-arm-trial-using-two-step-randomization/index.en_files/figure-html/unnamed-chunk-4-1.png?w=450&amp;ssl=1\"/></noscript></p>\n<p>A mixed effects model with a provider-level random effect gives the parameter estimates for the effect of CDS (versus control) and CDS+ (also versus control):</p>\n<pre>lmerfit &lt;- lmer(y ~ factor(A) + (1 | provider), data = dd)\nas_flextable(lmerfit) |&gt; delete_part(part = \"footer\")</pre>\n<p><br/></p>\n<div class=\"tabwid\"><table class=\"cl-c9375b48\" data-quarto-disable-processing=\"true\"><thead><tr style=\"overflow-wrap:break-word;\"><th class=\"cl-c934c1e4\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\">group</span></p></th><th class=\"cl-c934c1e5\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\"></span></p></th><th class=\"cl-c934c1e6\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">Estimate</span></p></th><th class=\"cl-c934c1ee\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">Standard Error</span></p></th><th class=\"cl-c934c1ef\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">df</span></p></th><th class=\"cl-c934c1f0\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">statistic</span></p></th><th class=\"cl-c934c1f1\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">p-value</span></p></th><th class=\"cl-c934c1f8\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\"></span></p></th></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-c934c1f9\" colspan=\"8\"><p class=\"cl-c934b745\"><span class=\"cl-c9334d00\">Fixed effects</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-c934c20e\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\"></span></p></td><td class=\"cl-c934c216\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\">(Intercept)</span></p></td><td class=\"cl-c934c217\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">-0.733</span></p></td><td class=\"cl-c934c218\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">0.339</span></p></td><td class=\"cl-c934c219\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">27</span></p></td><td class=\"cl-c934c220\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">-2.164</span></p></td><td class=\"cl-c934c221\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">0.0395</span></p></td><td class=\"cl-c934c222\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\">  *</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-c934c223\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\"></span></p></td><td class=\"cl-c934c22a\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\">factor(A)2</span></p></td><td class=\"cl-c934c22b\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">1.853</span></p></td><td class=\"cl-c934c234\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">0.479</span></p></td><td class=\"cl-c934c235\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">27</span></p></td><td class=\"cl-c934c236\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">3.865</span></p></td><td class=\"cl-c934c237\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">0.0006</span></p></td><td class=\"cl-c934c238\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\">***</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-c934c223\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\"></span></p></td><td class=\"cl-c934c22a\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\">factor(A)3</span></p></td><td class=\"cl-c934c22b\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">2.567</span></p></td><td class=\"cl-c934c234\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">0.479</span></p></td><td class=\"cl-c934c235\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">27</span></p></td><td class=\"cl-c934c236\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">5.353</span></p></td><td class=\"cl-c934c237\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">0.0000</span></p></td><td class=\"cl-c934c238\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\">***</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-c934c1f9\" colspan=\"8\"><p class=\"cl-c934b745\"><span class=\"cl-c9334d00\">Random effects</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-c934c20e\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\">provider</span></p></td><td class=\"cl-c934c216\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\">sd__(Intercept)</span></p></td><td class=\"cl-c934c217\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">0.975</span></p></td><td class=\"cl-c934c218\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\"></span></p></td><td class=\"cl-c934c219\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\"></span></p></td><td class=\"cl-c934c220\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\"></span></p></td><td class=\"cl-c934c221\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\"></span></p></td><td class=\"cl-c934c222\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\"></span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-c934c239\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\">Residual</span></p></td><td class=\"cl-c934c23e\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\">sd__Observation</span></p></td><td class=\"cl-c934c23f\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\">2.818</span></p></td><td class=\"cl-c934c240\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\"></span></p></td><td class=\"cl-c934c241\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\"></span></p></td><td class=\"cl-c934c242\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\"></span></p></td><td class=\"cl-c934c248\"><p class=\"cl-c934b744\"><span class=\"cl-c9334d00\"></span></p></td><td class=\"cl-c934c249\"><p class=\"cl-c934b73a\"><span class=\"cl-c9334d00\"></span></p></td></tr></tbody></table></div>\n<p>However, we are really interested in comparing CDS with Control and CDS+ with CDS (and not CDS+ with control); we can use the <code>glht</code> package to provide the contrasts. To ensure that our overall Type I error rate is 5%, we use a Bonferroni-corrected p-value threshold of 0.025. In this particular case, we would not infer that there is any benefit to CDS+ over CDS, though it does appear that CDS is better than no CDS.</p>\n<pre>K1 &lt;- matrix(c(0, 1, 0, 0, -1, 1), 2, byrow = T)\nsummary(glht(lmerfit, K1))\r\n## \n## \t Simultaneous Tests for General Linear Hypotheses\n## \n## Fit: lmer(formula = y ~ factor(A) + (1 | provider), data = dd)\n## \n## Linear Hypotheses:\n##        Estimate Std. Error z value Pr(&gt;|z|)    \n## 1 == 0   1.8530     0.4794   3.865  0.00022 ***\n## 2 == 0   0.7136     0.4794   1.488  0.23509    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## (Adjusted p values reported -- single-step method)</pre>\n<p>In the next step, I’m generating 2500 data sets and fitting a model for each one. The estimated parameters, standard errors, and p-values are saved to an <code>R</code> <em>list</em> so that I can estimate the power to detect an effect for each comparison (based on the assumptions used to generate the data):</p>\n<pre>genandfit &lt;- function() {\n  \n  dc &lt;- genData(30, defs, id = \"provider\")\n  dd &lt;- genCluster(dc, \"provider\", 40, \"id\")\n  dd &lt;- addColumns(defy, dd)\n  \n  lmerfit &lt;- lmer(y ~ factor(A) + (1 | provider), data = dd)\n  K1 &lt;- matrix(c(0, 1, 0, 0, -1, 1), 2, byrow = T)\n  data.table(ests = summary(glht(lmerfit, K1))$test$coefficients,\n             sd = summary(glht(lmerfit, K1))$test$sigma,\n             pvals = summary(glht(lmerfit, K1))$test$pvalues\n  )\n  \n}\n\nreps &lt;- mclapply(1:2500, function(x) genandfit())\nreps[1:3]\r\n## [[1]]\n##         ests        sd       pvals\n## 1: 1.6634678 0.5213168 0.002768887\n## 2: 0.8372875 0.5213168 0.189092375\n## \n## [[2]]\n##         ests        sd        pvals\n## 1: 0.8206728 0.4380257 0.1097610533\n## 2: 1.6465060 0.4380257 0.0003375337\n## \n## [[3]]\n##        ests        sd        pvals\n## 1: 1.340631 0.4691332 0.0082278928\n## 2: 1.777505 0.4691332 0.0002994282</pre>\n<p>The estimated power for each effect estimate is the proportion of iterations with a p-value less than 0.025. Using this standard cluster-randomized three-arm study design, there is 74% power to detect a difference between CDS and Control when the true difference is 1.50, and only 19% power to detect a difference between CDS+ and CDS when the true difference is 0.75:</p>\n<pre>pvals &lt;- rbindlist(mclapply(reps, function(x) data.table(t(x[, pvals]))))\npvals[, .(`CDS vs Control` = mean(V1 &lt; 0.025), `CDS+ vs CDS` = mean(V2 &lt; 0.025))]\r\n##    CDS vs Control CDS+ vs CDS\n## 1:         0.7356      0.1904</pre>\n</div>\n<div class=\"section level3\" id=\"two-step-randomization\">\n<h3>Two-step randomization</h3>\n<p>The same process can be applied to evaluate the two-step randomization. In this formulation, the clusters are randomized in a 1:2 ratio to control <span class=\"math inline\">\\((A = 0)\\)</span> or CDS <span class=\"math inline\">\\((A = 1)\\)</span>. For the the clusters randomized to CDS (<span class=\"math inline\">\\(2/3\\)</span> of the total clusters), the individual patients are randomized to standard CDS <span class=\"math inline\">\\((X=0)\\)</span> or CDS+ <span class=\"math inline\">\\((X=1)\\)</span>. The randomization is stratified by provider with a 1:1 ratio. The randomization scheme is facilitated by the <code>simstudy</code> <code>defCondition</code> and <code>addCondition</code> functions. For the patients in the control arm, <span class=\"math inline\">\\(A=0\\)</span> and <span class=\"math inline\">\\(X=0\\)</span>.</p>\n<p>The individual outcome <span class=\"math inline\">\\(y\\)</span> is generated slightly differently than in the three-arm trial, but the effect sizes are equivalent: 1.50 point difference between standard CDS and control and 0.75 difference between CDS+ and CDS.</p>\n<pre>defs &lt;- \n  defData(varname = \"b\", formula = 0, variance = 1) |&gt;\n  defData(varname = \"A\", formula = \"1;2\", dist = \"trtAssign\")\n\ndefc &lt;- \n  defCondition(condition = \"A == 1\", formula = \"1;1\", \n    variance = \"provider\", dist = \"trtAssign\") |&gt;\n  defCondition(condition = \"A == 0\", formula = 0, \n    dist = \"nonrandom\")\n\ndefy &lt;- \n  defDataAdd(varname = \"y\", formula = \"1.50 * A + 0.75 * X + b\", variance = 8)\n\ndc &lt;- genData(30, defs, id = \"provider\")\ndd &lt;- genCluster(dc, \"provider\", 40, \"id\")\ndd &lt;- addCondition(defc, dd, \"X\")\ndd &lt;- addColumns(defy, dd)</pre>\n<p><img data-lazy-src=\"https://i1.wp.com/www.rdatagen.net/post/2023-12-19-a-three-arm-trial-using-two-step-randomization/index.en_files/figure-html/unnamed-chunk-11-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.rdatagen.net/post/2023-12-19-a-three-arm-trial-using-two-step-randomization/index.en_files/figure-html/unnamed-chunk-11-1.png?w=450&amp;ssl=1\"/></noscript></p>\n<p>The model for this data set also looks slightly different than the three arm case, as we can model the CDS+ vs CDS directly; as a result, there is no need to consider the contrasts. In this example, we would conclude that CDS+ is an improvement over CDS and CDS is better than no CDS.</p>\n<pre>lmerfit &lt;- lmer(y ~ A + X + (1|provider), data = dd)\nas_flextable(lmerfit) |&gt; delete_part(part = \"footer\")</pre>\n<p><br/></p>\n<div class=\"tabwid\"><table class=\"cl-e1571538\" data-quarto-disable-processing=\"true\"><thead><tr style=\"overflow-wrap:break-word;\"><th class=\"cl-e154a910\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\">group</span></p></th><th class=\"cl-e154a911\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\"></span></p></th><th class=\"cl-e154a91a\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">Estimate</span></p></th><th class=\"cl-e154a91b\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">Standard Error</span></p></th><th class=\"cl-e154a91c\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">df</span></p></th><th class=\"cl-e154a924\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">statistic</span></p></th><th class=\"cl-e154a925\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">p-value</span></p></th><th class=\"cl-e154a92e\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\"></span></p></th></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-e154a92f\" colspan=\"8\"><p class=\"cl-e154a046\"><span class=\"cl-e1534ee4\">Fixed effects</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-e154a944\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\"></span></p></td><td class=\"cl-e154a945\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\">(Intercept)</span></p></td><td class=\"cl-e154a94c\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">-0.123</span></p></td><td class=\"cl-e154a960\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">0.362</span></p></td><td class=\"cl-e154a96a\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">28</span></p></td><td class=\"cl-e154a96b\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">-0.341</span></p></td><td class=\"cl-e154a96c\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">0.7358</span></p></td><td class=\"cl-e154a974\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\"> </span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-e154a975\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\"></span></p></td><td class=\"cl-e154a97e\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\">A</span></p></td><td class=\"cl-e154a97f\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">1.641</span></p></td><td class=\"cl-e154a980\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">0.455</span></p></td><td class=\"cl-e154a988\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">31</span></p></td><td class=\"cl-e154a989\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">3.608</span></p></td><td class=\"cl-e154a98a\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">0.0011</span></p></td><td class=\"cl-e154a992\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\"> **</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-e154a993\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\"></span></p></td><td class=\"cl-e154a994\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\">X</span></p></td><td class=\"cl-e154a99c\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">1.078</span></p></td><td class=\"cl-e154a99d\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">0.200</span></p></td><td class=\"cl-e154a9a6\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">1,169</span></p></td><td class=\"cl-e154a9a7\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">5.391</span></p></td><td class=\"cl-e154a9a8\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">0.0000</span></p></td><td class=\"cl-e154a9a9\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\">***</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-e154a92f\" colspan=\"8\"><p class=\"cl-e154a046\"><span class=\"cl-e1534ee4\">Random effects</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-e154a944\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\">provider</span></p></td><td class=\"cl-e154a945\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\">sd__(Intercept)</span></p></td><td class=\"cl-e154a94c\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">1.055</span></p></td><td class=\"cl-e154a960\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\"></span></p></td><td class=\"cl-e154a96a\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\"></span></p></td><td class=\"cl-e154a96b\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\"></span></p></td><td class=\"cl-e154a96c\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\"></span></p></td><td class=\"cl-e154a974\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\"></span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-e154a9b0\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\">Residual</span></p></td><td class=\"cl-e154a9b1\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\">sd__Observation</span></p></td><td class=\"cl-e154a9b2\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\">2.828</span></p></td><td class=\"cl-e154a9ba\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\"></span></p></td><td class=\"cl-e154a9bb\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\"></span></p></td><td class=\"cl-e154a9bc\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\"></span></p></td><td class=\"cl-e154a9c4\"><p class=\"cl-e154a03d\"><span class=\"cl-e1534ee4\"></span></p></td><td class=\"cl-e154a9c5\"><p class=\"cl-e154a03c\"><span class=\"cl-e1534ee4\"></span></p></td></tr></tbody></table></div>\n<p>The estimated the power from replicated data sets makes it pretty clear that the two-step randomization design has considerably more power for both effects, each reaching the 80% threshold.</p>\n<pre>pvals[, .(`CDS vs Control` = mean(A &lt; .025), `CDS+ vs CDS` = mean(X &lt; 0.025))]\r\n##    CDS vs Control CDS+ vs CDS\n## 1:         0.8392      0.8544</pre>\n<p>While it appears that the two-step randomization design is clearly superior to the three-arm cluster randomized design, it is important to again point out the key caveat here that, conditional on the provider, the patient outcomes in the CDS and CDS+ arms patients need to be independent of each other. For example, if the provider can’t avoid applying CDS+ tools to the CDS only patients, this assumption of independence is violated and the two-step design is not going to be appropriate. Instead, a three-arm cluster randomized design with more providers (clusters) will be needed.</p>\n</div>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://www.rdatagen.net/post/2023-12-19-a-three-arm-trial-using-two-step-randomization/\"> ouR data generation</a></strong>.</div>\n<hr>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</hr></div> </link></div>\n</article>",
    "main_text": "A three-arm trial using two-step randomization\nPosted on\nDecember 18, 2023\nby\nKeith Goldfeld\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nouR data generation\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nClinical Decision Support\n(CDS) tools are systems created to support clinical decision-making. Health care professionals using these tools can get guidance about diagnostic and treatment options when providing care to a patient. I’m currently involved with designing a trial focused on comparing a standard CDS tool with an enhanced version (CDS+). The main goal is to directly compare patient-level outcomes for those who have been exposed to the different versions of the CDS. However, we might also be interested in comparing the basic CDS with a control arm, which would suggest some type of three-arm trial.\nA key question is the unit of randomization – should it be at the provider or patient level? If we can assume that CDS and CDS+ can be implemented at the patient level without any contamination, a trial comparing the two CDS versions could take advantage of patient-level randomization. However, once you turn on CDS or CDS+ at the provider level, it may not be possible to have an uncontaminated control arm, suggesting a less efficient cluster randomized trial. One of my colleagues came up with a design that takes advantage of patient-level randomization while acknowledging the need to address potential contamination of the patients in the control arm. This would be accomplished by randomizing providers to either the control or CDS arms, and then randomizing patients within the CDS arm (stratified by provider) to either CDS or CDS+ intervention.\nIt should be fairly obvious that two-step approach with at least some patient-level randomization would be better (with respect to statistical power) than a more standard three-arm cluster randomized trial that could provide the same effect estimates (though my initial reaction was that it wasn’t so obvious). My goal here is to simulate data (and provide code) using each design and estimate power under each.\nPreliminaries\nBefore we get started, here are the libraries that will be need for the simulations, model fitting, and outputting the results:\nlibrary(simstudy)\nlibrary(ggplot2)\nlibrary(lmerTest)\nlibrary(data.table)\nlibrary(multcomp)\nlibrary(parallel)\nlibrary(flextable)\n\nRNGkind(\"L'Ecuyer-CMRG\")  # to set seed for parallel process\nThree-arm cluster randomized trial\nWe’ll start with the three-arm cluster randomized trial, where providers would be randomized in a 1:1:1 ratio to either\n\\(Control\\)\n,\n\\(CDS\\)\n, or\n\\(CDS+\\)\n. The data definitions for the cluster-level data includes a random effect\n\\(b\\)\nand a three-level treatment indicator\n\\(A\\)\n. The individual-level outcome is a continuous variable centered around 0 for patients in the control arm (offset by the provider-specific random effect). The effect of CDS (compared to Control) is 1.5, and the incremental effect of CDS+ (compared to CDS) is 0.75.\ndefs <- \n  defData(varname = \"b\", formula = 0, variance = 1) |>\n  defData(varname = \"A\", formula = \"1;1;1\", dist = \"trtAssign\") \n\ndefy <- \n  defDataAdd(varname = \"y\", formula = \"1.50 * (A==2) + 2.25 * (A==3) + b\", variance = 8)\nTo generate a single data set, we generate the provider level data, add the patient-level records and generate the patient-level outcomes.\nset.seed(9612)\n\ndc <- genData(30, defs, id = \"provider\")\ndd <- genCluster(dc, \"provider\", 40, \"id\")\ndd <- addColumns(defy, dd)\nA mixed effects model with a provider-level random effect gives the parameter estimates for the effect of CDS (versus control) and CDS+ (also versus control):\nlmerfit <- lmer(y ~ factor(A) + (1 | provider), data = dd)\nas_flextable(lmerfit) |> delete_part(part = \"footer\")\ngroup\nEstimate\nStandard Error\ndf\nstatistic\np-value\nFixed effects\n(Intercept)\n-0.733\n0.339\n27\n-2.164\n0.0395\n*\nfactor(A)2\n1.853\n0.479\n27\n3.865\n0.0006\n***\nfactor(A)3\n2.567\n0.479\n27\n5.353\n0.0000\n***\nRandom effects\nprovider\nsd__(Intercept)\n0.975\nResidual\nsd__Observation\n2.818\nHowever, we are really interested in comparing CDS with Control and CDS+ with CDS (and not CDS+ with control); we can use the\nglht\npackage to provide the contrasts. To ensure that our overall Type I error rate is 5%, we use a Bonferroni-corrected p-value threshold of 0.025. In this particular case, we would not infer that there is any benefit to CDS+ over CDS, though it does appear that CDS is better than no CDS.\nK1 <- matrix(c(0, 1, 0, 0, -1, 1), 2, byrow = T)\nsummary(glht(lmerfit, K1))\n## \n## \t Simultaneous Tests for General Linear Hypotheses\n## \n## Fit: lmer(formula = y ~ factor(A) + (1 | provider), data = dd)\n## \n## Linear Hypotheses:\n##        Estimate Std. Error z value Pr(>|z|)    \n## 1 == 0   1.8530     0.4794   3.865  0.00022 ***\n## 2 == 0   0.7136     0.4794   1.488  0.23509    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## (Adjusted p values reported -- single-step method)\nIn the next step, I’m generating 2500 data sets and fitting a model for each one. The estimated parameters, standard errors, and p-values are saved to an\nR\nlist\nso that I can estimate the power to detect an effect for each comparison (based on the assumptions used to generate the data):\ngenandfit <- function() {\n  \n  dc <- genData(30, defs, id = \"provider\")\n  dd <- genCluster(dc, \"provider\", 40, \"id\")\n  dd <- addColumns(defy, dd)\n  \n  lmerfit <- lmer(y ~ factor(A) + (1 | provider), data = dd)\n  K1 <- matrix(c(0, 1, 0, 0, -1, 1), 2, byrow = T)\n  data.table(ests = summary(glht(lmerfit, K1))$test$coefficients,\n             sd = summary(glht(lmerfit, K1))$test$sigma,\n             pvals = summary(glht(lmerfit, K1))$test$pvalues\n  )\n  \n}\n\nreps <- mclapply(1:2500, function(x) genandfit())\nreps[1:3]\n## [[1]]\n##         ests        sd       pvals\n## 1: 1.6634678 0.5213168 0.002768887\n## 2: 0.8372875 0.5213168 0.189092375\n## \n## [[2]]\n##         ests        sd        pvals\n## 1: 0.8206728 0.4380257 0.1097610533\n## 2: 1.6465060 0.4380257 0.0003375337\n## \n## [[3]]\n##        ests        sd        pvals\n## 1: 1.340631 0.4691332 0.0082278928\n## 2: 1.777505 0.4691332 0.0002994282\nThe estimated power for each effect estimate is the proportion of iterations with a p-value less than 0.025. Using this standard cluster-randomized three-arm study design, there is 74% power to detect a difference between CDS and Control when the true difference is 1.50, and only 19% power to detect a difference between CDS+ and CDS when the true difference is 0.75:\npvals <- rbindlist(mclapply(reps, function(x) data.table(t(x[, pvals]))))\npvals[, .(`CDS vs Control` = mean(V1 < 0.025), `CDS+ vs CDS` = mean(V2 < 0.025))]\n##    CDS vs Control CDS+ vs CDS\n## 1:         0.7356      0.1904\nTwo-step randomization\nThe same process can be applied to evaluate the two-step randomization. In this formulation, the clusters are randomized in a 1:2 ratio to control\n\\((A = 0)\\)\nor CDS\n\\((A = 1)\\)\n. For the the clusters randomized to CDS (\n\\(2/3\\)\nof the total clusters), the individual patients are randomized to standard CDS\n\\((X=0)\\)\nor CDS+\n\\((X=1)\\)\n. The randomization is stratified by provider with a 1:1 ratio. The randomization scheme is facilitated by the\nsimstudy\ndefCondition\nand\naddCondition\nfunctions. For the patients in the control arm,\n\\(A=0\\)\nand\n\\(X=0\\)\n.\nThe individual outcome\n\\(y\\)\nis generated slightly differently than in the three-arm trial, but the effect sizes are equivalent: 1.50 point difference between standard CDS and control and 0.75 difference between CDS+ and CDS.\ndefs <- \n  defData(varname = \"b\", formula = 0, variance = 1) |>\n  defData(varname = \"A\", formula = \"1;2\", dist = \"trtAssign\")\n\ndefc <- \n  defCondition(condition = \"A == 1\", formula = \"1;1\", \n    variance = \"provider\", dist = \"trtAssign\") |>\n  defCondition(condition = \"A == 0\", formula = 0, \n    dist = \"nonrandom\")\n\ndefy <- \n  defDataAdd(varname = \"y\", formula = \"1.50 * A + 0.75 * X + b\", variance = 8)\n\ndc <- genData(30, defs, id = \"provider\")\ndd <- genCluster(dc, \"provider\", 40, \"id\")\ndd <- addCondition(defc, dd, \"X\")\ndd <- addColumns(defy, dd)\nThe model for this data set also looks slightly different than the three arm case, as we can model the CDS+ vs CDS directly; as a result, there is no need to consider the contrasts. In this example, we would conclude that CDS+ is an improvement over CDS and CDS is better than no CDS.\nlmerfit <- lmer(y ~ A + X + (1|provider), data = dd)\nas_flextable(lmerfit) |> delete_part(part = \"footer\")\ngroup\nEstimate\nStandard Error\ndf\nstatistic\np-value\nFixed effects\n(Intercept)\n-0.123\n0.362\n28\n-0.341\n0.7358\nA\n1.641\n0.455\n31\n3.608\n0.0011\n**\nX\n1.078\n0.200\n1,169\n5.391\n0.0000\n***\nRandom effects\nprovider\nsd__(Intercept)\n1.055\nResidual\nsd__Observation\n2.828\nThe estimated the power from replicated data sets makes it pretty clear that the two-step randomization design has considerably more power for both effects, each reaching the 80% threshold.\npvals[, .(`CDS vs Control` = mean(A < .025), `CDS+ vs CDS` = mean(X < 0.025))]\n##    CDS vs Control CDS+ vs CDS\n## 1:         0.8392      0.8544\nWhile it appears that the two-step randomization design is clearly superior to the three-arm cluster randomized design, it is important to again point out the key caveat here that, conditional on the provider, the patient outcomes in the CDS and CDS+ arms patients need to be independent of each other. For example, if the provider can’t avoid applying CDS+ tools to the CDS only patients, this assumption of independence is violated and the two-step design is not going to be appropriate. Instead, a three-arm cluster randomized design with more providers (clusters) will be needed.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nouR data generation\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "meta_description": "Clinical Decision Support (CDS) tools are systems created to support clinical decision-making. Health care professionals using these tools can get guidance about diagnostic and treatment options when providing care to a patient. I’m currently involved with designing a trial focused on comparing a standard CDS tool with an enhanced version (CDS+). The main goal is to directly compare patient-level outcomes for those who have been exposed to the different versions of the CDS. However, we might also be interested in comparing the basic CDS with a control arm, which would suggest some type of three-arm trial. A key question is the unit of randomization - should it be at the provider or patient level? If we can assume that CDS and CDS+ can be implemented at the patient level without any contamination, a trial comparing the two CDS versions could take advantage of patient-level randomization. However, once you turn on CDS or CDS+ at the provider level, it may not be possible to have an uncontaminated control arm, suggesting a less efficient cluster randomized trial. One of my colleagues came up with a design that takes advantage of patient-level randomization while acknowledging the need to address potential contamination of the patients in the control arm. This would be accomplished by randomizing providers to either the control or CDS arms, and then randomizing patients within the CDS arm (stratified by provider) to either CDS or CDS+ intervention. It should be fairly obvious that two-step approach with at least some patient-level randomization would be better (with respect to statistical power) than a more standard three-arm cluster randomized trial that could provide the same effect estimates (though my initial reaction was that it wasn’t so obvious). My goal here is to simulate data (and provide code) using each design and estimate power under each. Preliminaries Before we get started, here are the libraries that will be need for the simulations, model fitting, and outputting the results: library(simstudy) library(ggplot2) library(lmerTest) library(data.table) library(multcomp) library(parallel) library(flextable) RNGkind(\"L'Ecuyer-CMRG\") # to set seed for parallel process Three-arm cluster randomized trial We’ll start with the three-arm cluster randomized trial, where providers would be randomized in a 1:1:1 ratio to either \\(Control\\), \\(CDS\\), or \\(CDS+\\). The data definitions for the cluster-level data includes a random effect \\(b\\) and a three-level treatment indicator \\(A\\). The individual-level outcome is a continuous variable centered around 0 for patients in the control arm (offset by the provider-specific random effect). The effect of CDS (compared to Control) is 1.5, and the incremental effect of CDS+ (compared to CDS) is 0.75. defs defData(varname = \"A\", formula = \"1;1;1\", dist = \"trtAssign\") defy",
    "meta_keywords": null,
    "og_description": "Clinical Decision Support (CDS) tools are systems created to support clinical decision-making. Health care professionals using these tools can get guidance about diagnostic and treatment options when providing care to a patient. I’m currently involved with designing a trial focused on comparing a standard CDS tool with an enhanced version (CDS+). The main goal is to directly compare patient-level outcomes for those who have been exposed to the different versions of the CDS. However, we might also be interested in comparing the basic CDS with a control arm, which would suggest some type of three-arm trial. A key question is the unit of randomization - should it be at the provider or patient level? If we can assume that CDS and CDS+ can be implemented at the patient level without any contamination, a trial comparing the two CDS versions could take advantage of patient-level randomization. However, once you turn on CDS or CDS+ at the provider level, it may not be possible to have an uncontaminated control arm, suggesting a less efficient cluster randomized trial. One of my colleagues came up with a design that takes advantage of patient-level randomization while acknowledging the need to address potential contamination of the patients in the control arm. This would be accomplished by randomizing providers to either the control or CDS arms, and then randomizing patients within the CDS arm (stratified by provider) to either CDS or CDS+ intervention. It should be fairly obvious that two-step approach with at least some patient-level randomization would be better (with respect to statistical power) than a more standard three-arm cluster randomized trial that could provide the same effect estimates (though my initial reaction was that it wasn’t so obvious). My goal here is to simulate data (and provide code) using each design and estimate power under each. Preliminaries Before we get started, here are the libraries that will be need for the simulations, model fitting, and outputting the results: library(simstudy) library(ggplot2) library(lmerTest) library(data.table) library(multcomp) library(parallel) library(flextable) RNGkind(\"L'Ecuyer-CMRG\") # to set seed for parallel process Three-arm cluster randomized trial We’ll start with the three-arm cluster randomized trial, where providers would be randomized in a 1:1:1 ratio to either \\(Control\\), \\(CDS\\), or \\(CDS+\\). The data definitions for the cluster-level data includes a random effect \\(b\\) and a three-level treatment indicator \\(A\\). The individual-level outcome is a continuous variable centered around 0 for patients in the control arm (offset by the provider-specific random effect). The effect of CDS (compared to Control) is 1.5, and the incremental effect of CDS+ (compared to CDS) is 0.75. defs defData(varname = \"A\", formula = \"1;1;1\", dist = \"trtAssign\") defy",
    "og_image": "https://www.rdatagen.net/post/2023-12-19-a-three-arm-trial-using-two-step-randomization/index.en_files/figure-html/unnamed-chunk-4-1.png",
    "og_title": "A three-arm trial using two-step randomization | R-bloggers",
    "raw_jsonld_article": null,
    "reading_time_min": 8.5,
    "sitemap_lastmod": "2023-12-19T00:00:00+00:00",
    "twitter_description": "Clinical Decision Support (CDS) tools are systems created to support clinical decision-making. Health care professionals using these tools can get guidance about diagnostic and treatment options when providing care to a patient. I’m currently involved with designing a trial focused on comparing a standard CDS tool with an enhanced version (CDS+). The main goal is to directly compare patient-level outcomes for those who have been exposed to the different versions of the CDS. However, we might also be interested in comparing the basic CDS with a control arm, which would suggest some type of three-arm trial. A key question is the unit of randomization - should it be at the provider or patient level? If we can assume that CDS and CDS+ can be implemented at the patient level without any contamination, a trial comparing the two CDS versions could take advantage of patient-level randomization. However, once you turn on CDS or CDS+ at the provider level, it may not be possible to have an uncontaminated control arm, suggesting a less efficient cluster randomized trial. One of my colleagues came up with a design that takes advantage of patient-level randomization while acknowledging the need to address potential contamination of the patients in the control arm. This would be accomplished by randomizing providers to either the control or CDS arms, and then randomizing patients within the CDS arm (stratified by provider) to either CDS or CDS+ intervention. It should be fairly obvious that two-step approach with at least some patient-level randomization would be better (with respect to statistical power) than a more standard three-arm cluster randomized trial that could provide the same effect estimates (though my initial reaction was that it wasn’t so obvious). My goal here is to simulate data (and provide code) using each design and estimate power under each. Preliminaries Before we get started, here are the libraries that will be need for the simulations, model fitting, and outputting the results: library(simstudy) library(ggplot2) library(lmerTest) library(data.table) library(multcomp) library(parallel) library(flextable) RNGkind(\"L'Ecuyer-CMRG\") # to set seed for parallel process Three-arm cluster randomized trial We’ll start with the three-arm cluster randomized trial, where providers would be randomized in a 1:1:1 ratio to either \\(Control\\), \\(CDS\\), or \\(CDS+\\). The data definitions for the cluster-level data includes a random effect \\(b\\) and a three-level treatment indicator \\(A\\). The individual-level outcome is a continuous variable centered around 0 for patients in the control arm (offset by the provider-specific random effect). The effect of CDS (compared to Control) is 1.5, and the incremental effect of CDS+ (compared to CDS) is 0.75. defs defData(varname = \"A\", formula = \"1;1;1\", dist = \"trtAssign\") defy",
    "twitter_title": "A three-arm trial using two-step randomization | R-bloggers",
    "url": "https://www.r-bloggers.com/2023/12/a-three-arm-trial-using-two-step-randomization/",
    "word_count": 1692
  }
}