{
  "id": "1b0fa2807a7ff77365c6dd74acb01aee03cd75eb",
  "url": "https://www.r-bloggers.com/2025/06/counting-digits-quickly/",
  "created_at_utc": "2025-11-22T19:58:14Z",
  "data": null,
  "raw_original": {
    "uuid": "98068140-a4a9-4f52-823d-a12286e1ef1c",
    "created_at": "2025-11-22 19:58:14",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2025/06/counting-digits-quickly/",
      "crawled_at": "2025-11-22T10:46:36.053187",
      "external_links": [
        {
          "href": "https://jcarroll.com.au/2025/06/29/counting-digits-quickly/",
          "text": "rstats on Irregularly Scheduled Programming"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://github.com/t-kalinowski/quickr",
          "text": "{quickr}"
        },
        {
          "href": "https://github.com/jonocarroll/Dirac",
          "text": "postdoc code to GitHub"
        },
        {
          "href": "https://github.com/search?q=repo%3Awch%2Fr-source+%22.Fortran%28%22+path%3A*.R&type=code",
          "text": "call out to Fortran code"
        },
        {
          "href": "https://jcarroll.com.au/2025/05/03/rotation-with-modulo/",
          "text": "this post"
        },
        {
          "href": "https://fosstodon.org/@jonocarroll/114441466559717402",
          "text": "discussions on Mastodon"
        },
        {
          "href": "https://jcarroll.com.au/2023/08/29/now-you-re-thinking-with-arrays/",
          "text": "another post of mine"
        },
        {
          "href": "https://cs50.harvard.edu/x/2025/",
          "text": "CS50 ‘Introduction to Computer Science’ course"
        },
        {
          "href": "https://contributor.r-project.org/events/c-study-group-2025/",
          "text": "R Contributors"
        },
        {
          "href": "https://github.com/coolbutuseless/callme",
          "text": "{callme}"
        },
        {
          "href": "https://github.com/JuliaLang/julia/blob/760b2e5b7396f9cc0da5efce0cadd5d1974c4069/base/intfuncs.jl#L633",
          "text": "the implementation for which"
        },
        {
          "href": "https://jbytecode.github.io/juliac/",
          "text": "making Julia binaries out of scripts"
        },
        {
          "href": "https://fosstodon.org/@jonocarroll",
          "text": "Mastodon"
        },
        {
          "href": "https://jcarroll.com.au/2025/06/29/counting-digits-quickly/",
          "text": "rstats on Irregularly Scheduled Programming"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Counting Digits Quickly | R-bloggers",
      "images": [
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-12-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-13-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-15-1.png?w=450&ssl=1"
        },
        {
          "alt": "Impressively fast",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Impressively fast",
          "base64": null,
          "src": "https://i1.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/images/vince1.jpg?w=400&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-16-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-18-1.png?w=450&ssl=1"
        },
        {
          "alt": "That’s really fast!",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "That’s really fast!",
          "base64": null,
          "src": "https://i1.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/images/vince2.jpg?w=400&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-19-1.png?w=450&ssl=1"
        },
        {
          "alt": "Ridiculous speeds!",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Ridiculous speeds!",
          "base64": null,
          "src": "https://i0.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/images/vince3.jpg?w=400&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-20-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-21-1.png?w=450&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/jonathan-carroll/",
          "text": "Jonathan Carroll"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-393553 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Counting Digits Quickly</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">June 28, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/jonathan-carroll/\">Jonathan Carroll</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://jcarroll.com.au/2025/06/29/counting-digits-quickly/\"> rstats on Irregularly Scheduled Programming</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47--><p>When things run slower than we’d like in R we tend to reach for another, usually\ncompiled, language, and move our code there. What if it “just happened”? What\nstarted out as a silly exploration of how to count digits ended up with a race\nto see which language does it fastest. Maybe some surprises here for some, maybe\nsome bad implementations on my part – let’s find out.</p>\n<p>I saw some recent activity on <a href=\"https://github.com/t-kalinowski/quickr\" rel=\"nofollow\" target=\"_blank\">{quickr}</a>;\nTomasz Kalinowski’s R to Fortran transpiler – I had starred the repo a long time\nago (and in haste, accidentally unstarred it, then re-starred it) but never\nreally played with it. I’m familiar with slightly older Fortran; nowadays it’s\ncalled “modern Fortran”, but I did my PhD using Fortran95 in the late 2000’s.\nI’ve even pushed some of my <a href=\"https://github.com/jonocarroll/Dirac\" rel=\"nofollow\" target=\"_blank\">postdoc code to GitHub</a>\nafter getting it working again for a recent student.</p>\n<p>I figured now was a great chance to have a proper play with the package.</p>\n<p>{quickr} “transpiles” R code which means it takes R code converts the syntax\ninto Fortran syntax using the same variables and equivalent functions where\navailable. The idea being that when R isn’t working fast enough for you, instead\nof re-writing your function in something like C++ (via {Rcpp}) it can\nautomatically write a Fortran version of your code and compile that into a\nhighly performant function which can be called with the same arguments. Faster\nrunning code with no additional effort – sounds great!</p>\n<p>The README for {quickr} has some examples highlighting how it can improve the\nperformance of some functions beyond what {Rcpp} can offer, in some cases\napproaching C speeds. That’s not surprising to those who know Fortran – it’s\nstill very much used in theoretical physics partly because of the performance,\npartly due to the existing support in that field, but also partly because despite\nbeing an ‘old’ language, it’s actually pretty nice to use.</p>\n<p>One of the big advantages of Fortran I found when learning other languages\n<em>after</em> learning Fortran was that there’s no manual memory management. If you\nwant a vector or an array/tensor with many dimensions, you just ask for it\n(specifying a size along each dimension or dynamically sizing, but never\nmanually freeing memory). R is known for its statistics chops, but under the\nhood of some of these functions still <a href=\"https://github.com/search?q=repo%3Awch%2Fr-source+%22.Fortran%28%22+path%3A*.R&amp;type=code\" rel=\"nofollow\" target=\"_blank\">call out to Fortran code</a>.</p>\n<p>I wanted some example code to try out myself and see if I even recognise the\nFortran it produces. I didn’t just want to use the example code from the package,\nso what could I use?</p>\n<p>In <a href=\"https://jcarroll.com.au/2025/05/03/rotation-with-modulo/\" rel=\"nofollow\" target=\"_blank\">this post</a> I\ncelebrated the fact that Julia has a <code>ndigits()</code> function, while in R I cheated\nand used <code>nchar()</code> which works fine provided you’re dealing with non-negative\nintegers up to 99999, outside of which it doesn’t do what you want</p>\n<pre>nchar(99)       # 99    = 2 characters\n## [1] 2\nnchar(99999)    # 99999 = 5 characters\n## [1] 5\nnchar(99999+1)  # 1e+05 = 5 characters\n## [1] 5\nnchar(-99)      # -99   = 3 characters\n## [1] 3</pre>\n<p>I had some interesting <a href=\"https://fosstodon.org/@jonocarroll/114441466559717402\" rel=\"nofollow\" target=\"_blank\">discussions on Mastodon</a>\nabout different ways to implement <code>ndigits()</code> properly for R and in the end,\nre-implementing the Julia solution seemed to work great for all edge cases. I\ndecided to use this for my Fortran testing with {quickr}.</p>\n<p>I got the package installed and the compiler hooked up correctly so that I could\nrun the example code, then tried adapting it to the <code>ndigits()</code> problem.</p>\n<div class=\"section level2\" id=\"r\">\n<h2>R</h2>\n<p>The R code I started with was</p>\n<pre>nd_R &lt;- function(x) {\n  out &lt;- double(length(x))\n  x &lt;- abs(x / 10)\n  for (v in seq_along(x)) {\n    d &lt;- 1\n    m &lt;- 1\n    while (m &lt;= x[v]) {\n      m &lt;- m * 10\n      d &lt;- d + 1\n    }\n    out[v] &lt;- d\n  }\n  out\n}\n\nnd_R(c(123456, 234, -72))\n## [1] 6 3 2</pre>\n<p>and while this looks like a moderate amount of code, in essence it’s taking the\nabsolute value of the input (since we want to ignore negatives, and which is\nnicely vectorised in R), dividing by 10, checking if we’ve exceeded the input\nyet, and if not, stepping through successive multiples of 10 until we do, which\nfinds the first power of 10 that is greater than our value, indicating the\nnumber of digits. For what it’s worth, this is why in that post I noted an\nalternative route to achieving this; <code>ceil(log10(x))</code>.</p>\n</div>\n<div class=\"section level2\" id=\"fortran\">\n<h2>Fortran</h2>\n<p>Hoping to immediately transpile this to Fortran, <del>I immediately hit my first\nsnag; {quickr} hasn’t yet implemented <code>while()</code> so I can’t transpile this\nexactly as I have it. There’s no early <code>return()</code> or <code>break</code> either, so I can’t\njust exit an oversized loop early. Without an alternative, I’m going to cheat a\nbit and just run a loop 12 times - this puts an upper limit on the input to a 12\ndigit number, but I can live with that.</del></p>\n<p>Update <em>while writing the post</em>: I suppose good things come to those who wait -\non digging through some source code for this post I saw that <code>while</code> has been\nimplemented in the last week, so I’m going to pretend that was always the case.</p>\n<p>The other piece this transpiler needs is a type declaration for the input; R\nis fully dynamic in that a function can take any type of object and it’s up to\nthe function to decide what to do with it. Fortran is a bit stricter, and\nrequires types to be annotated, so I need to add a <code>declare(type())</code> to the code.</p>\n<pre>nd2f &lt;- function(x) {\n  declare(\n    type(x = double(NA))\n  )\n  out &lt;- double(length(x))\n  x &lt;- abs(x / 10)\n  for (v in seq_along(x)) {\n    d &lt;- 1\n    m &lt;- 1\n    while (m &lt;= x[v]) {\n      m &lt;- m * 10\n      d &lt;- d + 1\n    }\n    out[v] &lt;- d\n  }\n  out\n}</pre>\n<p>Note that this is still very much R code at this point - I can even run it\nin R and get the same answers as before</p>\n<pre>nd2f(c(123456, 234, -72))\n## [1] 6 3 2</pre>\n<p>What surprised me here is that <code>declare()</code> is a base R function (not from\n{quickr}) intended for “specifying information about R code for use by the\ninterpreter, compiler, and code analysis tools”. I was originally thinking it\nwould be neat to be able to leverage that for some type-checking on the R side\nas well as being informative to the Fortran code, but it “ignores the arguments\nand returns <code>NULL</code> invisibly”, so no go on this throwing an error from R</p>\n<pre>int_id &lt;- function(x) {\n  declare(type(x = integer(NA)))\n  x\n}\n\nint_id(3L)\n## [1] 3\nint_id(1.5)\n## [1] 1.5</pre>\n<p>The magic happens when we ask {quickr} to do the transpilation.</p>\n<p>The type information is used in the Fortran code, so compiling the <code>id()</code> example\nproduces something that is more restrictive on types</p>\n<pre>int_id_F &lt;- quickr::quick(int_id)\nint_id_F(3L)\n## [1] 3\nint_id_F(1.5)\n## Error in int_id_F(1.5): typeof(x) must be 'integer', not 'double'</pre>\n<p>I can inspect the generated code with <code>r2f()</code>, though one wouldn’t normally need\nto - it’s interesting to see what the Fortran code looks like</p>\n<pre>quickr:::r2f(int_id)\n## subroutine int_id(x, x__len_) bind(c)\n##   use iso_c_binding, only: c_int, c_ptrdiff_t\n##   implicit none\n## \n##   ! manifest start\n##   ! sizes\n##   integer(c_ptrdiff_t), intent(in), value :: x__len_\n## \n##   ! args\n##   integer(c_int), intent(in out) :: x(x__len_)\n##   ! manifest end\n## \n## \n## end subroutine\n## \n## @r: function (x)\n##   {\n##       declare(type(x = integer(NA)))\n##       x\n##   }\n## @closure: function (x)\n##   {\n##       declare(type(x = integer(NA)))\n##       x\n##   }</pre>\n<p>But of course, this just returns the value and that’s not particularly\nenlightening. Doing the same for the <code>ndigits</code> code</p>\n<pre>quickr:::r2f(nd2f)\n## subroutine nd2f(x, out, x__len_) bind(c)\n##   use iso_c_binding, only: c_double, c_int, c_ptrdiff_t\n##   implicit none\n## \n##   ! manifest start\n##   ! sizes\n##   integer(c_ptrdiff_t), intent(in), value :: x__len_\n## \n##   ! args\n##   real(c_double), intent(in out) :: x(x__len_)\n##   real(c_double), intent(out) :: out(x__len_)\n## \n##   ! locals\n##   integer(c_int) :: v\n##   real(c_double) :: d\n##   real(c_double) :: m\n##   ! manifest end\n## \n## \n##   out = 0\n##   x = abs((x / 10.0_c_double))\n##   do v = 1, size(x)\n##     d = 1.0_c_double\n##     m = 1.0_c_double\n##     do while ((m &lt;= x(v)))\n##       m = (m * 10.0_c_double)\n##       d = (d + 1.0_c_double)\n##     end do\n##     out(v) = d\n##   end do\n## end subroutine\n## \n## @r: function (x)\n##   {\n##       declare(type(x = double(NA)))\n##       out &lt;- double(length(x))\n##       x &lt;- abs(x/10)\n##       for (v in seq_along(x)) {\n##           d &lt;- 1\n##           m &lt;- 1\n##           while (m &lt;= x[v]) {\n##               m &lt;- m * 10\n##               d &lt;- d + 1\n##           }\n##           out[v] &lt;- d\n##       }\n##       out\n##   }\n## @closure: function (x)\n##   {\n##       declare(type(x = double(NA)))\n##       out &lt;- double(length(x))\n##       x &lt;- abs(x/10)\n##       for (v in seq_along(x)) {\n##           d &lt;- 1\n##           m &lt;- 1\n##           while (m &lt;= x[v]) {\n##               m &lt;- m * 10\n##               d &lt;- d + 1\n##           }\n##           out[v] &lt;- d\n##       }\n##       out\n##   }</pre>\n<p>The subroutine itself looks a lot like the R code; sure, some type annotations\nare sprinkled around, <code>do v = 1, size(x)</code> replaces <code>for v in seq_along(x)</code> and\n<code>do while</code> replaces <code>while</code>, but I don’t think it’s entirely alien.</p>\n<p>What might surprise some is the line</p>\n<pre>x = abs((x / 10.0_c_double))</pre>\n<p>Notice there’s no loop around this? Fortran is an array language…\nRank-polymorphism, baby! I covered this in\n<a href=\"https://jcarroll.com.au/2023/08/29/now-you-re-thinking-with-arrays/\" rel=\"nofollow\" target=\"_blank\">another post of mine</a>\nbut thanks to this, <code>abs()</code> is vectorised wherever needed</p>\n<pre>program test_abs\n  implicit none\n  integer, dimension(5) :: i = [-1, 2, -3, 4, -5]\n  write(*,*) abs(i)\nend program test_abs\n#           1           2           3           4           5</pre>\n<p>Generating the compiled Fortran code from <code>nd2f</code> is as easy as</p>\n<pre>nd_F &lt;- quickr::quick(nd2f)\nnd_F\n## function (x) \n## .External(&lt;pointer: 0x11fddd73c&gt;, x)</pre>\n<p>and we see that it’s referencing some external code. This can be called</p>\n<pre>nd_F(c(123456, 234, -72))\n## [1] 6 3 2</pre>\n<p>with the big benefit that now it’s a LOT faster!</p>\n<p>Generating a million random values and excluding any zero values, we can see the\n40x performance increase (!!!)</p>\n<pre>set.seed(1)\nnums &lt;- round(runif(1e6, -1, 1) * 1e6)\nnums &lt;- nums[nums != 0]\n\nb0 &lt;- bench::mark(\n  R = nd_R(nums),\n  Fortran = nd_F(nums),\n  min_iterations = 10\n)\n\ndplyr::arrange(b0[, 1:8], median)\n## # A tibble: 2 × 6\n##   expression      min   median `itr/sec` mem_alloc `gc/sec`\n##   &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n## 1 Fortran      3.56ms   3.88ms    255.      15.3MB    266. \n## 2 R          154.27ms 154.42ms      6.48    15.3MB     25.9\nplot(b0)</pre>\n<p><img data-lazy-src=\"https://i1.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-12-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i1.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-12-1.png?w=450&amp;ssl=1\"/></noscript></p>\n<p>For those not familiar, this benchmark plot shows the individual times taken for\nrepeated executions of the code in each ‘expression’, grouped vertically by the\n‘expression’ itself (annotated as the language here) with some random scatter to show\nthe spread of execution times. Points to the left are faster. It’s also worth\nnoting that <code>bench::mark()</code> defaults to <code>check = TRUE</code> so we can rest assured that\nthe results from each of the different languages we’re about to explore are\nconsistent and it’s not some artifact of one language doing less work.</p>\n<p>If you run these yourself you’ll get slightly different results. I’m running them\non a newish M3 Macbook Pro.</p>\n<p>All that performance increase from just adding one line to the R code and\nwrapping it with one other function (resulting in an entirely different program\nbeing written and compiled, producing the correct results).</p>\n<p>I should note that in the first iteration of this post (in which <code>while</code> was not yet\nsupported) I used an excessive <code>for</code> loop which resulted in a\nnot-as-impressive-but-still-very-impressive 15x performance boost.</p>\n</div>\n<div class=\"section level2\" id=\"r-compiled\">\n<h2>R (compiled)</h2>\n<p>If compiled code is so great, what about just compiling the R code with, e.g.\n<code>compiler::cmpfun()</code>?</p>\n<pre>nd_comp = compiler::cmpfun(nd_R)\n\nnd_comp(c(123456, 234, -72))\n## [1] 6 3 2\nb1 &lt;- bench::mark(\n  compiled = nd_comp(nums),\n  R = nd_R(nums),\n  Fortran = nd_F(nums),\n  min_iterations = 10\n)\n\ndplyr::arrange(b1[, 1:8], median)\n## # A tibble: 3 × 6\n##   expression      min   median `itr/sec` mem_alloc `gc/sec`\n##   &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n## 1 Fortran      3.58ms   3.93ms    253.      15.3MB   123.  \n## 2 compiled   147.86ms    149ms      6.66    15.3MB     6.66\n## 3 R          154.69ms 155.25ms      6.30    15.3MB     2.70\nplot(b1)</pre>\n<p><img data-lazy-src=\"https://i2.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-13-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i2.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-13-1.png?w=450&amp;ssl=1\"/></noscript></p>\n<p>That doesn’t help; by the time the benchmark was running the <code>nd_R</code> function had\nbeen called enough times for it to be JIT compiled, anyway.</p>\n<p>This did get me thinking, though - what about other compiled alternatives?</p>\n</div>\n<div class=\"section level2\" id=\"c\">\n<h2>C</h2>\n<p>Since I’m going through Harvard’s <a href=\"https://cs50.harvard.edu/x/2025/\" rel=\"nofollow\" target=\"_blank\">CS50 ‘Introduction to Computer Science’ course</a>\nwith <a href=\"https://contributor.r-project.org/events/c-study-group-2025/\" rel=\"nofollow\" target=\"_blank\">R Contributors</a>\nto learn a bit more structured C I figured I’d add that via coolbutuseless’\n<a href=\"https://github.com/coolbutuseless/callme\" rel=\"nofollow\" target=\"_blank\">{callme}</a> package. This surely isn’t\nthe world’s greatest C code, but it compiles and runs…</p>\n<pre>callme::compile(\n  \"\n#include &lt;R.h&gt;\n#include &lt;Rinternals.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;math.h&gt;\n\nSEXP nd_C(SEXP vec) {\n  double *vec_ptr = REAL(vec);\n  SEXP res = PROTECT(allocVector(REALSXP, length(vec)));\n  double *res_ptr = REAL(res);\n  for (int i = 0; i &lt; length(vec); i++) {\n    double abs_x = fabs(vec_ptr[i] / 10.0);\n        int d = 1;\n        double m = 1.0;\n        while (m &lt;= abs_x) {\n            m *= 10.0;\n            d++;\n        }\n        res_ptr[i] = d;\n  }\n\n  UNPROTECT(1);\n  return res;\n}\n\"\n)\n\nnd_C(c(123456, 234, -72))\n## [1] 6 3 2</pre>\n<p>So, how does it compare?</p>\n<pre>b2 &lt;- bench::mark(\n  C = nd_C(nums),\n  R = nd_R(nums),\n  Fortran = nd_F(nums),\n  min_iterations = 10\n)\n\ndplyr::arrange(b2[, 1:8], median)\n## # A tibble: 3 × 6\n##   expression      min   median `itr/sec` mem_alloc `gc/sec`\n##   &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n## 1 Fortran       3.3ms   3.58ms    277.     15.26MB   107.  \n## 2 C            3.92ms   4.14ms    240.      7.63MB    50.6 \n## 3 R          147.99ms 149.25ms      6.71   15.26MB     4.47\nplot(b2)</pre>\n<p><img data-lazy-src=\"https://i2.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-15-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i2.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-15-1.png?w=450&amp;ssl=1\"/></noscript></p>\n<p>Whoa - automatically transpiled Fortran runs faster than (my) C… That’s fast.</p>\n<div class=\"float\">\n<img alt=\"Impressively fast\" data-lazy-src=\"https://i1.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/images/vince1.jpg?w=400&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Impressively fast\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/images/vince1.jpg?w=400&amp;ssl=1\"/></noscript>\n<div class=\"figcaption\">Impressively fast</div>\n</div>\n</div>\n<div class=\"section level2\" id=\"c-1\">\n<h2>C++</h2>\n<p>What about C++ via {Rcpp}? Dealing with vectors is made easier by {Rcpp} having\npre-built types compatible with R, and this otherwise looks very similar to the\nR code</p>\n<pre>nd_Rcpp &lt;- Rcpp::cppFunction(\n  \"\nIntegerVector nd(NumericVector x) {\n    int n = x.size();\n    IntegerVector out(n);\n\n    for (int v = 0; v &lt; n; v++) {\n        double abs_x = std::abs(x[v] / 10.0);\n        int d = 1;\n        int m = 1;\n        while (m &lt;= abs_x) {\n            m *= 10;\n            d++;\n        }\n        out[v] = d;\n    }\n\n    return out;\n}\n\"\n)\n\nnd_Rcpp(c(123456, 234, -72))\n## [1] 6 3 2\nb3 &lt;- bench::mark(\n  `C++` = nd_Rcpp(nums),\n  C = nd_C(nums),\n  R = nd_R(nums),\n  Fortran = nd_F(nums),\n  min_iterations = 10\n)\n\ndplyr::arrange(b3[, 1:8], median)\n## # A tibble: 4 × 6\n##   expression      min   median `itr/sec` mem_alloc `gc/sec`\n##   &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n## 1 C++          3.02ms   3.12ms    320.      3.82MB    16.6 \n## 2 Fortran      3.29ms   3.58ms    279.     15.26MB    92.9 \n## 3 C            3.75ms   3.93ms    255.      7.63MB    24.9 \n## 4 R          148.52ms 148.85ms      6.71   15.26MB     1.68\nplot(b3)</pre>\n<p><img data-lazy-src=\"https://i0.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-16-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i0.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-16-1.png?w=450&amp;ssl=1\"/></noscript></p>\n<p>This one seems to wander around a bit; on different runs I’ve seen performance\nequal or better to the C code and on others, about 3x as long, but generally\npretty fast.</p>\n</div>\n<div class=\"section level2\" id=\"julia\">\n<h2>Julia</h2>\n<p>After all of this, I remembered that I was comparing the Julia implementation -\nhow does <em>that</em> perform? Julia is a JIT/AOT compiled language, so maybe it’s not\ntoo bad… I can still call that directly from R</p>\n<pre>JuliaCall::julia_eval(\"ndigits.([123456, 234, -72])\")\n## [1] 6 3 2</pre>\n<p>keeping in mind that the Julia function <code>ndigits</code> (<a href=\"https://github.com/JuliaLang/julia/blob/760b2e5b7396f9cc0da5efce0cadd5d1974c4069/base/intfuncs.jl#L633\" rel=\"nofollow\" target=\"_blank\">the implementation for which</a>\nI’ve borrowed for all of the examples, so we <em>are</em> dealing with the same\nalgorithm in each case) is in fact compiled, but available as <code>ndigits()</code>. As\nlong as I make the vector available in a Julia session (as integers; the\nfunction is only defined for integers) I can run this</p>\n<pre>JuliaCall::julia_assign(\"nums\", as.integer(nums))\n\nb4 &lt;- bench::mark(\n  Julia = JuliaCall::julia_eval(\"ndigits.(nums)\"),\n  `C++` = nd_Rcpp(nums),\n  C = nd_C(nums),\n  R = nd_R(nums),\n  Fortran = nd_F(nums),\n  min_iterations = 10\n)\n\ndplyr::arrange(b4[, 1:8], median)\n## # A tibble: 5 × 6\n##   expression      min   median `itr/sec` mem_alloc `gc/sec`\n##   &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n## 1 C++          3.02ms   3.06ms    324.      3.81MB    26.6 \n## 2 Julia         3.1ms   3.32ms    266.      3.81MB    22.0 \n## 3 Fortran      3.29ms    3.6ms    270.     15.26MB    84.2 \n## 4 C            3.74ms   3.94ms    251.      7.63MB    50.7 \n## 5 R          157.75ms 157.91ms      6.33   15.26MB     2.71\nplot(b4)</pre>\n<p><img data-lazy-src=\"https://i2.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-18-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i2.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-18-1.png?w=450&amp;ssl=1\"/></noscript></p>\n<p>Ten points to Julia - remember, this is an interpreted language.</p>\n<div class=\"float\">\n<img alt=\"That’s really fast!\" data-lazy-src=\"https://i1.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/images/vince2.jpg?w=400&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"That’s really fast!\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/images/vince2.jpg?w=400&amp;ssl=1\"/></noscript>\n<div class=\"figcaption\">That’s really fast!</div>\n</div>\n<p>I should note there’s work being done towards <a href=\"https://jbytecode.github.io/juliac/\" rel=\"nofollow\" target=\"_blank\">making Julia binaries out of scripts</a>, but this still has a startup time\nof a few dozen milliseconds for even a Hello, World example.</p>\n</div>\n<div class=\"section level2\" id=\"rust\">\n<h2>Rust</h2>\n<p>One more? What about Rust? We can use {rextendr} to call Rust code inline,\nmaking sure to target the release profile for maximum performance</p>\n<pre>rextendr::rust_function(\n  r\"(\n  fn nd_Rust(x: &amp;[f64]) -&gt; Vec&lt;i32&gt; {\n    let mut out = vec![0; x.len()];\n    for v in 0..x.len() {\n        let abs_x = (x[v].abs() / 10.0);\n        let mut d = 1;\n        let mut m = 1.0;\n        while m &lt;= abs_x {\n            m *= 10.0;\n            d += 1;\n        }\n        out[v] = d;\n    }\n    out\n  }\n)\",\n  profile = \"release\"\n)\n## ℹ build directory: '/private/var/folders/1h/k6c5hb4d2qx07m8kfqb54f9c0000gn/T/RtmppiKq7x/file8b2f28646e2'\n## ✔ Writing '/private/var/folders/1h/k6c5hb4d2qx07m8kfqb54f9c0000gn/T/RtmppiKq7x/file8b2f28646e2/target/extendr_wrappers.R'\nnd_Rust(c(123456, 234, -72))\n## [1] 6 3 2\nb5 &lt;- bench::mark(\n  Rust = nd_Rust(nums),\n  Julia = JuliaCall::julia_eval(\"ndigits.(nums)\"),\n  `C++` = nd_Rcpp(nums),\n  C = nd_C(nums),\n  R = nd_R(nums),\n  Fortran = nd_F(nums),\n  min_iterations = 10\n)\n\ndplyr::arrange(b5[, 1:8], median)\n## # A tibble: 6 × 6\n##   expression      min   median `itr/sec` mem_alloc `gc/sec`\n##   &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n## 1 Rust         2.87ms   3.07ms    322.      3.82MB   24.9  \n## 2 C++          3.03ms   3.13ms    318.      3.81MB   22.1  \n## 3 Fortran      3.28ms   3.56ms    283.     15.26MB   65.5  \n## 4 Julia        3.24ms   3.66ms    265.      3.81MB   17.8  \n## 5 C            3.75ms   3.94ms    255.      7.63MB   22.5  \n## 6 R          150.69ms 151.09ms      6.61   15.26MB    0.734\nplot(b5)</pre>\n<p><img data-lazy-src=\"https://i0.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-19-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i0.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-19-1.png?w=450&amp;ssl=1\"/></noscript></p>\n<div class=\"float\">\n<img alt=\"Ridiculous speeds!\" data-lazy-src=\"https://i0.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/images/vince3.jpg?w=400&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Ridiculous speeds!\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/images/vince3.jpg?w=400&amp;ssl=1\"/></noscript>\n<div class=\"figcaption\">Ridiculous speeds!</div>\n</div>\n<p>We are truly spoiled for choice these days - not only do we have a plethora of\nlanguages we can call directly from R, but several languages which run faster than\neven (at least my implementation of) C and count number of digits of\na million values in under 4ms.</p>\n</div>\n<div class=\"section level2\" id=\"python\">\n<h2>Python</h2>\n<p>Just for funsies, what about Python? It’s not a compiled language, but maybe if\nI use numpy it will be fast … ? It’s at least another language I can call from\nR that is generally considered ‘faster’. Is it?</p>\n<pre>library(reticulate)\nreticulate::py_run_string('\nimport numpy as np\ndef nd_python(x):\n    x = np.asarray(x)\n    out = np.zeros(len(x), dtype=int)\n\n    for v in range(len(x)):\n        abs_x = abs(x[v] / 10.0)\n        d = 1\n        m = 1\n        while m &lt;= abs_x:\n            m *= 10\n            d += 1\n        out[v] = d\n\n    return out.tolist()\n')\n\npy$nd_python(c(123456, 234, -72))\n## [1] 6 3 2\nb6 &lt;- bench::mark(\n  Python = py$nd_python(nums),\n  Rust = nd_Rust(nums),\n  Julia = JuliaCall::julia_eval(\"ndigits.(nums)\"),\n  `C++` = nd_Rcpp(nums),\n  C = nd_C(nums),\n  R = nd_R(nums),\n  Fortran = nd_F(nums),\n  min_iterations = 10\n)\n\ndplyr::arrange(b6[, 1:8], median)\n## # A tibble: 7 × 6\n##   expression      min   median `itr/sec` mem_alloc `gc/sec`\n##   &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n## 1 Rust         2.87ms   3.08ms    322.      3.81MB   13.0  \n## 2 C++          3.02ms   3.13ms    321.      3.81MB    6.21 \n## 3 Fortran      3.27ms   3.44ms    285.     15.26MB   32.7  \n## 4 Julia        3.33ms   3.53ms    280.      3.81MB    7.49 \n## 5 C            3.74ms   3.94ms    255.      7.63MB   10.6  \n## 6 R           157.9ms 158.51ms      6.31   15.26MB    0.701\n## 7 Python     269.08ms 271.27ms      3.64    3.81MB    0\nplot(b6)</pre>\n<p><img data-lazy-src=\"https://i2.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-20-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i2.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-20-1.png?w=450&amp;ssl=1\"/></noscript></p>\n<p>In fairness, there’s overhead here involved with calling it from R, but I think\nthat’s apples-to-apples considering I’m doing the same with all the compiled\nlanguages.</p>\n</div>\n<div class=\"section level2\" id=\"does-it-scale\">\n<h2>Does it scale?</h2>\n<p>I’ve been running these benchmarks for a million numbers, but how do the results\nscale with that size? What if it’s just a handful of numbers? What about in\nbetween these extremes? Running the benchmarks at various scales should show this.</p>\n<pre>n_vals &lt;- 10^(1:7)\nscales &lt;- purrr::map_df(n_vals, ~{\n  set.seed(1)\n  nums &lt;- round(runif(.x, -1, 1) * .x)\n  nums &lt;- nums[nums != 0]\n  JuliaCall::julia_assign(\"nums\", as.integer(nums))\n  b &lt;- bench::mark(\n    Python = py$nd_python(nums),\n    Rust = nd_Rust(nums),\n    Julia = JuliaCall::julia_eval(\"ndigits.(nums)\"),\n    `C++` = nd_Rcpp(nums),\n    C = nd_C(nums),\n    R = nd_R(nums),\n    Fortran = nd_F(nums),\n    min_iterations = 10,\n    check = TRUE\n  )\n  dplyr::bind_cols(vec_len = .x, b[, 1:8])\n})\n\nlibrary(ggplot2)\nggplot(scales,\n       aes(x = vec_len,\n           y = 1e6*as.numeric(median),\n           col = as.character(expression)\n       )) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  scale_y_log10() +\n  scale_color_discrete(palette = \"Set2\") +\n  labs(\n    title = \"Scaling of Counting ndigits Benchmarks\",\n    x = \"Vector Length\",\n    y = \"Microseconds\",\n    color = \"Language\"\n  ) +\n  theme_bw()</pre>\n<p><img data-lazy-src=\"https://i0.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-21-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i0.wp.com/jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-21-1.png?w=450&amp;ssl=1\"/></noscript></p>\n<p>What a nice, log-log linear result with that one exception - Julia is pretty\nconstant up until 1000, after which it starts to follow the same trajectory as\nthe other languages - presumably that’s just the overhead of starting up the\nJulia runtime, which is a known bottleneck.</p>\n<p>There’s definitely a clear divide between the interpreted languages (R and Python)\nand the compiled ones.</p>\n<p>At lower vector lengths there’s a little bit of a spread with Fortran really showing\noff at the lowest lengths</p>\n<pre>dplyr::arrange(scales[scales$vec_len == 10, ], median)\n## # A tibble: 7 × 7\n##   vec_len expression      min   median `itr/sec` mem_alloc `gc/sec`\n##     &lt;dbl&gt; &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n## 1      10 Fortran     122.9ns 205.12ns  4081331.        0B     0   \n## 2      10 C++         287.1ns 369.04ns  2585126.        0B     0   \n## 3      10 C             410ns 491.97ns  1914470.        0B     0   \n## 4      10 Rust        532.9ns  697.1ns  1367702.        0B     0   \n## 5      10 R             943ns   1.11µs   878760.        0B     0   \n## 6      10 Python       20.7µs  22.92µs    43281.        0B     4.33\n## 7      10 Julia        69.8µs  71.59µs    13636.        0B     2.03</pre>\n<p>but we’re looking at sub microsecond differences - what <em>will</em> you do with all\nthat free time?</p>\n<p>By the time we’re looking at 1000 values, the compiled languages are all about\nthe same</p>\n<pre>dplyr::arrange(scales[scales$vec_len == 1000, ], median)\n## # A tibble: 7 × 7\n##   vec_len expression      min   median `itr/sec` mem_alloc `gc/sec`\n##     &lt;dbl&gt; &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n## 1    1000 C++          1.68µs   1.84µs   487745.    3.95KB     0   \n## 2    1000 Rust         2.13µs   2.46µs   397120.    3.95KB     0   \n## 3    1000 Fortran      1.97µs   2.79µs   347513.   15.72KB    34.8 \n## 4    1000 C            2.79µs   3.08µs   299955.    7.86KB    30.0 \n## 5    1000 Julia       73.06µs  77.49µs    12381.    3.95KB     0   \n## 6    1000 R           77.53µs  81.22µs    12306.   15.72KB     0   \n## 7    1000 Python      213.9µs 232.35µs     4282.    3.95KB     2.06</pre>\n<p>At ten million values it’s a complete wash the compiled languages with maybe a\nslight drop for C</p>\n<pre>dplyr::arrange(scales[scales$vec_len == 1e7, ], median)\n## # A tibble: 7 × 7\n##    vec_len expression      min   median `itr/sec` mem_alloc `gc/sec`\n##      &lt;dbl&gt; &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n## 1 10000000 Rust        33.78ms  34.58ms    28.9      38.1MB   2.07  \n## 2 10000000 C++         35.05ms  35.38ms    28.3      38.1MB   2.02  \n## 3 10000000 Julia       37.63ms  38.56ms    18.1      38.1MB   2.01  \n## 4 10000000 Fortran     39.29ms   41.9ms    23.8     152.6MB  17.0   \n## 5 10000000 C           43.99ms  44.19ms    22.5      76.3MB   2.05  \n## 6 10000000 R              1.8s    1.81s     0.550   152.6MB   0.236 \n## 7 10000000 Python        3.06s     3.1s     0.322    38.1MB   0.0357</pre>\n<p>All very interesting!</p>\n<p>It would probably be worthwhile digging into the memory usage of all of these\nsince there’s a big difference that likely indicates something different is\nhappening, but that’s beyond my understanding - feel free to let me know!</p>\n<p>So, what might be the reason for Rust and Julia to be so fast, even compared to\nC? These are newer languages with a lot of focus on their compilers, and it’s\nentirely possible that they’re able to make some better optimisations compared\nto a very general C compiler, but more likely that’s the upper limit of what a\ncomputer can do in that much time and my C code is non-optimal.</p>\n</div>\n<div class=\"section level2\" id=\"conclusions\">\n<h2>Conclusions</h2>\n<p>Back to the original point, though - the transpilation does an amazing job\nof improving the code <em>without having to write more code in a different\nlanguage</em>. Sure, Julia solves this ‘two language problem’ by just being\nridiculously fast to begin with, but if I <em>am</em> writing R code, it’s fantastic to\nsee there’s an option for just “making it go brrr” without actually doing\nanything extra.</p>\n<p>Not all of R has been translated to Fortran so there’s a lot of code that won’t\ntranspile just yet, but it’s a truly inspiring project that I’ll surely be\nkeeping a close eye on.</p>\n<p>I’d love to hear what people think about these comparisons - are there points I’ve\noverlooked? Better ways to do it? Improvements to my implementations which change\nthe results? Other considerations I’ve missed? As always, I can be found on\n<a href=\"https://fosstodon.org/@jonocarroll\" rel=\"nofollow\" target=\"_blank\">Mastodon</a> and the comment section below.</p>\n<br/>\n<details>\n<summary>\n<tt>devtools::session_info()</tt>\n</summary>\n<pre>## ─ Session info ───────────────────────────────────────────────────────────────\n##  setting  value\n##  version  R version 4.4.1 (2024-06-14)\n##  os       macOS 15.5\n##  system   aarch64, darwin20\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       Australia/Adelaide\n##  date     2025-06-29\n##  pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n## \n## ─ Packages ───────────────────────────────────────────────────────────────────\n##  package      * version    date (UTC) lib source\n##  beeswarm       0.4.0      2021-06-01 [1] CRAN (R 4.4.1)\n##  bench          1.1.4      2025-01-16 [1] CRAN (R 4.4.1)\n##  blogdown       1.21.1     2025-06-28 [1] Github (rstudio/blogdown@33313a5)\n##  bookdown       0.41       2024-10-16 [1] CRAN (R 4.4.1)\n##  brio           1.1.5      2024-04-24 [1] CRAN (R 4.4.0)\n##  bslib          0.8.0      2024-07-29 [1] CRAN (R 4.4.0)\n##  cachem         1.1.0      2024-05-16 [1] CRAN (R 4.4.0)\n##  callme         0.1.10     2024-07-27 [1] CRAN (R 4.4.0)\n##  cli            3.6.4      2025-02-13 [1] CRAN (R 4.4.1)\n##  codetools      0.2-20     2024-03-31 [1] CRAN (R 4.4.1)\n##  devtools       2.4.5      2022-10-11 [1] CRAN (R 4.4.0)\n##  dichromat      2.0-0.1    2022-05-02 [1] CRAN (R 4.4.1)\n##  digest         0.6.37     2024-08-19 [1] CRAN (R 4.4.1)\n##  dotty          0.1.0      2024-08-30 [1] CRAN (R 4.4.1)\n##  dplyr          1.1.4      2023-11-17 [1] CRAN (R 4.4.0)\n##  ellipsis       0.3.2      2021-04-29 [1] CRAN (R 4.4.0)\n##  evaluate       1.0.3      2025-01-10 [1] CRAN (R 4.4.1)\n##  farver         2.1.2      2024-05-13 [1] CRAN (R 4.4.0)\n##  fastmap        1.2.0      2024-05-15 [1] CRAN (R 4.4.0)\n##  fs             1.6.5      2024-10-30 [1] CRAN (R 4.4.1)\n##  generics       0.1.3      2022-07-05 [1] CRAN (R 4.4.0)\n##  ggbeeswarm     0.7.2      2023-04-29 [1] CRAN (R 4.4.0)\n##  ggplot2      * 3.5.2.9001 2025-06-15 [1] Github (tidyverse/ggplot2@9f80c8c)\n##  glue           1.8.0      2024-09-30 [1] CRAN (R 4.4.1)\n##  gtable         0.3.6      2024-10-25 [1] CRAN (R 4.4.1)\n##  here           1.0.1      2020-12-13 [1] CRAN (R 4.4.0)\n##  htmltools      0.5.8.1    2024-04-04 [1] CRAN (R 4.4.0)\n##  htmlwidgets    1.6.4      2023-12-06 [1] CRAN (R 4.4.0)\n##  httpuv         1.6.15     2024-03-26 [1] CRAN (R 4.4.0)\n##  jquerylib      0.1.4      2021-04-26 [1] CRAN (R 4.4.0)\n##  jsonlite       2.0.0      2025-03-27 [1] CRAN (R 4.4.1)\n##  JuliaCall      0.17.6     2024-12-07 [1] CRAN (R 4.4.1)\n##  knitr          1.50       2025-03-16 [1] CRAN (R 4.4.1)\n##  later          1.4.1      2024-11-27 [1] CRAN (R 4.4.1)\n##  lattice        0.22-6     2024-03-20 [1] CRAN (R 4.4.1)\n##  lifecycle      1.0.4      2023-11-07 [1] CRAN (R 4.4.0)\n##  magrittr       2.0.3      2022-03-30 [1] CRAN (R 4.4.0)\n##  Matrix         1.7-1      2024-10-18 [1] CRAN (R 4.4.1)\n##  memoise        2.0.1      2021-11-26 [1] CRAN (R 4.4.0)\n##  mime           0.12       2021-09-28 [1] CRAN (R 4.4.0)\n##  miniUI         0.1.1.1    2018-05-18 [1] CRAN (R 4.4.0)\n##  pillar         1.10.1     2025-01-07 [1] CRAN (R 4.4.1)\n##  pkgbuild       1.4.7      2025-03-24 [1] CRAN (R 4.4.1)\n##  pkgconfig      2.0.3      2019-09-22 [1] CRAN (R 4.4.0)\n##  pkgload        1.4.0      2024-06-28 [1] CRAN (R 4.4.0)\n##  png            0.1-8      2022-11-29 [1] CRAN (R 4.4.0)\n##  processx       3.8.6      2025-02-21 [1] CRAN (R 4.4.1)\n##  profmem        0.7.0      2025-05-02 [1] CRAN (R 4.4.1)\n##  profvis        0.4.0      2024-09-20 [1] CRAN (R 4.4.1)\n##  promises       1.3.2      2024-11-28 [1] CRAN (R 4.4.1)\n##  ps             1.9.0      2025-02-18 [1] CRAN (R 4.4.1)\n##  purrr          1.0.4      2025-02-05 [1] CRAN (R 4.4.1)\n##  quickr         0.1.0.9000 2025-06-29 [1] Github (t-kalinowski/quickr@254b4d0)\n##  R6             2.6.1      2025-02-15 [1] CRAN (R 4.4.1)\n##  RColorBrewer   1.1-3      2022-04-03 [1] CRAN (R 4.4.0)\n##  Rcpp           1.0.14     2025-01-12 [1] CRAN (R 4.4.1)\n##  remotes        2.5.0      2024-03-17 [1] CRAN (R 4.4.1)\n##  reticulate   * 1.42.0     2025-03-25 [1] CRAN (R 4.4.1)\n##  rextendr       0.3.1      2023-06-20 [1] CRAN (R 4.4.0)\n##  rlang          1.1.5      2025-01-17 [1] CRAN (R 4.4.1)\n##  rmarkdown      2.28       2024-08-17 [1] CRAN (R 4.4.0)\n##  rprojroot      2.0.4      2023-11-05 [1] CRAN (R 4.4.0)\n##  rstudioapi     0.17.1     2024-10-22 [1] CRAN (R 4.4.1)\n##  S7             0.2.0      2024-11-07 [1] CRAN (R 4.4.1)\n##  sass           0.4.9      2024-03-15 [1] CRAN (R 4.4.0)\n##  scales         1.4.0      2025-04-24 [1] CRAN (R 4.4.1)\n##  sessioninfo    1.2.2      2021-12-06 [1] CRAN (R 4.4.0)\n##  shiny          1.9.1      2024-08-01 [1] CRAN (R 4.4.0)\n##  stringi        1.8.4      2024-05-06 [1] CRAN (R 4.4.0)\n##  tibble         3.2.1      2023-03-20 [1] CRAN (R 4.4.0)\n##  tidyr          1.3.1      2024-01-24 [1] CRAN (R 4.4.0)\n##  tidyselect     1.2.1      2024-03-11 [1] CRAN (R 4.4.0)\n##  urlchecker     1.0.1      2021-11-30 [1] CRAN (R 4.4.0)\n##  usethis        3.1.0.9000 2025-03-31 [1] Github (r-lib/usethis@a653d6e)\n##  utf8           1.2.4      2023-10-22 [1] CRAN (R 4.4.0)\n##  vctrs          0.6.5      2023-12-01 [1] CRAN (R 4.4.0)\n##  vipor          0.4.7      2023-12-18 [1] CRAN (R 4.4.1)\n##  withr          3.0.2      2024-10-28 [1] CRAN (R 4.4.1)\n##  xfun           0.51       2025-02-19 [1] CRAN (R 4.4.1)\n##  xtable         1.8-4      2019-04-21 [1] CRAN (R 4.4.0)\n##  yaml           2.3.10     2024-07-26 [1] CRAN (R 4.4.0)\n## \n##  [1] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n## \n## ─ Python configuration ───────────────────────────────────────────────────────\n##  python:         /Users/jono/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/2tc-cviHm3ODucI_hIfUb/bin/python3\n##  libpython:      /Users/jono/Library/Caches/org.R-project.R/R/reticulate/uv/python/cpython-3.11.12-macos-aarch64-none/lib/libpython3.11.dylib\n##  pythonhome:     /Users/jono/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/2tc-cviHm3ODucI_hIfUb:/Users/jono/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/2tc-cviHm3ODucI_hIfUb\n##  virtualenv:     /Users/jono/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/2tc-cviHm3ODucI_hIfUb/bin/activate_this.py\n##  version:        3.11.12 (main, Apr  9 2025, 03:49:53) [Clang 20.1.0 ]\n##  numpy:          /Users/jono/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/2tc-cviHm3ODucI_hIfUb/lib/python3.11/site-packages/numpy\n##  numpy_version:  2.3.1\n##  \n##  NOTE: Python version was forced by py_require()\n## \n## ──────────────────────────────────────────────────────────────────────────────</pre>\n</details>\n<p><br/></p>\n</div>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://jcarroll.com.au/2025/06/29/counting-digits-quickly/\"> rstats on Irregularly Scheduled Programming</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
      "main_text": "Counting Digits Quickly\nPosted on\nJune 28, 2025\nby\nJonathan Carroll\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nrstats on Irregularly Scheduled Programming\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nWhen things run slower than we’d like in R we tend to reach for another, usually\ncompiled, language, and move our code there. What if it “just happened”? What\nstarted out as a silly exploration of how to count digits ended up with a race\nto see which language does it fastest. Maybe some surprises here for some, maybe\nsome bad implementations on my part – let’s find out.\nI saw some recent activity on\n{quickr}\n;\nTomasz Kalinowski’s R to Fortran transpiler – I had starred the repo a long time\nago (and in haste, accidentally unstarred it, then re-starred it) but never\nreally played with it. I’m familiar with slightly older Fortran; nowadays it’s\ncalled “modern Fortran”, but I did my PhD using Fortran95 in the late 2000’s.\nI’ve even pushed some of my\npostdoc code to GitHub\nafter getting it working again for a recent student.\nI figured now was a great chance to have a proper play with the package.\n{quickr} “transpiles” R code which means it takes R code converts the syntax\ninto Fortran syntax using the same variables and equivalent functions where\navailable. The idea being that when R isn’t working fast enough for you, instead\nof re-writing your function in something like C++ (via {Rcpp}) it can\nautomatically write a Fortran version of your code and compile that into a\nhighly performant function which can be called with the same arguments. Faster\nrunning code with no additional effort – sounds great!\nThe README for {quickr} has some examples highlighting how it can improve the\nperformance of some functions beyond what {Rcpp} can offer, in some cases\napproaching C speeds. That’s not surprising to those who know Fortran – it’s\nstill very much used in theoretical physics partly because of the performance,\npartly due to the existing support in that field, but also partly because despite\nbeing an ‘old’ language, it’s actually pretty nice to use.\nOne of the big advantages of Fortran I found when learning other languages\nafter\nlearning Fortran was that there’s no manual memory management. If you\nwant a vector or an array/tensor with many dimensions, you just ask for it\n(specifying a size along each dimension or dynamically sizing, but never\nmanually freeing memory). R is known for its statistics chops, but under the\nhood of some of these functions still\ncall out to Fortran code\n.\nI wanted some example code to try out myself and see if I even recognise the\nFortran it produces. I didn’t just want to use the example code from the package,\nso what could I use?\nIn\nthis post\nI\ncelebrated the fact that Julia has a\nndigits()\nfunction, while in R I cheated\nand used\nnchar()\nwhich works fine provided you’re dealing with non-negative\nintegers up to 99999, outside of which it doesn’t do what you want\nnchar(99)       # 99    = 2 characters\n## [1] 2\nnchar(99999)    # 99999 = 5 characters\n## [1] 5\nnchar(99999+1)  # 1e+05 = 5 characters\n## [1] 5\nnchar(-99)      # -99   = 3 characters\n## [1] 3\nI had some interesting\ndiscussions on Mastodon\nabout different ways to implement\nndigits()\nproperly for R and in the end,\nre-implementing the Julia solution seemed to work great for all edge cases. I\ndecided to use this for my Fortran testing with {quickr}.\nI got the package installed and the compiler hooked up correctly so that I could\nrun the example code, then tried adapting it to the\nndigits()\nproblem.\nR\nThe R code I started with was\nnd_R <- function(x) {\n  out <- double(length(x))\n  x <- abs(x / 10)\n  for (v in seq_along(x)) {\n    d <- 1\n    m <- 1\n    while (m <= x[v]) {\n      m <- m * 10\n      d <- d + 1\n    }\n    out[v] <- d\n  }\n  out\n}\n\nnd_R(c(123456, 234, -72))\n## [1] 6 3 2\nand while this looks like a moderate amount of code, in essence it’s taking the\nabsolute value of the input (since we want to ignore negatives, and which is\nnicely vectorised in R), dividing by 10, checking if we’ve exceeded the input\nyet, and if not, stepping through successive multiples of 10 until we do, which\nfinds the first power of 10 that is greater than our value, indicating the\nnumber of digits. For what it’s worth, this is why in that post I noted an\nalternative route to achieving this;\nceil(log10(x))\n.\nFortran\nHoping to immediately transpile this to Fortran,\nI immediately hit my first\nsnag; {quickr} hasn’t yet implemented\nwhile()\nso I can’t transpile this\nexactly as I have it. There’s no early\nreturn()\nor\nbreak\neither, so I can’t\njust exit an oversized loop early. Without an alternative, I’m going to cheat a\nbit and just run a loop 12 times - this puts an upper limit on the input to a 12\ndigit number, but I can live with that.\nUpdate\nwhile writing the post\n: I suppose good things come to those who wait -\non digging through some source code for this post I saw that\nwhile\nhas been\nimplemented in the last week, so I’m going to pretend that was always the case.\nThe other piece this transpiler needs is a type declaration for the input; R\nis fully dynamic in that a function can take any type of object and it’s up to\nthe function to decide what to do with it. Fortran is a bit stricter, and\nrequires types to be annotated, so I need to add a\ndeclare(type())\nto the code.\nnd2f <- function(x) {\n  declare(\n    type(x = double(NA))\n  )\n  out <- double(length(x))\n  x <- abs(x / 10)\n  for (v in seq_along(x)) {\n    d <- 1\n    m <- 1\n    while (m <= x[v]) {\n      m <- m * 10\n      d <- d + 1\n    }\n    out[v] <- d\n  }\n  out\n}\nNote that this is still very much R code at this point - I can even run it\nin R and get the same answers as before\nnd2f(c(123456, 234, -72))\n## [1] 6 3 2\nWhat surprised me here is that\ndeclare()\nis a base R function (not from\n{quickr}) intended for “specifying information about R code for use by the\ninterpreter, compiler, and code analysis tools”. I was originally thinking it\nwould be neat to be able to leverage that for some type-checking on the R side\nas well as being informative to the Fortran code, but it “ignores the arguments\nand returns\nNULL\ninvisibly”, so no go on this throwing an error from R\nint_id <- function(x) {\n  declare(type(x = integer(NA)))\n  x\n}\n\nint_id(3L)\n## [1] 3\nint_id(1.5)\n## [1] 1.5\nThe magic happens when we ask {quickr} to do the transpilation.\nThe type information is used in the Fortran code, so compiling the\nid()\nexample\nproduces something that is more restrictive on types\nint_id_F <- quickr::quick(int_id)\nint_id_F(3L)\n## [1] 3\nint_id_F(1.5)\n## Error in int_id_F(1.5): typeof(x) must be 'integer', not 'double'\nI can inspect the generated code with\nr2f()\n, though one wouldn’t normally need\nto - it’s interesting to see what the Fortran code looks like\nquickr:::r2f(int_id)\n## subroutine int_id(x, x__len_) bind(c)\n##   use iso_c_binding, only: c_int, c_ptrdiff_t\n##   implicit none\n## \n##   ! manifest start\n##   ! sizes\n##   integer(c_ptrdiff_t), intent(in), value :: x__len_\n## \n##   ! args\n##   integer(c_int), intent(in out) :: x(x__len_)\n##   ! manifest end\n## \n## \n## end subroutine\n## \n## @r: function (x)\n##   {\n##       declare(type(x = integer(NA)))\n##       x\n##   }\n## @closure: function (x)\n##   {\n##       declare(type(x = integer(NA)))\n##       x\n##   }\nBut of course, this just returns the value and that’s not particularly\nenlightening. Doing the same for the\nndigits\ncode\nquickr:::r2f(nd2f)\n## subroutine nd2f(x, out, x__len_) bind(c)\n##   use iso_c_binding, only: c_double, c_int, c_ptrdiff_t\n##   implicit none\n## \n##   ! manifest start\n##   ! sizes\n##   integer(c_ptrdiff_t), intent(in), value :: x__len_\n## \n##   ! args\n##   real(c_double), intent(in out) :: x(x__len_)\n##   real(c_double), intent(out) :: out(x__len_)\n## \n##   ! locals\n##   integer(c_int) :: v\n##   real(c_double) :: d\n##   real(c_double) :: m\n##   ! manifest end\n## \n## \n##   out = 0\n##   x = abs((x / 10.0_c_double))\n##   do v = 1, size(x)\n##     d = 1.0_c_double\n##     m = 1.0_c_double\n##     do while ((m <= x(v)))\n##       m = (m * 10.0_c_double)\n##       d = (d + 1.0_c_double)\n##     end do\n##     out(v) = d\n##   end do\n## end subroutine\n## \n## @r: function (x)\n##   {\n##       declare(type(x = double(NA)))\n##       out <- double(length(x))\n##       x <- abs(x/10)\n##       for (v in seq_along(x)) {\n##           d <- 1\n##           m <- 1\n##           while (m <= x[v]) {\n##               m <- m * 10\n##               d <- d + 1\n##           }\n##           out[v] <- d\n##       }\n##       out\n##   }\n## @closure: function (x)\n##   {\n##       declare(type(x = double(NA)))\n##       out <- double(length(x))\n##       x <- abs(x/10)\n##       for (v in seq_along(x)) {\n##           d <- 1\n##           m <- 1\n##           while (m <= x[v]) {\n##               m <- m * 10\n##               d <- d + 1\n##           }\n##           out[v] <- d\n##       }\n##       out\n##   }\nThe subroutine itself looks a lot like the R code; sure, some type annotations\nare sprinkled around,\ndo v = 1, size(x)\nreplaces\nfor v in seq_along(x)\nand\ndo while\nreplaces\nwhile\n, but I don’t think it’s entirely alien.\nWhat might surprise some is the line\nx = abs((x / 10.0_c_double))\nNotice there’s no loop around this? Fortran is an array language…\nRank-polymorphism, baby! I covered this in\nanother post of mine\nbut thanks to this,\nabs()\nis vectorised wherever needed\nprogram test_abs\n  implicit none\n  integer, dimension(5) :: i = [-1, 2, -3, 4, -5]\n  write(*,*) abs(i)\nend program test_abs\n#           1           2           3           4           5\nGenerating the compiled Fortran code from\nnd2f\nis as easy as\nnd_F <- quickr::quick(nd2f)\nnd_F\n## function (x) \n## .External(<pointer: 0x11fddd73c>, x)\nand we see that it’s referencing some external code. This can be called\nnd_F(c(123456, 234, -72))\n## [1] 6 3 2\nwith the big benefit that now it’s a LOT faster!\nGenerating a million random values and excluding any zero values, we can see the\n40x performance increase (!!!)\nset.seed(1)\nnums <- round(runif(1e6, -1, 1) * 1e6)\nnums <- nums[nums != 0]\n\nb0 <- bench::mark(\n  R = nd_R(nums),\n  Fortran = nd_F(nums),\n  min_iterations = 10\n)\n\ndplyr::arrange(b0[, 1:8], median)\n## # A tibble: 2 × 6\n##   expression      min   median `itr/sec` mem_alloc `gc/sec`\n##   <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n## 1 Fortran      3.56ms   3.88ms    255.      15.3MB    266. \n## 2 R          154.27ms 154.42ms      6.48    15.3MB     25.9\nplot(b0)\nFor those not familiar, this benchmark plot shows the individual times taken for\nrepeated executions of the code in each ‘expression’, grouped vertically by the\n‘expression’ itself (annotated as the language here) with some random scatter to show\nthe spread of execution times. Points to the left are faster. It’s also worth\nnoting that\nbench::mark()\ndefaults to\ncheck = TRUE\nso we can rest assured that\nthe results from each of the different languages we’re about to explore are\nconsistent and it’s not some artifact of one language doing less work.\nIf you run these yourself you’ll get slightly different results. I’m running them\non a newish M3 Macbook Pro.\nAll that performance increase from just adding one line to the R code and\nwrapping it with one other function (resulting in an entirely different program\nbeing written and compiled, producing the correct results).\nI should note that in the first iteration of this post (in which\nwhile\nwas not yet\nsupported) I used an excessive\nfor\nloop which resulted in a\nnot-as-impressive-but-still-very-impressive 15x performance boost.\nR (compiled)\nIf compiled code is so great, what about just compiling the R code with, e.g.\ncompiler::cmpfun()\n?\nnd_comp = compiler::cmpfun(nd_R)\n\nnd_comp(c(123456, 234, -72))\n## [1] 6 3 2\nb1 <- bench::mark(\n  compiled = nd_comp(nums),\n  R = nd_R(nums),\n  Fortran = nd_F(nums),\n  min_iterations = 10\n)\n\ndplyr::arrange(b1[, 1:8], median)\n## # A tibble: 3 × 6\n##   expression      min   median `itr/sec` mem_alloc `gc/sec`\n##   <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n## 1 Fortran      3.58ms   3.93ms    253.      15.3MB   123.  \n## 2 compiled   147.86ms    149ms      6.66    15.3MB     6.66\n## 3 R          154.69ms 155.25ms      6.30    15.3MB     2.70\nplot(b1)\nThat doesn’t help; by the time the benchmark was running the\nnd_R\nfunction had\nbeen called enough times for it to be JIT compiled, anyway.\nThis did get me thinking, though - what about other compiled alternatives?\nC\nSince I’m going through Harvard’s\nCS50 ‘Introduction to Computer Science’ course\nwith\nR Contributors\nto learn a bit more structured C I figured I’d add that via coolbutuseless’\n{callme}\npackage. This surely isn’t\nthe world’s greatest C code, but it compiles and runs…\ncallme::compile(\n  \"\n#include <R.h>\n#include <Rinternals.h>\n#include <stdlib.h>\n#include <math.h>\n\nSEXP nd_C(SEXP vec) {\n  double *vec_ptr = REAL(vec);\n  SEXP res = PROTECT(allocVector(REALSXP, length(vec)));\n  double *res_ptr = REAL(res);\n  for (int i = 0; i < length(vec); i++) {\n    double abs_x = fabs(vec_ptr[i] / 10.0);\n        int d = 1;\n        double m = 1.0;\n        while (m <= abs_x) {\n            m *= 10.0;\n            d++;\n        }\n        res_ptr[i] = d;\n  }\n\n  UNPROTECT(1);\n  return res;\n}\n\"\n)\n\nnd_C(c(123456, 234, -72))\n## [1] 6 3 2\nSo, how does it compare?\nb2 <- bench::mark(\n  C = nd_C(nums),\n  R = nd_R(nums),\n  Fortran = nd_F(nums),\n  min_iterations = 10\n)\n\ndplyr::arrange(b2[, 1:8], median)\n## # A tibble: 3 × 6\n##   expression      min   median `itr/sec` mem_alloc `gc/sec`\n##   <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n## 1 Fortran       3.3ms   3.58ms    277.     15.26MB   107.  \n## 2 C            3.92ms   4.14ms    240.      7.63MB    50.6 \n## 3 R          147.99ms 149.25ms      6.71   15.26MB     4.47\nplot(b2)\nWhoa - automatically transpiled Fortran runs faster than (my) C… That’s fast.\nImpressively fast\nC++\nWhat about C++ via {Rcpp}? Dealing with vectors is made easier by {Rcpp} having\npre-built types compatible with R, and this otherwise looks very similar to the\nR code\nnd_Rcpp <- Rcpp::cppFunction(\n  \"\nIntegerVector nd(NumericVector x) {\n    int n = x.size();\n    IntegerVector out(n);\n\n    for (int v = 0; v < n; v++) {\n        double abs_x = std::abs(x[v] / 10.0);\n        int d = 1;\n        int m = 1;\n        while (m <= abs_x) {\n            m *= 10;\n            d++;\n        }\n        out[v] = d;\n    }\n\n    return out;\n}\n\"\n)\n\nnd_Rcpp(c(123456, 234, -72))\n## [1] 6 3 2\nb3 <- bench::mark(\n  `C++` = nd_Rcpp(nums),\n  C = nd_C(nums),\n  R = nd_R(nums),\n  Fortran = nd_F(nums),\n  min_iterations = 10\n)\n\ndplyr::arrange(b3[, 1:8], median)\n## # A tibble: 4 × 6\n##   expression      min   median `itr/sec` mem_alloc `gc/sec`\n##   <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n## 1 C++          3.02ms   3.12ms    320.      3.82MB    16.6 \n## 2 Fortran      3.29ms   3.58ms    279.     15.26MB    92.9 \n## 3 C            3.75ms   3.93ms    255.      7.63MB    24.9 \n## 4 R          148.52ms 148.85ms      6.71   15.26MB     1.68\nplot(b3)\nThis one seems to wander around a bit; on different runs I’ve seen performance\nequal or better to the C code and on others, about 3x as long, but generally\npretty fast.\nJulia\nAfter all of this, I remembered that I was comparing the Julia implementation -\nhow does\nthat\nperform? Julia is a JIT/AOT compiled language, so maybe it’s not\ntoo bad… I can still call that directly from R\nJuliaCall::julia_eval(\"ndigits.([123456, 234, -72])\")\n## [1] 6 3 2\nkeeping in mind that the Julia function\nndigits\n(\nthe implementation for which\nI’ve borrowed for all of the examples, so we\nare\ndealing with the same\nalgorithm in each case) is in fact compiled, but available as\nndigits()\n. As\nlong as I make the vector available in a Julia session (as integers; the\nfunction is only defined for integers) I can run this\nJuliaCall::julia_assign(\"nums\", as.integer(nums))\n\nb4 <- bench::mark(\n  Julia = JuliaCall::julia_eval(\"ndigits.(nums)\"),\n  `C++` = nd_Rcpp(nums),\n  C = nd_C(nums),\n  R = nd_R(nums),\n  Fortran = nd_F(nums),\n  min_iterations = 10\n)\n\ndplyr::arrange(b4[, 1:8], median)\n## # A tibble: 5 × 6\n##   expression      min   median `itr/sec` mem_alloc `gc/sec`\n##   <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n## 1 C++          3.02ms   3.06ms    324.      3.81MB    26.6 \n## 2 Julia         3.1ms   3.32ms    266.      3.81MB    22.0 \n## 3 Fortran      3.29ms    3.6ms    270.     15.26MB    84.2 \n## 4 C            3.74ms   3.94ms    251.      7.63MB    50.7 \n## 5 R          157.75ms 157.91ms      6.33   15.26MB     2.71\nplot(b4)\nTen points to Julia - remember, this is an interpreted language.\nThat’s really fast!\nI should note there’s work being done towards\nmaking Julia binaries out of scripts\n, but this still has a startup time\nof a few dozen milliseconds for even a Hello, World example.\nRust\nOne more? What about Rust? We can use {rextendr} to call Rust code inline,\nmaking sure to target the release profile for maximum performance\nrextendr::rust_function(\n  r\"(\n  fn nd_Rust(x: &[f64]) -> Vec<i32> {\n    let mut out = vec![0; x.len()];\n    for v in 0..x.len() {\n        let abs_x = (x[v].abs() / 10.0);\n        let mut d = 1;\n        let mut m = 1.0;\n        while m <= abs_x {\n            m *= 10.0;\n            d += 1;\n        }\n        out[v] = d;\n    }\n    out\n  }\n)\",\n  profile = \"release\"\n)\n## ℹ build directory: '/private/var/folders/1h/k6c5hb4d2qx07m8kfqb54f9c0000gn/T/RtmppiKq7x/file8b2f28646e2'\n## ✔ Writing '/private/var/folders/1h/k6c5hb4d2qx07m8kfqb54f9c0000gn/T/RtmppiKq7x/file8b2f28646e2/target/extendr_wrappers.R'\nnd_Rust(c(123456, 234, -72))\n## [1] 6 3 2\nb5 <- bench::mark(\n  Rust = nd_Rust(nums),\n  Julia = JuliaCall::julia_eval(\"ndigits.(nums)\"),\n  `C++` = nd_Rcpp(nums),\n  C = nd_C(nums),\n  R = nd_R(nums),\n  Fortran = nd_F(nums),\n  min_iterations = 10\n)\n\ndplyr::arrange(b5[, 1:8], median)\n## # A tibble: 6 × 6\n##   expression      min   median `itr/sec` mem_alloc `gc/sec`\n##   <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n## 1 Rust         2.87ms   3.07ms    322.      3.82MB   24.9  \n## 2 C++          3.03ms   3.13ms    318.      3.81MB   22.1  \n## 3 Fortran      3.28ms   3.56ms    283.     15.26MB   65.5  \n## 4 Julia        3.24ms   3.66ms    265.      3.81MB   17.8  \n## 5 C            3.75ms   3.94ms    255.      7.63MB   22.5  \n## 6 R          150.69ms 151.09ms      6.61   15.26MB    0.734\nplot(b5)\nRidiculous speeds!\nWe are truly spoiled for choice these days - not only do we have a plethora of\nlanguages we can call directly from R, but several languages which run faster than\neven (at least my implementation of) C and count number of digits of\na million values in under 4ms.\nPython\nJust for funsies, what about Python? It’s not a compiled language, but maybe if\nI use numpy it will be fast … ? It’s at least another language I can call from\nR that is generally considered ‘faster’. Is it?\nlibrary(reticulate)\nreticulate::py_run_string('\nimport numpy as np\ndef nd_python(x):\n    x = np.asarray(x)\n    out = np.zeros(len(x), dtype=int)\n\n    for v in range(len(x)):\n        abs_x = abs(x[v] / 10.0)\n        d = 1\n        m = 1\n        while m <= abs_x:\n            m *= 10\n            d += 1\n        out[v] = d\n\n    return out.tolist()\n')\n\npy$nd_python(c(123456, 234, -72))\n## [1] 6 3 2\nb6 <- bench::mark(\n  Python = py$nd_python(nums),\n  Rust = nd_Rust(nums),\n  Julia = JuliaCall::julia_eval(\"ndigits.(nums)\"),\n  `C++` = nd_Rcpp(nums),\n  C = nd_C(nums),\n  R = nd_R(nums),\n  Fortran = nd_F(nums),\n  min_iterations = 10\n)\n\ndplyr::arrange(b6[, 1:8], median)\n## # A tibble: 7 × 6\n##   expression      min   median `itr/sec` mem_alloc `gc/sec`\n##   <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n## 1 Rust         2.87ms   3.08ms    322.      3.81MB   13.0  \n## 2 C++          3.02ms   3.13ms    321.      3.81MB    6.21 \n## 3 Fortran      3.27ms   3.44ms    285.     15.26MB   32.7  \n## 4 Julia        3.33ms   3.53ms    280.      3.81MB    7.49 \n## 5 C            3.74ms   3.94ms    255.      7.63MB   10.6  \n## 6 R           157.9ms 158.51ms      6.31   15.26MB    0.701\n## 7 Python     269.08ms 271.27ms      3.64    3.81MB    0\nplot(b6)\nIn fairness, there’s overhead here involved with calling it from R, but I think\nthat’s apples-to-apples considering I’m doing the same with all the compiled\nlanguages.\nDoes it scale?\nI’ve been running these benchmarks for a million numbers, but how do the results\nscale with that size? What if it’s just a handful of numbers? What about in\nbetween these extremes? Running the benchmarks at various scales should show this.\nn_vals <- 10^(1:7)\nscales <- purrr::map_df(n_vals, ~{\n  set.seed(1)\n  nums <- round(runif(.x, -1, 1) * .x)\n  nums <- nums[nums != 0]\n  JuliaCall::julia_assign(\"nums\", as.integer(nums))\n  b <- bench::mark(\n    Python = py$nd_python(nums),\n    Rust = nd_Rust(nums),\n    Julia = JuliaCall::julia_eval(\"ndigits.(nums)\"),\n    `C++` = nd_Rcpp(nums),\n    C = nd_C(nums),\n    R = nd_R(nums),\n    Fortran = nd_F(nums),\n    min_iterations = 10,\n    check = TRUE\n  )\n  dplyr::bind_cols(vec_len = .x, b[, 1:8])\n})\n\nlibrary(ggplot2)\nggplot(scales,\n       aes(x = vec_len,\n           y = 1e6*as.numeric(median),\n           col = as.character(expression)\n       )) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 2) +\n  scale_x_log10() +\n  scale_y_log10() +\n  scale_color_discrete(palette = \"Set2\") +\n  labs(\n    title = \"Scaling of Counting ndigits Benchmarks\",\n    x = \"Vector Length\",\n    y = \"Microseconds\",\n    color = \"Language\"\n  ) +\n  theme_bw()\nWhat a nice, log-log linear result with that one exception - Julia is pretty\nconstant up until 1000, after which it starts to follow the same trajectory as\nthe other languages - presumably that’s just the overhead of starting up the\nJulia runtime, which is a known bottleneck.\nThere’s definitely a clear divide between the interpreted languages (R and Python)\nand the compiled ones.\nAt lower vector lengths there’s a little bit of a spread with Fortran really showing\noff at the lowest lengths\ndplyr::arrange(scales[scales$vec_len == 10, ], median)\n## # A tibble: 7 × 7\n##   vec_len expression      min   median `itr/sec` mem_alloc `gc/sec`\n##     <dbl> <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n## 1      10 Fortran     122.9ns 205.12ns  4081331.        0B     0   \n## 2      10 C++         287.1ns 369.04ns  2585126.        0B     0   \n## 3      10 C             410ns 491.97ns  1914470.        0B     0   \n## 4      10 Rust        532.9ns  697.1ns  1367702.        0B     0   \n## 5      10 R             943ns   1.11µs   878760.        0B     0   \n## 6      10 Python       20.7µs  22.92µs    43281.        0B     4.33\n## 7      10 Julia        69.8µs  71.59µs    13636.        0B     2.03\nbut we’re looking at sub microsecond differences - what\nwill\nyou do with all\nthat free time?\nBy the time we’re looking at 1000 values, the compiled languages are all about\nthe same\ndplyr::arrange(scales[scales$vec_len == 1000, ], median)\n## # A tibble: 7 × 7\n##   vec_len expression      min   median `itr/sec` mem_alloc `gc/sec`\n##     <dbl> <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n## 1    1000 C++          1.68µs   1.84µs   487745.    3.95KB     0   \n## 2    1000 Rust         2.13µs   2.46µs   397120.    3.95KB     0   \n## 3    1000 Fortran      1.97µs   2.79µs   347513.   15.72KB    34.8 \n## 4    1000 C            2.79µs   3.08µs   299955.    7.86KB    30.0 \n## 5    1000 Julia       73.06µs  77.49µs    12381.    3.95KB     0   \n## 6    1000 R           77.53µs  81.22µs    12306.   15.72KB     0   \n## 7    1000 Python      213.9µs 232.35µs     4282.    3.95KB     2.06\nAt ten million values it’s a complete wash the compiled languages with maybe a\nslight drop for C\ndplyr::arrange(scales[scales$vec_len == 1e7, ], median)\n## # A tibble: 7 × 7\n##    vec_len expression      min   median `itr/sec` mem_alloc `gc/sec`\n##      <dbl> <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n## 1 10000000 Rust        33.78ms  34.58ms    28.9      38.1MB   2.07  \n## 2 10000000 C++         35.05ms  35.38ms    28.3      38.1MB   2.02  \n## 3 10000000 Julia       37.63ms  38.56ms    18.1      38.1MB   2.01  \n## 4 10000000 Fortran     39.29ms   41.9ms    23.8     152.6MB  17.0   \n## 5 10000000 C           43.99ms  44.19ms    22.5      76.3MB   2.05  \n## 6 10000000 R              1.8s    1.81s     0.550   152.6MB   0.236 \n## 7 10000000 Python        3.06s     3.1s     0.322    38.1MB   0.0357\nAll very interesting!\nIt would probably be worthwhile digging into the memory usage of all of these\nsince there’s a big difference that likely indicates something different is\nhappening, but that’s beyond my understanding - feel free to let me know!\nSo, what might be the reason for Rust and Julia to be so fast, even compared to\nC? These are newer languages with a lot of focus on their compilers, and it’s\nentirely possible that they’re able to make some better optimisations compared\nto a very general C compiler, but more likely that’s the upper limit of what a\ncomputer can do in that much time and my C code is non-optimal.\nConclusions\nBack to the original point, though - the transpilation does an amazing job\nof improving the code\nwithout having to write more code in a different\nlanguage\n. Sure, Julia solves this ‘two language problem’ by just being\nridiculously fast to begin with, but if I\nam\nwriting R code, it’s fantastic to\nsee there’s an option for just “making it go brrr” without actually doing\nanything extra.\nNot all of R has been translated to Fortran so there’s a lot of code that won’t\ntranspile just yet, but it’s a truly inspiring project that I’ll surely be\nkeeping a close eye on.\nI’d love to hear what people think about these comparisons - are there points I’ve\noverlooked? Better ways to do it? Improvements to my implementations which change\nthe results? Other considerations I’ve missed? As always, I can be found on\nMastodon\nand the comment section below.\ndevtools::session_info()\n## ─ Session info ───────────────────────────────────────────────────────────────\n##  setting  value\n##  version  R version 4.4.1 (2024-06-14)\n##  os       macOS 15.5\n##  system   aarch64, darwin20\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       Australia/Adelaide\n##  date     2025-06-29\n##  pandoc   3.4 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n## \n## ─ Packages ───────────────────────────────────────────────────────────────────\n##  package      * version    date (UTC) lib source\n##  beeswarm       0.4.0      2021-06-01 [1] CRAN (R 4.4.1)\n##  bench          1.1.4      2025-01-16 [1] CRAN (R 4.4.1)\n##  blogdown       1.21.1     2025-06-28 [1] Github (rstudio/blogdown@33313a5)\n##  bookdown       0.41       2024-10-16 [1] CRAN (R 4.4.1)\n##  brio           1.1.5      2024-04-24 [1] CRAN (R 4.4.0)\n##  bslib          0.8.0      2024-07-29 [1] CRAN (R 4.4.0)\n##  cachem         1.1.0      2024-05-16 [1] CRAN (R 4.4.0)\n##  callme         0.1.10     2024-07-27 [1] CRAN (R 4.4.0)\n##  cli            3.6.4      2025-02-13 [1] CRAN (R 4.4.1)\n##  codetools      0.2-20     2024-03-31 [1] CRAN (R 4.4.1)\n##  devtools       2.4.5      2022-10-11 [1] CRAN (R 4.4.0)\n##  dichromat      2.0-0.1    2022-05-02 [1] CRAN (R 4.4.1)\n##  digest         0.6.37     2024-08-19 [1] CRAN (R 4.4.1)\n##  dotty          0.1.0      2024-08-30 [1] CRAN (R 4.4.1)\n##  dplyr          1.1.4      2023-11-17 [1] CRAN (R 4.4.0)\n##  ellipsis       0.3.2      2021-04-29 [1] CRAN (R 4.4.0)\n##  evaluate       1.0.3      2025-01-10 [1] CRAN (R 4.4.1)\n##  farver         2.1.2      2024-05-13 [1] CRAN (R 4.4.0)\n##  fastmap        1.2.0      2024-05-15 [1] CRAN (R 4.4.0)\n##  fs             1.6.5      2024-10-30 [1] CRAN (R 4.4.1)\n##  generics       0.1.3      2022-07-05 [1] CRAN (R 4.4.0)\n##  ggbeeswarm     0.7.2      2023-04-29 [1] CRAN (R 4.4.0)\n##  ggplot2      * 3.5.2.9001 2025-06-15 [1] Github (tidyverse/ggplot2@9f80c8c)\n##  glue           1.8.0      2024-09-30 [1] CRAN (R 4.4.1)\n##  gtable         0.3.6      2024-10-25 [1] CRAN (R 4.4.1)\n##  here           1.0.1      2020-12-13 [1] CRAN (R 4.4.0)\n##  htmltools      0.5.8.1    2024-04-04 [1] CRAN (R 4.4.0)\n##  htmlwidgets    1.6.4      2023-12-06 [1] CRAN (R 4.4.0)\n##  httpuv         1.6.15     2024-03-26 [1] CRAN (R 4.4.0)\n##  jquerylib      0.1.4      2021-04-26 [1] CRAN (R 4.4.0)\n##  jsonlite       2.0.0      2025-03-27 [1] CRAN (R 4.4.1)\n##  JuliaCall      0.17.6     2024-12-07 [1] CRAN (R 4.4.1)\n##  knitr          1.50       2025-03-16 [1] CRAN (R 4.4.1)\n##  later          1.4.1      2024-11-27 [1] CRAN (R 4.4.1)\n##  lattice        0.22-6     2024-03-20 [1] CRAN (R 4.4.1)\n##  lifecycle      1.0.4      2023-11-07 [1] CRAN (R 4.4.0)\n##  magrittr       2.0.3      2022-03-30 [1] CRAN (R 4.4.0)\n##  Matrix         1.7-1      2024-10-18 [1] CRAN (R 4.4.1)\n##  memoise        2.0.1      2021-11-26 [1] CRAN (R 4.4.0)\n##  mime           0.12       2021-09-28 [1] CRAN (R 4.4.0)\n##  miniUI         0.1.1.1    2018-05-18 [1] CRAN (R 4.4.0)\n##  pillar         1.10.1     2025-01-07 [1] CRAN (R 4.4.1)\n##  pkgbuild       1.4.7      2025-03-24 [1] CRAN (R 4.4.1)\n##  pkgconfig      2.0.3      2019-09-22 [1] CRAN (R 4.4.0)\n##  pkgload        1.4.0      2024-06-28 [1] CRAN (R 4.4.0)\n##  png            0.1-8      2022-11-29 [1] CRAN (R 4.4.0)\n##  processx       3.8.6      2025-02-21 [1] CRAN (R 4.4.1)\n##  profmem        0.7.0      2025-05-02 [1] CRAN (R 4.4.1)\n##  profvis        0.4.0      2024-09-20 [1] CRAN (R 4.4.1)\n##  promises       1.3.2      2024-11-28 [1] CRAN (R 4.4.1)\n##  ps             1.9.0      2025-02-18 [1] CRAN (R 4.4.1)\n##  purrr          1.0.4      2025-02-05 [1] CRAN (R 4.4.1)\n##  quickr         0.1.0.9000 2025-06-29 [1] Github (t-kalinowski/quickr@254b4d0)\n##  R6             2.6.1      2025-02-15 [1] CRAN (R 4.4.1)\n##  RColorBrewer   1.1-3      2022-04-03 [1] CRAN (R 4.4.0)\n##  Rcpp           1.0.14     2025-01-12 [1] CRAN (R 4.4.1)\n##  remotes        2.5.0      2024-03-17 [1] CRAN (R 4.4.1)\n##  reticulate   * 1.42.0     2025-03-25 [1] CRAN (R 4.4.1)\n##  rextendr       0.3.1      2023-06-20 [1] CRAN (R 4.4.0)\n##  rlang          1.1.5      2025-01-17 [1] CRAN (R 4.4.1)\n##  rmarkdown      2.28       2024-08-17 [1] CRAN (R 4.4.0)\n##  rprojroot      2.0.4      2023-11-05 [1] CRAN (R 4.4.0)\n##  rstudioapi     0.17.1     2024-10-22 [1] CRAN (R 4.4.1)\n##  S7             0.2.0      2024-11-07 [1] CRAN (R 4.4.1)\n##  sass           0.4.9      2024-03-15 [1] CRAN (R 4.4.0)\n##  scales         1.4.0      2025-04-24 [1] CRAN (R 4.4.1)\n##  sessioninfo    1.2.2      2021-12-06 [1] CRAN (R 4.4.0)\n##  shiny          1.9.1      2024-08-01 [1] CRAN (R 4.4.0)\n##  stringi        1.8.4      2024-05-06 [1] CRAN (R 4.4.0)\n##  tibble         3.2.1      2023-03-20 [1] CRAN (R 4.4.0)\n##  tidyr          1.3.1      2024-01-24 [1] CRAN (R 4.4.0)\n##  tidyselect     1.2.1      2024-03-11 [1] CRAN (R 4.4.0)\n##  urlchecker     1.0.1      2021-11-30 [1] CRAN (R 4.4.0)\n##  usethis        3.1.0.9000 2025-03-31 [1] Github (r-lib/usethis@a653d6e)\n##  utf8           1.2.4      2023-10-22 [1] CRAN (R 4.4.0)\n##  vctrs          0.6.5      2023-12-01 [1] CRAN (R 4.4.0)\n##  vipor          0.4.7      2023-12-18 [1] CRAN (R 4.4.1)\n##  withr          3.0.2      2024-10-28 [1] CRAN (R 4.4.1)\n##  xfun           0.51       2025-02-19 [1] CRAN (R 4.4.1)\n##  xtable         1.8-4      2019-04-21 [1] CRAN (R 4.4.0)\n##  yaml           2.3.10     2024-07-26 [1] CRAN (R 4.4.0)\n## \n##  [1] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n## \n## ─ Python configuration ───────────────────────────────────────────────────────\n##  python:         /Users/jono/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/2tc-cviHm3ODucI_hIfUb/bin/python3\n##  libpython:      /Users/jono/Library/Caches/org.R-project.R/R/reticulate/uv/python/cpython-3.11.12-macos-aarch64-none/lib/libpython3.11.dylib\n##  pythonhome:     /Users/jono/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/2tc-cviHm3ODucI_hIfUb:/Users/jono/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/2tc-cviHm3ODucI_hIfUb\n##  virtualenv:     /Users/jono/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/2tc-cviHm3ODucI_hIfUb/bin/activate_this.py\n##  version:        3.11.12 (main, Apr  9 2025, 03:49:53) [Clang 20.1.0 ]\n##  numpy:          /Users/jono/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/2tc-cviHm3ODucI_hIfUb/lib/python3.11/site-packages/numpy\n##  numpy_version:  2.3.1\n##  \n##  NOTE: Python version was forced by py_require()\n## \n## ──────────────────────────────────────────────────────────────────────────────\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nrstats on Irregularly Scheduled Programming\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "When things run slower than we’d like in R we tend to reach for another, usually compiled, language, and move our code there. What if it “just happened”? What started out as a silly exploration of how to count digits ended up with a race to see which l...",
      "meta_keywords": null,
      "og_description": "When things run slower than we’d like in R we tend to reach for another, usually compiled, language, and move our code there. What if it “just happened”? What started out as a silly exploration of how to count digits ended up with a race to see which l...",
      "og_image": "https://jcarroll.com.au/2025/06/29/counting-digits-quickly/unnamed-chunk-12-1.png",
      "og_title": "Counting Digits Quickly | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 28,
      "sitemap_lastmod": null,
      "twitter_description": "When things run slower than we’d like in R we tend to reach for another, usually compiled, language, and move our code there. What if it “just happened”? What started out as a silly exploration of how to count digits ended up with a race to see which l...",
      "twitter_title": "Counting Digits Quickly | R-bloggers",
      "url": "https://www.r-bloggers.com/2025/06/counting-digits-quickly/",
      "word_count": 5607
    }
  }
}