{
  "id": "dd20f9ca4dff542bbd2e7ec1e6ac168661979657",
  "url": "https://www.r-bloggers.com/2025/02/you-dont-need-airflow-orchestrate-many-data-flows-in-r-with-maestro/",
  "created_at_utc": "2025-11-22T19:59:11Z",
  "data": null,
  "raw_original": {
    "uuid": "d05beae1-3c3d-427c-8b59-a40dc7adce39",
    "created_at": "2025-11-22 19:59:11",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2025/02/you-dont-need-airflow-orchestrate-many-data-flows-in-r-with-maestro/",
      "crawled_at": "2025-11-22T10:53:42.547461",
      "external_links": [
        {
          "href": "https://whipson.github.io/data-in-flight/posts/you-dont-need-airflow/main.html",
          "text": "data-in-flight"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://whipson.github.io/maestro/",
          "text": "maestro"
        },
        {
          "href": "https://documenter.getpostman.com/view/664302/S1ENwy59",
          "text": "eBird API"
        },
        {
          "href": "https://whipson.github.io/maestro/index.html",
          "text": "maestro docs"
        },
        {
          "href": "https://motherduck.com/duckdb-book-brief/?utm_campaign=manning4&utm_medium=paid&utm_source=google&utm_content=sponsored_ad&utm_term=duckdb&utm_campaign=DuckDB+In+Action+%7C+Landing+Page+Test+%7C+US+%26+Canada&utm_source=adwords&utm_medium=ppc&hsa_acc=6957541599&hsa_cam=21716136677&hsa_grp=169023858473&hsa_ad=713954371320&hsa_src=g&hsa_tgt=kwd-1637281685009&hsa_kw=duckdb&hsa_mt=b&hsa_net=adwords&hsa_ver=3&gad_source=1&gclid=CjwKCAiA5eC9BhAuEiwA3CKwQtsR_YIV8w9EBIUbZZ_djYTL8VL-IBkFtuXNYHIaidYECqq_EbI7HRoCprMQAvD_BwE",
          "text": "duckdb"
        },
        {
          "href": "https://whipson.github.io/maestro/articles/maestro-1-quick-start.html#anatomy-of-a-pipeline",
          "text": "here"
        },
        {
          "href": "https://whipson.github.io/data-in-flight/posts/maestro-gcp-deployment/maestro-gcp-deployment.html",
          "text": "previous post"
        },
        {
          "href": "https://whipson.github.io/data-in-flight/posts/you-dont-need-airflow/main.html",
          "text": "data-in-flight"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "You Don‚Äôt Need Airflow: Orchestrate Many Data Flows in R with Maestro | R-bloggers",
      "images": [
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/whipson.github.io/data-in-flight/posts/you-dont-need-airflow/main_files/figure-html/unnamed-chunk-8-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/whipson.github.io/data-in-flight/posts/you-dont-need-airflow/images/maestro-pipeline-monitor.png?w=578&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/will-hipson/",
          "text": "Will Hipson"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-390837 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">You Don‚Äôt Need Airflow: Orchestrate Many Data Flows in R with Maestro</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">February 25, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/will-hipson/\">Will Hipson</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://whipson.github.io/data-in-flight/posts/you-dont-need-airflow/main.html\"> data-in-flight</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<p>Data never stays in one place for long. Any business or team that works with data needs to be thinking about how data moves from one place to the next. This often happens multiple times, continuously, and in multiple different streams. The concept of moving data is data flow<sup>1</sup>. When you have many data flows that need to be managed it‚Äôs called data orchestration. More specifically, data orchestration is the process of automating the ingestion, transformation, and analysis of data from multiple different locations and then making it widely accessible to users.</p>\n<p>If you look at data orchestration tools today you are bombarded with a dizzying array of software platforms that claim unsurpassed processing capability, AI-readiness, elegant UIs, etc. Apache Airflow is just one example of a popular orchestration platform that scales to meet virtually any orchestration need. And while these claims may be true, I argue it is rarely the case that these gargantuan platforms are needed in the first place. For most data engineers, you probably only need to process a moderate amount of data at a moderate time scale. Moreover, if you‚Äôre an R user, you don‚Äôt want to have to define your data pipelines using drag-and-drop tools or learn another programming language. Not only will this reduce cloud costs but also development time costs.</p>\n<p>This was the inspiration for <a href=\"https://whipson.github.io/maestro/\" rel=\"nofollow\" target=\"_blank\">maestro</a> ‚Äì an R package for orchestrating data jobs within a single project. Here I‚Äôll demonstrate a maestro project and how the cost of deploying it likely compares to other data orchestration platforms currently available.</p>\n<p>In this example, I‚Äôll use open data from Cornell Lab‚Äôs <a href=\"https://documenter.getpostman.com/view/664302/S1ENwy59\" rel=\"nofollow\" target=\"_blank\">eBird API</a> providing free access to global bird observations and statistics. Note that a user account and API key are required to access the API.</p>\n<section class=\"level2\" id=\"maestro\">\n<h2 class=\"anchored\" data-anchor-id=\"maestro\">Maestro</h2>\n<div class=\"callout callout-style-default callout-note callout-titled\">\n<div class=\"callout-header d-flex align-content-center\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nNote\n</div>\n</div>\n<div class=\"callout-body-container callout-body\">\n<p>Check out the <a href=\"https://whipson.github.io/maestro/index.html\" rel=\"nofollow\" target=\"_blank\">maestro docs</a> for a more detailed introduction to maestro.</p>\n</div>\n</div>\n<p>A maestro project consists of one or more pipelines (i.e., R functions with roxygen tags) and a single orchestrator script responsible for invoking the pipelines according to a schedule.</p>\n<p>The project structure will look something like this:</p>\n<pre>sample_project\n‚îú‚îÄ‚îÄ orchestrator.R\n‚îî‚îÄ‚îÄ pipelines\n    ‚îú‚îÄ‚îÄ get_nearby_notable_obs.R\n    ‚îú‚îÄ‚îÄ get_region_stats.R\n    ‚îî‚îÄ‚îÄ get_species_list.R</pre>\n<section class=\"level3\" id=\"pipelines\">\n<h3 class=\"anchored\" data-anchor-id=\"pipelines\">Pipelines</h3>\n<p>I‚Äôve created three pipelines that each retrieve data from one of the eBird endpoints and stores it in a <a href=\"https://motherduck.com/duckdb-book-brief/?utm_campaign=manning4&amp;utm_medium=paid&amp;utm_source=google&amp;utm_content=sponsored_ad&amp;utm_term=duckdb&amp;utm_campaign=DuckDB+In+Action+%7C+Landing+Page+Test+%7C+US+%26+Canada&amp;utm_source=adwords&amp;utm_medium=ppc&amp;hsa_acc=6957541599&amp;hsa_cam=21716136677&amp;hsa_grp=169023858473&amp;hsa_ad=713954371320&amp;hsa_src=g&amp;hsa_tgt=kwd-1637281685009&amp;hsa_kw=duckdb&amp;hsa_mt=b&amp;hsa_net=adwords&amp;hsa_ver=3&amp;gad_source=1&amp;gclid=CjwKCAiA5eC9BhAuEiwA3CKwQtsR_YIV8w9EBIUbZZ_djYTL8VL-IBkFtuXNYHIaidYECqq_EbI7HRoCprMQAvD_BwE\" rel=\"nofollow\" target=\"_blank\">duckdb</a> table. Each pipeline is scheduled to run at a particular time interval so that new data is regularly inserted into the table.</p>\n<div class=\"callout callout-style-default callout-tip callout-titled\">\n<div class=\"callout-header d-flex align-content-center\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nTip\n</div>\n</div>\n<div class=\"callout-body-container callout-body\">\n<p>The <code>#' @maestroFrequency</code> is one of several tags that can be used to configure the scheduling of the pipeline. See <a href=\"https://whipson.github.io/maestro/articles/maestro-1-quick-start.html#anatomy-of-a-pipeline\" rel=\"nofollow\" target=\"_blank\">here</a> for more details.</p>\n</div>\n</div>\n<div class=\"tabset-margin-container\"></div><div class=\"panel-tabset\">\n<ul class=\"nav nav-tabs\"><li class=\"nav-item\"><a aria-controls=\"tabset-1-1\" aria-selected=\"true\" class=\"nav-link active\" data-bs-=\"\" data-bs-toggle=\"tab\" id=\"tabset-1-1-tab\">get_nearby_notable_obs.R</a></li><li class=\"nav-item\"><a aria-controls=\"tabset-1-2\" aria-selected=\"false\" class=\"nav-link\" data-bs-=\"\" data-bs-toggle=\"tab\" id=\"tabset-1-2-tab\">get_region_stats.R</a></li><li class=\"nav-item\"><a aria-controls=\"tabset-1-3\" aria-selected=\"false\" class=\"nav-link\" data-bs-=\"\" data-bs-toggle=\"tab\" id=\"tabset-1-3-tab\">get_species_list.R</a></li></ul>\n<div class=\"tab-content\">\n<div aria-labelledby=\"tabset-1-1-tab\" class=\"tab-pane active\" id=\"tabset-1-1\">\n<div class=\"cell\">\n<pre>#' @maestroFrequency 3 hours\n#' @maestroStartTime 2025-02-20 12:00:00\n#' @maestroTz America/Halifax\nget_nearby_notable_obs &lt;- function() {\n\n  req &lt;- httr2::request(\"https://api.ebird.org/v2\") |&gt;\n    httr2::req_url_path_append(\"data/obs/geo/recent/notable\") |&gt;\n    httr2::req_url_query(\n      lat = 44.88,\n      lng = -63.52\n    ) |&gt;\n    httr2::req_headers(\n      `X-eBirdApiToken` = Sys.getenv(\"EBIRD_API_KEY\")\n    )\n\n  resp &lt;- req |&gt;\n    httr2::req_perform()\n\n  obs &lt;- resp |&gt;\n    httr2::resp_body_json(simplifyVector = TRUE) |&gt;\n    dplyr::mutate(\n      insert_time = Sys.time()\n    )\n\n  # Connect to a local in-memory duckdb\n  conn &lt;- DBI::dbConnect(duckdb::duckdb())\n  on.exit(DBI::dbDisconnect(conn))\n\n  # Create and write to a table\n  DBI::dbWriteTable(\n    conn,\n    name = \"recent_notable_observations\",\n    value = obs,\n    append = TRUE\n  )\n}</pre>\n</div>\n</div>\n<div aria-labelledby=\"tabset-1-2-tab\" class=\"tab-pane\" id=\"tabset-1-2\">\n<div class=\"cell\">\n<pre>#' @maestroFrequency 1 day\n#' @maestroStartTime 2025-02-20 18:00:00\n#' @maestroTz America/Halifax\nget_region_stats &lt;- function() {\n\n  now &lt;- Sys.time()\n  cur_year &lt;- lubridate::year(now)\n  cur_month &lt;- lubridate::month(now)\n  cur_day &lt;- lubridate::day(now)\n\n  req &lt;- httr2::request(\"https://api.ebird.org/v2\") |&gt;\n    httr2::req_url_path_append(\"product/stats\", \"CA-NS\", cur_year, cur_month, cur_day) |&gt;\n    httr2::req_headers(\n      `X-eBirdApiToken` = Sys.getenv(\"EBIRD_API_KEY\")\n    )\n\n  resp &lt;- req |&gt;\n    httr2::req_perform()\n\n  stats &lt;- resp |&gt;\n    httr2::resp_body_json(simplifyVector = TRUE) |&gt;\n    dplyr::as_tibble()\n\n  # Connect to a local in-memory duckdb\n  conn &lt;- DBI::dbConnect(duckdb::duckdb())\n  on.exit(DBI::dbDisconnect(conn))\n\n  # Create and write to a table\n  DBI::dbWriteTable(\n    conn,\n    name = \"region_stats\",\n    value = stats,\n    append = TRUE\n  )\n}</pre>\n</div>\n</div>\n<div aria-labelledby=\"tabset-1-3-tab\" class=\"tab-pane\" id=\"tabset-1-3\">\n<div class=\"cell\">\n<pre>#' @maestroFrequency 1 day\n#' @maestroStartTime 2025-02-20 15:00:00\n#' @maestroTz America/Halifax\nget_species_list &lt;- function() {\n\n  req &lt;- httr2::request(\"https://api.ebird.org/v2\") |&gt;\n    httr2::req_url_path_append(\"product/spplist\", \"CA-NS\") |&gt;\n    httr2::req_headers(\n      `X-eBirdApiToken` = Sys.getenv(\"EBIRD_API_KEY\")\n    )\n\n  resp &lt;- req |&gt;\n    httr2::req_perform()\n\n  spec_list &lt;- resp |&gt;\n    httr2::resp_body_json(simplifyVector = TRUE)\n\n  spec_df &lt;- dplyr::tibble(\n    speciesCode = spec_list\n  ) |&gt;\n    dplyr::mutate(\n      insert_time = Sys.time()\n    )\n\n  # Connect to a local in-memory duckdb\n  conn &lt;- DBI::dbConnect(duckdb::duckdb())\n  on.exit(DBI::dbDisconnect(conn))\n\n  # Create and write to a table\n  DBI::dbWriteTable(\n    conn,\n    name = \"species_list\",\n    value = spec_df,\n    append = TRUE\n  )\n}</pre>\n</div>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level3\" id=\"orchestrator\">\n<h3 class=\"anchored\" data-anchor-id=\"orchestrator\">Orchestrator</h3>\n<p>With the pipelines created we move to the orchestrator script. This is an R script or Quarto document that runs maestro functions to create the schedule from the tags and the run the schedule according to some frequency - a frequency that should always be at least as frequent as your most frequent pipeline.</p>\n<div class=\"cell\">\n<pre>library(maestro)\n\nschedule &lt;- build_schedule()</pre>\n<div class=\"cell-output cell-output-stderr\">\n<pre>‚Ñπ 3 scripts successfully parsed</pre>\n</div>\n<pre>run_schedule(\n  schedule, \n  orch_frequency = \"1 hour\",\n  check_datetime = as.POSIXct(\"2025-02-26 15:00:00\", tz = \"America/Halifax\") # for reproducibility - in practice use Sys.time()\n)</pre>\n<div class=\"cell-output cell-output-stderr\">\n<pre>\n‚îÄ‚îÄ [2025-02-26 15:14:23]\nRunning pipelines ‚ñ∂ \n‚Ñπ get_nearby_notable_obs\n‚úî get_nearby_notable_obs [758ms]\n\n‚Ñπ get_species_list\n‚úî get_species_list [108ms]\n\n\n‚îÄ‚îÄ [2025-02-26 15:14:24]\nPipeline execution completed ‚ñ† | 0.885 sec elapsed \n‚úî 2 successes | ‚Üí 1 skipped | ! 0 warnings | ‚úñ 0 errors | ‚óº 3 total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n‚îÄ‚îÄ Next scheduled pipelines ‚ùØ \nPipe name | Next scheduled run\n‚Ä¢ get_nearby_notable_obs | 2025-02-26 22:00:00\n‚Ä¢ get_region_stats | 2025-02-26 22:00:00\n‚Ä¢ get_species_list | 2025-02-27 19:00:00\n\n‚îÄ‚îÄ Maestro Schedule with 3 pipelines:  \n‚Ä¢ Success</pre>\n</div>\n</div>\n<div class=\"cell\">\n<pre>status &lt;- get_status(schedule)\nstatus</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre># A tibble: 3 √ó 10\n  pipe_name  script_path invoked success pipeline_started    pipeline_ended     \n  &lt;chr&gt;      &lt;chr&gt;       &lt;lgl&gt;   &lt;lgl&gt;   &lt;dttm&gt;              &lt;dttm&gt;             \n1 get_nearb‚Ä¶ ./pipeline‚Ä¶ TRUE    TRUE    2025-02-26 19:14:23 2025-02-26 19:14:24\n2 get_regio‚Ä¶ ./pipeline‚Ä¶ FALSE   FALSE   NA                  NA                 \n3 get_speci‚Ä¶ ./pipeline‚Ä¶ TRUE    TRUE    2025-02-26 19:14:24 2025-02-26 19:14:24\n# ‚Ñπ 4 more variables: errors &lt;int&gt;, warnings &lt;int&gt;, messages &lt;int&gt;,\n#   next_run &lt;dttm&gt;</pre>\n</div>\n</div>\n<p>We can run all this interactively, but the power of maestro is in running it scheduled in production. This way, the data will grow and update regularly. Deployment is not special in the case of maestro - you just need to be sure that the orchestrator is scheduled to run at the same frequency as specified in <code>orch_frequency</code>. Check out my <a href=\"https://whipson.github.io/data-in-flight/posts/maestro-gcp-deployment/maestro-gcp-deployment.html\" rel=\"nofollow\" target=\"_blank\">previous post</a> for a walk through of deployment on Google Cloud.</p>\n</section>\n</section>\n<section class=\"level2\" id=\"monitoring\">\n<h2 class=\"anchored\" data-anchor-id=\"monitoring\">Monitoring</h2>\n<p>In production it is essential to monitor the status of data flows so that issues can be identified and resolved. There are a few extra steps to set this up for maestro:</p>\n<ol type=\"1\">\n<li>Store results of <code>get_status()</code> in a separate table.</li>\n<li>Create and host a visualization/dashboard with the pipeline statuses.</li>\n</ol>\n<p>Step 1 will involve adding a few lines of code in the orchestrator script. In our example using duckdb, it looks like this:</p>\n<div class=\"cell\">\n<pre>status &lt;- get_status(schedule)\n\nconn &lt;- DBI::dbConnect(duckdb::duckdb())\n\nDBI::dbWriteTable(\n  conn,\n  name = \"maestro_status\",\n  value = status,\n  append = TRUE\n)\n\nDBI::dbDisconnect(conn)</pre>\n</div>\n<p>Here, I‚Äôll simulate multiple runs of the orchestrator to make it seem like it had been running for a few days. In practice, you would just read the table containing the pipeline statuses.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>set.seed(233)\nn_runs &lt;- 3 * 24\nlast_run &lt;- as.POSIXct(\"2025-02-26 15:00:00\", tz = \"America/Halifax\")\nrun_seq &lt;- last_run - lubridate::hours(0:n_runs)\n\n# This leverages the lower-level MaestroPipeline class. This is almost never needed in practice\nstatus_extended_ls &lt;- purrr::map(schedule$PipelineList$MaestroPipelines, \\(x) {\n  purrr::map(run_seq, \\(y) {\n    pipe_name &lt;- x$get_pipe_name()\n    run_pipe &lt;- x$check_timeliness(orch_n = 1, orch_unit = \"hour\", check_datetime = y)\n    if (run_pipe) {\n      dplyr::tibble(\n        pipe_name = pipe_name,\n        invoked = TRUE,\n        success = sample(c(TRUE, FALSE), 1, prob = c(0.8, 0.2)),\n        pipeline_started = y,\n        pipeline_ended = pipeline_started + lubridate::seconds(sample(seq(0.4, 5, by = 0.05), 1)),\n      )\n    } else {\n      dplyr::tibble(\n        pipe_name = pipe_name,\n        invoked = FALSE,\n        success = FALSE,\n        pipeline_started = NA,\n        pipeline_ended = NA\n      )\n    }\n  }) |&gt; \n    purrr::list_rbind()\n})\n\nstatus_extended_df &lt;- purrr::list_rbind(status_extended_ls)</pre>\n</details>\n</div>\n<p>There are many ways to visualize the status of pipelines. If the number of pipelines is small and your time window is similarly small you can get away with a static <em>ggplot.</em> The code below uses the simulated status data.frame to generate a simple Gantt chart where green indicates success and red failure.</p>\n<div class=\"cell\">\n<details class=\"code-fold\">\n<summary>Show the code</summary>\n<pre>library(ggplot2)\n\nstatus_extended_df |&gt; \n  ggplot(aes(x = pipeline_started, y = 0)) +\n  geom_segment(aes(xend = pipeline_ended, yend = 1, color = success)) +\n  scale_color_manual(values = c(\"firebrick2\", \"seagreen3\")) +\n  facet_wrap(~pipe_name, ncol = 1) +\n  labs(\n    y = NULL,\n    x = NULL,\n    title = \"Pipeline Status\"\n  ) +\n  guides(color = \"none\") +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_blank()\n  )</pre>\n</details>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i2.wp.com/whipson.github.io/data-in-flight/posts/you-dont-need-airflow/main_files/figure-html/unnamed-chunk-8-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/whipson.github.io/data-in-flight/posts/you-dont-need-airflow/main_files/figure-html/unnamed-chunk-8-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<p>As the number of pipelines grows and/or you want more flexibility around time frame, you may want to build a dashboard with interactive figures. The below image is a screenshot of the dashboard I built using shiny at Halifax Stanfield International Airport that monitors the ~20 production pipelines in our environment.</p>\n<div class=\"quarto-figure quarto-figure-center\">\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i0.wp.com/whipson.github.io/data-in-flight/posts/you-dont-need-airflow/images/maestro-pipeline-monitor.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/whipson.github.io/data-in-flight/posts/you-dont-need-airflow/images/maestro-pipeline-monitor.png?w=578&amp;ssl=1\"/></noscript></p>\n<figcaption>Pipeline monitoring dashboard used in production at Halifax Stanfield International Airport</figcaption>\n</figure>\n</div>\n<p>It‚Äôs not hard to imagine a future extension package that creates these sorts of monitoring dashboards automatically.</p>\n<p>Now that we‚Äôve seen how maestro works, let‚Äôs look at why we might want to use maestro over something like Airflow.</p>\n</section>\n<section class=\"level2\" id=\"maestro-reduces-cost\">\n<h2 class=\"anchored\" data-anchor-id=\"maestro-reduces-cost\">Maestro Reduces Cost</h2>\n<p>If you‚Äôre an R developer, the answer to the question <em>Why use Maestro</em> is obvious: <em>because I don‚Äôt need to use another language</em>. However, there are other reasons for preferring maestro over enterprise orchestration software like Airflow or Mage, chief among these being cost.<sup>2</sup></p>\n<p>There are two primary reasons why maestro saves on cloud bills:</p>\n<ol type=\"1\">\n<li><strong>Maestro is serverless</strong> - it can scale down to zero when the orchestrator is not running. In other words, if the orchestrator frequency isn‚Äôt too high (~15 minutes or more) you don‚Äôt need to run it on a continuously available server. Something like AWS Lambda, Google Cloud Run, or Azure Functions would work just fine.</li>\n<li><strong>Maestro bundles multiple flows into a single instance</strong>. Assuming the number of flows and their frequencies doesn‚Äôt exceed limits you can run a moderate enterprise entirely within a single instance. No need to spin up and schedule separate instances for each data flow.<sup>3</sup></li>\n</ol>\n<p>Let‚Äôs compare a few scenarios for cost estimates. In all cases, we‚Äôll imagine we have 10 production data flows that run at various intervals ranging from every hour to every day. The scenarios are:</p>\n<ol type=\"1\">\n<li>Maestro running serverless every 1 hour</li>\n<li>Separate scripts running serverless on separate instances</li>\n<li>Running an Airflow project open-source in the cloud</li>\n<li>Orchestration platform provided by the cloud provider</li>\n</ol>\n<div class=\"callout callout-style-default callout-note callout-titled\">\n<div class=\"callout-header d-flex align-content-center\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nNote\n</div>\n</div>\n<div class=\"callout-body-container callout-body\">\n<p>These are back-of-the-napkin estimates based on conversations with ChatGPT and cloud computing documentation. Do not use these estimates as the sole basis for determining which tech stack will be more affordable. If I have made egregious errors in my estimates, please reach out to me via LinkedIn.</p>\n</div>\n</div>\n<p>I asked ChatGPT to provide estimates not specific to any one cloud provider (see appendix ChatGPT Conversation for conversation). The monthly costs in CAD are listed below:</p>\n<ol type=\"1\">\n<li>Maestro-style serverless: <strong>$25-35</strong> ($35-45 if using multi-core)</li>\n<li>Separate scheduled serverless scripts: <strong>$110-130</strong></li>\n<li>Airflow: <strong>$170‚Äì200</strong></li>\n<li>Cloud managed: <strong>$80‚Äì100</strong></li>\n</ol>\n<p>This suggests a substantial cost savings for using a maestro-style architecture. Please note that these are estimates and are not substantiated by any experimentation. It‚Äôs worth considering that the costs appear to take into account storage but probably don‚Äôt account for image hosting, CI/CD, out-of-the-box monitoring, etc. that would likely come with fully featured orchestration platforms.</p>\n</section>\n<section class=\"level2\" id=\"maestro-eases-configuration-and-bolsters-metadata\">\n<h2 class=\"anchored\" data-anchor-id=\"maestro-eases-configuration-and-bolsters-metadata\">Maestro Eases Configuration and Bolsters Metadata</h2>\n<p>One of the challenges of orchestrating multiple data flows is keeping track of scheduling. Maestro eases this burden by requiring the scheduling configuration to be exactly where the pipeline is. This is not a new concept (Dagster uses decorators for scheduling) but it is rare to find in other platforms.<sup>4</sup> This also follows the practice of infrastructure-as-code which makes projects more portable and reproducible.</p>\n<p>I‚Äôm also discovering a new advantage to declaring pipeline configuration with the pipeline code itself, and that is it makes it more AI-interpretable. In my own environment at the airport, I‚Äôm looking for ways to reduce and even eliminate manual effort to document tables and processes. In our informal explorations, we‚Äôve found that giving an LLM sample data and pipeline code is enough to populate almost all the critical metadata around table descriptions, column descriptions, and update frequency even for domain-specific processes. I‚Äôm hopeful that this will greatly cutback on the amount of manual documentation and metadata entry that no one wants to do anyway.</p>\n</section>\n<section class=\"level2\" id=\"conclusions\">\n<h2 class=\"anchored\" data-anchor-id=\"conclusions\">Conclusions</h2>\n<p>Here we saw how a single, cost-efficient maestro project can meet data orchestration needs for a moderate enterprise. Too often, I see people arguing on LinkedIn that if you‚Äôre a data engineer you need to use Airflow, or Spark, or [insert next trendy orchestration platform here]. The people who say this are usually trying to inflate their ego, sell you something, or they work for companies processing terabytes of data a minute and thus genuinely need a beastly platform. Most organizations don‚Äôt need that kind of power. In the end, it‚Äôs important to right-size the hardware and compute resources for the actual compute needs of your project. At the very least, if you‚Äôre an R user facing the conundrum of how to orchestrate your scripts, maestro is a great way to start familiar, start small, but with the potential to scale up to meet most of your needs.</p>\n<p>This post was created using R version 4.4.2 (2024-10-31) and maestro version 0.5.1.</p>\n</section>\n<section class=\"level2\" id=\"appendices\">\n<h2 class=\"anchored\" data-anchor-id=\"appendices\">Appendices</h2>\n<section class=\"level3\" id=\"chatgpt-conversation\">\n<h3 class=\"anchored\" data-anchor-id=\"chatgpt-conversation\">ChatGPT Conversation</h3>\n<p>The conversation below was with ChatGPT 4-o on February 26th 2025.</p>\n<p>Me: I want to do some cost estimates for cloud computing. I have three proposed tech stacks, all of which I could run on any cloud provider. I don‚Äôt want to compare cloud providers but instead compare the estimated cost of each architecture. In all cases, the project would involve taking 10 data flows that process around 500MB-2GB of data at varying time intervals with the most frequent being every hour and the least being every day. These data flows could be Python or R scripts or something else depending on the tech stack.</p>\n<p>Here are the three proposed tech stacks:</p>\n<ol type=\"1\">\n<li>All 10 data flows run on a single instance and an orchestrator script runs every hour to determine which script to run. Importantly, all of this runs on a single serverless instance.</li>\n<li>Each 10 data flow has its own serverless instance and a scheduling service from the cloud provider is used to configure each script to run at its required time interval.</li>\n<li>An open-source Apache Airflow project is hosted on a compute instance.</li>\n<li>An orchestration platform provided by the cloud provider is used out of the box.</li>\n</ol>\n<p>For each scenario, provide some estimate as to the hardware requirements (e.g., instance size, compute nodes, etc.) and give a rough estimate of monthly cost in CAD.</p>\n<blockquote class=\"blockquote\">\n<p>I‚Äôll break down the estimated cloud costs for each of the four approaches based on typical cloud pricing. Since we‚Äôre not comparing cloud providers directly, I‚Äôll use common pricing models across AWS, GCP, and Azure. Prices will be in <strong>CAD</strong>.</p>\n<hr/>\n<h3 class=\"anchored\" id=\"approach-1-single-serverless-instance-for-all-data-flows\"><strong>Approach 1: Single Serverless Instance for All Data Flows</strong></h3>\n<ul>\n<li><p><strong>Hardware Requirements:</strong></p>\n<ul>\n<li><p>One serverless instance that scales based on workload.</p></li>\n<li><p>Needs at least <strong>2 vCPUs and 4GB RAM</strong>, but scales up if a heavy script runs.</p></li>\n<li><p>~2GB of storage for script dependencies.</p></li>\n<li><p>Assumes processing 500MB-2GB per run.</p></li>\n</ul></li>\n<li><p><strong>Cost Breakdown:</strong></p>\n<ul>\n<li><p><strong>Compute:</strong> <del>$0.000016 per second per vCPU (</del>$0.06 per vCPU-hour)</p></li>\n<li><p><strong>Memory:</strong> <del>$0.0000025 per second per GB (</del>$0.009 per GB-hour)</p></li>\n<li><p>Assuming each flow runs for an <strong>average of 5 minutes</strong> and scales up to <strong>4 vCPUs and 8GB RAM</strong> occasionally:</p>\n<ul>\n<li><p>10 flows √ó 24 runs/day √ó 30 days = <strong>7,200 runs/month</strong></p></li>\n<li><p>Avg runtime: 5 min per run = <strong>36,000 minutes per month</strong> = <strong>600 hours</strong></p></li>\n<li><p>At <strong>$0.06 per vCPU-hour</strong>, 2 vCPUs cost <strong>$72/month</strong>.</p></li>\n<li><p>At <strong>$0.009 per GB-hour</strong>, 4GB RAM costs <strong>$21.6/month</strong>.</p></li>\n</ul></li>\n<li><p><strong>Storage &amp; Data Transfer:</strong> Minimal, say <strong>$5/month</strong>.</p></li>\n</ul>\n<p><strong>Estimated Cost: $100‚Äì120 CAD/month</strong></p></li>\n</ul>\n<hr/>\n<h3 class=\"anchored\" id=\"approach-2-separate-serverless-instance-for-each-data-flow\"><strong>Approach 2: Separate Serverless Instance for Each Data Flow</strong></h3>\n<ul>\n<li><p><strong>Hardware Requirements:</strong></p>\n<ul>\n<li><p>Each of the <strong>10 data flows</strong> has its own <strong>serverless function</strong>.</p></li>\n<li><p>Similar compute and memory needs as Approach 1 but scaled per function.</p></li>\n<li><p>A <strong>cloud scheduling service</strong> (e.g., AWS EventBridge, Azure Logic Apps, or GCP Cloud Scheduler) triggers them.</p></li>\n</ul></li>\n<li><p><strong>Cost Breakdown:</strong></p>\n<ul>\n<li><p>Compute per function: Assume <strong>same 5 minutes per run</strong>.</p></li>\n<li><p>10 functions √ó 24 runs/day √ó 30 days = <strong>7,200 total executions</strong>.</p></li>\n<li><p>If each function scales to <strong>2 vCPUs and 4GB RAM</strong> per run:</p>\n<ul>\n<li><p>At <strong>$0.06 per vCPU-hour</strong>, cost per function = <strong>$7.2/month</strong> √ó 10 = <strong>$72/month</strong>.</p></li>\n<li><p>At <strong>$0.009 per GB-hour</strong>, cost per function = <strong>$2.16/month</strong> √ó 10 = <strong>$21.6/month</strong>.</p></li>\n</ul></li>\n<li><p><strong>Scheduling service:</strong> ~$5/month.</p></li>\n<li><p><strong>Storage &amp; Data Transfer:</strong> ~$10/month.</p></li>\n</ul>\n<p><strong>Estimated Cost: $110‚Äì130 CAD/month</strong></p></li>\n</ul>\n<hr/>\n<h3 class=\"anchored\" id=\"approach-3-apache-airflow-on-a-compute-instance\"><strong>Approach 3: Apache Airflow on a Compute Instance</strong></h3>\n<ul>\n<li><p><strong>Hardware Requirements:</strong></p>\n<ul>\n<li><p>1 compute instance for <strong>Airflow scheduler and web server</strong>: <strong>2 vCPUs, 4GB RAM</strong>.</p></li>\n<li><p>1 compute instance for <strong>Airflow worker</strong>: <strong>4 vCPUs, 8GB RAM</strong>.</p></li>\n<li><p>10 tasks run dynamically on the worker.</p></li>\n</ul></li>\n<li><p><strong>Cost Breakdown:</strong></p>\n<ul>\n<li><p><strong>Compute:</strong></p>\n<ul>\n<li><p>Scheduler instance: <strong>$50‚Äì60/month</strong>.</p></li>\n<li><p>Worker instance: <strong>$80‚Äì100/month</strong>.</p></li>\n</ul></li>\n<li><p><strong>Storage &amp; Networking:</strong> ~$10/month.</p></li>\n<li><p><strong>Managed Database (PostgreSQL for metadata):</strong> ~$30/month.</p></li>\n</ul>\n<p><strong>Estimated Cost: $170‚Äì200 CAD/month</strong></p></li>\n</ul>\n<hr/>\n<h3 class=\"anchored\" id=\"approach-4-cloud-providers-managed-orchestration-service\"><strong>Approach 4: Cloud Provider‚Äôs Managed Orchestration Service</strong></h3>\n<ul>\n<li><p><strong>Hardware Requirements:</strong></p>\n<ul>\n<li><p>Fully managed service.</p></li>\n<li><p>Underlying compute managed by the provider (often charged per task execution).</p></li>\n<li><p>Assumes a <strong>pay-per-task execution model</strong>.</p></li>\n</ul></li>\n<li><p><strong>Cost Breakdown:</strong></p>\n<ul>\n<li><p><strong>Task Execution Pricing:</strong> ~<strong>$0.0025‚Äì$0.005 per task execution</strong>.</p></li>\n<li><p>7,200 runs √ó <strong>$0.003</strong> = <strong>$22/month</strong>.</p></li>\n<li><p><strong>Compute Costs:</strong> (~$50/month for light usage, scales if workflows are complex).</p></li>\n<li><p><strong>Storage &amp; API Calls:</strong> ~$5‚Äì10/month.</p></li>\n</ul>\n<p><strong>Estimated Cost: $80‚Äì100 CAD/month</strong></p></li>\n</ul>\n<hr/>\n<h3 class=\"anchored\" id=\"summary-of-estimated-monthly-costs-cad\"><strong>Summary of Estimated Monthly Costs (CAD)</strong></h3>\n<table class=\"caption-top table\">\n<colgroup>\n<col style=\"width: 33%\"/>\n<col style=\"width: 33%\"/>\n<col style=\"width: 33%\"/>\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th>Approach</th>\n<th>Estimated Monthly Cost (CAD)</th>\n<th>Key Considerations</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td><strong>1. Single Serverless Instance</strong></td>\n<td><strong>$100‚Äì120</strong></td>\n<td>Simple but limited scalability.</td>\n</tr>\n<tr class=\"even\">\n<td><strong>2. Separate Serverless Instances</strong></td>\n<td><strong>$110‚Äì130</strong></td>\n<td>More parallelism but increased function calls.</td>\n</tr>\n<tr class=\"odd\">\n<td><strong>3. Apache Airflow on Compute</strong></td>\n<td><strong>$170‚Äì200</strong></td>\n<td>More control, but higher infra cost.</td>\n</tr>\n<tr class=\"even\">\n<td><strong>4. Cloud Managed Orchestration</strong></td>\n<td><strong>$80‚Äì100</strong></td>\n<td>Scalable and cost-efficient.</td>\n</tr>\n</tbody>\n</table>\n<hr/>\n<h3 class=\"anchored\" id=\"recommendation\"><strong>Recommendation</strong></h3>\n<ul>\n<li><p><strong>If cost is the main factor</strong> ‚Üí <strong>Approach 4</strong> (Managed Orchestration) is best.</p></li>\n<li><p><strong>If you prefer full control</strong> ‚Üí <strong>Approach 3</strong> (Airflow).</p></li>\n<li><p><strong>If you need balance between control and scalability</strong> ‚Üí <strong>Approach 2</strong> (Separate Serverless Instances).</p></li>\n</ul>\n</blockquote>\n<p>Me: In the first scenario are you properly accounting for the fact that the job would only run once every hour? Even if there are multiple processes being executed, it is still one job scheduled to run hourly.</p>\n<blockquote class=\"blockquote\">\n<p>You‚Äôre absolutely right! In <strong>Scenario 1 (Single Serverless Instance Running an Orchestrator Script Hourly)</strong>, the <strong>orchestrator script only runs once per hour</strong>, making the cost lower than I initially estimated. Let‚Äôs correct that calculation.</p>\n<hr/>\n<h3 class=\"anchored\" id=\"scenario-1-revised-cost-calculation\"><strong>Scenario 1: Revised Cost Calculation</strong></h3>\n<ul>\n<li><p><strong>Execution Frequency:</strong></p>\n<ul>\n<li><p>The orchestrator runs <strong>once every hour</strong> ‚Üí <strong>24 runs per day</strong>.</p></li>\n<li><p>Each run executes <strong>one or more data flows sequentially</strong>.</p></li>\n<li><p>Assume an <strong>average runtime of 10 minutes per execution</strong> (to process multiple flows).</p></li>\n</ul></li>\n<li><p><strong>Compute Usage:</strong></p>\n<ul>\n<li><p>Suppose the instance scales between <strong>2‚Äì4 vCPUs and 4‚Äì8GB RAM</strong>, depending on the workload.</p></li>\n<li><p>At peak, assume <strong>2 vCPUs and 4GB RAM</strong> for the <strong>entire execution</strong>.</p></li>\n<li><p>Cost estimation:</p>\n<ul>\n<li><p><strong>24 runs/day √ó 30 days = 720 runs/month</strong>.</p></li>\n<li><p><strong>10 minutes per run</strong> = <strong>7,200 minutes per month</strong> = <strong>120 compute hours/month</strong>.</p></li>\n<li><p>Compute cost: <strong>$0.06 per vCPU-hour</strong> √ó <strong>2 vCPUs</strong> √ó <strong>120 hours</strong> = <strong>$14.40/month</strong>.</p></li>\n<li><p>Memory cost: <strong>$0.009 per GB-hour</strong> √ó <strong>4GB</strong> √ó <strong>120 hours</strong> = <strong>$4.32/month</strong>.</p></li>\n</ul></li>\n</ul></li>\n<li><p><strong>Storage &amp; Data Transfer:</strong></p>\n<ul>\n<li><p>Storage: <strong>~$5/month</strong>.</p></li>\n<li><p>Data transfer: <strong>~$5/month</strong>.</p></li>\n</ul></li>\n</ul>\n<p><strong>Total Estimated Cost: $25‚Äì35 CAD/month</strong></p>\n<hr/>\n<h3 class=\"anchored\" id=\"updated-cost-comparison-cad\"><strong>Updated Cost Comparison (CAD)</strong></h3>\n<table class=\"caption-top table\">\n<colgroup>\n<col style=\"width: 33%\"/>\n<col style=\"width: 33%\"/>\n<col style=\"width: 33%\"/>\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th>Approach</th>\n<th>Updated Monthly Cost (CAD)</th>\n<th>Key Considerations</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td><strong>1. Single Serverless Instance</strong></td>\n<td><strong>$25‚Äì35</strong> ‚úÖ</td>\n<td>Most cost-effective but limited parallelism.</td>\n</tr>\n<tr class=\"even\">\n<td><strong>2. Separate Serverless Instances</strong></td>\n<td><strong>$110‚Äì130</strong></td>\n<td>More parallelism but higher function call costs.</td>\n</tr>\n<tr class=\"odd\">\n<td><strong>3. Apache Airflow on Compute</strong></td>\n<td><strong>$170‚Äì200</strong></td>\n<td>Full control but highest infra cost.</td>\n</tr>\n<tr class=\"even\">\n<td><strong>4. Cloud Managed Orchestration</strong></td>\n<td><strong>$80‚Äì100</strong></td>\n<td>Scalable and cost-efficient.</td>\n</tr>\n</tbody>\n</table>\n<hr/>\n<h3 class=\"anchored\" id=\"final-thoughts\"><strong>Final Thoughts</strong></h3>\n<ul>\n<li><p><strong>Scenario 1 is now clearly the cheapest option (~$25‚Äì35 CAD/month).</strong></p></li>\n<li><p>However, it <strong>lacks parallelism</strong>‚Äîif multiple heavy processes need to run, the single instance might <strong>take longer to complete</strong>.</p></li>\n<li><p>If <strong>cost is the priority</strong>, Scenario 1 is the best choice.</p></li>\n<li><p>If <strong>scalability and efficiency</strong> matter, Scenario 4 (Managed Orchestration) is a good balance.</p></li>\n</ul>\n<p>Would you like a <strong>cost efficiency vs.¬†performance trade-off chart</strong> to visualize these differences? üöÄ</p>\n</blockquote>\n<p>Me: Finally, let‚Äôs say for Scenario 1 that we enable parallel processing if needed. For example, if 4 processes need to run simultaneously it can scale up to 4 cores.</p>\n<blockquote class=\"blockquote\">\n<p>Great! If we allow <strong>Scenario 1</strong> to <strong>scale dynamically to support parallel processing</strong>, we need to adjust the compute cost based on variable CPU utilization. Here‚Äôs how that impacts the estimation.</p>\n<hr/>\n<h3 class=\"anchored\" id=\"scenario-1-revised-cost-with-parallel-processing\"><strong>Scenario 1: Revised Cost with Parallel Processing</strong></h3>\n<h4 class=\"anchored\" id=\"assumptions\"><strong>Assumptions:</strong></h4>\n<ul>\n<li><p><strong>Orchestrator runs every hour</strong> (<strong>24 times per day</strong>).</p></li>\n<li><p>Each execution lasts <strong>10 minutes</strong> but now <strong>can use up to 4 vCPUs when needed</strong>.</p></li>\n<li><p><strong>Average vCPU usage per run</strong>:</p>\n<ul>\n<li><p>Some runs may use <strong>1‚Äì2 vCPUs</strong> (light workloads).</p></li>\n<li><p>Others may spike to <strong>4 vCPUs</strong> (heavy parallel processing).</p></li>\n<li><p>Assume an <strong>average usage of 3 vCPUs per execution</strong>.</p></li>\n</ul></li>\n<li><p><strong>Memory scales accordingly</strong>: Assume <strong>6GB RAM on average</strong>.</p></li>\n</ul>\n<h4 class=\"anchored\" id=\"compute-cost-calculation\"><strong>Compute Cost Calculation:</strong></h4>\n<ul>\n<li><p><strong>Total monthly runtime</strong>:</p>\n<ul>\n<li><strong>10 min per execution √ó 24 runs/day √ó 30 days = 7,200 minutes (~120 hours/month).</strong></li>\n</ul></li>\n<li><p><strong>CPU Cost:</strong></p>\n<ul>\n<li><p>Avg <strong>3 vCPUs per run</strong>.</p></li>\n<li><p><strong>$0.06 per vCPU-hour</strong> √ó <strong>3 vCPUs</strong> √ó <strong>120 hours</strong> = <strong>$21.60/month</strong>.</p></li>\n</ul></li>\n<li><p><strong>Memory Cost:</strong></p>\n<ul>\n<li><p>Avg <strong>6GB RAM per run</strong>.</p></li>\n<li><p><strong>$0.009 per GB-hour</strong> √ó <strong>6GB</strong> √ó <strong>120 hours</strong> = <strong>$6.48/month</strong>.</p></li>\n</ul></li>\n<li><p><strong>Storage &amp; Data Transfer:</strong></p>\n<ul>\n<li><strong>$5‚Äì10/month</strong> (no significant change).</li>\n</ul></li>\n</ul>\n<p><strong>Final Total Cost: ~$35‚Äì45 CAD/month</strong></p>\n<hr/>\n<h3 class=\"anchored\" id=\"final-cost-comparison-cad\"><strong>Final Cost Comparison (CAD)</strong></h3>\n<table class=\"caption-top table\">\n<colgroup>\n<col style=\"width: 33%\"/>\n<col style=\"width: 33%\"/>\n<col style=\"width: 33%\"/>\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th>Approach</th>\n<th>Monthly Cost (CAD)</th>\n<th>Key Considerations</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td><strong>1. Single Serverless Instance (Parallel Processing)</strong></td>\n<td><strong>$35‚Äì45</strong> ‚úÖ</td>\n<td>Cheapest, allows parallelism but limited by single-instance performance.</td>\n</tr>\n<tr class=\"even\">\n<td><strong>2. Separate Serverless Instances</strong></td>\n<td><strong>$110‚Äì130</strong></td>\n<td>Fully scalable, better for frequent workloads.</td>\n</tr>\n<tr class=\"odd\">\n<td><strong>3. Apache Airflow on Compute</strong></td>\n<td><strong>$170‚Äì200</strong></td>\n<td>Self-managed, full control, higher maintenance.</td>\n</tr>\n<tr class=\"even\">\n<td><strong>4. Cloud Managed Orchestration</strong></td>\n<td><strong>$80‚Äì100</strong></td>\n<td>Best for scalability without management overhead.</td>\n</tr>\n</tbody>\n</table>\n<hr/>\n<h3 class=\"anchored\" id=\"conclusion\"><strong>Conclusion</strong></h3>\n<ul>\n<li><p><strong>Scenario 1 with parallelism remains the cheapest (~$35‚Äì45 CAD/month).</strong></p></li>\n<li><p><strong>It allows parallel execution when needed</strong>, reducing the risk of long-running sequential jobs.</p></li>\n<li><p><strong>It‚Äôs best if workload concurrency is manageable</strong> (e.g., not exceeding 4 vCPUs often).</p></li>\n<li><p>If <strong>greater scalability is required</strong>, <strong>Scenario 4 (Managed Orchestration) would be the next best option</strong>.</p></li>\n</ul>\n<p>Would you like a cost vs.¬†scalability chart to visualize these trade-offs? üöÄ</p>\n</blockquote>\n</section>\n</section>\n<div class=\"default\" id=\"quarto-appendix\"><section class=\"footnotes footnotes-end-of-document\" id=\"footnotes\"><h2 class=\"anchored quarto-appendix-heading\">Footnotes</h2>\n<ol>\n<li id=\"fn1\"><p>Data <em>flows</em> through a pipeline. I‚Äôll use the terms data flow and pipeline interchangeably.‚Ü©Ô∏é</p></li>\n<li id=\"fn2\"><p>By cost I‚Äôm mostly referring to cloud computing costs, although in theory it could reduce the cost of on-premise servers if it means purchasing fewer and less expensive servers.‚Ü©Ô∏é</p></li>\n<li id=\"fn3\"><p>I‚Äôm using the term <em>moderate enterprise</em> loosely to mean any organization that has around 10-50 data flows that process gigabytes of data for ETL, machine learning, etc. in batch jobs occurring at hourly or daily frequencies. This is what we have at the airport and it works perfectly fine with room to grow. As jobs become heavier and/or more frequent, you may need to be run maestro multicore or break up the project into multiple maestro projects.‚Ü©Ô∏é</p></li>\n<li id=\"fn4\"><p>At the airport we use Apache Nifi for legacy reasons and for the occasional time that streaming is needed. Managing the scheduling of each flow is inexplicably convoluted.‚Ü©Ô∏é</p></li>\n</ol>\n</section></div>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://whipson.github.io/data-in-flight/posts/you-dont-need-airflow/main.html\"> data-in-flight</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
      "main_text": "You Don‚Äôt Need Airflow: Orchestrate Many Data Flows in R with Maestro\nPosted on\nFebruary 25, 2025\nby\nWill Hipson\nin\nR bloggers\n| 0 Comments\n[This article was first published on\ndata-in-flight\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nData never stays in one place for long. Any business or team that works with data needs to be thinking about how data moves from one place to the next. This often happens multiple times, continuously, and in multiple different streams. The concept of moving data is data flow\n1\n. When you have many data flows that need to be managed it‚Äôs called data orchestration. More specifically, data orchestration is the process of automating the ingestion, transformation, and analysis of data from multiple different locations and then making it widely accessible to users.\nIf you look at data orchestration tools today you are bombarded with a dizzying array of software platforms that claim unsurpassed processing capability, AI-readiness, elegant UIs, etc. Apache Airflow is just one example of a popular orchestration platform that scales to meet virtually any orchestration need. And while these claims may be true, I argue it is rarely the case that these gargantuan platforms are needed in the first place. For most data engineers, you probably only need to process a moderate amount of data at a moderate time scale. Moreover, if you‚Äôre an R user, you don‚Äôt want to have to define your data pipelines using drag-and-drop tools or learn another programming language. Not only will this reduce cloud costs but also development time costs.\nThis was the inspiration for\nmaestro\n‚Äì an R package for orchestrating data jobs within a single project. Here I‚Äôll demonstrate a maestro project and how the cost of deploying it likely compares to other data orchestration platforms currently available.\nIn this example, I‚Äôll use open data from Cornell Lab‚Äôs\neBird API\nproviding free access to global bird observations and statistics. Note that a user account and API key are required to access the API.\nMaestro\nNote\nCheck out the\nmaestro docs\nfor a more detailed introduction to maestro.\nA maestro project consists of one or more pipelines (i.e., R functions with roxygen tags) and a single orchestrator script responsible for invoking the pipelines according to a schedule.\nThe project structure will look something like this:\nsample_project\n‚îú‚îÄ‚îÄ orchestrator.R\n‚îî‚îÄ‚îÄ pipelines\n    ‚îú‚îÄ‚îÄ get_nearby_notable_obs.R\n    ‚îú‚îÄ‚îÄ get_region_stats.R\n    ‚îî‚îÄ‚îÄ get_species_list.R\nPipelines\nI‚Äôve created three pipelines that each retrieve data from one of the eBird endpoints and stores it in a\nduckdb\ntable. Each pipeline is scheduled to run at a particular time interval so that new data is regularly inserted into the table.\nTip\nThe\n#' @maestroFrequency\nis one of several tags that can be used to configure the scheduling of the pipeline. See\nhere\nfor more details.\nget_nearby_notable_obs.R\nget_region_stats.R\nget_species_list.R\n#' @maestroFrequency 3 hours\n#' @maestroStartTime 2025-02-20 12:00:00\n#' @maestroTz America/Halifax\nget_nearby_notable_obs <- function() {\n\n  req <- httr2::request(\"https://api.ebird.org/v2\") |>\n    httr2::req_url_path_append(\"data/obs/geo/recent/notable\") |>\n    httr2::req_url_query(\n      lat = 44.88,\n      lng = -63.52\n    ) |>\n    httr2::req_headers(\n      `X-eBirdApiToken` = Sys.getenv(\"EBIRD_API_KEY\")\n    )\n\n  resp <- req |>\n    httr2::req_perform()\n\n  obs <- resp |>\n    httr2::resp_body_json(simplifyVector = TRUE) |>\n    dplyr::mutate(\n      insert_time = Sys.time()\n    )\n\n  # Connect to a local in-memory duckdb\n  conn <- DBI::dbConnect(duckdb::duckdb())\n  on.exit(DBI::dbDisconnect(conn))\n\n  # Create and write to a table\n  DBI::dbWriteTable(\n    conn,\n    name = \"recent_notable_observations\",\n    value = obs,\n    append = TRUE\n  )\n}\n#' @maestroFrequency 1 day\n#' @maestroStartTime 2025-02-20 18:00:00\n#' @maestroTz America/Halifax\nget_region_stats <- function() {\n\n  now <- Sys.time()\n  cur_year <- lubridate::year(now)\n  cur_month <- lubridate::month(now)\n  cur_day <- lubridate::day(now)\n\n  req <- httr2::request(\"https://api.ebird.org/v2\") |>\n    httr2::req_url_path_append(\"product/stats\", \"CA-NS\", cur_year, cur_month, cur_day) |>\n    httr2::req_headers(\n      `X-eBirdApiToken` = Sys.getenv(\"EBIRD_API_KEY\")\n    )\n\n  resp <- req |>\n    httr2::req_perform()\n\n  stats <- resp |>\n    httr2::resp_body_json(simplifyVector = TRUE) |>\n    dplyr::as_tibble()\n\n  # Connect to a local in-memory duckdb\n  conn <- DBI::dbConnect(duckdb::duckdb())\n  on.exit(DBI::dbDisconnect(conn))\n\n  # Create and write to a table\n  DBI::dbWriteTable(\n    conn,\n    name = \"region_stats\",\n    value = stats,\n    append = TRUE\n  )\n}\n#' @maestroFrequency 1 day\n#' @maestroStartTime 2025-02-20 15:00:00\n#' @maestroTz America/Halifax\nget_species_list <- function() {\n\n  req <- httr2::request(\"https://api.ebird.org/v2\") |>\n    httr2::req_url_path_append(\"product/spplist\", \"CA-NS\") |>\n    httr2::req_headers(\n      `X-eBirdApiToken` = Sys.getenv(\"EBIRD_API_KEY\")\n    )\n\n  resp <- req |>\n    httr2::req_perform()\n\n  spec_list <- resp |>\n    httr2::resp_body_json(simplifyVector = TRUE)\n\n  spec_df <- dplyr::tibble(\n    speciesCode = spec_list\n  ) |>\n    dplyr::mutate(\n      insert_time = Sys.time()\n    )\n\n  # Connect to a local in-memory duckdb\n  conn <- DBI::dbConnect(duckdb::duckdb())\n  on.exit(DBI::dbDisconnect(conn))\n\n  # Create and write to a table\n  DBI::dbWriteTable(\n    conn,\n    name = \"species_list\",\n    value = spec_df,\n    append = TRUE\n  )\n}\nOrchestrator\nWith the pipelines created we move to the orchestrator script. This is an R script or Quarto document that runs maestro functions to create the schedule from the tags and the run the schedule according to some frequency - a frequency that should always be at least as frequent as your most frequent pipeline.\nlibrary(maestro)\n\nschedule <- build_schedule()\n‚Ñπ 3 scripts successfully parsed\nrun_schedule(\n  schedule, \n  orch_frequency = \"1 hour\",\n  check_datetime = as.POSIXct(\"2025-02-26 15:00:00\", tz = \"America/Halifax\") # for reproducibility - in practice use Sys.time()\n)\n‚îÄ‚îÄ [2025-02-26 15:14:23]\nRunning pipelines ‚ñ∂ \n‚Ñπ get_nearby_notable_obs\n‚úî get_nearby_notable_obs [758ms]\n\n‚Ñπ get_species_list\n‚úî get_species_list [108ms]\n\n‚îÄ‚îÄ [2025-02-26 15:14:24]\nPipeline execution completed ‚ñ† | 0.885 sec elapsed \n‚úî 2 successes | ‚Üí 1 skipped | ! 0 warnings | ‚úñ 0 errors | ‚óº 3 total\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n‚îÄ‚îÄ Next scheduled pipelines ‚ùØ \nPipe name | Next scheduled run\n‚Ä¢ get_nearby_notable_obs | 2025-02-26 22:00:00\n‚Ä¢ get_region_stats | 2025-02-26 22:00:00\n‚Ä¢ get_species_list | 2025-02-27 19:00:00\n\n‚îÄ‚îÄ Maestro Schedule with 3 pipelines:  \n‚Ä¢ Success\nstatus <- get_status(schedule)\nstatus\n# A tibble: 3 √ó 10\n  pipe_name  script_path invoked success pipeline_started    pipeline_ended     \n  <chr>      <chr>       <lgl>   <lgl>   <dttm>              <dttm>             \n1 get_nearb‚Ä¶ ./pipeline‚Ä¶ TRUE    TRUE    2025-02-26 19:14:23 2025-02-26 19:14:24\n2 get_regio‚Ä¶ ./pipeline‚Ä¶ FALSE   FALSE   NA                  NA                 \n3 get_speci‚Ä¶ ./pipeline‚Ä¶ TRUE    TRUE    2025-02-26 19:14:24 2025-02-26 19:14:24\n# ‚Ñπ 4 more variables: errors <int>, warnings <int>, messages <int>,\n#   next_run <dttm>\nWe can run all this interactively, but the power of maestro is in running it scheduled in production. This way, the data will grow and update regularly. Deployment is not special in the case of maestro - you just need to be sure that the orchestrator is scheduled to run at the same frequency as specified in\norch_frequency\n. Check out my\nprevious post\nfor a walk through of deployment on Google Cloud.\nMonitoring\nIn production it is essential to monitor the status of data flows so that issues can be identified and resolved. There are a few extra steps to set this up for maestro:\nStore results of\nget_status()\nin a separate table.\nCreate and host a visualization/dashboard with the pipeline statuses.\nStep 1 will involve adding a few lines of code in the orchestrator script. In our example using duckdb, it looks like this:\nstatus <- get_status(schedule)\n\nconn <- DBI::dbConnect(duckdb::duckdb())\n\nDBI::dbWriteTable(\n  conn,\n  name = \"maestro_status\",\n  value = status,\n  append = TRUE\n)\n\nDBI::dbDisconnect(conn)\nHere, I‚Äôll simulate multiple runs of the orchestrator to make it seem like it had been running for a few days. In practice, you would just read the table containing the pipeline statuses.\nShow the code\nset.seed(233)\nn_runs <- 3 * 24\nlast_run <- as.POSIXct(\"2025-02-26 15:00:00\", tz = \"America/Halifax\")\nrun_seq <- last_run - lubridate::hours(0:n_runs)\n\n# This leverages the lower-level MaestroPipeline class. This is almost never needed in practice\nstatus_extended_ls <- purrr::map(schedule$PipelineList$MaestroPipelines, \\(x) {\n  purrr::map(run_seq, \\(y) {\n    pipe_name <- x$get_pipe_name()\n    run_pipe <- x$check_timeliness(orch_n = 1, orch_unit = \"hour\", check_datetime = y)\n    if (run_pipe) {\n      dplyr::tibble(\n        pipe_name = pipe_name,\n        invoked = TRUE,\n        success = sample(c(TRUE, FALSE), 1, prob = c(0.8, 0.2)),\n        pipeline_started = y,\n        pipeline_ended = pipeline_started + lubridate::seconds(sample(seq(0.4, 5, by = 0.05), 1)),\n      )\n    } else {\n      dplyr::tibble(\n        pipe_name = pipe_name,\n        invoked = FALSE,\n        success = FALSE,\n        pipeline_started = NA,\n        pipeline_ended = NA\n      )\n    }\n  }) |> \n    purrr::list_rbind()\n})\n\nstatus_extended_df <- purrr::list_rbind(status_extended_ls)\nThere are many ways to visualize the status of pipelines. If the number of pipelines is small and your time window is similarly small you can get away with a static\nggplot.\nThe code below uses the simulated status data.frame to generate a simple Gantt chart where green indicates success and red failure.\nShow the code\nlibrary(ggplot2)\n\nstatus_extended_df |> \n  ggplot(aes(x = pipeline_started, y = 0)) +\n  geom_segment(aes(xend = pipeline_ended, yend = 1, color = success)) +\n  scale_color_manual(values = c(\"firebrick2\", \"seagreen3\")) +\n  facet_wrap(~pipe_name, ncol = 1) +\n  labs(\n    y = NULL,\n    x = NULL,\n    title = \"Pipeline Status\"\n  ) +\n  guides(color = \"none\") +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_blank()\n  )\nAs the number of pipelines grows and/or you want more flexibility around time frame, you may want to build a dashboard with interactive figures. The below image is a screenshot of the dashboard I built using shiny at Halifax Stanfield International Airport that monitors the ~20 production pipelines in our environment.\nPipeline monitoring dashboard used in production at Halifax Stanfield International Airport\nIt‚Äôs not hard to imagine a future extension package that creates these sorts of monitoring dashboards automatically.\nNow that we‚Äôve seen how maestro works, let‚Äôs look at why we might want to use maestro over something like Airflow.\nMaestro Reduces Cost\nIf you‚Äôre an R developer, the answer to the question\nWhy use Maestro\nis obvious:\nbecause I don‚Äôt need to use another language\n. However, there are other reasons for preferring maestro over enterprise orchestration software like Airflow or Mage, chief among these being cost.\n2\nThere are two primary reasons why maestro saves on cloud bills:\nMaestro is serverless\n- it can scale down to zero when the orchestrator is not running. In other words, if the orchestrator frequency isn‚Äôt too high (~15 minutes or more) you don‚Äôt need to run it on a continuously available server. Something like AWS Lambda, Google Cloud Run, or Azure Functions would work just fine.\nMaestro bundles multiple flows into a single instance\n. Assuming the number of flows and their frequencies doesn‚Äôt exceed limits you can run a moderate enterprise entirely within a single instance. No need to spin up and schedule separate instances for each data flow.\n3\nLet‚Äôs compare a few scenarios for cost estimates. In all cases, we‚Äôll imagine we have 10 production data flows that run at various intervals ranging from every hour to every day. The scenarios are:\nMaestro running serverless every 1 hour\nSeparate scripts running serverless on separate instances\nRunning an Airflow project open-source in the cloud\nOrchestration platform provided by the cloud provider\nNote\nThese are back-of-the-napkin estimates based on conversations with ChatGPT and cloud computing documentation. Do not use these estimates as the sole basis for determining which tech stack will be more affordable. If I have made egregious errors in my estimates, please reach out to me via LinkedIn.\nI asked ChatGPT to provide estimates not specific to any one cloud provider (see appendix ChatGPT Conversation for conversation). The monthly costs in CAD are listed below:\nMaestro-style serverless:\n$25-35\n($35-45 if using multi-core)\nSeparate scheduled serverless scripts:\n$110-130\nAirflow:\n$170‚Äì200\nCloud managed:\n$80‚Äì100\nThis suggests a substantial cost savings for using a maestro-style architecture. Please note that these are estimates and are not substantiated by any experimentation. It‚Äôs worth considering that the costs appear to take into account storage but probably don‚Äôt account for image hosting, CI/CD, out-of-the-box monitoring, etc. that would likely come with fully featured orchestration platforms.\nMaestro Eases Configuration and Bolsters Metadata\nOne of the challenges of orchestrating multiple data flows is keeping track of scheduling. Maestro eases this burden by requiring the scheduling configuration to be exactly where the pipeline is. This is not a new concept (Dagster uses decorators for scheduling) but it is rare to find in other platforms.\n4\nThis also follows the practice of infrastructure-as-code which makes projects more portable and reproducible.\nI‚Äôm also discovering a new advantage to declaring pipeline configuration with the pipeline code itself, and that is it makes it more AI-interpretable. In my own environment at the airport, I‚Äôm looking for ways to reduce and even eliminate manual effort to document tables and processes. In our informal explorations, we‚Äôve found that giving an LLM sample data and pipeline code is enough to populate almost all the critical metadata around table descriptions, column descriptions, and update frequency even for domain-specific processes. I‚Äôm hopeful that this will greatly cutback on the amount of manual documentation and metadata entry that no one wants to do anyway.\nConclusions\nHere we saw how a single, cost-efficient maestro project can meet data orchestration needs for a moderate enterprise. Too often, I see people arguing on LinkedIn that if you‚Äôre a data engineer you need to use Airflow, or Spark, or [insert next trendy orchestration platform here]. The people who say this are usually trying to inflate their ego, sell you something, or they work for companies processing terabytes of data a minute and thus genuinely need a beastly platform. Most organizations don‚Äôt need that kind of power. In the end, it‚Äôs important to right-size the hardware and compute resources for the actual compute needs of your project. At the very least, if you‚Äôre an R user facing the conundrum of how to orchestrate your scripts, maestro is a great way to start familiar, start small, but with the potential to scale up to meet most of your needs.\nThis post was created using R version 4.4.2 (2024-10-31) and maestro version 0.5.1.\nAppendices\nChatGPT Conversation\nThe conversation below was with ChatGPT 4-o on February 26th 2025.\nMe: I want to do some cost estimates for cloud computing. I have three proposed tech stacks, all of which I could run on any cloud provider. I don‚Äôt want to compare cloud providers but instead compare the estimated cost of each architecture. In all cases, the project would involve taking 10 data flows that process around 500MB-2GB of data at varying time intervals with the most frequent being every hour and the least being every day. These data flows could be Python or R scripts or something else depending on the tech stack.\nHere are the three proposed tech stacks:\nAll 10 data flows run on a single instance and an orchestrator script runs every hour to determine which script to run. Importantly, all of this runs on a single serverless instance.\nEach 10 data flow has its own serverless instance and a scheduling service from the cloud provider is used to configure each script to run at its required time interval.\nAn open-source Apache Airflow project is hosted on a compute instance.\nAn orchestration platform provided by the cloud provider is used out of the box.\nFor each scenario, provide some estimate as to the hardware requirements (e.g., instance size, compute nodes, etc.) and give a rough estimate of monthly cost in CAD.\nI‚Äôll break down the estimated cloud costs for each of the four approaches based on typical cloud pricing. Since we‚Äôre not comparing cloud providers directly, I‚Äôll use common pricing models across AWS, GCP, and Azure. Prices will be in\nCAD\n.\nApproach 1: Single Serverless Instance for All Data Flows\nHardware Requirements:\nOne serverless instance that scales based on workload.\nNeeds at least\n2 vCPUs and 4GB RAM\n, but scales up if a heavy script runs.\n~2GB of storage for script dependencies.\nAssumes processing 500MB-2GB per run.\nCost Breakdown:\nCompute:\n$0.000016 per second per vCPU (\n$0.06 per vCPU-hour)\nMemory:\n$0.0000025 per second per GB (\n$0.009 per GB-hour)\nAssuming each flow runs for an\naverage of 5 minutes\nand scales up to\n4 vCPUs and 8GB RAM\noccasionally:\n10 flows √ó 24 runs/day √ó 30 days =\n7,200 runs/month\nAvg runtime: 5 min per run =\n36,000 minutes per month\n=\n600 hours\nAt\n$0.06 per vCPU-hour\n, 2 vCPUs cost\n$72/month\n.\nAt\n$0.009 per GB-hour\n, 4GB RAM costs\n$21.6/month\n.\nStorage & Data Transfer:\nMinimal, say\n$5/month\n.\nEstimated Cost: $100‚Äì120 CAD/month\nApproach 2: Separate Serverless Instance for Each Data Flow\nHardware Requirements:\nEach of the\n10 data flows\nhas its own\nserverless function\n.\nSimilar compute and memory needs as Approach 1 but scaled per function.\nA\ncloud scheduling service\n(e.g., AWS EventBridge, Azure Logic Apps, or GCP Cloud Scheduler) triggers them.\nCost Breakdown:\nCompute per function: Assume\nsame 5 minutes per run\n.\n10 functions √ó 24 runs/day √ó 30 days =\n7,200 total executions\n.\nIf each function scales to\n2 vCPUs and 4GB RAM\nper run:\nAt\n$0.06 per vCPU-hour\n, cost per function =\n$7.2/month\n√ó 10 =\n$72/month\n.\nAt\n$0.009 per GB-hour\n, cost per function =\n$2.16/month\n√ó 10 =\n$21.6/month\n.\nScheduling service:\n~$5/month.\nStorage & Data Transfer:\n~$10/month.\nEstimated Cost: $110‚Äì130 CAD/month\nApproach 3: Apache Airflow on a Compute Instance\nHardware Requirements:\n1 compute instance for\nAirflow scheduler and web server\n:\n2 vCPUs, 4GB RAM\n.\n1 compute instance for\nAirflow worker\n:\n4 vCPUs, 8GB RAM\n.\n10 tasks run dynamically on the worker.\nCost Breakdown:\nCompute:\nScheduler instance:\n$50‚Äì60/month\n.\nWorker instance:\n$80‚Äì100/month\n.\nStorage & Networking:\n~$10/month.\nManaged Database (PostgreSQL for metadata):\n~$30/month.\nEstimated Cost: $170‚Äì200 CAD/month\nApproach 4: Cloud Provider‚Äôs Managed Orchestration Service\nHardware Requirements:\nFully managed service.\nUnderlying compute managed by the provider (often charged per task execution).\nAssumes a\npay-per-task execution model\n.\nCost Breakdown:\nTask Execution Pricing:\n~\n$0.0025‚Äì$0.005 per task execution\n.\n7,200 runs √ó\n$0.003\n=\n$22/month\n.\nCompute Costs:\n(~$50/month for light usage, scales if workflows are complex).\nStorage & API Calls:\n~$5‚Äì10/month.\nEstimated Cost: $80‚Äì100 CAD/month\nSummary of Estimated Monthly Costs (CAD)\nApproach\nEstimated Monthly Cost (CAD)\nKey Considerations\n1. Single Serverless Instance\n$100‚Äì120\nSimple but limited scalability.\n2. Separate Serverless Instances\n$110‚Äì130\nMore parallelism but increased function calls.\n3. Apache Airflow on Compute\n$170‚Äì200\nMore control, but higher infra cost.\n4. Cloud Managed Orchestration\n$80‚Äì100\nScalable and cost-efficient.\nRecommendation\nIf cost is the main factor\n‚Üí\nApproach 4\n(Managed Orchestration) is best.\nIf you prefer full control\n‚Üí\nApproach 3\n(Airflow).\nIf you need balance between control and scalability\n‚Üí\nApproach 2\n(Separate Serverless Instances).\nMe: In the first scenario are you properly accounting for the fact that the job would only run once every hour? Even if there are multiple processes being executed, it is still one job scheduled to run hourly.\nYou‚Äôre absolutely right! In\nScenario 1 (Single Serverless Instance Running an Orchestrator Script Hourly)\n, the\norchestrator script only runs once per hour\n, making the cost lower than I initially estimated. Let‚Äôs correct that calculation.\nScenario 1: Revised Cost Calculation\nExecution Frequency:\nThe orchestrator runs\nonce every hour\n‚Üí\n24 runs per day\n.\nEach run executes\none or more data flows sequentially\n.\nAssume an\naverage runtime of 10 minutes per execution\n(to process multiple flows).\nCompute Usage:\nSuppose the instance scales between\n2‚Äì4 vCPUs and 4‚Äì8GB RAM\n, depending on the workload.\nAt peak, assume\n2 vCPUs and 4GB RAM\nfor the\nentire execution\n.\nCost estimation:\n24 runs/day √ó 30 days = 720 runs/month\n.\n10 minutes per run\n=\n7,200 minutes per month\n=\n120 compute hours/month\n.\nCompute cost:\n$0.06 per vCPU-hour\n√ó\n2 vCPUs\n√ó\n120 hours\n=\n$14.40/month\n.\nMemory cost:\n$0.009 per GB-hour\n√ó\n4GB\n√ó\n120 hours\n=\n$4.32/month\n.\nStorage & Data Transfer:\nStorage:\n~$5/month\n.\nData transfer:\n~$5/month\n.\nTotal Estimated Cost: $25‚Äì35 CAD/month\nUpdated Cost Comparison (CAD)\nApproach\nUpdated Monthly Cost (CAD)\nKey Considerations\n1. Single Serverless Instance\n$25‚Äì35\n‚úÖ\nMost cost-effective but limited parallelism.\n2. Separate Serverless Instances\n$110‚Äì130\nMore parallelism but higher function call costs.\n3. Apache Airflow on Compute\n$170‚Äì200\nFull control but highest infra cost.\n4. Cloud Managed Orchestration\n$80‚Äì100\nScalable and cost-efficient.\nFinal Thoughts\nScenario 1 is now clearly the cheapest option (~$25‚Äì35 CAD/month).\nHowever, it\nlacks parallelism\n‚Äîif multiple heavy processes need to run, the single instance might\ntake longer to complete\n.\nIf\ncost is the priority\n, Scenario 1 is the best choice.\nIf\nscalability and efficiency\nmatter, Scenario 4 (Managed Orchestration) is a good balance.\nWould you like a\ncost efficiency vs.¬†performance trade-off chart\nto visualize these differences? üöÄ\nMe: Finally, let‚Äôs say for Scenario 1 that we enable parallel processing if needed. For example, if 4 processes need to run simultaneously it can scale up to 4 cores.\nGreat! If we allow\nScenario 1\nto\nscale dynamically to support parallel processing\n, we need to adjust the compute cost based on variable CPU utilization. Here‚Äôs how that impacts the estimation.\nScenario 1: Revised Cost with Parallel Processing\nAssumptions:\nOrchestrator runs every hour\n(\n24 times per day\n).\nEach execution lasts\n10 minutes\nbut now\ncan use up to 4 vCPUs when needed\n.\nAverage vCPU usage per run\n:\nSome runs may use\n1‚Äì2 vCPUs\n(light workloads).\nOthers may spike to\n4 vCPUs\n(heavy parallel processing).\nAssume an\naverage usage of 3 vCPUs per execution\n.\nMemory scales accordingly\n: Assume\n6GB RAM on average\n.\nCompute Cost Calculation:\nTotal monthly runtime\n:\n10 min per execution √ó 24 runs/day √ó 30 days = 7,200 minutes (~120 hours/month).\nCPU Cost:\nAvg\n3 vCPUs per run\n.\n$0.06 per vCPU-hour\n√ó\n3 vCPUs\n√ó\n120 hours\n=\n$21.60/month\n.\nMemory Cost:\nAvg\n6GB RAM per run\n.\n$0.009 per GB-hour\n√ó\n6GB\n√ó\n120 hours\n=\n$6.48/month\n.\nStorage & Data Transfer:\n$5‚Äì10/month\n(no significant change).\nFinal Total Cost: ~$35‚Äì45 CAD/month\nFinal Cost Comparison (CAD)\nApproach\nMonthly Cost (CAD)\nKey Considerations\n1. Single Serverless Instance (Parallel Processing)\n$35‚Äì45\n‚úÖ\nCheapest, allows parallelism but limited by single-instance performance.\n2. Separate Serverless Instances\n$110‚Äì130\nFully scalable, better for frequent workloads.\n3. Apache Airflow on Compute\n$170‚Äì200\nSelf-managed, full control, higher maintenance.\n4. Cloud Managed Orchestration\n$80‚Äì100\nBest for scalability without management overhead.\nConclusion\nScenario 1 with parallelism remains the cheapest (~$35‚Äì45 CAD/month).\nIt allows parallel execution when needed\n, reducing the risk of long-running sequential jobs.\nIt‚Äôs best if workload concurrency is manageable\n(e.g., not exceeding 4 vCPUs often).\nIf\ngreater scalability is required\n,\nScenario 4 (Managed Orchestration) would be the next best option\n.\nWould you like a cost vs.¬†scalability chart to visualize these trade-offs? üöÄ\nFootnotes\nData\nflows\nthrough a pipeline. I‚Äôll use the terms data flow and pipeline interchangeably.‚Ü©Ô∏é\nBy cost I‚Äôm mostly referring to cloud computing costs, although in theory it could reduce the cost of on-premise servers if it means purchasing fewer and less expensive servers.‚Ü©Ô∏é\nI‚Äôm using the term\nmoderate enterprise\nloosely to mean any organization that has around 10-50 data flows that process gigabytes of data for ETL, machine learning, etc. in batch jobs occurring at hourly or daily frequencies. This is what we have at the airport and it works perfectly fine with room to grow. As jobs become heavier and/or more frequent, you may need to be run maestro multicore or break up the project into multiple maestro projects.‚Ü©Ô∏é\nAt the airport we use Apache Nifi for legacy reasons and for the occasional time that streaming is needed. Managing the scheduling of each flow is inexplicably convoluted.‚Ü©Ô∏é\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\ndata-in-flight\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "Data never stays in one place for long. Any business or team that works with data needs to be thinking about how data moves from one place to the next. This often happens multiple times, continuously, and in multiple different streams. The conce...",
      "meta_keywords": null,
      "og_description": "Data never stays in one place for long. Any business or team that works with data needs to be thinking about how data moves from one place to the next. This often happens multiple times, continuously, and in multiple different streams. The conce...",
      "og_image": "https://whipson.github.io/data-in-flight/posts/you-dont-need-airflow/main_files/figure-html/unnamed-chunk-8-1.png",
      "og_title": "You Don‚Äôt Need Airflow: Orchestrate Many Data Flows in R with Maestro | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 20,
      "sitemap_lastmod": null,
      "twitter_description": "Data never stays in one place for long. Any business or team that works with data needs to be thinking about how data moves from one place to the next. This often happens multiple times, continuously, and in multiple different streams. The conce...",
      "twitter_title": "You Don‚Äôt Need Airflow: Orchestrate Many Data Flows in R with Maestro | R-bloggers",
      "url": "https://www.r-bloggers.com/2025/02/you-dont-need-airflow-orchestrate-many-data-flows-in-r-with-maestro/",
      "word_count": 4004
    }
  }
}