{
  "uuid": "d7f81dcb-f466-4cd6-a63a-49859bccd2aa",
  "created_at": "2025-11-22 19:57:33",
  "raw_json": {
    "article_author": null,
    "article_headline": null,
    "article_modified": null,
    "article_published": null,
    "article_section": null,
    "article_tags": null,
    "canonical_url": "https://www.r-bloggers.com/2025/10/iterating-some-sample-data/",
    "crawled_at": "2025-11-22T10:42:17.259164",
    "external_links": [
      {
        "href": "https://kieranhealy.org/blog/archives/2025/10/03/iterating-some-sample-data/",
        "text": "R on kieranhealy.org"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://mptc.io/",
        "text": "Modern Plain Text Computing"
      },
      {
        "href": "https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html",
        "text": "mtcars"
      },
      {
        "href": "https://allisonhorst.github.io/palmerpenguins/",
        "text": "palmerpenguins"
      },
      {
        "href": "https://en.wikipedia.org/wiki/Confusion_matrix",
        "text": "confusion matrix"
      },
      {
        "href": "https://en.wikipedia.org/wiki/Quasi-quotation",
        "text": "quasi-quote"
      },
      {
        "href": "https://rlang.r-lib.org/reference/topic-data-mask.html",
        "text": "does inside the function"
      },
      {
        "href": "https://www.tidyverse.org/blog/2020/02/glue-strings-and-tidy-eval/",
        "text": "walrus operator"
      },
      {
        "href": "https://purrr.tidyverse.org/",
        "text": "map functions"
      },
      {
        "href": "https://purrr.tidyverse.org/reference/pmap.html",
        "text": "pmap"
      },
      {
        "href": "https://r4ds.had.co.nz/factors.html",
        "text": "factors"
      },
      {
        "href": "https://kieranhealy.org/blog/archives/2018/11/19/zero-counts-in-dplyr/",
        "text": "ungroup and complete"
      },
      {
        "href": "https://i2.wp.com/kieranhealy.org/blog/archives/2025/10/03/iterating-some-sample-data/llm-example.png?ssl=1",
        "text": null
      },
      {
        "href": "https://kieranhealy.org/blog/archives/2025/10/03/iterating-some-sample-data/",
        "text": "R on kieranhealy.org"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "h1_title": "R-bloggers",
    "html_title": "Iterating some sample data | R-bloggers",
    "images": [
      {
        "alt": "A stacked bar chart",
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": "A stacked bar chart",
        "base64": null,
        "src": "https://i2.wp.com/kieranhealy.org/blog/archives/2025/10/03/iterating-some-sample-data/llm-example.png?w=578&ssl=1"
      }
    ],
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/r-on-kieranhealy-org/",
        "text": "R on kieranhealy.org"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "lang": "en-US",
    "main_html": "<article class=\"post-395859 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Iterating some sample data</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">October 3, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/r-on-kieranhealy-org/\">R on kieranhealy.org</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://kieranhealy.org/blog/archives/2025/10/03/iterating-some-sample-data/\"> R on kieranhealy.org</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47--><p>I’m teaching my <a href=\"https://mptc.io/\" rel=\"nofollow\" target=\"_blank\">Modern Plain Text Computing</a> course this semester and so I’m on the lookout for small examples that I can use to show some of the small techniques we regularly use when working with tables of data. One of those is just coming up with some sample data to illustrate something else, like how to draw a plot or fit a model or what have you. This is partly what the stock datasets that come bundled with packages are for, like the venerable <a href=\"https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html\" rel=\"nofollow\" target=\"_blank\">mtcars</a> or the more recent <a href=\"https://allisonhorst.github.io/palmerpenguins/\" rel=\"nofollow\" target=\"_blank\">palmerpenguins</a>. Sometimes, though, you end up quickly making up an example yourself. This can be a good way to practice stuff that computers are good at, like doing things repeatedly.</p>\n<p>This happened the other day in response to a question about visualizing some evaluation data. The task goes like this. You are testing a bunch of different LLMs. Say, fifteen of them. You have  trained them to return Yes/No answers when they look at repeated samples of some test data. Let’s say each LLM is asked a hundred questions. You have also had an expert person look at the same hundred questions and give you their Yes/No answers. The person’s answers are the ground truth. You want to know how the LLM performs against them. So for each LLM you have a two-by-two table showing counts or rates of true positives, true negatives, false positives, and false negatives. This is called a “<a href=\"https://en.wikipedia.org/wiki/Confusion_matrix\" rel=\"nofollow\" target=\"_blank\">confusion matrix</a>”. You want to visualize LLM performance for all the LLMs. An additional wrinkle is that, from the point of view of your business, responses are variably costly. Correct answers (true positives or true negatives) cost one unit. Then, say, a False Negative costs two units and a False Positive is worst, costing four units.</p>\n<p>The questioner just wanted some thoughts on what sort of graph to draw. You can of course just picture what the data would look like and figure out which of your many stock datasets has an analogous structure. Or you’d just sketch out an answer. In this case, even though they have problems in general, a kind of stacked bar chart (but flipped on its side) might work OK. But half the fun (for some values of “fun”) is generating data that looks like this. And as I said, I’m on the lookout for iteration examples, somewhere I can repeatedly do something and gather the results into a nice table.</p>\n<p>When we want to repeatedly do something, we first solve the base case and then we generalize it by putting in some sort of placeholder and use an engine that can iterate over an index of values, feeding each one to the placeholder. In imperative languages you might use a counter and a for loop. In a functional approach you repeatedly map or apply some function.</p>\n<p>We’ve got a hundred questions and fifteen llms. We imagine that the LLMs can range in accuracy from 40 percent to 99 percent in one percent steps.</p>\n<div class=\"highlight-wrapper\">\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre>1\n2\n3\n4\n5\n</pre></td>\n<td class=\"lntd\">\n<pre>set.seed(100125) # so we get the same 'random' results each time\n\nn_runs &lt;- 100\nn_llms &lt;- 15\naccuracy_range &lt;- seq(0.4, 0.99, 0.01)</pre></td></tr></table>\n</div>\n</div>\n</div>\n<p>Our baseline is <code>n_runs</code> human answers with some given distribution of Yes/No answers. Let’s say 80% No, 20% Yes. It doesn’t matter what they are; the person is the ground truth. We sample with replacement a hundred times from “N” or “Y” at that probability.</p>\n<div class=\"highlight-wrapper\">\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre>1\n2\n3\n4\n5\n6\n7\n</pre></td>\n<td class=\"lntd\">\n<pre>human_evals &lt;- sample(c(\"N\", \"Y\"), n_runs, replace = TRUE, prob = c(0.8, 0.20))\n\nhuman_evals\n#&gt;   [1] \"N\" \"N\" \"N\" \"Y\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"N\"\n#&gt;  [34] \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"N\" \"Y\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"N\"\n#&gt;  [67] \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"Y\" \"N\" \"N\" \"Y\" \"Y\" \"N\" \"Y\" \"Y\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\"\n#&gt; [100] \"N\"</pre></td></tr></table>\n</div>\n</div>\n</div>\n<p>For each of our fifteen LLM what we want to do is generate a string of its one hundred Y/N answers in the same way, but with its particular idiosyncratic distribution of Ys and Ns, and then evaluate it against the human baseline. And we’d like to gather all the answers into a single data frame so we can keep everything tidy.</p>\n<p>Our evaluation function looks like this:</p>\n<div class=\"highlight-wrapper\">\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre>1\n2\n3\n4\n5\n6\n7\n8\n</pre></td>\n<td class=\"lntd\">\n<pre>eval_llm &lt;- function(llm_evals, human_eval) {\n  case_when(\n    llm_evals == \"Y\" &amp; human_eval == \"Y\" ~ \"True Positive\",\n    llm_evals == \"Y\" &amp; human_eval == \"N\" ~ \"False Positive\",\n    llm_evals == \"N\" &amp; human_eval == \"Y\" ~ \"False Negative\",\n    llm_evals == \"N\" &amp; human_eval == \"N\" ~ \"True Negative\",\n  )\n}</pre></td></tr></table>\n</div>\n</div>\n</div>\n<p>We generate a string of responses for an imaginary LLM just like we did for the imaginary person. The single case would look like this:</p>\n<div class=\"highlight-wrapper\">\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre>1\n</pre></td>\n<td class=\"lntd\">\n<pre>llm_01 &lt;- sample(c(\"N\", \"Y\"), n_runs, replace = TRUE, prob = c(0.7, 0.3))</pre></td></tr></table>\n</div>\n</div>\n</div>\n<p>But we want to do this fifteen times, with varying values for <code>prob</code> and also we want to put each LLM in its own column in a data frame. So we replace the values with variables. First we generate a vector of LLM names. We use <code>str_pad</code> to get sortable numbers with a leading zero.</p>\n<div class=\"highlight-wrapper\">\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre>1\n2\n3\n4\n</pre></td>\n<td class=\"lntd\">\n<pre>llm_id &lt;- paste(\"LLM\", str_pad(1:n_llms, width = 2, pad = \"0\"), sep = \"_\")\n\nllm_id\n#&gt;  [1] \"LLM_01\" \"LLM_02\" \"LLM_03\" \"LLM_04\" \"LLM_05\" \"LLM_06\" \"LLM_07\" \"LLM_08\" \"LLM_09\" \"LLM_10\" \"LLM_11\" \"LLM_12\" \"LLM_13\" \"LLM_14\" \"LLM_15\"</pre></td></tr></table>\n</div>\n</div>\n</div>\n<p>Now we’re going to create a little table of LLM parameters. We already created a vector of probabilities for the LLMs, <code>accuracy_range</code>. We’ll sample from that to get fifteen values. The number of runs is fixed at a hundred. R’s naturally vectorized way of working will take care of the table getting filled in properly.</p>\n<div class=\"highlight-wrapper\">\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n</pre></td>\n<td class=\"lntd\">\n<pre>llm_df &lt;- tibble(\n  llm_id = llm_id,\n  p_yes = sample(accuracy_range, n_llms),\n  p_no = 1 - p_yes,\n  n = n_runs\n)\n\n\nllm_df\n#&gt; # A tibble: 15 × 4\n#&gt;    llm_id p_yes   p_no     n\n#&gt;    &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt;  1 LLM_01  0.49 0.51     100\n#&gt;  2 LLM_02  0.91 0.09     100\n#&gt;  3 LLM_03  0.46 0.54     100\n#&gt;  4 LLM_04  0.88 0.12     100\n#&gt;  5 LLM_05  0.45 0.55     100\n#&gt;  6 LLM_06  0.52 0.48     100\n#&gt;  7 LLM_07  0.55 0.45     100\n#&gt;  8 LLM_08  0.6  0.4      100\n#&gt;  9 LLM_09  0.65 0.35     100\n#&gt; 10 LLM_10  0.61 0.39     100\n#&gt; 11 LLM_11  0.93 0.0700   100\n#&gt; 12 LLM_12  0.53 0.47     100\n#&gt; 13 LLM_13  0.94 0.0600   100\n#&gt; 14 LLM_14  0.69 0.31     100\n#&gt; 15 LLM_15  0.92 0.0800   100</pre></td></tr></table>\n</div>\n</div>\n</div>\n<p>Next we need a function that can accept each row as a series of arguments and use it to generate a vector of LLM answers:</p>\n<div class=\"highlight-wrapper\">\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre>1\n2\n3\n4\n5\n</pre></td>\n<td class=\"lntd\">\n<pre>run_llm &lt;- function(llm_id, p_yes, p_no, n_runs) {\n  tibble(\n    {{ llm_id }} := sample(c(\"N\", \"Y\"), n_runs, replace = TRUE, prob = c(p_yes, p_no))\n  )\n}</pre></td></tr></table>\n</div>\n</div>\n</div>\n<p>This function returns a data frame that has one column and a hundred rows of Y/N answers sampled at a given probability of yes and no answers. There are two tricks. The first is, we want the name of the column to be the same as the <code>llm_id</code>. To do this we have to <a href=\"https://en.wikipedia.org/wiki/Quasi-quotation\" rel=\"nofollow\" target=\"_blank\">quasi-quote</a> the <code>llm_id</code> argument. This is what the <code>{{  }}</code> around <code>llm_id</code> <a href=\"https://rlang.r-lib.org/reference/topic-data-mask.html\" rel=\"nofollow\" target=\"_blank\">does inside the function</a>. It lets us use the value of <code>llm_id</code> as a symbol that’ll name the column. Normally when using <code>tibble()</code> to make a data frame we create a column with <code>col_name = vector_of_values</code>. We did that when we made <code>llm_df</code> a minute ago. But because we’re doing this on the <em>left</em> side of a naming operation, we can’t use <code>=</code>, either. We have to assign the name’s contents using the excellently-named <a href=\"https://www.tidyverse.org/blog/2020/02/glue-strings-and-tidy-eval/\" rel=\"nofollow\" target=\"_blank\">walrus operator</a>, <code>:=</code>.</p>\n<p>Now we’re ready to go. We feed the <code>llm_df</code> table a row at a time to the <code>run_llm</code> function by using one of purrr’s <a href=\"https://purrr.tidyverse.org/\" rel=\"nofollow\" target=\"_blank\">map functions</a>. Specifically, we use <a href=\"https://purrr.tidyverse.org/reference/pmap.html\" rel=\"nofollow\" target=\"_blank\">pmap</a>, which takes a list of function arguments and hands them to a function.</p>\n<div class=\"highlight-wrapper\">\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n</pre></td>\n<td class=\"lntd\">\n<pre>llm_results &lt;- map(llm_outputs, \\(x) eval_llm(x, human_evals)) |&gt;\n  bind_cols() |&gt; \n  mutate(\n    across(everything(), as.factor))\n\nllm_results\n#&gt; # A tibble: 100 × 15\n#&gt;    LLM_01         LLM_02         LLM_03         LLM_04         LLM_05  LLM_06 LLM_07 LLM_08 LLM_09 LLM_10 LLM_11 LLM_12 LLM_13 LLM_14 LLM_15\n#&gt;    &lt;fct&gt;          &lt;fct&gt;          &lt;fct&gt;          &lt;fct&gt;          &lt;fct&gt;   &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt; \n#&gt;  1 False Positive False Positive False Positive True Negative  True N… True … False… True … True … True … True … True … False… True … True …\n#&gt;  2 True Positive  False Negative False Negative False Negative False … False… False… True … False… False… False… False… False… True … False…\n#&gt;  3 False Negative True Positive  False Negative False Negative False … False… True … False… False… False… False… False… False… True … False…\n#&gt;  4 False Positive False Positive True Negative  True Negative  True N… True … True … True … True … True … True … True … True … False… True …\n#&gt;  5 True Negative  True Negative  True Negative  True Negative  False … False… False… True … False… True … True … True … True … False… False…\n#&gt;  6 False Positive True Negative  True Negative  False Positive False … False… True … False… False… True … True … True … False… True … True …\n#&gt;  7 False Positive False Positive True Negative  False Positive True N… True … False… False… False… True … True … True … True … True … True …\n#&gt;  8 False Negative True Positive  False Negative False Negative True P… False… False… False… False… False… False… False… False… True … True …\n#&gt;  9 False Negative True Positive  False Negative True Positive  True P… False… True … False… True … False… False… False… False… False… False…\n#&gt; 10 True Negative  True Negative  False Positive True Negative  True N… True … False… False… False… True … True … True … False… False… False…\n#&gt; # ℹ 90 more rows</pre></td></tr></table>\n</div>\n</div>\n</div>\n<p>We write <code>as.list(llm_df)</code> because <code>pmap()</code> wants its series of arguments as a list. (A data frame is just a list where each list element—each column—is the same length, by the way.) It returns a list of fifteen LLM runs, which we then bind by column back into a data frame. Nice. At the end there I deliberately convert all these character vectors to <a href=\"https://r4ds.had.co.nz/factors.html\" rel=\"nofollow\" target=\"_blank\">factors</a> for a reason I’ll get to momentarily.</p>\n<p>Now we can evaluate all these LLMs against our <code>human_evals</code> vector in the same way, by mapping or applying the <code>eval_llm()</code> function we wrote earlier. This time we can just use regular <code>map()</code> because there’s only one varying argument, the LLM id. We take the <code>llm_outputs</code> data frame and use an anonymous or lambda function, <code>\\(x\\)</code> to say “pass each column to <code>eval_llm()</code> along with the non-varying <code>human_evals</code> vector”. (You could write this without a lambda, too, but I find this syntax more consistent.)</p>\n<div class=\"highlight-wrapper\">\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n</pre></td>\n<td class=\"lntd\">\n<pre>llm_results &lt;- map(llm_outputs, \\(x) eval_llm(x, human_evals)) |&gt;\n  bind_cols() |&gt; \n  mutate(\n    across(everything(), as.factor))\n\nllm_results\n#&gt; # A tibble: 100 × 15\n#&gt;    LLM_01         LLM_02         LLM_03         LLM_04         LLM_05  LLM_06 LLM_07 LLM_08 LLM_09 LLM_10 LLM_11 LLM_12 LLM_13 LLM_14 LLM_15\n#&gt;    &lt;fct&gt;          &lt;fct&gt;          &lt;fct&gt;          &lt;fct&gt;          &lt;fct&gt;   &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt; \n#&gt;  1 False Positive False Positive False Positive True Negative  True N… True … False… True … True … True … True … True … False… True … True …\n#&gt;  2 True Positive  False Negative False Negative False Negative False … False… False… True … False… False… False… False… False… True … False…\n#&gt;  3 False Negative True Positive  False Negative False Negative False … False… True … False… False… False… False… False… False… True … False…\n#&gt;  4 False Positive False Positive True Negative  True Negative  True N… True … True … True … True … True … True … True … True … False… True …\n#&gt;  5 True Negative  True Negative  True Negative  True Negative  False … False… False… True … False… True … True … True … True … False… False…\n#&gt;  6 False Positive True Negative  True Negative  False Positive False … False… True … False… False… True … True … True … False… True … True …\n#&gt;  7 False Positive False Positive True Negative  False Positive True N… True … False… False… False… True … True … True … True … True … True …\n#&gt;  8 False Negative True Positive  False Negative False Negative True P… False… False… False… False… False… False… False… False… True … True …\n#&gt;  9 False Negative True Positive  False Negative True Positive  True P… False… True … False… True … False… False… False… False… False… False…\n#&gt; 10 True Negative  True Negative  False Positive True Negative  True N… True … False… False… False… True … True … True … False… False… False…\n#&gt; # ℹ 90 more rows</pre></td></tr></table>\n</div>\n</div>\n</div>\n<p>Now we’re done; each LLM has been compared to the ground truth and we can construct a confusion matrix of counts for each column if we want. Let’s summarize the table, adding a cost code for the bad answers:</p>\n<div class=\"highlight-wrapper\">\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n</pre></td>\n<td class=\"lntd\">\n<pre>llm_summary &lt;- llm_results |&gt;\n  pivot_longer(everything()) |&gt;\n  group_by(name, value, .drop = FALSE) |&gt;\n  tally() |&gt;\n  mutate(prop = n/sum(n),\n         cost = case_when(\n           value %in% c(\"True Positive\", \"True Negative\") ~ 1L,\n           value == \"False Negative\" ~ 2L,\n           value == \"False Positive\" ~ 4L)\n  ) \n\nllm_summary \n#&gt; # A tibble: 60 × 5\n#&gt; # Groups:   name [15]\n#&gt;    name   value              n  prop  cost\n#&gt;    &lt;chr&gt;  &lt;fct&gt;          &lt;int&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt;  1 LLM_01 False Negative    18  0.18     2\n#&gt;  2 LLM_01 False Positive    19  0.19     4\n#&gt;  3 LLM_01 True Negative     59  0.59     1\n#&gt;  4 LLM_01 True Positive      4  0.04     1\n#&gt;  5 LLM_02 False Negative    16  0.16     2\n#&gt;  6 LLM_02 False Positive    22  0.22     4\n#&gt;  7 LLM_02 True Negative     56  0.56     1\n#&gt;  8 LLM_02 True Positive      6  0.06     1\n#&gt;  9 LLM_03 False Negative    19  0.19     2\n#&gt; 10 LLM_03 False Positive    17  0.17     4\n#&gt; # ℹ 50 more rows</pre></td></tr></table>\n</div>\n</div>\n</div>\n<p>Now, why did I convert the LLM results table from characters to factors? It’s because of how <code>dplyr</code> handles table summaries. It’s possible that an LLM could get e.g. all True Positive answers, leaving the other three cells in its confusion matrix empty, i.e. zero counts. But, by default, when tallying counts of character vectors, <code>dplyr</code> drops empty groups. For some kinds of tallying that’s fine, but for others you definitely want to keep a tally of zero-count cells. With factors we can tell <code>dplyr</code> explicitly not to drop them. (You can also set this option permanently for a given analysis.) The alternative is to <a href=\"https://kieranhealy.org/blog/archives/2018/11/19/zero-counts-in-dplyr/\" rel=\"nofollow\" target=\"_blank\">ungroup and complete</a> the table once its been created, explicitly adding back in the implicitly missing zero-count rows.</p>\n<p>Now that we have our table, we can graph it. As I said at the beginning, stacked bar charts are not great in many cases but it’s fine here, and better than trying to repeatedly draw fifteen confusion matrices. We don’t really care about the difference between true positives and true negatives anyway. We take the results table, merge it with the summary table, and draw our graph ordering the LLMs by perforance weighted by average cost. We use a manual four-value color palette to distinguish the broadly bad from the broadly good answers.</p>\n<div class=\"highlight-wrapper\">\n<div class=\"highlight\"><div class=\"chroma\">\n<table class=\"lntable\"><tr><td class=\"lntd\">\n<pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n</pre></td>\n<td class=\"lntd\">\n<pre>llm_results |&gt;\n  pivot_longer(everything()) |&gt;\n  left_join(llm_summary) |&gt;\n  mutate(name = str_replace(name, \"_\", \" \")) |&gt;\n  ggplot(aes(y = reorder(name, cost), fill = value)) +\n  geom_bar(color = \"white\", linewidth = 0.25) +\n  scale_fill_manual(values = fourval_pal) +\n  guides(fill = guide_legend(reverse = TRUE,\n                             title.position = \"top\",\n                             label.position = \"bottom\",\n                             keywidth = 3,\n                             nrow = 1)) +\n  labs(x = \"N Questions\", y = NULL,\n       fill = \"Compared with a Person the LLM Yielded ...\",\n       title = \"LLM Performance Relative to Human Baseline\",\n       subtitle = \"False Positives are twice as costly as False Negatives\") +\n  theme_minimal() +\n  theme(legend.position = \"top\")</pre></td></tr></table>\n</div>\n</div>\n</div>\n<figure><a href=\"https://i2.wp.com/kieranhealy.org/blog/archives/2025/10/03/iterating-some-sample-data/llm-example.png?ssl=1\" rel=\"nofollow\" target=\"_blank\">\n<img alt=\"A stacked bar chart\" data-lazy-src=\"https://i2.wp.com/kieranhealy.org/blog/archives/2025/10/03/iterating-some-sample-data/llm-example.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"A stacked bar chart\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/kieranhealy.org/blog/archives/2025/10/03/iterating-some-sample-data/llm-example.png?w=578&amp;ssl=1\"/></noscript></a><figcaption>\n<p>Ordered and stacked bar chart of imaginary LLM performance.</p>\n</figcaption>\n</figure>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://kieranhealy.org/blog/archives/2025/10/03/iterating-some-sample-data/\"> R on kieranhealy.org</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
    "main_text": "Iterating some sample data\nPosted on\nOctober 3, 2025\nby\nR on kieranhealy.org\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nR on kieranhealy.org\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nI’m teaching my\nModern Plain Text Computing\ncourse this semester and so I’m on the lookout for small examples that I can use to show some of the small techniques we regularly use when working with tables of data. One of those is just coming up with some sample data to illustrate something else, like how to draw a plot or fit a model or what have you. This is partly what the stock datasets that come bundled with packages are for, like the venerable\nmtcars\nor the more recent\npalmerpenguins\n. Sometimes, though, you end up quickly making up an example yourself. This can be a good way to practice stuff that computers are good at, like doing things repeatedly.\nThis happened the other day in response to a question about visualizing some evaluation data. The task goes like this. You are testing a bunch of different LLMs. Say, fifteen of them. You have  trained them to return Yes/No answers when they look at repeated samples of some test data. Let’s say each LLM is asked a hundred questions. You have also had an expert person look at the same hundred questions and give you their Yes/No answers. The person’s answers are the ground truth. You want to know how the LLM performs against them. So for each LLM you have a two-by-two table showing counts or rates of true positives, true negatives, false positives, and false negatives. This is called a “\nconfusion matrix\n”. You want to visualize LLM performance for all the LLMs. An additional wrinkle is that, from the point of view of your business, responses are variably costly. Correct answers (true positives or true negatives) cost one unit. Then, say, a False Negative costs two units and a False Positive is worst, costing four units.\nThe questioner just wanted some thoughts on what sort of graph to draw. You can of course just picture what the data would look like and figure out which of your many stock datasets has an analogous structure. Or you’d just sketch out an answer. In this case, even though they have problems in general, a kind of stacked bar chart (but flipped on its side) might work OK. But half the fun (for some values of “fun”) is generating data that looks like this. And as I said, I’m on the lookout for iteration examples, somewhere I can repeatedly do something and gather the results into a nice table.\nWhen we want to repeatedly do something, we first solve the base case and then we generalize it by putting in some sort of placeholder and use an engine that can iterate over an index of values, feeding each one to the placeholder. In imperative languages you might use a counter and a for loop. In a functional approach you repeatedly map or apply some function.\nWe’ve got a hundred questions and fifteen llms. We imagine that the LLMs can range in accuracy from 40 percent to 99 percent in one percent steps.\n1\n2\n3\n4\n5\nset.seed(100125) # so we get the same 'random' results each time\n\nn_runs <- 100\nn_llms <- 15\naccuracy_range <- seq(0.4, 0.99, 0.01)\nOur baseline is\nn_runs\nhuman answers with some given distribution of Yes/No answers. Let’s say 80% No, 20% Yes. It doesn’t matter what they are; the person is the ground truth. We sample with replacement a hundred times from “N” or “Y” at that probability.\n1\n2\n3\n4\n5\n6\n7\nhuman_evals <- sample(c(\"N\", \"Y\"), n_runs, replace = TRUE, prob = c(0.8, 0.20))\n\nhuman_evals\n#>   [1] \"N\" \"N\" \"N\" \"Y\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"N\"\n#>  [34] \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"N\" \"Y\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"N\"\n#>  [67] \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"Y\" \"N\" \"Y\" \"N\" \"N\" \"Y\" \"Y\" \"N\" \"Y\" \"Y\" \"N\" \"Y\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\" \"N\"\n#> [100] \"N\"\nFor each of our fifteen LLM what we want to do is generate a string of its one hundred Y/N answers in the same way, but with its particular idiosyncratic distribution of Ys and Ns, and then evaluate it against the human baseline. And we’d like to gather all the answers into a single data frame so we can keep everything tidy.\nOur evaluation function looks like this:\n1\n2\n3\n4\n5\n6\n7\n8\neval_llm <- function(llm_evals, human_eval) {\n  case_when(\n    llm_evals == \"Y\" & human_eval == \"Y\" ~ \"True Positive\",\n    llm_evals == \"Y\" & human_eval == \"N\" ~ \"False Positive\",\n    llm_evals == \"N\" & human_eval == \"Y\" ~ \"False Negative\",\n    llm_evals == \"N\" & human_eval == \"N\" ~ \"True Negative\",\n  )\n}\nWe generate a string of responses for an imaginary LLM just like we did for the imaginary person. The single case would look like this:\n1\nllm_01 <- sample(c(\"N\", \"Y\"), n_runs, replace = TRUE, prob = c(0.7, 0.3))\nBut we want to do this fifteen times, with varying values for\nprob\nand also we want to put each LLM in its own column in a data frame. So we replace the values with variables. First we generate a vector of LLM names. We use\nstr_pad\nto get sortable numbers with a leading zero.\n1\n2\n3\n4\nllm_id <- paste(\"LLM\", str_pad(1:n_llms, width = 2, pad = \"0\"), sep = \"_\")\n\nllm_id\n#>  [1] \"LLM_01\" \"LLM_02\" \"LLM_03\" \"LLM_04\" \"LLM_05\" \"LLM_06\" \"LLM_07\" \"LLM_08\" \"LLM_09\" \"LLM_10\" \"LLM_11\" \"LLM_12\" \"LLM_13\" \"LLM_14\" \"LLM_15\"\nNow we’re going to create a little table of LLM parameters. We already created a vector of probabilities for the LLMs,\naccuracy_range\n. We’ll sample from that to get fifteen values. The number of runs is fixed at a hundred. R’s naturally vectorized way of working will take care of the table getting filled in properly.\n1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\nllm_df <- tibble(\n  llm_id = llm_id,\n  p_yes = sample(accuracy_range, n_llms),\n  p_no = 1 - p_yes,\n  n = n_runs\n)\n\nllm_df\n#> # A tibble: 15 × 4\n#>    llm_id p_yes   p_no     n\n#>    <chr>  <dbl>  <dbl> <dbl>\n#>  1 LLM_01  0.49 0.51     100\n#>  2 LLM_02  0.91 0.09     100\n#>  3 LLM_03  0.46 0.54     100\n#>  4 LLM_04  0.88 0.12     100\n#>  5 LLM_05  0.45 0.55     100\n#>  6 LLM_06  0.52 0.48     100\n#>  7 LLM_07  0.55 0.45     100\n#>  8 LLM_08  0.6  0.4      100\n#>  9 LLM_09  0.65 0.35     100\n#> 10 LLM_10  0.61 0.39     100\n#> 11 LLM_11  0.93 0.0700   100\n#> 12 LLM_12  0.53 0.47     100\n#> 13 LLM_13  0.94 0.0600   100\n#> 14 LLM_14  0.69 0.31     100\n#> 15 LLM_15  0.92 0.0800   100\nNext we need a function that can accept each row as a series of arguments and use it to generate a vector of LLM answers:\n1\n2\n3\n4\n5\nrun_llm <- function(llm_id, p_yes, p_no, n_runs) {\n  tibble(\n    {{ llm_id }} := sample(c(\"N\", \"Y\"), n_runs, replace = TRUE, prob = c(p_yes, p_no))\n  )\n}\nThis function returns a data frame that has one column and a hundred rows of Y/N answers sampled at a given probability of yes and no answers. There are two tricks. The first is, we want the name of the column to be the same as the\nllm_id\n. To do this we have to\nquasi-quote\nthe\nllm_id\nargument. This is what the\n{{  }}\naround\nllm_id\ndoes inside the function\n. It lets us use the value of\nllm_id\nas a symbol that’ll name the column. Normally when using\ntibble()\nto make a data frame we create a column with\ncol_name = vector_of_values\n. We did that when we made\nllm_df\na minute ago. But because we’re doing this on the\nleft\nside of a naming operation, we can’t use\n=\n, either. We have to assign the name’s contents using the excellently-named\nwalrus operator\n,\n:=\n.\nNow we’re ready to go. We feed the\nllm_df\ntable a row at a time to the\nrun_llm\nfunction by using one of purrr’s\nmap functions\n. Specifically, we use\npmap\n, which takes a list of function arguments and hands them to a function.\n1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\nllm_results <- map(llm_outputs, \\(x) eval_llm(x, human_evals)) |>\n  bind_cols() |> \n  mutate(\n    across(everything(), as.factor))\n\nllm_results\n#> # A tibble: 100 × 15\n#>    LLM_01         LLM_02         LLM_03         LLM_04         LLM_05  LLM_06 LLM_07 LLM_08 LLM_09 LLM_10 LLM_11 LLM_12 LLM_13 LLM_14 LLM_15\n#>    <fct>          <fct>          <fct>          <fct>          <fct>   <fct>  <fct>  <fct>  <fct>  <fct>  <fct>  <fct>  <fct>  <fct>  <fct> \n#>  1 False Positive False Positive False Positive True Negative  True N… True … False… True … True … True … True … True … False… True … True …\n#>  2 True Positive  False Negative False Negative False Negative False … False… False… True … False… False… False… False… False… True … False…\n#>  3 False Negative True Positive  False Negative False Negative False … False… True … False… False… False… False… False… False… True … False…\n#>  4 False Positive False Positive True Negative  True Negative  True N… True … True … True … True … True … True … True … True … False… True …\n#>  5 True Negative  True Negative  True Negative  True Negative  False … False… False… True … False… True … True … True … True … False… False…\n#>  6 False Positive True Negative  True Negative  False Positive False … False… True … False… False… True … True … True … False… True … True …\n#>  7 False Positive False Positive True Negative  False Positive True N… True … False… False… False… True … True … True … True … True … True …\n#>  8 False Negative True Positive  False Negative False Negative True P… False… False… False… False… False… False… False… False… True … True …\n#>  9 False Negative True Positive  False Negative True Positive  True P… False… True … False… True … False… False… False… False… False… False…\n#> 10 True Negative  True Negative  False Positive True Negative  True N… True … False… False… False… True … True … True … False… False… False…\n#> # ℹ 90 more rows\nWe write\nas.list(llm_df)\nbecause\npmap()\nwants its series of arguments as a list. (A data frame is just a list where each list element—each column—is the same length, by the way.) It returns a list of fifteen LLM runs, which we then bind by column back into a data frame. Nice. At the end there I deliberately convert all these character vectors to\nfactors\nfor a reason I’ll get to momentarily.\nNow we can evaluate all these LLMs against our\nhuman_evals\nvector in the same way, by mapping or applying the\neval_llm()\nfunction we wrote earlier. This time we can just use regular\nmap()\nbecause there’s only one varying argument, the LLM id. We take the\nllm_outputs\ndata frame and use an anonymous or lambda function,\n\\(x\\)\nto say “pass each column to\neval_llm()\nalong with the non-varying\nhuman_evals\nvector”. (You could write this without a lambda, too, but I find this syntax more consistent.)\n1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\nllm_results <- map(llm_outputs, \\(x) eval_llm(x, human_evals)) |>\n  bind_cols() |> \n  mutate(\n    across(everything(), as.factor))\n\nllm_results\n#> # A tibble: 100 × 15\n#>    LLM_01         LLM_02         LLM_03         LLM_04         LLM_05  LLM_06 LLM_07 LLM_08 LLM_09 LLM_10 LLM_11 LLM_12 LLM_13 LLM_14 LLM_15\n#>    <fct>          <fct>          <fct>          <fct>          <fct>   <fct>  <fct>  <fct>  <fct>  <fct>  <fct>  <fct>  <fct>  <fct>  <fct> \n#>  1 False Positive False Positive False Positive True Negative  True N… True … False… True … True … True … True … True … False… True … True …\n#>  2 True Positive  False Negative False Negative False Negative False … False… False… True … False… False… False… False… False… True … False…\n#>  3 False Negative True Positive  False Negative False Negative False … False… True … False… False… False… False… False… False… True … False…\n#>  4 False Positive False Positive True Negative  True Negative  True N… True … True … True … True … True … True … True … True … False… True …\n#>  5 True Negative  True Negative  True Negative  True Negative  False … False… False… True … False… True … True … True … True … False… False…\n#>  6 False Positive True Negative  True Negative  False Positive False … False… True … False… False… True … True … True … False… True … True …\n#>  7 False Positive False Positive True Negative  False Positive True N… True … False… False… False… True … True … True … True … True … True …\n#>  8 False Negative True Positive  False Negative False Negative True P… False… False… False… False… False… False… False… False… True … True …\n#>  9 False Negative True Positive  False Negative True Positive  True P… False… True … False… True … False… False… False… False… False… False…\n#> 10 True Negative  True Negative  False Positive True Negative  True N… True … False… False… False… True … True … True … False… False… False…\n#> # ℹ 90 more rows\nNow we’re done; each LLM has been compared to the ground truth and we can construct a confusion matrix of counts for each column if we want. Let’s summarize the table, adding a cost code for the bad answers:\n1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\nllm_summary <- llm_results |>\n  pivot_longer(everything()) |>\n  group_by(name, value, .drop = FALSE) |>\n  tally() |>\n  mutate(prop = n/sum(n),\n         cost = case_when(\n           value %in% c(\"True Positive\", \"True Negative\") ~ 1L,\n           value == \"False Negative\" ~ 2L,\n           value == \"False Positive\" ~ 4L)\n  ) \n\nllm_summary \n#> # A tibble: 60 × 5\n#> # Groups:   name [15]\n#>    name   value              n  prop  cost\n#>    <chr>  <fct>          <int> <dbl> <int>\n#>  1 LLM_01 False Negative    18  0.18     2\n#>  2 LLM_01 False Positive    19  0.19     4\n#>  3 LLM_01 True Negative     59  0.59     1\n#>  4 LLM_01 True Positive      4  0.04     1\n#>  5 LLM_02 False Negative    16  0.16     2\n#>  6 LLM_02 False Positive    22  0.22     4\n#>  7 LLM_02 True Negative     56  0.56     1\n#>  8 LLM_02 True Positive      6  0.06     1\n#>  9 LLM_03 False Negative    19  0.19     2\n#> 10 LLM_03 False Positive    17  0.17     4\n#> # ℹ 50 more rows\nNow, why did I convert the LLM results table from characters to factors? It’s because of how\ndplyr\nhandles table summaries. It’s possible that an LLM could get e.g. all True Positive answers, leaving the other three cells in its confusion matrix empty, i.e. zero counts. But, by default, when tallying counts of character vectors,\ndplyr\ndrops empty groups. For some kinds of tallying that’s fine, but for others you definitely want to keep a tally of zero-count cells. With factors we can tell\ndplyr\nexplicitly not to drop them. (You can also set this option permanently for a given analysis.) The alternative is to\nungroup and complete\nthe table once its been created, explicitly adding back in the implicitly missing zero-count rows.\nNow that we have our table, we can graph it. As I said at the beginning, stacked bar charts are not great in many cases but it’s fine here, and better than trying to repeatedly draw fifteen confusion matrices. We don’t really care about the difference between true positives and true negatives anyway. We take the results table, merge it with the summary table, and draw our graph ordering the LLMs by perforance weighted by average cost. We use a manual four-value color palette to distinguish the broadly bad from the broadly good answers.\n1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nllm_results |>\n  pivot_longer(everything()) |>\n  left_join(llm_summary) |>\n  mutate(name = str_replace(name, \"_\", \" \")) |>\n  ggplot(aes(y = reorder(name, cost), fill = value)) +\n  geom_bar(color = \"white\", linewidth = 0.25) +\n  scale_fill_manual(values = fourval_pal) +\n  guides(fill = guide_legend(reverse = TRUE,\n                             title.position = \"top\",\n                             label.position = \"bottom\",\n                             keywidth = 3,\n                             nrow = 1)) +\n  labs(x = \"N Questions\", y = NULL,\n       fill = \"Compared with a Person the LLM Yielded ...\",\n       title = \"LLM Performance Relative to Human Baseline\",\n       subtitle = \"False Positives are twice as costly as False Negatives\") +\n  theme_minimal() +\n  theme(legend.position = \"top\")\nOrdered and stacked bar chart of imaginary LLM performance.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nR on kieranhealy.org\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "meta_description": "I’m teaching my Modern Plain Text Computing course this semester and so I’m on the lookout for small examples that I can use to show some of the small techniques we regularly use when working with tables of data. One of those is just coming up with some sample data to illustrate something else, like how to draw a plot or fit a model or what have you. This is partly what the stock datasets that come bundled with packages are for, like the venerable mtcars or the more recent palmerpenguins. Sometimes, though, you end up quickly making up an example yourself. This can be a good way to practice stuff that computers are good at, like doing things repeatedly. This happened the other day in response to a question about visualizing some evaluation data. The task goes like this. You are testing a bunch of different LLMs. Say, fifteen of them. You have trained them to return Yes/No answers when they look at repeated samples of some test data. Let’s say each LLM is asked a hundred questions. You have also had an expert person look at the same hundred questions and give you their Yes/No answers. The person’s answers are the ground truth. You want to know how the LLM performs against them. So for each LLM you have a two-by-two table showing counts or rates of true positives, true negatives, false positives, and false negatives. This is called a “confusion matrix”. You want to visualize LLM performance for all the LLMs. An additional wrinkle is that, from the point of view of your business, responses are variably costly. Correct answers (true positives or true negatives) cost one unit. Then, say, a False Negative costs two units and a False Positive is worst, costing four units. The questioner just wanted some thoughts on what sort of graph to draw. You can of course just picture what the data would look like and figure out which of your many stock datasets has an analogous structure. Or you’d just sketch out an answer. In this case, even though they have problems in general, a kind of stacked bar chart (but flipped on its side) might work OK. But half the fun (for some values of “fun”) is generating data that looks like this. And as I said, I’m on the lookout for iteration examples, somewhere I can repeatedly do something and gather the results into a nice table. When we want to repeatedly do something, we first solve the base case and then we generalize it by putting in some sort of placeholder and use an engine that can iterate over an index of values, feeding each one to the placeholder. In imperative languages you might use a counter and a for loop. In a functional approach you repeatedly map or apply some function. We’ve got a hundred questions and fifteen llms. We imagine that the LLMs can range in accuracy from 40 percent to 99 percent in one percent steps. 1 2 3 4 5 set.seed(100125) # so we get the same 'random' results each time n_runs [100] \"N\" For each of our fifteen LLM what we want to do is generate a string of its one hundred Y/N answers in the same way, but with its particular idiosyncratic distribution of Ys and Ns, and then evaluate it against the human baseline. And we’d like to gather all the answers into a single data frame so we can keep everything tidy. Our evaluation function looks like this: 1 2 3 4 5 6 7 8 eval_llm #> 1 LLM_01 0.49 0.51 100 #> 2 LLM_02 0.91 0.09 100 #> 3 LLM_03 0.46 0.54 100 #> 4 LLM_04 0.88 0.12 100 #> 5 LLM_05 0.45 0.55 100 #> 6 LLM_06 0.52 0.48 100 #> 7 LLM_07 0.55 0.45 100 #> 8 LLM_08 0.6 0.4 100 #> 9 LLM_09 0.65 0.35 100 #> 10 LLM_10 0.61 0.39 100 #> 11 LLM_11 0.93 0.0700 100 #> 12 LLM_12 0.53 0.47 100 #> 13 LLM_13 0.94 0.0600 100 #> 14 LLM_14 0.69 0.31 100 #> 15 LLM_15 0.92 0.0800 100 Next we need a function that can accept each row as a series of arguments and use it to generate a vector of LLM answers: 1 2 3 4 5 run_llm mutate( across(everything(), as.factor)) llm_results #> # A tibble: 100 × 15 #> LLM_01 LLM_02 LLM_03 LLM_04 LLM_05 LLM_06 LLM_07 LLM_08 LLM_09 LLM_10 LLM_11 LLM_12 LLM_13 LLM_14 LLM_15 #> #> 1 False Positive False Positive False Positive True Negative True N… True … False… True … True … True … True … True … False… True … True … #> 2 True Positive False Negative False Negative False Negative False … False… False… True … False… False… False… False… False… True … False… #> 3 False Negative True Positive False Negative False Negative False … False… True … False… False… False… False… False… False… True … False… #> 4 False Positive False Positive True Negative True Negative True N… True … True … True … True … True … True … True … True … False… True … #> 5 True Negative True Negative True Negative True Negative False … False… False… True … False… True … True … True … True … False… False… #> 6 False Positive True Negative True Negative False Positive False … False… True … False… False… True … True … True … False… True … True … #> 7 False Positive False Positive True Negative False Positive True N… True … False… False… False… True … True … True … True … True … True … #> 8 False Negative True Positive False Negative False Negative True P… False… False… False… False… False… False… False… False… True … True … #> 9 False Negative True Positive False Negative True Positive True P… False… True … False… True … False… False… False… False… False… False… #> 10 True Negative True Negative False Positive True Negative True N… True … False… False… False… True … True … True … False… False… False… #> # ℹ 90 more rows We write as.list(llm_df) because pmap() wants its series of arguments as a list. (A data frame is just a list where each list element—each column—is the same length, by the way.) It returns a list of fifteen LLM runs, which we then bind by column back into a data frame. Nice. At the end there I deliberately convert all these character vectors to factors for a reason I’ll get to momentarily. Now we can evaluate all these LLMs against our human_evals vector in the same way, by mapping or applying the eval_llm() function we wrote earlier. This time we can just use regular map() because there’s only one varying argument, the LLM id. We take the llm_outputs data frame and use an anonymous or lambda function, \\(x\\) to say “pass each column to eval_llm() along with the non-varying human_evals vector”. (You could write this without a lambda, too, but I find this syntax more consistent.) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 llm_results bind_cols() |> mutate( across(everything(), as.factor)) llm_results #> # A tibble: 100 × 15 #> LLM_01 LLM_02 LLM_03 LLM_04 LLM_05 LLM_06 LLM_07 LLM_08 LLM_09 LLM_10 LLM_11 LLM_12 LLM_13 LLM_14 LLM_15 #> #> 1 False Positive False Positive False Positive True Negative True N… True … False… True … True … True … True … True … False… True … True … #> 2 True Positive False Negative False Negative False Negative False … False… False… True … False… False… False… False… False… True … False… #> 3 False Negative True Positive False Negative False Negative False … False… True … False… False… False… False… False… False… True … False… #> 4 False Positive False Positive True Negative True Negative True N… True … True … True … True … True … True … True … True … False… True … #> 5 True Negative True Negative True Negative True Negative False … False… False… True … False… True … True … True … True … False… False… #> 6 False Positive True Negative True Negative False Positive False … False… True … False… False… True … True … True … False… True … True … #> 7 False Positive False Positive True Negative False Positive True N… True … False… False… False… True … True … True … True … True … True … #> 8 False Negative True Positive False Negative False Negative True P… False… False… False… False… False… False… False… False… True … True … #> 9 False Negative True Positive False Negative True Positive True P… False… True … False… True … False… False… False… False… False… False… #> 10 True Negative True Negative False Positive True Negative True N… True … False… False… False… True … True … True … False… False… False… #> # ℹ 90 more rows Now we’re done; each LLM has been compared to the ground truth and we can construct a confusion matrix of counts for each column if we want. Let’s summarize the table, adding a cost code for the bad answers: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 llm_summary pivot_longer(everything()) |> group_by(name, value, .drop = FALSE) |> tally() |> mutate(prop = n/sum(n), cost = case_when( value %in% c(\"True Positive\", \"True Negative\") ~ 1L, value == \"False Negative\" ~ 2L, value == \"False Positive\" ~ 4L) ) llm_summary #> # A tibble: 60 × 5 #> # Groups: name [15] #> name value n prop cost #> #> 1 LLM_01 False Negative 18 0.18 2 #> 2 LLM_01 False Positive 19 0.19 4 #> 3 LLM_01 True Negative 59 0.59 1 #> 4 LLM_01 True Positive 4 0.04 1 #> 5 LLM_02 False Negative 16 0.16 2 #> 6 LLM_02 False Positive 22 0.22 4 #> 7 LLM_02 True Negative 56 0.56 1 #> 8 LLM_02 True Positive 6 0.06 1 #> 9 LLM_03 False Negative 19 0.19 2 #> 10 LLM_03 False Positive 17 0.17 4 #> # ℹ 50 more rows Now, why did I convert the LLM results table from characters to factors? It’s because of how dplyr handles table summaries. It’s possible that an LLM could get e.g. all True Positive answers, leaving the other three cells in its confusion matrix empty, i.e. zero counts. But, by default, when tallying counts of character vectors, dplyr drops empty groups. For some kinds of tallying that’s fine, but for others you definitely want to keep a tally of zero-count cells. With factors we can tell dplyr explicitly not to drop them. (You can also set this option permanently for a given analysis.) The alternative is to ungroup and complete the table once its been created, explicitly adding back in the implicitly missing zero-count rows. Now that we have our table, we can graph it. As I said at the beginning, stacked bar charts are not great in many cases but it’s fine here, and better than trying to repeatedly draw fifteen confusion matrices. We don’t really care about the difference between true positives and true negatives anyway. We take the results table, merge it with the summary table, and draw our graph ordering the LLMs by perforance weighted by average cost. We use a manual four-value color palette to distinguish the broadly bad from the broadly good answers. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 llm_results |> pivot_longer(everything()) |> left_join(llm_summary) |> mutate(name = str_replace(name, \"_\", \" \")) |> ggplot(aes(y = reorder(name, cost), fill = value)) + geom_bar(color = \"white\", linewidth = 0.25) + scale_fill_manual(values = fourval_pal) + guides(fill = guide_legend(reverse = TRUE, title.position = \"top\", label.position = \"bottom\", keywidth = 3, nrow = 1)) + labs(x = \"N Questions\", y = NULL, fill = \"Compared with a Person the LLM Yielded ...\", title = \"LLM Performance Relative to Human Baseline\", subtitle = \"False Positives are twice as costly as False Negatives\") + theme_minimal() + theme(legend.position = \"top\") Ordered and stacked bar chart of imaginary LLM performance.",
    "meta_keywords": null,
    "og_description": "I’m teaching my Modern Plain Text Computing course this semester and so I’m on the lookout for small examples that I can use to show some of the small techniques we regularly use when working with tables of data. One of those is just coming up with some sample data to illustrate something else, like how to draw a plot or fit a model or what have you. This is partly what the stock datasets that come bundled with packages are for, like the venerable mtcars or the more recent palmerpenguins. Sometimes, though, you end up quickly making up an example yourself. This can be a good way to practice stuff that computers are good at, like doing things repeatedly. This happened the other day in response to a question about visualizing some evaluation data. The task goes like this. You are testing a bunch of different LLMs. Say, fifteen of them. You have trained them to return Yes/No answers when they look at repeated samples of some test data. Let’s say each LLM is asked a hundred questions. You have also had an expert person look at the same hundred questions and give you their Yes/No answers. The person’s answers are the ground truth. You want to know how the LLM performs against them. So for each LLM you have a two-by-two table showing counts or rates of true positives, true negatives, false positives, and false negatives. This is called a “confusion matrix”. You want to visualize LLM performance for all the LLMs. An additional wrinkle is that, from the point of view of your business, responses are variably costly. Correct answers (true positives or true negatives) cost one unit. Then, say, a False Negative costs two units and a False Positive is worst, costing four units. The questioner just wanted some thoughts on what sort of graph to draw. You can of course just picture what the data would look like and figure out which of your many stock datasets has an analogous structure. Or you’d just sketch out an answer. In this case, even though they have problems in general, a kind of stacked bar chart (but flipped on its side) might work OK. But half the fun (for some values of “fun”) is generating data that looks like this. And as I said, I’m on the lookout for iteration examples, somewhere I can repeatedly do something and gather the results into a nice table. When we want to repeatedly do something, we first solve the base case and then we generalize it by putting in some sort of placeholder and use an engine that can iterate over an index of values, feeding each one to the placeholder. In imperative languages you might use a counter and a for loop. In a functional approach you repeatedly map or apply some function. We’ve got a hundred questions and fifteen llms. We imagine that the LLMs can range in accuracy from 40 percent to 99 percent in one percent steps. 1 2 3 4 5 set.seed(100125) # so we get the same 'random' results each time n_runs [100] \"N\" For each of our fifteen LLM what we want to do is generate a string of its one hundred Y/N answers in the same way, but with its particular idiosyncratic distribution of Ys and Ns, and then evaluate it against the human baseline. And we’d like to gather all the answers into a single data frame so we can keep everything tidy. Our evaluation function looks like this: 1 2 3 4 5 6 7 8 eval_llm #> 1 LLM_01 0.49 0.51 100 #> 2 LLM_02 0.91 0.09 100 #> 3 LLM_03 0.46 0.54 100 #> 4 LLM_04 0.88 0.12 100 #> 5 LLM_05 0.45 0.55 100 #> 6 LLM_06 0.52 0.48 100 #> 7 LLM_07 0.55 0.45 100 #> 8 LLM_08 0.6 0.4 100 #> 9 LLM_09 0.65 0.35 100 #> 10 LLM_10 0.61 0.39 100 #> 11 LLM_11 0.93 0.0700 100 #> 12 LLM_12 0.53 0.47 100 #> 13 LLM_13 0.94 0.0600 100 #> 14 LLM_14 0.69 0.31 100 #> 15 LLM_15 0.92 0.0800 100 Next we need a function that can accept each row as a series of arguments and use it to generate a vector of LLM answers: 1 2 3 4 5 run_llm mutate( across(everything(), as.factor)) llm_results #> # A tibble: 100 × 15 #> LLM_01 LLM_02 LLM_03 LLM_04 LLM_05 LLM_06 LLM_07 LLM_08 LLM_09 LLM_10 LLM_11 LLM_12 LLM_13 LLM_14 LLM_15 #> #> 1 False Positive False Positive False Positive True Negative True N… True … False… True … True … True … True … True … False… True … True … #> 2 True Positive False Negative False Negative False Negative False … False… False… True … False… False… False… False… False… True … False… #> 3 False Negative True Positive False Negative False Negative False … False… True … False… False… False… False… False… False… True … False… #> 4 False Positive False Positive True Negative True Negative True N… True … True … True … True … True … True … True … True … False… True … #> 5 True Negative True Negative True Negative True Negative False … False… False… True … False… True … True … True … True … False… False… #> 6 False Positive True Negative True Negative False Positive False … False… True … False… False… True … True … True … False… True … True … #> 7 False Positive False Positive True Negative False Positive True N… True … False… False… False… True … True … True … True … True … True … #> 8 False Negative True Positive False Negative False Negative True P… False… False… False… False… False… False… False… False… True … True … #> 9 False Negative True Positive False Negative True Positive True P… False… True … False… True … False… False… False… False… False… False… #> 10 True Negative True Negative False Positive True Negative True N… True … False… False… False… True … True … True … False… False… False… #> # ℹ 90 more rows We write as.list(llm_df) because pmap() wants its series of arguments as a list. (A data frame is just a list where each list element—each column—is the same length, by the way.) It returns a list of fifteen LLM runs, which we then bind by column back into a data frame. Nice. At the end there I deliberately convert all these character vectors to factors for a reason I’ll get to momentarily. Now we can evaluate all these LLMs against our human_evals vector in the same way, by mapping or applying the eval_llm() function we wrote earlier. This time we can just use regular map() because there’s only one varying argument, the LLM id. We take the llm_outputs data frame and use an anonymous or lambda function, \\(x\\) to say “pass each column to eval_llm() along with the non-varying human_evals vector”. (You could write this without a lambda, too, but I find this syntax more consistent.) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 llm_results bind_cols() |> mutate( across(everything(), as.factor)) llm_results #> # A tibble: 100 × 15 #> LLM_01 LLM_02 LLM_03 LLM_04 LLM_05 LLM_06 LLM_07 LLM_08 LLM_09 LLM_10 LLM_11 LLM_12 LLM_13 LLM_14 LLM_15 #> #> 1 False Positive False Positive False Positive True Negative True N… True … False… True … True … True … True … True … False… True … True … #> 2 True Positive False Negative False Negative False Negative False … False… False… True … False… False… False… False… False… True … False… #> 3 False Negative True Positive False Negative False Negative False … False… True … False… False… False… False… False… False… True … False… #> 4 False Positive False Positive True Negative True Negative True N… True … True … True … True … True … True … True … True … False… True … #> 5 True Negative True Negative True Negative True Negative False … False… False… True … False… True … True … True … True … False… False… #> 6 False Positive True Negative True Negative False Positive False … False… True … False… False… True … True … True … False… True … True … #> 7 False Positive False Positive True Negative False Positive True N… True … False… False… False… True … True … True … True … True … True … #> 8 False Negative True Positive False Negative False Negative True P… False… False… False… False… False… False… False… False… True … True … #> 9 False Negative True Positive False Negative True Positive True P… False… True … False… True … False… False… False… False… False… False… #> 10 True Negative True Negative False Positive True Negative True N… True … False… False… False… True … True … True … False… False… False… #> # ℹ 90 more rows Now we’re done; each LLM has been compared to the ground truth and we can construct a confusion matrix of counts for each column if we want. Let’s summarize the table, adding a cost code for the bad answers: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 llm_summary pivot_longer(everything()) |> group_by(name, value, .drop = FALSE) |> tally() |> mutate(prop = n/sum(n), cost = case_when( value %in% c(\"True Positive\", \"True Negative\") ~ 1L, value == \"False Negative\" ~ 2L, value == \"False Positive\" ~ 4L) ) llm_summary #> # A tibble: 60 × 5 #> # Groups: name [15] #> name value n prop cost #> #> 1 LLM_01 False Negative 18 0.18 2 #> 2 LLM_01 False Positive 19 0.19 4 #> 3 LLM_01 True Negative 59 0.59 1 #> 4 LLM_01 True Positive 4 0.04 1 #> 5 LLM_02 False Negative 16 0.16 2 #> 6 LLM_02 False Positive 22 0.22 4 #> 7 LLM_02 True Negative 56 0.56 1 #> 8 LLM_02 True Positive 6 0.06 1 #> 9 LLM_03 False Negative 19 0.19 2 #> 10 LLM_03 False Positive 17 0.17 4 #> # ℹ 50 more rows Now, why did I convert the LLM results table from characters to factors? It’s because of how dplyr handles table summaries. It’s possible that an LLM could get e.g. all True Positive answers, leaving the other three cells in its confusion matrix empty, i.e. zero counts. But, by default, when tallying counts of character vectors, dplyr drops empty groups. For some kinds of tallying that’s fine, but for others you definitely want to keep a tally of zero-count cells. With factors we can tell dplyr explicitly not to drop them. (You can also set this option permanently for a given analysis.) The alternative is to ungroup and complete the table once its been created, explicitly adding back in the implicitly missing zero-count rows. Now that we have our table, we can graph it. As I said at the beginning, stacked bar charts are not great in many cases but it’s fine here, and better than trying to repeatedly draw fifteen confusion matrices. We don’t really care about the difference between true positives and true negatives anyway. We take the results table, merge it with the summary table, and draw our graph ordering the LLMs by perforance weighted by average cost. We use a manual four-value color palette to distinguish the broadly bad from the broadly good answers. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 llm_results |> pivot_longer(everything()) |> left_join(llm_summary) |> mutate(name = str_replace(name, \"_\", \" \")) |> ggplot(aes(y = reorder(name, cost), fill = value)) + geom_bar(color = \"white\", linewidth = 0.25) + scale_fill_manual(values = fourval_pal) + guides(fill = guide_legend(reverse = TRUE, title.position = \"top\", label.position = \"bottom\", keywidth = 3, nrow = 1)) + labs(x = \"N Questions\", y = NULL, fill = \"Compared with a Person the LLM Yielded ...\", title = \"LLM Performance Relative to Human Baseline\", subtitle = \"False Positives are twice as costly as False Negatives\") + theme_minimal() + theme(legend.position = \"top\") Ordered and stacked bar chart of imaginary LLM performance.",
    "og_image": "https://www.r-bloggers.com/wp-content/uploads/2016/04/R_02_2016-05-01.png",
    "og_title": "Iterating some sample data | R-bloggers",
    "raw_jsonld_article": null,
    "reading_time_min": 14,
    "sitemap_lastmod": null,
    "twitter_description": "I’m teaching my Modern Plain Text Computing course this semester and so I’m on the lookout for small examples that I can use to show some of the small techniques we regularly use when working with tables of data. One of those is just coming up with some sample data to illustrate something else, like how to draw a plot or fit a model or what have you. This is partly what the stock datasets that come bundled with packages are for, like the venerable mtcars or the more recent palmerpenguins. Sometimes, though, you end up quickly making up an example yourself. This can be a good way to practice stuff that computers are good at, like doing things repeatedly. This happened the other day in response to a question about visualizing some evaluation data. The task goes like this. You are testing a bunch of different LLMs. Say, fifteen of them. You have trained them to return Yes/No answers when they look at repeated samples of some test data. Let’s say each LLM is asked a hundred questions. You have also had an expert person look at the same hundred questions and give you their Yes/No answers. The person’s answers are the ground truth. You want to know how the LLM performs against them. So for each LLM you have a two-by-two table showing counts or rates of true positives, true negatives, false positives, and false negatives. This is called a “confusion matrix”. You want to visualize LLM performance for all the LLMs. An additional wrinkle is that, from the point of view of your business, responses are variably costly. Correct answers (true positives or true negatives) cost one unit. Then, say, a False Negative costs two units and a False Positive is worst, costing four units. The questioner just wanted some thoughts on what sort of graph to draw. You can of course just picture what the data would look like and figure out which of your many stock datasets has an analogous structure. Or you’d just sketch out an answer. In this case, even though they have problems in general, a kind of stacked bar chart (but flipped on its side) might work OK. But half the fun (for some values of “fun”) is generating data that looks like this. And as I said, I’m on the lookout for iteration examples, somewhere I can repeatedly do something and gather the results into a nice table. When we want to repeatedly do something, we first solve the base case and then we generalize it by putting in some sort of placeholder and use an engine that can iterate over an index of values, feeding each one to the placeholder. In imperative languages you might use a counter and a for loop. In a functional approach you repeatedly map or apply some function. We’ve got a hundred questions and fifteen llms. We imagine that the LLMs can range in accuracy from 40 percent to 99 percent in one percent steps. 1 2 3 4 5 set.seed(100125) # so we get the same 'random' results each time n_runs [100] \"N\" For each of our fifteen LLM what we want to do is generate a string of its one hundred Y/N answers in the same way, but with its particular idiosyncratic distribution of Ys and Ns, and then evaluate it against the human baseline. And we’d like to gather all the answers into a single data frame so we can keep everything tidy. Our evaluation function looks like this: 1 2 3 4 5 6 7 8 eval_llm #> 1 LLM_01 0.49 0.51 100 #> 2 LLM_02 0.91 0.09 100 #> 3 LLM_03 0.46 0.54 100 #> 4 LLM_04 0.88 0.12 100 #> 5 LLM_05 0.45 0.55 100 #> 6 LLM_06 0.52 0.48 100 #> 7 LLM_07 0.55 0.45 100 #> 8 LLM_08 0.6 0.4 100 #> 9 LLM_09 0.65 0.35 100 #> 10 LLM_10 0.61 0.39 100 #> 11 LLM_11 0.93 0.0700 100 #> 12 LLM_12 0.53 0.47 100 #> 13 LLM_13 0.94 0.0600 100 #> 14 LLM_14 0.69 0.31 100 #> 15 LLM_15 0.92 0.0800 100 Next we need a function that can accept each row as a series of arguments and use it to generate a vector of LLM answers: 1 2 3 4 5 run_llm mutate( across(everything(), as.factor)) llm_results #> # A tibble: 100 × 15 #> LLM_01 LLM_02 LLM_03 LLM_04 LLM_05 LLM_06 LLM_07 LLM_08 LLM_09 LLM_10 LLM_11 LLM_12 LLM_13 LLM_14 LLM_15 #> #> 1 False Positive False Positive False Positive True Negative True N… True … False… True … True … True … True … True … False… True … True … #> 2 True Positive False Negative False Negative False Negative False … False… False… True … False… False… False… False… False… True … False… #> 3 False Negative True Positive False Negative False Negative False … False… True … False… False… False… False… False… False… True … False… #> 4 False Positive False Positive True Negative True Negative True N… True … True … True … True … True … True … True … True … False… True … #> 5 True Negative True Negative True Negative True Negative False … False… False… True … False… True … True … True … True … False… False… #> 6 False Positive True Negative True Negative False Positive False … False… True … False… False… True … True … True … False… True … True … #> 7 False Positive False Positive True Negative False Positive True N… True … False… False… False… True … True … True … True … True … True … #> 8 False Negative True Positive False Negative False Negative True P… False… False… False… False… False… False… False… False… True … True … #> 9 False Negative True Positive False Negative True Positive True P… False… True … False… True … False… False… False… False… False… False… #> 10 True Negative True Negative False Positive True Negative True N… True … False… False… False… True … True … True … False… False… False… #> # ℹ 90 more rows We write as.list(llm_df) because pmap() wants its series of arguments as a list. (A data frame is just a list where each list element—each column—is the same length, by the way.) It returns a list of fifteen LLM runs, which we then bind by column back into a data frame. Nice. At the end there I deliberately convert all these character vectors to factors for a reason I’ll get to momentarily. Now we can evaluate all these LLMs against our human_evals vector in the same way, by mapping or applying the eval_llm() function we wrote earlier. This time we can just use regular map() because there’s only one varying argument, the LLM id. We take the llm_outputs data frame and use an anonymous or lambda function, \\(x\\) to say “pass each column to eval_llm() along with the non-varying human_evals vector”. (You could write this without a lambda, too, but I find this syntax more consistent.) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 llm_results bind_cols() |> mutate( across(everything(), as.factor)) llm_results #> # A tibble: 100 × 15 #> LLM_01 LLM_02 LLM_03 LLM_04 LLM_05 LLM_06 LLM_07 LLM_08 LLM_09 LLM_10 LLM_11 LLM_12 LLM_13 LLM_14 LLM_15 #> #> 1 False Positive False Positive False Positive True Negative True N… True … False… True … True … True … True … True … False… True … True … #> 2 True Positive False Negative False Negative False Negative False … False… False… True … False… False… False… False… False… True … False… #> 3 False Negative True Positive False Negative False Negative False … False… True … False… False… False… False… False… False… True … False… #> 4 False Positive False Positive True Negative True Negative True N… True … True … True … True … True … True … True … True … False… True … #> 5 True Negative True Negative True Negative True Negative False … False… False… True … False… True … True … True … True … False… False… #> 6 False Positive True Negative True Negative False Positive False … False… True … False… False… True … True … True … False… True … True … #> 7 False Positive False Positive True Negative False Positive True N… True … False… False… False… True … True … True … True … True … True … #> 8 False Negative True Positive False Negative False Negative True P… False… False… False… False… False… False… False… False… True … True … #> 9 False Negative True Positive False Negative True Positive True P… False… True … False… True … False… False… False… False… False… False… #> 10 True Negative True Negative False Positive True Negative True N… True … False… False… False… True … True … True … False… False… False… #> # ℹ 90 more rows Now we’re done; each LLM has been compared to the ground truth and we can construct a confusion matrix of counts for each column if we want. Let’s summarize the table, adding a cost code for the bad answers: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 llm_summary pivot_longer(everything()) |> group_by(name, value, .drop = FALSE) |> tally() |> mutate(prop = n/sum(n), cost = case_when( value %in% c(\"True Positive\", \"True Negative\") ~ 1L, value == \"False Negative\" ~ 2L, value == \"False Positive\" ~ 4L) ) llm_summary #> # A tibble: 60 × 5 #> # Groups: name [15] #> name value n prop cost #> #> 1 LLM_01 False Negative 18 0.18 2 #> 2 LLM_01 False Positive 19 0.19 4 #> 3 LLM_01 True Negative 59 0.59 1 #> 4 LLM_01 True Positive 4 0.04 1 #> 5 LLM_02 False Negative 16 0.16 2 #> 6 LLM_02 False Positive 22 0.22 4 #> 7 LLM_02 True Negative 56 0.56 1 #> 8 LLM_02 True Positive 6 0.06 1 #> 9 LLM_03 False Negative 19 0.19 2 #> 10 LLM_03 False Positive 17 0.17 4 #> # ℹ 50 more rows Now, why did I convert the LLM results table from characters to factors? It’s because of how dplyr handles table summaries. It’s possible that an LLM could get e.g. all True Positive answers, leaving the other three cells in its confusion matrix empty, i.e. zero counts. But, by default, when tallying counts of character vectors, dplyr drops empty groups. For some kinds of tallying that’s fine, but for others you definitely want to keep a tally of zero-count cells. With factors we can tell dplyr explicitly not to drop them. (You can also set this option permanently for a given analysis.) The alternative is to ungroup and complete the table once its been created, explicitly adding back in the implicitly missing zero-count rows. Now that we have our table, we can graph it. As I said at the beginning, stacked bar charts are not great in many cases but it’s fine here, and better than trying to repeatedly draw fifteen confusion matrices. We don’t really care about the difference between true positives and true negatives anyway. We take the results table, merge it with the summary table, and draw our graph ordering the LLMs by perforance weighted by average cost. We use a manual four-value color palette to distinguish the broadly bad from the broadly good answers. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 llm_results |> pivot_longer(everything()) |> left_join(llm_summary) |> mutate(name = str_replace(name, \"_\", \" \")) |> ggplot(aes(y = reorder(name, cost), fill = value)) + geom_bar(color = \"white\", linewidth = 0.25) + scale_fill_manual(values = fourval_pal) + guides(fill = guide_legend(reverse = TRUE, title.position = \"top\", label.position = \"bottom\", keywidth = 3, nrow = 1)) + labs(x = \"N Questions\", y = NULL, fill = \"Compared with a Person the LLM Yielded ...\", title = \"LLM Performance Relative to Human Baseline\", subtitle = \"False Positives are twice as costly as False Negatives\") + theme_minimal() + theme(legend.position = \"top\") Ordered and stacked bar chart of imaginary LLM performance.",
    "twitter_title": "Iterating some sample data | R-bloggers",
    "url": "https://www.r-bloggers.com/2025/10/iterating-some-sample-data/",
    "word_count": 2802
  }
}