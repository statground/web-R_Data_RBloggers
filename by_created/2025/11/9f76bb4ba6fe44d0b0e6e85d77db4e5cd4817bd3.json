{
  "id": "9f76bb4ba6fe44d0b0e6e85d77db4e5cd4817bd3",
  "url": "https://www.r-bloggers.com/2025/02/tisthemachinelearner-a-lightweight-interface-to-scikit-learn-with-2-classes-classifier-and-regressor-in-python-and-r/",
  "created_at_utc": "2025-11-22T19:59:13Z",
  "data": null,
  "raw_original": {
    "uuid": "591db3be-5dd6-4da5-a47f-05a82b32ffee",
    "created_at": "2025-11-22 19:59:13",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2025/02/tisthemachinelearner-a-lightweight-interface-to-scikit-learn-with-2-classes-classifier-and-regressor-in-python-and-r/",
      "crawled_at": "2025-11-22T10:53:52.882786",
      "external_links": [
        {
          "href": "https://thierrymoudiki.github.io//blog/2025/02/17/python/r/tisthemllearner",
          "text": "T. Moudiki's Webpage - R"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://thierrymoudiki.github.io//blog/2025/02/17/python/r/tisthemllearner#contents",
          "text": "Contents"
        },
        {
          "href": "https://thierrymoudiki.github.io//blog/2025/02/17/python/r/tisthemllearner#1---python-version",
          "text": "1 – Python version"
        },
        {
          "href": "https://thierrymoudiki.github.io//blog/2025/02/17/python/r/tisthemllearner#2---r-version",
          "text": "2 – R version"
        },
        {
          "href": "https://thierrymoudiki.github.io//blog/2025/02/17/python/r/tisthemllearner",
          "text": "T. Moudiki's Webpage - R"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "tisthemachinelearner: A Lightweight interface to scikit-learn with 2 classes, Classifier and Regressor (in Python and R) | R-bloggers",
      "images": [
        {
          "alt": "image-title-here",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "image-title-here",
          "base64": null,
          "src": "https://i0.wp.com/thierrymoudiki.github.io/images/2025-02-17/2025-02-17-image1.png?w=578&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/t-moudiki/",
          "text": "T. Moudiki"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-390633 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">tisthemachinelearner: A Lightweight interface to scikit-learn with 2 classes, Classifier and Regressor (in Python and R)</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">February 16, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/t-moudiki/\">T. Moudiki</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://thierrymoudiki.github.io//blog/2025/02/17/python/r/tisthemllearner\"> T. Moudiki's Webpage - R</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47--><h1 id=\"contents\">Contents</h1>\n<ul>\n<li><a href=\"https://thierrymoudiki.github.io//blog/2025/02/17/python/r/tisthemllearner#contents\" rel=\"nofollow\" target=\"_blank\">Contents</a></li>\n<li><a href=\"https://thierrymoudiki.github.io//blog/2025/02/17/python/r/tisthemllearner#1---python-version\" rel=\"nofollow\" target=\"_blank\">1 – Python version</a></li>\n<li><a href=\"https://thierrymoudiki.github.io//blog/2025/02/17/python/r/tisthemllearner#2---r-version\" rel=\"nofollow\" target=\"_blank\">2 – R version</a></li>\n</ul>\n<h1 id=\"1---python-version\">1 – Python version</h1>\n<pre>!pip install tisthemachinelearner\n\nimport numpy as np\nfrom sklearn.datasets import load_diabetes, load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom tisthemachinelearner import Classifier, Regressor\n\n# Classification\nX, y = load_breast_cancer(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf = Classifier(\"LogisticRegression\", random_state=42)\nclf.fit(X_train, y_train)\nprint(clf.predict(X_test))\nprint(clf.score(X_test, y_test))\n\nclf = Classifier(\"RandomForestClassifier\", n_estimators=100, random_state=42)\nclf.fit(X_train, y_train)\nprint(clf.predict(X_test))\nprint(clf.score(X_test, y_test))\n\n# Regression\nX, y = load_diabetes(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nreg = Regressor(\"LinearRegression\")\nreg.fit(X_train, y_train)\nprint(reg.predict(X_test))\nprint(np.sqrt(np.mean((reg.predict(X_test) - y_test) ** 2)))\n\nreg = Regressor(\"RidgeCV\", alphas=[0.01, 0.1, 1, 10])\nreg.fit(X_train, y_train)\nprint(reg.predict(X_test))\nprint(np.sqrt(np.mean((reg.predict(X_test) - y_test) ** 2)))\n\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n\n\n[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n 1 0 0]\n0.956140350877193\n[1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n 1 1 0]\n0.9649122807017544\n[139.5475584  179.51720835 134.03875572 291.41702925 123.78965872\n  92.1723465  258.23238899 181.33732057  90.22411311 108.63375858\n  94.13865744 168.43486358  53.5047888  206.63081659 100.12925869\n 130.66657085 219.53071499 250.7803234  196.3688346  218.57511815\n 207.35050182  88.48340941  70.43285917 188.95914235 154.8868162\n 159.36170122 188.31263363 180.39094033  47.99046561 108.97453871\n 174.77897633  86.36406656 132.95761215 184.53819483 173.83220911\n 190.35858492 124.4156176  119.65110656 147.95168682  59.05405241\n  71.62331856 107.68284704 165.45365458 155.00975931 171.04799096\n  61.45761356  71.66672581 114.96732206  51.57975523 167.57599528\n 152.52291955  62.95568515 103.49741722 109.20751489 175.64118426\n 154.60296242  94.41704366 210.74209145 120.2566205   77.61585399\n 187.93203995 206.49337474 140.63167076 105.59678023 130.70432536\n 202.18534537 171.13039501 164.91423047 124.72472569 144.81030894\n 181.99635452 199.41369642 234.21436188 145.95665512  79.86703276\n 157.36941275 192.74412541 208.89814032 158.58722555 206.02195855\n 107.47971675 140.93598906  54.82129332  55.92573195 115.01180018\n  78.95584188  81.56087285  54.37997256 166.2543518 ]\n53.85344583676593\n[140.48932729 180.39358466 138.26095011 292.70472351 122.54953663\n  93.61127853 256.94944065 185.46640503  86.4960167  110.59467587\n  95.04571587 164.19550268  60.59798796 205.82695673  99.72760443\n 131.91526636 220.91412088 247.87634694 195.84576355 215.78308828\n 206.82609175  89.01546302  72.05374047 188.47495433 155.71143723\n 161.25320029 189.08097216 178.04173865  49.65268248 110.50254797\n 178.39994134  90.08024148 132.14592247 181.98946205 173.37370782\n 190.81087767 123.38010922 118.90948131 146.69459204  60.67799313\n  74.18510938 108.16651262 162.96843997 151.55290246 173.76202246\n  64.5447612   76.57353392 109.83957197  56.57149752 163.18082268\n 155.2330795   64.94611225 110.68142707 108.69309211 172.0029122\n 157.94954707  94.8588743  208.43411608 118.81317959  72.11719648\n 185.80485787 203.47916991 141.32147862 105.78698586 127.7320836\n 202.81245148 168.55319265 162.78471685 120.58057123 142.15774259\n 180.74853766 196.43247773 234.92016137 143.87413715  81.91095295\n 153.24099082 193.15008313 206.58954277 158.12424491 201.30838954\n 112.09889377 138.42466927  54.61388245  56.57971753 112.85843725\n  83.27187052  81.11235009  59.60136702 164.50759424]\n53.68696471589718\n</pre>\n<h1 id=\"2---r-version\">2 – R version</h1>\n<pre>%load_ext rpy2.ipython\n\n%%R\n\ninstall.packages(\"reticulate\")\n\n%%R\n\nlibrary(reticulate)\n\n# Importation des bibliothèques Python\nnp &lt;- import(\"numpy\")\nsklearn &lt;- import(\"sklearn\")\ndatasets &lt;- import(\"sklearn.datasets\")\nmodel_selection &lt;- import(\"sklearn.model_selection\")\ntisthemachinelearner &lt;- import(\"tisthemachinelearner\")\n\n# Classification\nbreast_cancer &lt;- datasets$load_breast_cancer(return_X_y = TRUE)\nX &lt;- breast_cancer[[1]]\ny &lt;- breast_cancer[[2]]\n\nsplit &lt;- model_selection$train_test_split(X, y, test_size = 0.2, random_state = 42L)\nX_train &lt;- split[[1]]\nX_test &lt;- split[[2]]\ny_train &lt;- split[[3]]\ny_test &lt;- split[[4]]\n\n# Logistic Regression\nclf &lt;- tisthemachinelearner$Classifier(\"LogisticRegression\", random_state = 42L)\nclf$fit(X_train, y_train)\nprint(clf$predict(X_test))\nprint(clf$score(X_test, y_test))\n\n# Random Forest Classifier\nclf &lt;- tisthemachinelearner$Classifier(\"RandomForestClassifier\", n_estimators = 100L, random_state = 42L)\nclf$fit(X_train, y_train)\nprint(clf$predict(X_test))\nprint(clf$score(X_test, y_test))\n\n# Regression\ndiabetes &lt;- datasets$load_diabetes(return_X_y = TRUE)\nX &lt;- diabetes[[1]]\ny &lt;- diabetes[[2]]\n\nsplit &lt;- model_selection$train_test_split(X, y, test_size = 0.2, random_state = 42L)\nX_train &lt;- split[[1]]\nX_test &lt;- split[[2]]\ny_train &lt;- split[[3]]\ny_test &lt;- split[[4]]\n\n# Linear Regression\nreg &lt;- tisthemachinelearner$Regressor(\"LinearRegression\")\nreg$fit(X_train, y_train)\ny_pred &lt;- reg$predict(X_test)\nprint(y_pred)\nprint(np$sqrt(np$mean((y_pred - y_test) ** 2)))\n\n# Ridge Regression with Cross-Validation\nreg &lt;- tisthemachinelearner$Regressor(\"RidgeCV\", alphas = c(0.01, 0.1, 1, 10))\nreg$fit(X_train, y_train)\ny_pred_ridge &lt;- reg$predict(X_test)\nprint(y_pred_ridge)\nprint(np$sqrt(np$mean((y_pred_ridge - y_test) ** 2)))\n\n\n  [1] 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n [38] 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n [75] 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0\n\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n\n\n 0 1 0 0 1 1 1 0 1 1 0\n[112] 1 0 0\n[1] 0.9561404\n  [1] 1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n [38] 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n [75] 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n[112] 1 1 0\n[1] 0.9649123\n [1] 139.54756 179.51721 134.03876 291.41703 123.78966  92.17235 258.23239\n [8] 181.33732  90.22411 108.63376  94.13866 168.43486  53.50479 206.63082\n[15] 100.12926 130.66657 219.53071 250.78032 196.36883 218.57512 207.35050\n[22]  88.48341  70.43286 188.95914 154.88682 159.36170 188.31263 180.39094\n[29]  47.99047 108.97454 174.77898  86.36407 132.95761 184.53819 173.83221\n[36] 190.35858 124.41562 119.65111 147.95169  59.05405  71.62332 107.68285\n[43] 165.45365 155.00976 171.04799  61.45761  71.66673 114.96732  51.57976\n[50] 167.57600 152.52292  62.95569 103.49742 109.20751 175.64118 154.60296\n[57]  94.41704 210.74209 120.25662  77.61585 187.93204 206.49337 140.63167\n[64] 105.59678 130.70433 202.18535 171.13040 164.91423 124.72473 144.81031\n[71] 181.99635 199.41370 234.21436 145.95666  79.86703 157.36941 192.74413\n[78] 208.89814 158.58723 206.02196 107.47972 140.93599  54.82129  55.92573\n[85] 115.01180  78.95584  81.56087  54.37997 166.25435\n[1] 53.85345\n [1] 140.48933 180.39358 138.26095 292.70472 122.54954  93.61128 256.94944\n [8] 185.46641  86.49602 110.59468  95.04572 164.19550  60.59799 205.82696\n[15]  99.72760 131.91527 220.91412 247.87635 195.84576 215.78309 206.82609\n[22]  89.01546  72.05374 188.47495 155.71144 161.25320 189.08097 178.04174\n[29]  49.65268 110.50255 178.39994  90.08024 132.14592 181.98946 173.37371\n[36] 190.81088 123.38011 118.90948 146.69459  60.67799  74.18511 108.16651\n[43] 162.96844 151.55290 173.76202  64.54476  76.57353 109.83957  56.57150\n[50] 163.18082 155.23308  64.94611 110.68143 108.69309 172.00291 157.94955\n[57]  94.85887 208.43412 118.81318  72.11720 185.80486 203.47917 141.32148\n[64] 105.78699 127.73208 202.81245 168.55319 162.78472 120.58057 142.15774\n[71] 180.74854 196.43248 234.92016 143.87414  81.91095 153.24099 193.15008\n[78] 206.58954 158.12424 201.30839 112.09889 138.42467  54.61388  56.57972\n[85] 112.85844  83.27187  81.11235  59.60137 164.50759\n[1] 53.68696\n\n%%R\n\nplot(y_pred_ridge, y_test, type=\"p\", pch=19)\npoints(y_pred, y_test, col=\"blue\", pch=19)\nabline(a = 0, b = 1, col=\"red\")\n</pre>\n<p><img alt=\"image-title-here\" data-lazy-src=\"https://i0.wp.com/thierrymoudiki.github.io/images/2025-02-17/2025-02-17-image1.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"image-title-here\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/thierrymoudiki.github.io/images/2025-02-17/2025-02-17-image1.png?w=578&amp;ssl=1\"/></noscript></p>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://thierrymoudiki.github.io//blog/2025/02/17/python/r/tisthemllearner\"> T. Moudiki's Webpage - R</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
      "main_text": "tisthemachinelearner: A Lightweight interface to scikit-learn with 2 classes, Classifier and Regressor (in Python and R)\nPosted on\nFebruary 16, 2025\nby\nT. Moudiki\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nT. Moudiki's Webpage - R\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nContents\nContents\n1 – Python version\n2 – R version\n1 – Python version\n!pip install tisthemachinelearner\n\nimport numpy as np\nfrom sklearn.datasets import load_diabetes, load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom tisthemachinelearner import Classifier, Regressor\n\n# Classification\nX, y = load_breast_cancer(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf = Classifier(\"LogisticRegression\", random_state=42)\nclf.fit(X_train, y_train)\nprint(clf.predict(X_test))\nprint(clf.score(X_test, y_test))\n\nclf = Classifier(\"RandomForestClassifier\", n_estimators=100, random_state=42)\nclf.fit(X_train, y_train)\nprint(clf.predict(X_test))\nprint(clf.score(X_test, y_test))\n\n# Regression\nX, y = load_diabetes(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nreg = Regressor(\"LinearRegression\")\nreg.fit(X_train, y_train)\nprint(reg.predict(X_test))\nprint(np.sqrt(np.mean((reg.predict(X_test) - y_test) ** 2)))\n\nreg = Regressor(\"RidgeCV\", alphas=[0.01, 0.1, 1, 10])\nreg.fit(X_train, y_train)\nprint(reg.predict(X_test))\nprint(np.sqrt(np.mean((reg.predict(X_test) - y_test) ** 2)))\n\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n\n[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n 1 0 0]\n0.956140350877193\n[1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n 1 1 0]\n0.9649122807017544\n[139.5475584  179.51720835 134.03875572 291.41702925 123.78965872\n  92.1723465  258.23238899 181.33732057  90.22411311 108.63375858\n  94.13865744 168.43486358  53.5047888  206.63081659 100.12925869\n 130.66657085 219.53071499 250.7803234  196.3688346  218.57511815\n 207.35050182  88.48340941  70.43285917 188.95914235 154.8868162\n 159.36170122 188.31263363 180.39094033  47.99046561 108.97453871\n 174.77897633  86.36406656 132.95761215 184.53819483 173.83220911\n 190.35858492 124.4156176  119.65110656 147.95168682  59.05405241\n  71.62331856 107.68284704 165.45365458 155.00975931 171.04799096\n  61.45761356  71.66672581 114.96732206  51.57975523 167.57599528\n 152.52291955  62.95568515 103.49741722 109.20751489 175.64118426\n 154.60296242  94.41704366 210.74209145 120.2566205   77.61585399\n 187.93203995 206.49337474 140.63167076 105.59678023 130.70432536\n 202.18534537 171.13039501 164.91423047 124.72472569 144.81030894\n 181.99635452 199.41369642 234.21436188 145.95665512  79.86703276\n 157.36941275 192.74412541 208.89814032 158.58722555 206.02195855\n 107.47971675 140.93598906  54.82129332  55.92573195 115.01180018\n  78.95584188  81.56087285  54.37997256 166.2543518 ]\n53.85344583676593\n[140.48932729 180.39358466 138.26095011 292.70472351 122.54953663\n  93.61127853 256.94944065 185.46640503  86.4960167  110.59467587\n  95.04571587 164.19550268  60.59798796 205.82695673  99.72760443\n 131.91526636 220.91412088 247.87634694 195.84576355 215.78308828\n 206.82609175  89.01546302  72.05374047 188.47495433 155.71143723\n 161.25320029 189.08097216 178.04173865  49.65268248 110.50254797\n 178.39994134  90.08024148 132.14592247 181.98946205 173.37370782\n 190.81087767 123.38010922 118.90948131 146.69459204  60.67799313\n  74.18510938 108.16651262 162.96843997 151.55290246 173.76202246\n  64.5447612   76.57353392 109.83957197  56.57149752 163.18082268\n 155.2330795   64.94611225 110.68142707 108.69309211 172.0029122\n 157.94954707  94.8588743  208.43411608 118.81317959  72.11719648\n 185.80485787 203.47916991 141.32147862 105.78698586 127.7320836\n 202.81245148 168.55319265 162.78471685 120.58057123 142.15774259\n 180.74853766 196.43247773 234.92016137 143.87413715  81.91095295\n 153.24099082 193.15008313 206.58954277 158.12424491 201.30838954\n 112.09889377 138.42466927  54.61388245  56.57971753 112.85843725\n  83.27187052  81.11235009  59.60136702 164.50759424]\n53.68696471589718\n2 – R version\n%load_ext rpy2.ipython\n\n%%R\n\ninstall.packages(\"reticulate\")\n\n%%R\n\nlibrary(reticulate)\n\n# Importation des bibliothèques Python\nnp <- import(\"numpy\")\nsklearn <- import(\"sklearn\")\ndatasets <- import(\"sklearn.datasets\")\nmodel_selection <- import(\"sklearn.model_selection\")\ntisthemachinelearner <- import(\"tisthemachinelearner\")\n\n# Classification\nbreast_cancer <- datasets$load_breast_cancer(return_X_y = TRUE)\nX <- breast_cancer[[1]]\ny <- breast_cancer[[2]]\n\nsplit <- model_selection$train_test_split(X, y, test_size = 0.2, random_state = 42L)\nX_train <- split[[1]]\nX_test <- split[[2]]\ny_train <- split[[3]]\ny_test <- split[[4]]\n\n# Logistic Regression\nclf <- tisthemachinelearner$Classifier(\"LogisticRegression\", random_state = 42L)\nclf$fit(X_train, y_train)\nprint(clf$predict(X_test))\nprint(clf$score(X_test, y_test))\n\n# Random Forest Classifier\nclf <- tisthemachinelearner$Classifier(\"RandomForestClassifier\", n_estimators = 100L, random_state = 42L)\nclf$fit(X_train, y_train)\nprint(clf$predict(X_test))\nprint(clf$score(X_test, y_test))\n\n# Regression\ndiabetes <- datasets$load_diabetes(return_X_y = TRUE)\nX <- diabetes[[1]]\ny <- diabetes[[2]]\n\nsplit <- model_selection$train_test_split(X, y, test_size = 0.2, random_state = 42L)\nX_train <- split[[1]]\nX_test <- split[[2]]\ny_train <- split[[3]]\ny_test <- split[[4]]\n\n# Linear Regression\nreg <- tisthemachinelearner$Regressor(\"LinearRegression\")\nreg$fit(X_train, y_train)\ny_pred <- reg$predict(X_test)\nprint(y_pred)\nprint(np$sqrt(np$mean((y_pred - y_test) ** 2)))\n\n# Ridge Regression with Cross-Validation\nreg <- tisthemachinelearner$Regressor(\"RidgeCV\", alphas = c(0.01, 0.1, 1, 10))\nreg$fit(X_train, y_train)\ny_pred_ridge <- reg$predict(X_test)\nprint(y_pred_ridge)\nprint(np$sqrt(np$mean((y_pred_ridge - y_test) ** 2)))\n\n  [1] 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n [38] 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n [75] 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0\n\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n\n 0 1 0 0 1 1 1 0 1 1 0\n[112] 1 0 0\n[1] 0.9561404\n  [1] 1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n [38] 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n [75] 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n[112] 1 1 0\n[1] 0.9649123\n [1] 139.54756 179.51721 134.03876 291.41703 123.78966  92.17235 258.23239\n [8] 181.33732  90.22411 108.63376  94.13866 168.43486  53.50479 206.63082\n[15] 100.12926 130.66657 219.53071 250.78032 196.36883 218.57512 207.35050\n[22]  88.48341  70.43286 188.95914 154.88682 159.36170 188.31263 180.39094\n[29]  47.99047 108.97454 174.77898  86.36407 132.95761 184.53819 173.83221\n[36] 190.35858 124.41562 119.65111 147.95169  59.05405  71.62332 107.68285\n[43] 165.45365 155.00976 171.04799  61.45761  71.66673 114.96732  51.57976\n[50] 167.57600 152.52292  62.95569 103.49742 109.20751 175.64118 154.60296\n[57]  94.41704 210.74209 120.25662  77.61585 187.93204 206.49337 140.63167\n[64] 105.59678 130.70433 202.18535 171.13040 164.91423 124.72473 144.81031\n[71] 181.99635 199.41370 234.21436 145.95666  79.86703 157.36941 192.74413\n[78] 208.89814 158.58723 206.02196 107.47972 140.93599  54.82129  55.92573\n[85] 115.01180  78.95584  81.56087  54.37997 166.25435\n[1] 53.85345\n [1] 140.48933 180.39358 138.26095 292.70472 122.54954  93.61128 256.94944\n [8] 185.46641  86.49602 110.59468  95.04572 164.19550  60.59799 205.82696\n[15]  99.72760 131.91527 220.91412 247.87635 195.84576 215.78309 206.82609\n[22]  89.01546  72.05374 188.47495 155.71144 161.25320 189.08097 178.04174\n[29]  49.65268 110.50255 178.39994  90.08024 132.14592 181.98946 173.37371\n[36] 190.81088 123.38011 118.90948 146.69459  60.67799  74.18511 108.16651\n[43] 162.96844 151.55290 173.76202  64.54476  76.57353 109.83957  56.57150\n[50] 163.18082 155.23308  64.94611 110.68143 108.69309 172.00291 157.94955\n[57]  94.85887 208.43412 118.81318  72.11720 185.80486 203.47917 141.32148\n[64] 105.78699 127.73208 202.81245 168.55319 162.78472 120.58057 142.15774\n[71] 180.74854 196.43248 234.92016 143.87414  81.91095 153.24099 193.15008\n[78] 206.58954 158.12424 201.30839 112.09889 138.42467  54.61388  56.57972\n[85] 112.85844  83.27187  81.11235  59.60137 164.50759\n[1] 53.68696\n\n%%R\n\nplot(y_pred_ridge, y_test, type=\"p\", pch=19)\npoints(y_pred, y_test, col=\"blue\", pch=19)\nabline(a = 0, b = 1, col=\"red\")\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nT. Moudiki's Webpage - R\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "Demo usage of tisthemachinelearner, in Python and R",
      "meta_keywords": null,
      "og_description": "Demo usage of tisthemachinelearner, in Python and R",
      "og_image": "https://thierrymoudiki.github.io/images/2025-02-17/2025-02-17-image1.png",
      "og_title": "tisthemachinelearner: A Lightweight interface to scikit-learn with 2 classes, Classifier and Regressor (in Python and R) | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 9.5,
      "sitemap_lastmod": null,
      "twitter_description": "Demo usage of tisthemachinelearner, in Python and R",
      "twitter_title": "tisthemachinelearner: A Lightweight interface to scikit-learn with 2 classes, Classifier and Regressor (in Python and R) | R-bloggers",
      "url": "https://www.r-bloggers.com/2025/02/tisthemachinelearner-a-lightweight-interface-to-scikit-learn-with-2-classes-classifier-and-regressor-in-python-and-r/",
      "word_count": 1902
    }
  }
}