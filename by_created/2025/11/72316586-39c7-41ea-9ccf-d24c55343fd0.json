{
  "uuid": "72316586-39c7-41ea-9ccf-d24c55343fd0",
  "created_at": "2025-11-17 20:39:23",
  "raw_json": {
    "article_author": null,
    "article_headline": null,
    "article_modified": null,
    "article_published": null,
    "article_section": null,
    "article_tags": null,
    "canonical_url": "https://www.r-bloggers.com/2023/11/faqs-on-mixed-effects-models/",
    "crawled_at": "2025-11-17T10:00:41.391368",
    "external_links": [
      {
        "href": "https://pablobernabeu.github.io/2023/faqs-on-mixed-effects-models/",
        "text": "R on Pablo Bernabeu"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://doi.org/10.1016/S0022-5371(73)80014-3",
        "text": "Clark (1973)"
      },
      {
        "href": "https://psych.wisc.edu/Brauer/BrauerLab/wp-content/uploads/2014/04/Brauer-Curtin-2018-on-LMEMs.pdf",
        "text": "Brauer & Curtin, 2018"
      },
      {
        "href": "http://singmann.org/download/publications/singmann_kellen-introduction-mixed-models.pdf",
        "text": "Singmann & Kellen, 2019"
      },
      {
        "href": "https://psych.wisc.edu/Brauer/BrauerLab/wp-content/uploads/2014/04/Brauer-Curtin-2018-on-LMEMs.pdf",
        "text": "Brauer & Curtin, 2018"
      },
      {
        "href": "https://bookdown.org/pablobernabeu/language-sensorimotor-conceptual-processing-statistical-power/study-2.1-semantic-priming.html#semanticpriming-results",
        "text": "example"
      },
      {
        "href": "https://doi.org/10.3758/s13428-016-0809-y",
        "text": "Luke (2017)"
      },
      {
        "href": "https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf",
        "text": "lmerTest"
      },
      {
        "href": "https://cran.r-project.org/web/packages/afex/afex.pdf",
        "text": "afex"
      },
      {
        "href": "https://stackoverflow.com/questions/48315268/how-can-i-make-r-using-more-than-1-core-8-available-on-a-ubuntu-rstudio-server",
        "text": "here"
      },
      {
        "href": "https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q3/027170.html",
        "text": "here"
      },
      {
        "href": "https://github.com/lme4/lme4/issues?q=is%3Aissue+parallel",
        "text": "here"
      },
      {
        "href": "https://cran.r-project.org/web/packages/lme4/lme4.pdf",
        "text": "lme4"
      },
      {
        "href": "https://pablobernabeu.github.io/2023/faqs-on-mixed-effects-models/",
        "text": "surprised about them"
      },
      {
        "href": "https://github.com/lme4/lme4/issues/492",
        "text": "here"
      },
      {
        "href": "https://github.com/lme4/lme4/issues/627",
        "text": "here"
      },
      {
        "href": "https://osf.io/97u5c",
        "text": "https://osf.io/97u5c"
      },
      {
        "href": "https://pablobernabeu.github.io/2021/a-new-function-to-plot-convergence-diagnostics-from-lme4-allfit",
        "text": "blog post"
      },
      {
        "href": "https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/frequentist_analysis/semanticpriming_lmerTest.R#L109",
        "text": "increasing the max number of iterations"
      },
      {
        "href": "https://psych.wisc.edu/Brauer/BrauerLab/wp-content/uploads/2014/04/Brauer-Curtin-2018-on-LMEMs.pdf",
        "text": "Brauer & Curtin, 2018"
      },
      {
        "href": "https://pablobernabeu.github.io/2023/faqs-on-mixed-effects-models/",
        "text": "R on Pablo Bernabeu"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "h1_title": "R-bloggers",
    "html_title": "FAQs on mixed-effects models | R-bloggers",
    "images": [],
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/r-on-pablo-bernabeu/",
        "text": "R on Pablo Bernabeu"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "lang": "en-US",
    "main_html": "<article class=\"post-379696 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">FAQs on mixed-effects models</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">November 3, 2023</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/r-on-pablo-bernabeu/\">R on Pablo Bernabeu</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://pablobernabeu.github.io/2023/faqs-on-mixed-effects-models/\"> R on Pablo Bernabeu</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<blockquote style=\"color: black; background-color: #FFF9F3; margin-bottom: 30px;\">\n<p>I am dealing with nested data, and I remember from an article by <a href=\"https://doi.org/10.1016/S0022-5371(73)80014-3\" rel=\"nofollow\" target=\"_blank\">Clark (1973)</a> that nested should be analysed using special models. I’ve looked into mixed-effects models, and I’ve reached a structure with random intercepts by subjects and by items. Is this fine?</p>\n</blockquote>\n<div style=\"padding-left: 60px;\">\n<blockquote style=\"color: black; background-color: #F4FFF3; margin-bottom: 45px;\">\n<p>In early days, researchers would aggregate the data across these repeated measures to prevent the violation of the assumption of independence of observations, which is one of the most important assumptions in statistics. With the advent of mixed-effects models, researchers began accounting for these repeated measures using random intercepts and slopes. However, problems of convergence led many researchers to remove random slopes. This became widespread until, over the past few years, we have realised that random slopes are necessary to prevent an inflation of the Type I error due to the violation of the assumption of independence (<a href=\"https://psych.wisc.edu/Brauer/BrauerLab/wp-content/uploads/2014/04/Brauer-Curtin-2018-on-LMEMs.pdf\" rel=\"nofollow\" target=\"_blank\">Brauer &amp; Curtin, 2018</a>; <a href=\"http://singmann.org/download/publications/singmann_kellen-introduction-mixed-models.pdf\" rel=\"nofollow\" target=\"_blank\">Singmann &amp; Kellen, 2019</a>). Please see Table 17 in Brauer and Curtin (2018). Due to the present reasons, the models in the current article are anti-conservative. To redress this problem, please consider the inclusion of random slopes by participant for all between-items variables [e.g., <code>(stimulus_condition | participant)</code>], and random slopes by item for all between-participants variables [e.g., <code>(extraversion | item)</code>]. Interaction terms should also have the corresponding slopes, except when the variables in the interaction vary within different units, that is, one between participants and one between items (<a href=\"https://psych.wisc.edu/Brauer/BrauerLab/wp-content/uploads/2014/04/Brauer-Curtin-2018-on-LMEMs.pdf\" rel=\"nofollow\" target=\"_blank\">Brauer &amp; Curtin, 2018</a>). Each of the random intercepts and random slopes included in the model should be noted in the main text, for instance using footnotes in the results table (see <a href=\"https://bookdown.org/pablobernabeu/language-sensorimotor-conceptual-processing-statistical-power/study-2.1-semantic-priming.html#semanticpriming-results\" rel=\"nofollow\" target=\"_blank\">example</a>).</p>\n</blockquote>\n</div>\n<blockquote style=\"color: black; background-color: #FFF9F3; margin-bottom: 30px;\">\n<p>I calculated the <em>p</em> values by comparing minimally-different models using the <code>anova</code> function. Is this fine?</p>\n</blockquote>\n<div style=\"padding-left: 60px;\">\n<blockquote style=\"color: black; background-color: #F4FFF3; margin-bottom: 45px;\">\n<p><a href=\"https://doi.org/10.3758/s13428-016-0809-y\" rel=\"nofollow\" target=\"_blank\">Luke (2017)</a> warns that the <em>p</em> values calculated by model comparison—which are based on likelihood ratio tests—can be anti-conservative. Therefore, the Kenward-Roger and the Satterthwaite methods are recommended instead (both available in other packages, such as <a href=\"https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf\" rel=\"nofollow\" target=\"_blank\">lmerTest</a> and <a href=\"https://cran.r-project.org/web/packages/afex/afex.pdf\" rel=\"nofollow\" target=\"_blank\">afex</a>).</p>\n</blockquote>\n</div>\n<blockquote style=\"color: black; background-color: #FFF9F3; margin-bottom: 30px;\">\n<p>The lme4 package only runs on one thread (CPU) but the computer has 8. Do you have any advice on making the model run using more of the threads? It’s taking a very long time. I’ve seen these two possible solutions online from 2018 (<a href=\"https://stackoverflow.com/questions/48315268/how-can-i-make-r-using-more-than-1-core-8-available-on-a-ubuntu-rstudio-server\" rel=\"nofollow\" target=\"_blank\">here</a> and <a href=\"https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q3/027170.html\" rel=\"nofollow\" target=\"_blank\">here</a>) but would like some advice if they have any or have attempted either of these solutions.</p>\n</blockquote>\n<div style=\"padding-left: 60px;\">\n<blockquote style=\"color: black; background-color: #F4FFF3; margin-bottom: 45px;\">\n<p>From the information I have seen in the past as well as right now, parallelising (g)lmer intentionally would be very involved. There is certainly interest in it, as your resources show (also see <a href=\"https://github.com/lme4/lme4/issues?q=is%3Aissue+parallel\" rel=\"nofollow\" target=\"_blank\">here</a>). However, the current information suggests to me that it is not possible.</p>\n<p>Interestingly, some isolated cases of unintentional parallelisation have been documented, and the developers of the <a href=\"https://cran.r-project.org/web/packages/lme4/lme4.pdf\" rel=\"nofollow\" target=\"_blank\">lme4</a> package were <a href=\"https://pablobernabeu.github.io/2023/faqs-on-mixed-effects-models/\" rel=\"nofollow\" target=\"_blank\">surprised about them</a> because they have not created this feature (see <a href=\"https://github.com/lme4/lme4/issues/492\" rel=\"nofollow\" target=\"_blank\">here</a> and <a href=\"https://github.com/lme4/lme4/issues/627\" rel=\"nofollow\" target=\"_blank\">here</a>).</p>\n<p>I think the best approach may be running your model(s) in a high-performance computing (HPC) cluster. Although this would not reduce the amount of time required for each model, it would have two advantages. First, your own computers wouldn’t be busy for days, and second, you could even run several models at the same time without exhausting your own computers. I still have access to the HPC at my previous university, and it would be fine for me to send your model(s) there if that would help you. Feel free to let me know. Otherwise I can see that your university has this facility too.</p>\n</blockquote>\n</div>\n<blockquote style=\"color: black; background-color: #FFF9F3; margin-bottom: 30px;\">\n<p>We took your advice and ran the model on a supercomputer – it took roughly 2.5 days, which is what it took for the model to run on my iMac and a gaming laptop Vivienne has.</p>\n<p>The model, however, didn’t converge. We have read that you can use <code>allFit()</code> to try the fit with all available optimizers. Do you have any experience using this? If you did, I wondered where this would sit in the code for the model? How and where do I add this in to check all available optimizers, please?</p>\n<p>I have attached my code in a txt file and the data in excel for you to see, in case it is of any use.</p>\n</blockquote>\n<div style=\"padding-left: 60px;\">\n<blockquote style=\"color: black; background-color: #F4FFF3; margin-bottom: 45px;\">\n<p>The multi-optimizer check is indeed a way (albeit tentative) to probe into the convergence. Convergence has long been a fuzzy subject, as there are different standpoints depending on the degree of conservativeness that is sought after by the analysts.</p>\n<p>On Page 124 in my thesis (<a class=\"uri\" href=\"https://osf.io/97u5c\" rel=\"nofollow\" target=\"_blank\">https://osf.io/97u5c</a>), you can find this multi-optimizer check (also see this <a href=\"https://pablobernabeu.github.io/2021/a-new-function-to-plot-convergence-diagnostics-from-lme4-allfit\" rel=\"nofollow\" target=\"_blank\">blog post</a>). All the code is available on OSF. More generally, I discuss the issue of convergence throughout the thesis.</p>\n</blockquote>\n</div>\n<blockquote style=\"color: black; background-color: #FFF9F3; margin-bottom: 30px;\">\n<p>I have run the model with <code>optimizer=\"nloptwrap\"</code> and <code>algorithm=\"NLOPT_LN_BOBYQA\"</code> and received the following warning message (once the model ran) –</p>\n<pre>In optwrap(optimizer, devfun, start, rho$lower, control = control, :\nconvergence code 5 from nloptwrap: NLOPT_MAXEVAL_REACHED: optimization stopped becasue maxeval (above) was reached.</pre>\n<p>Does this mean that the model didn’t converge? I’m only asking because I wasn’t given a statement saying it didn’t converge, as it did with Nelder_Mead. It was stated (at the end of summary table)</p>\n<pre>Optimizer (Nelder_Mead) convergence code: 4 (failure to converge in 10000 evaluations)\nfailure to converge in 10000 evaluations</pre>\n</blockquote>\n<div style=\"padding-left: 60px;\">\n<blockquote style=\"color: black; background-color: #F4FFF3; margin-bottom: 45px;\">\n<p>Please try <a href=\"https://github.com/pablobernabeu/language-sensorimotor-simulation-PhD-thesis/blob/main/semanticpriming/frequentist_analysis/semanticpriming_lmerTest.R#L109\" rel=\"nofollow\" target=\"_blank\">increasing the max number of iterations</a>.</p>\n</blockquote>\n</div>\n<blockquote style=\"color: black; background-color: #FFF9F3; margin-bottom: 30px;\">\n<p>We increased the max number of iterations to 1e6 and then 1e7, and the model didn’t converge. But it has converged with <code>maxeval=1e8</code>.</p>\n<p>I wanted to ask please, do you know of any issues with the max iterations being this high and effecting the interpretability of the model? Or is it completely fine?</p>\n</blockquote>\n<div style=\"padding-left: 60px;\">\n<blockquote style=\"color: black; background-color: #F4FFF3; margin-bottom: 45px;\">\n<p>There are no side-effects to increasing the number of iterations (see Remedy 6 in <a href=\"https://psych.wisc.edu/Brauer/BrauerLab/wp-content/uploads/2014/04/Brauer-Curtin-2018-on-LMEMs.pdf\" rel=\"nofollow\" target=\"_blank\">Brauer &amp; Curtin, 2018</a>).</p>\n</blockquote>\n</div>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://pablobernabeu.github.io/2023/faqs-on-mixed-effects-models/\"> R on Pablo Bernabeu</a></strong>.</div>\n<hr>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</hr></div> </div>\n</article>",
    "main_text": "FAQs on mixed-effects models\nPosted on\nNovember 3, 2023\nby\nR on Pablo Bernabeu\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nR on Pablo Bernabeu\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nI am dealing with nested data, and I remember from an article by\nClark (1973)\nthat nested should be analysed using special models. I’ve looked into mixed-effects models, and I’ve reached a structure with random intercepts by subjects and by items. Is this fine?\nIn early days, researchers would aggregate the data across these repeated measures to prevent the violation of the assumption of independence of observations, which is one of the most important assumptions in statistics. With the advent of mixed-effects models, researchers began accounting for these repeated measures using random intercepts and slopes. However, problems of convergence led many researchers to remove random slopes. This became widespread until, over the past few years, we have realised that random slopes are necessary to prevent an inflation of the Type I error due to the violation of the assumption of independence (\nBrauer & Curtin, 2018\n;\nSingmann & Kellen, 2019\n). Please see Table 17 in Brauer and Curtin (2018). Due to the present reasons, the models in the current article are anti-conservative. To redress this problem, please consider the inclusion of random slopes by participant for all between-items variables [e.g.,\n(stimulus_condition | participant)\n], and random slopes by item for all between-participants variables [e.g.,\n(extraversion | item)\n]. Interaction terms should also have the corresponding slopes, except when the variables in the interaction vary within different units, that is, one between participants and one between items (\nBrauer & Curtin, 2018\n). Each of the random intercepts and random slopes included in the model should be noted in the main text, for instance using footnotes in the results table (see\nexample\n).\nI calculated the\np\nvalues by comparing minimally-different models using the\nanova\nfunction. Is this fine?\nLuke (2017)\nwarns that the\np\nvalues calculated by model comparison—which are based on likelihood ratio tests—can be anti-conservative. Therefore, the Kenward-Roger and the Satterthwaite methods are recommended instead (both available in other packages, such as\nlmerTest\nand\nafex\n).\nThe lme4 package only runs on one thread (CPU) but the computer has 8. Do you have any advice on making the model run using more of the threads? It’s taking a very long time. I’ve seen these two possible solutions online from 2018 (\nhere\nand\nhere\n) but would like some advice if they have any or have attempted either of these solutions.\nFrom the information I have seen in the past as well as right now, parallelising (g)lmer intentionally would be very involved. There is certainly interest in it, as your resources show (also see\nhere\n). However, the current information suggests to me that it is not possible.\nInterestingly, some isolated cases of unintentional parallelisation have been documented, and the developers of the\nlme4\npackage were\nsurprised about them\nbecause they have not created this feature (see\nhere\nand\nhere\n).\nI think the best approach may be running your model(s) in a high-performance computing (HPC) cluster. Although this would not reduce the amount of time required for each model, it would have two advantages. First, your own computers wouldn’t be busy for days, and second, you could even run several models at the same time without exhausting your own computers. I still have access to the HPC at my previous university, and it would be fine for me to send your model(s) there if that would help you. Feel free to let me know. Otherwise I can see that your university has this facility too.\nWe took your advice and ran the model on a supercomputer – it took roughly 2.5 days, which is what it took for the model to run on my iMac and a gaming laptop Vivienne has.\nThe model, however, didn’t converge. We have read that you can use\nallFit()\nto try the fit with all available optimizers. Do you have any experience using this? If you did, I wondered where this would sit in the code for the model? How and where do I add this in to check all available optimizers, please?\nI have attached my code in a txt file and the data in excel for you to see, in case it is of any use.\nThe multi-optimizer check is indeed a way (albeit tentative) to probe into the convergence. Convergence has long been a fuzzy subject, as there are different standpoints depending on the degree of conservativeness that is sought after by the analysts.\nOn Page 124 in my thesis (\nhttps://osf.io/97u5c\n), you can find this multi-optimizer check (also see this\nblog post\n). All the code is available on OSF. More generally, I discuss the issue of convergence throughout the thesis.\nI have run the model with\noptimizer=\"nloptwrap\"\nand\nalgorithm=\"NLOPT_LN_BOBYQA\"\nand received the following warning message (once the model ran) –\nIn optwrap(optimizer, devfun, start, rho$lower, control = control, :\nconvergence code 5 from nloptwrap: NLOPT_MAXEVAL_REACHED: optimization stopped becasue maxeval (above) was reached.\nDoes this mean that the model didn’t converge? I’m only asking because I wasn’t given a statement saying it didn’t converge, as it did with Nelder_Mead. It was stated (at the end of summary table)\nOptimizer (Nelder_Mead) convergence code: 4 (failure to converge in 10000 evaluations)\nfailure to converge in 10000 evaluations\nPlease try\nincreasing the max number of iterations\n.\nWe increased the max number of iterations to 1e6 and then 1e7, and the model didn’t converge. But it has converged with\nmaxeval=1e8\n.\nI wanted to ask please, do you know of any issues with the max iterations being this high and effecting the interpretability of the model? Or is it completely fine?\nThere are no side-effects to increasing the number of iterations (see Remedy 6 in\nBrauer & Curtin, 2018\n).\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nR on Pablo Bernabeu\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "meta_description": "I am dealing with nested data, and I remember from an article by Clark (1973) that nested should be analysed using special models. I’ve looked into mixed-effects models, and I’ve reached a structure with random intercepts by subjects and by items. ...",
    "meta_keywords": null,
    "og_description": "I am dealing with nested data, and I remember from an article by Clark (1973) that nested should be analysed using special models. I’ve looked into mixed-effects models, and I’ve reached a structure with random intercepts by subjects and by items. ...",
    "og_image": "https://www.r-bloggers.com/wp-content/uploads/2016/04/R_02_2016-05-01.png",
    "og_title": "FAQs on mixed-effects models | R-bloggers",
    "raw_jsonld_article": null,
    "reading_time_min": 5.5,
    "sitemap_lastmod": "2023-11-04T00:00:00+00:00",
    "twitter_description": "I am dealing with nested data, and I remember from an article by Clark (1973) that nested should be analysed using special models. I’ve looked into mixed-effects models, and I’ve reached a structure with random intercepts by subjects and by items. ...",
    "twitter_title": "FAQs on mixed-effects models | R-bloggers",
    "url": "https://www.r-bloggers.com/2023/11/faqs-on-mixed-effects-models/",
    "word_count": 1107
  }
}