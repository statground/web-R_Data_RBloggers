{
  "id": "713992f2cc342577081a9b56e4be67522b13fb7f",
  "url": "https://www.r-bloggers.com/2025/11/unifiedml-in-r-a-unified-machine-learning-interface/",
  "created_at_utc": "2025-11-22T19:57:26Z",
  "data": null,
  "raw_original": {
    "uuid": "032e1ada-e766-40fd-afd9-ba56932b7c12",
    "created_at": "2025-11-22 19:57:26",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2025/11/unifiedml-in-r-a-unified-machine-learning-interface/",
      "crawled_at": "2025-11-22T10:41:32.502976",
      "external_links": [
        {
          "href": "https://thierrymoudiki.github.io//blog/2025/11/05/r/unifiedml-in-r",
          "text": "T. Moudiki's Webpage - R"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://techtonique.github.io/unifiedml/index.html",
          "text": null
        },
        {
          "href": "https://thierrymoudiki.github.io//blog/2025/11/05/r/unifiedml-in-r",
          "text": "T. Moudiki's Webpage - R"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "unifiedml in R: A Unified Machine Learning Interface | R-bloggers",
      "images": [
        {
          "alt": "image-title-here",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "image-title-here",
          "base64": null,
          "src": "https://i0.wp.com/thierrymoudiki.github.io/images/2025-11-05/2025-11-05-unifiedml-in-r_4_7.png?w=578&ssl=1"
        },
        {
          "alt": "Documentation",
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": "Documentation",
          "base64": "data:image/jpeg;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNDAiIGhlaWdodD0iMjAiIHJvbGU9ImltZyIgYXJpYS1sYWJlbD0iZG9jdW1lbnRhdGlvbjogaXMgaGVyZSI+PHRpdGxlPmRvY3VtZW50YXRpb246IGlzIGhlcmU8L3RpdGxlPjxsaW5lYXJHcmFkaWVudCBpZD0icyIgeDI9IjAiIHkyPSIxMDAlIj48c3RvcCBvZmZzZXQ9IjAiIHN0b3AtY29sb3I9IiNiYmIiIHN0b3Atb3BhY2l0eT0iLjEiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3Atb3BhY2l0eT0iLjEiLz48L2xpbmVhckdyYWRpZW50PjxjbGlwUGF0aCBpZD0iciI+PHJlY3Qgd2lkdGg9IjE0MCIgaGVpZ2h0PSIyMCIgcng9IjMiIGZpbGw9IiNmZmYiLz48L2NsaXBQYXRoPjxnIGNsaXAtcGF0aD0idXJsKCNyKSI+PHJlY3Qgd2lkdGg9IjkzIiBoZWlnaHQ9IjIwIiBmaWxsPSIjNTU1Ii8+PHJlY3QgeD0iOTMiIHdpZHRoPSI0NyIgaGVpZ2h0PSIyMCIgZmlsbD0iIzk3Y2EwMCIvPjxyZWN0IHdpZHRoPSIxNDAiIGhlaWdodD0iMjAiIGZpbGw9InVybCgjcykiLz48L2c+PGcgZmlsbD0iI2ZmZiIgdGV4dC1hbmNob3I9Im1pZGRsZSIgZm9udC1mYW1pbHk9IlZlcmRhbmEsR2VuZXZhLERlamFWdSBTYW5zLHNhbnMtc2VyaWYiIHRleHQtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iIGZvbnQtc2l6ZT0iMTEwIj48dGV4dCBhcmlhLWhpZGRlbj0idHJ1ZSIgeD0iNDc1IiB5PSIxNTAiIGZpbGw9IiMwMTAxMDEiIGZpbGwtb3BhY2l0eT0iLjMiIHRyYW5zZm9ybT0ic2NhbGUoLjEpIiB0ZXh0TGVuZ3RoPSI4MzAiPmRvY3VtZW50YXRpb248L3RleHQ+PHRleHQgeD0iNDc1IiB5PSIxNDAiIHRyYW5zZm9ybT0ic2NhbGUoLjEpIiBmaWxsPSIjZmZmIiB0ZXh0TGVuZ3RoPSI4MzAiPmRvY3VtZW50YXRpb248L3RleHQ+PHRleHQgYXJpYS1oaWRkZW49InRydWUiIHg9IjExNTUiIHk9IjE1MCIgZmlsbD0iIzAxMDEwMSIgZmlsbC1vcGFjaXR5PSIuMyIgdHJhbnNmb3JtPSJzY2FsZSguMSkiIHRleHRMZW5ndGg9IjM3MCI+aXMgaGVyZTwvdGV4dD48dGV4dCB4PSIxMTU1IiB5PSIxNDAiIHRyYW5zZm9ybT0ic2NhbGUoLjEpIiBmaWxsPSIjZmZmIiB0ZXh0TGVuZ3RoPSIzNzAiPmlzIGhlcmU8L3RleHQ+PC9nPjwvc3ZnPg==",
          "src": "https://img.shields.io/badge/documentation-is_here-green"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/t-moudiki/",
          "text": "T. Moudiki"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-396787 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">unifiedml in R: A Unified Machine Learning Interface</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">November 4, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/t-moudiki/\">T. Moudiki</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://thierrymoudiki.github.io//blog/2025/11/05/r/unifiedml-in-r\"> T. Moudiki's Webpage - R</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47--><h1 id=\"unifiedml\">unifiedml</h1>\n<blockquote>\n<p>A Unified Machine Learning Interface for R</p>\n</blockquote>\n<h2 id=\"overview\">Overview</h2>\n<p><code>unifiedml</code> provides a consistent, sklearn-like interface for virtually any machine learning model in R.</p>\n<p>It eliminates the need to remember different function signatures across packages by <strong>automatically detecting the appropriate interface</strong> (formula vs matrix) and <strong>task type</strong> (regression vs classification).</p>\n<h3 id=\"key-features\">Key Features</h3>\n<p>For now:</p>\n<ul>\n<li><strong>Automatic Task Detection</strong>: Automatically detects regression vs classification based on response variable type (numeric → regression, factor → classification)</li>\n<li><strong>Universal Interface</strong>: Works seamlessly with <code>glmnet</code>, <code>randomForest</code>, <code>e1071::svm</code>, and other popular ML packages with formula or matrix interface</li>\n<li><strong>Built-in Cross-Validation</strong>: Consistent <code>cross_val_score()</code> function with automatic metric selection</li>\n<li><strong>Model Interpretability</strong>: Numerical derivatives and statistical significance testing via <code>summary()</code></li>\n<li><strong>Partial Dependence Plots</strong>: Visualize feature effects with <code>plot()</code></li>\n<li><strong>Method Chaining</strong>: Clean, pipeable syntax with R6 classes</li>\n</ul>\n<pre>devtools::install_github(\"Techtonique/unifiedml\")\n\ninstall.packages(c(\"glmnet\", \"randomForest\"))\n\ninstall.packages(\"e1071\")\n\nlibrary(unifiedml) # this package\nlibrary(glmnet)\nlibrary(randomForest)\nlibrary(e1071)\n\n# ------------------------------------------------------------\n# REGRESSION EXAMPLES\n# ------------------------------------------------------------\n\ncat(\"\\n=== REGRESSION EXAMPLES ===\\n\\n\")\n\n# Example 1: Synthetic data (numeric y → automatic regression)\nset.seed(123)\nX &lt;- MASS::Boston[, -ncol(MASS::Boston)]\ny &lt;- MASS::Boston$medv\n\n# glmnet regression\ncat(\"1. Ridge Regression (glmnet) - Auto-detected: Regression\\n\")\nmod1 &lt;- Model$new(glmnet::glmnet)  # No task parameter needed!\nmod1$fit(X, y, alpha = 0, lambda = 0.1)\nmod1$print()\ncat(\"\\nPredictions:\\n\")\nprint(head(mod1$predict(X)))\ncat(\"\\n\")\nmod1$summary()\nmod1$plot(feature = 1)\n(cv1 &lt;- cross_val_score(mod1, X, y, cv = 5L))  # Auto-uses RMSE\ncat(\"\\nMean RMSE:\", mean(cv1), \"\\n\\n\")\n\n# randomForest regression\ncat(\"\\n2. Random Forest Regression - Auto-detected: Regression\\n\")\nmod2 &lt;- Model$new(randomForest::randomForest)  # No task parameter!\nmod2$fit(X, y, ntree = 50)\nmod2$print()\ncat(\"\\n\")\nmod2$summary(h = 0.01)\n\n# ------------------------------------------------------------\n# CLASSIFICATION EXAMPLES\n# ------------------------------------------------------------\n\ncat(\"\\n\\n=== CLASSIFICATION EXAMPLES ===\\n\\n\")\n\n# Example: Iris dataset (factor y → automatic classification)\ndata(iris)\n\n# Binary classification with factor\ncat(\"3. Binary Classification with Factor Response\\n\")\niris_binary &lt;- iris[iris$Species %in% c(\"setosa\", \"versicolor\"), ]\nX_binary &lt;- as.matrix(iris_binary[, 1:4])\ny_binary &lt;- iris_binary$Species  # factor → classification\n\n# Multi-class classification\ncat(\"4. Multi-class Classification\\n\")\nX_multi &lt;- as.matrix(iris[, 1:4])\ny_multi &lt;- iris$Species  # factor with 3 levels → multi-class classification\n\nmod4 &lt;- Model$new(randomForest::randomForest)  # No task parameter!\nmod4$fit(X_multi, y_multi, ntree = 50)\nmod4$print()\n(cv4 &lt;- cross_val_score(mod4, X_multi, y_multi, cv = 5L))  # Auto-uses accuracy\ncat(\"\\nMean Accuracy:\", mean(cv4), \"\\n\")\n\n\ny_multi_numeric &lt;- as.numeric(y_multi)\nmod4 &lt;- Model$new(glmnet::glmnet)  # No task parameter!\nmod4$fit(X_multi, y_multi_numeric, family=\"multinomial\")\nmod4$print()\n(cv4 &lt;- cross_val_score(mod4, X_multi, y_multi_numeric, cv = 5L))  # Auto-uses accuracy\ncat(\"\\nMean Accuracy:\", mean(cv4), \"\\n\")\n\n=== REGRESSION EXAMPLES ===\n\n1. Ridge Regression (glmnet) - Auto-detected: Regression\nModel Object\n------------\nModel function: self$model_fn \nFitted: TRUE \nTask: regression \nTraining samples: 506 \nFeatures: 13 \n\nPredictions:\n       1        2        3        4        5        6 \n30.12476 25.01360 30.57030 28.68765 28.04710 25.31151 \n\n\nModel Summary - Numerical Derivatives\n======================================\nTask: regression \nSamples: 506 | Features: 13 \nStep size (h): 0.01 \n\n Feature Mean_Derivative    Std_Error       t_value p_value Significance\n    crim   -1.032452e-01 7.837905e-15 -1.317256e+13       0          ***\n      zn    4.322719e-02 5.216968e-15  8.285883e+12       0          ***\n   indus    2.743581e-03 1.273890e-14  2.153704e+11       0          ***\n    chas    2.753495e+00 6.050646e-15  4.550745e+14       0          ***\n     nox   -1.656232e+01 1.293028e-14 -1.280894e+15       0          ***\n      rm    3.868607e+00 9.300418e-15  4.159605e+14       0          ***\n     age   -4.129908e-04 1.108270e-14 -3.726444e+10       0          ***\n     dis   -1.411492e+00 4.776813e-15 -2.954882e+14       0          ***\n     rad    2.655385e-01 7.851465e-15  3.382025e+13       0          ***\n     tax   -1.038490e-02 8.323530e-15 -1.247656e+12       0          ***\n ptratio   -9.325559e-01 6.254096e-15 -1.491112e+14       0          ***\n   black    9.272792e-03 3.489110e-15  2.657638e+12       0          ***\n   lstat   -5.149643e-01 4.667193e-15 -1.103371e+14       0          ***\n\nSignificance codes: 0 '***' 0.01 '**' 0.05 '*' 0.1 ' ' 1\n  |======================================================================| 100%\n</pre>\n\n<p></p><ol class=\"list-inline\"><li>5.25548773596251</li><li>6.05059820073108</li><li>6.14742810453446</li><li>5.05465660887574</li><li>4.9428693648005</li></ol>\n<pre>Mean RMSE: 5.490208 \n\n\n2. Random Forest Regression - Auto-detected: Regression\nModel Object\n------------\nModel function: self$model_fn \nFitted: TRUE \nTask: regression \nTraining samples: 506 \nFeatures: 13 \n\n\nModel Summary - Numerical Derivatives\n======================================\nTask: regression \nSamples: 506 | Features: 13 \nStep size (h): 0.01 \n\n Feature Mean_Derivative   Std_Error    t_value      p_value Significance\n    crim      0.27808959 0.329662424  0.8435587 3.993155e-01             \n      zn      0.00000000 0.000000000        NaN          NaN         &lt;NA&gt;\n   indus      0.03961792 0.030839187  1.2846616 1.994995e-01            *\n    chas      0.00000000 0.000000000        NaN          NaN         &lt;NA&gt;\n     nox     -7.59855104 1.939451552 -3.9178865 1.016265e-04          ***\n      rm      4.33226614 0.538906676  8.0389914 6.471192e-15          ***\n     age     -0.02569829 0.023089867 -1.1129682 2.662516e-01             \n     dis     -0.71310569 0.405677973 -1.7578122 7.938528e-02           **\n     rad      0.01739130 0.017453435  0.9964402 3.195135e-01             \n     tax     -0.01361660 0.008303022 -1.6399573 1.016368e-01            *\n ptratio     -0.03075099 0.024143264 -1.2736881 2.033599e-01             \n   black      0.05649539 0.045334095  1.2462009 2.132684e-01             \n   lstat     -0.47499012 0.124407440 -3.8180202 1.512437e-04          ***\n\nSignificance codes: 0 '***' 0.01 '**' 0.05 '*' 0.1 ' ' 1\n\n\n=== CLASSIFICATION EXAMPLES ===\n\n3. Binary Classification with Factor Response\n4. Multi-class Classification\nModel Object\n------------\nModel function: self$model_fn \nFitted: TRUE \nTask: classification \nTraining samples: 150 \nFeatures: 4 \nClasses: setosa, versicolor, virginica \nClass distribution:\n\n    setosa versicolor  virginica \n        50         50         50 \n  |======================================================================| 100%\n</pre>\n\n<p></p><ol class=\"list-inline\"><li>0.966666666666667</li><li>0.933333333333333</li><li>1</li><li>0.966666666666667</li><li>0.933333333333333</li></ol>\n<pre>Mean Accuracy: 0.96 \nModel Object\n------------\nModel function: self$model_fn \nFitted: TRUE \nTask: regression \nTraining samples: 150 \nFeatures: 4 \n  |======================================================================| 100%\n</pre>\n\n<p></p><ol class=\"list-inline\"><li>0.318625110272249</li><li>0.350013640071924</li><li>0.319135702141902</li><li>0.27769983668844</li><li>0.348586362350429</li></ol>\n<pre>Mean Accuracy: 0.3228121 \n</pre>\n<p><img alt=\"image-title-here\" class=\"img-responsive\" data-lazy-src=\"https://i0.wp.com/thierrymoudiki.github.io/images/2025-11-05/2025-11-05-unifiedml-in-r_4_7.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"image-title-here\" class=\"img-responsive\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/thierrymoudiki.github.io/images/2025-11-05/2025-11-05-unifiedml-in-r_4_7.png?w=578&amp;ssl=1\"/></noscript></p>\n<p><a href=\"https://techtonique.github.io/unifiedml/index.html\" rel=\"nofollow\" target=\"_blank\"><img alt=\"Documentation\" data-lazy-src=\"https://img.shields.io/badge/documentation-is_here-green\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"Documentation\" src=\"https://img.shields.io/badge/documentation-is_here-green\"/></noscript></a></p>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://thierrymoudiki.github.io//blog/2025/11/05/r/unifiedml-in-r\"> T. Moudiki's Webpage - R</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
      "main_text": "unifiedml in R: A Unified Machine Learning Interface\nPosted on\nNovember 4, 2025\nby\nT. Moudiki\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nT. Moudiki's Webpage - R\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nunifiedml\nA Unified Machine Learning Interface for R\nOverview\nunifiedml\nprovides a consistent, sklearn-like interface for virtually any machine learning model in R.\nIt eliminates the need to remember different function signatures across packages by\nautomatically detecting the appropriate interface\n(formula vs matrix) and\ntask type\n(regression vs classification).\nKey Features\nFor now:\nAutomatic Task Detection\n: Automatically detects regression vs classification based on response variable type (numeric → regression, factor → classification)\nUniversal Interface\n: Works seamlessly with\nglmnet\n,\nrandomForest\n,\ne1071::svm\n, and other popular ML packages with formula or matrix interface\nBuilt-in Cross-Validation\n: Consistent\ncross_val_score()\nfunction with automatic metric selection\nModel Interpretability\n: Numerical derivatives and statistical significance testing via\nsummary()\nPartial Dependence Plots\n: Visualize feature effects with\nplot()\nMethod Chaining\n: Clean, pipeable syntax with R6 classes\ndevtools::install_github(\"Techtonique/unifiedml\")\n\ninstall.packages(c(\"glmnet\", \"randomForest\"))\n\ninstall.packages(\"e1071\")\n\nlibrary(unifiedml) # this package\nlibrary(glmnet)\nlibrary(randomForest)\nlibrary(e1071)\n\n# ------------------------------------------------------------\n# REGRESSION EXAMPLES\n# ------------------------------------------------------------\n\ncat(\"\\n=== REGRESSION EXAMPLES ===\\n\\n\")\n\n# Example 1: Synthetic data (numeric y → automatic regression)\nset.seed(123)\nX <- MASS::Boston[, -ncol(MASS::Boston)]\ny <- MASS::Boston$medv\n\n# glmnet regression\ncat(\"1. Ridge Regression (glmnet) - Auto-detected: Regression\\n\")\nmod1 <- Model$new(glmnet::glmnet)  # No task parameter needed!\nmod1$fit(X, y, alpha = 0, lambda = 0.1)\nmod1$print()\ncat(\"\\nPredictions:\\n\")\nprint(head(mod1$predict(X)))\ncat(\"\\n\")\nmod1$summary()\nmod1$plot(feature = 1)\n(cv1 <- cross_val_score(mod1, X, y, cv = 5L))  # Auto-uses RMSE\ncat(\"\\nMean RMSE:\", mean(cv1), \"\\n\\n\")\n\n# randomForest regression\ncat(\"\\n2. Random Forest Regression - Auto-detected: Regression\\n\")\nmod2 <- Model$new(randomForest::randomForest)  # No task parameter!\nmod2$fit(X, y, ntree = 50)\nmod2$print()\ncat(\"\\n\")\nmod2$summary(h = 0.01)\n\n# ------------------------------------------------------------\n# CLASSIFICATION EXAMPLES\n# ------------------------------------------------------------\n\ncat(\"\\n\\n=== CLASSIFICATION EXAMPLES ===\\n\\n\")\n\n# Example: Iris dataset (factor y → automatic classification)\ndata(iris)\n\n# Binary classification with factor\ncat(\"3. Binary Classification with Factor Response\\n\")\niris_binary <- iris[iris$Species %in% c(\"setosa\", \"versicolor\"), ]\nX_binary <- as.matrix(iris_binary[, 1:4])\ny_binary <- iris_binary$Species  # factor → classification\n\n# Multi-class classification\ncat(\"4. Multi-class Classification\\n\")\nX_multi <- as.matrix(iris[, 1:4])\ny_multi <- iris$Species  # factor with 3 levels → multi-class classification\n\nmod4 <- Model$new(randomForest::randomForest)  # No task parameter!\nmod4$fit(X_multi, y_multi, ntree = 50)\nmod4$print()\n(cv4 <- cross_val_score(mod4, X_multi, y_multi, cv = 5L))  # Auto-uses accuracy\ncat(\"\\nMean Accuracy:\", mean(cv4), \"\\n\")\n\ny_multi_numeric <- as.numeric(y_multi)\nmod4 <- Model$new(glmnet::glmnet)  # No task parameter!\nmod4$fit(X_multi, y_multi_numeric, family=\"multinomial\")\nmod4$print()\n(cv4 <- cross_val_score(mod4, X_multi, y_multi_numeric, cv = 5L))  # Auto-uses accuracy\ncat(\"\\nMean Accuracy:\", mean(cv4), \"\\n\")\n\n=== REGRESSION EXAMPLES ===\n\n1. Ridge Regression (glmnet) - Auto-detected: Regression\nModel Object\n------------\nModel function: self$model_fn \nFitted: TRUE \nTask: regression \nTraining samples: 506 \nFeatures: 13 \n\nPredictions:\n       1        2        3        4        5        6 \n30.12476 25.01360 30.57030 28.68765 28.04710 25.31151 \n\nModel Summary - Numerical Derivatives\n======================================\nTask: regression \nSamples: 506 | Features: 13 \nStep size (h): 0.01 \n\n Feature Mean_Derivative    Std_Error       t_value p_value Significance\n    crim   -1.032452e-01 7.837905e-15 -1.317256e+13       0          ***\n      zn    4.322719e-02 5.216968e-15  8.285883e+12       0          ***\n   indus    2.743581e-03 1.273890e-14  2.153704e+11       0          ***\n    chas    2.753495e+00 6.050646e-15  4.550745e+14       0          ***\n     nox   -1.656232e+01 1.293028e-14 -1.280894e+15       0          ***\n      rm    3.868607e+00 9.300418e-15  4.159605e+14       0          ***\n     age   -4.129908e-04 1.108270e-14 -3.726444e+10       0          ***\n     dis   -1.411492e+00 4.776813e-15 -2.954882e+14       0          ***\n     rad    2.655385e-01 7.851465e-15  3.382025e+13       0          ***\n     tax   -1.038490e-02 8.323530e-15 -1.247656e+12       0          ***\n ptratio   -9.325559e-01 6.254096e-15 -1.491112e+14       0          ***\n   black    9.272792e-03 3.489110e-15  2.657638e+12       0          ***\n   lstat   -5.149643e-01 4.667193e-15 -1.103371e+14       0          ***\n\nSignificance codes: 0 '***' 0.01 '**' 0.05 '*' 0.1 ' ' 1\n  |======================================================================| 100%\n5.25548773596251\n6.05059820073108\n6.14742810453446\n5.05465660887574\n4.9428693648005\nMean RMSE: 5.490208 \n\n2. Random Forest Regression - Auto-detected: Regression\nModel Object\n------------\nModel function: self$model_fn \nFitted: TRUE \nTask: regression \nTraining samples: 506 \nFeatures: 13 \n\nModel Summary - Numerical Derivatives\n======================================\nTask: regression \nSamples: 506 | Features: 13 \nStep size (h): 0.01 \n\n Feature Mean_Derivative   Std_Error    t_value      p_value Significance\n    crim      0.27808959 0.329662424  0.8435587 3.993155e-01             \n      zn      0.00000000 0.000000000        NaN          NaN         <NA>\n   indus      0.03961792 0.030839187  1.2846616 1.994995e-01            *\n    chas      0.00000000 0.000000000        NaN          NaN         <NA>\n     nox     -7.59855104 1.939451552 -3.9178865 1.016265e-04          ***\n      rm      4.33226614 0.538906676  8.0389914 6.471192e-15          ***\n     age     -0.02569829 0.023089867 -1.1129682 2.662516e-01             \n     dis     -0.71310569 0.405677973 -1.7578122 7.938528e-02           **\n     rad      0.01739130 0.017453435  0.9964402 3.195135e-01             \n     tax     -0.01361660 0.008303022 -1.6399573 1.016368e-01            *\n ptratio     -0.03075099 0.024143264 -1.2736881 2.033599e-01             \n   black      0.05649539 0.045334095  1.2462009 2.132684e-01             \n   lstat     -0.47499012 0.124407440 -3.8180202 1.512437e-04          ***\n\nSignificance codes: 0 '***' 0.01 '**' 0.05 '*' 0.1 ' ' 1\n\n=== CLASSIFICATION EXAMPLES ===\n\n3. Binary Classification with Factor Response\n4. Multi-class Classification\nModel Object\n------------\nModel function: self$model_fn \nFitted: TRUE \nTask: classification \nTraining samples: 150 \nFeatures: 4 \nClasses: setosa, versicolor, virginica \nClass distribution:\n\n    setosa versicolor  virginica \n        50         50         50 \n  |======================================================================| 100%\n0.966666666666667\n0.933333333333333\n1\n0.966666666666667\n0.933333333333333\nMean Accuracy: 0.96 \nModel Object\n------------\nModel function: self$model_fn \nFitted: TRUE \nTask: regression \nTraining samples: 150 \nFeatures: 4 \n  |======================================================================| 100%\n0.318625110272249\n0.350013640071924\n0.319135702141902\n0.27769983668844\n0.348586362350429\nMean Accuracy: 0.3228121\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nT. Moudiki's Webpage - R\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "A Unified Machine Learning Interface for R, providing a consistent sklearn-like API for various ML models.",
      "meta_keywords": null,
      "og_description": "A Unified Machine Learning Interface for R, providing a consistent sklearn-like API for various ML models.",
      "og_image": "https://thierrymoudiki.github.io/images/2025-11-05/2025-11-05-unifiedml-in-r_4_7.png",
      "og_title": "unifiedml in R: A Unified Machine Learning Interface | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 5.3,
      "sitemap_lastmod": null,
      "twitter_description": "A Unified Machine Learning Interface for R, providing a consistent sklearn-like API for various ML models.",
      "twitter_title": "unifiedml in R: A Unified Machine Learning Interface | R-bloggers",
      "url": "https://www.r-bloggers.com/2025/11/unifiedml-in-r-a-unified-machine-learning-interface/",
      "word_count": 1060
    }
  }
}