{
  "uuid": "4ce0bc47-ee13-4c9b-82b9-7c294d4f1ab8",
  "created_at": "2025-11-22 19:58:11",
  "raw_json": {
    "article_author": null,
    "article_headline": null,
    "article_modified": null,
    "article_published": null,
    "article_section": null,
    "article_tags": null,
    "canonical_url": "https://www.r-bloggers.com/2025/07/you-can-outsource-the-grunt-work-to-an-llm-not-expertise/",
    "crawled_at": "2025-11-22T10:46:14.456825",
    "external_links": [
      {
        "href": "https://b-rodrigues.github.io/posts/2025-07-03-llm_time.html",
        "text": "Econometrics and Free Software"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://b-rodrigues.github.io/posts/2025-07-03-llm_time.html",
        "text": "Econometrics and Free Software"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "h1_title": "R-bloggers",
    "html_title": "You can outsource the grunt work to an LLM, not expertise | R-bloggers",
    "images": [
      {
        "alt": null,
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": null,
        "base64": null,
        "src": "https://i0.wp.com/b-rodrigues.github.io/assets/img/llm_nope_lmao.png?w=578&ssl=1"
      }
    ],
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/econometrics-and-free-software/",
        "text": "Econometrics and Free Software"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "lang": "en-US",
    "main_html": "<article class=\"post-393707 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">You can outsource the grunt work to an LLM, not expertise</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">July 2, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/econometrics-and-free-software/\">Econometrics and Free Software</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://b-rodrigues.github.io/posts/2025-07-03-llm_time.html\"> Econometrics and Free Software</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"text-align: center;\">\n<p>\n<a> <img data-lazy-src=\"https://i0.wp.com/b-rodrigues.github.io/assets/img/llm_nope_lmao.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" style=\"width: 100%; height: auto;\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i0.wp.com/b-rodrigues.github.io/assets/img/llm_nope_lmao.png?w=578&amp;ssl=1\" style=\"width: 100%; height: auto;\"/></noscript> </a>\n</p>\n</div>\n<p>The more I use LLMs for programming, the more it seems to me that they can only be used successfully if you ask them to do things that you could do yourself.</p>\n<p>This seems to be the case because:</p>\n<ul>\n<li>you know exactly what you want/need and thus can exactly describe it;</li>\n<li>you know exactly if the LLM is actually delivering quality code or not;</li>\n<li>you know exactly if something the LLM suggests that you hadn’t thought about actually makes sense;</li>\n</ul>\n<p>This reminds me of my consulting years, where it was quite easy to predict if a consulting project would be successful. If the client could do it themselves <em>if they had time</em>, the project would always be successful. They knew exactly what they needed and could describe it to us, and most importantly, there was a very tight feedback loop between our intermediary outputs and their review. But when we were brought in and clients didn’t even understand what their problem was (but thought they knew), this is where things were difficult.</p>\n<p>It seems to me that as long as people cannot communicate their needs clearly, developers will keep their jobs.</p>\n<p>Now, this doesn’t mean that you cannot do things outside of your expertise with LLMs, but you must then use the LLM to teach you enough (alongside more traditional methods), or you must do something so trivial and done a billion times before and low stakes enough that you can blindly trust the output.</p>\n<p>I’ve used an LLM recently to write code to parse json and XML files, which is something I’ve done in the past and which I’m quite happy to likely never have to do myself again. The output was quite good, and only required minor correction before working. To help the LLM generate a correct output, I gave it one XML file as context.</p>\n<p>Another thing I ask the LLM to do is to write code to get data from the Openalex api using the <code>{openalexR}</code> package. To help it, I gave it the package’s and api’s documentation. Here again, the code worked flawlessly, and again, this is something I <em>could</em> have done myself, so my prompt was quite precise and I knew I had to give the LLM <em>something</em> to ensure it generated valid code.</p>\n<p>Btw, I’ve been using Claude Sonnet 4 and it works quite well for R. But I also like Gemini because of its very large context window.</p>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://b-rodrigues.github.io/posts/2025-07-03-llm_time.html\"> Econometrics and Free Software</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
    "main_text": "You can outsource the grunt work to an LLM, not expertise\nPosted on\nJuly 2, 2025\nby\nEconometrics and Free Software\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nEconometrics and Free Software\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nThe more I use LLMs for programming, the more it seems to me that they can only be used successfully if you ask them to do things that you could do yourself.\nThis seems to be the case because:\nyou know exactly what you want/need and thus can exactly describe it;\nyou know exactly if the LLM is actually delivering quality code or not;\nyou know exactly if something the LLM suggests that you hadn’t thought about actually makes sense;\nThis reminds me of my consulting years, where it was quite easy to predict if a consulting project would be successful. If the client could do it themselves\nif they had time\n, the project would always be successful. They knew exactly what they needed and could describe it to us, and most importantly, there was a very tight feedback loop between our intermediary outputs and their review. But when we were brought in and clients didn’t even understand what their problem was (but thought they knew), this is where things were difficult.\nIt seems to me that as long as people cannot communicate their needs clearly, developers will keep their jobs.\nNow, this doesn’t mean that you cannot do things outside of your expertise with LLMs, but you must then use the LLM to teach you enough (alongside more traditional methods), or you must do something so trivial and done a billion times before and low stakes enough that you can blindly trust the output.\nI’ve used an LLM recently to write code to parse json and XML files, which is something I’ve done in the past and which I’m quite happy to likely never have to do myself again. The output was quite good, and only required minor correction before working. To help the LLM generate a correct output, I gave it one XML file as context.\nAnother thing I ask the LLM to do is to write code to get data from the Openalex api using the\n{openalexR}\npackage. To help it, I gave it the package’s and api’s documentation. Here again, the code worked flawlessly, and again, this is something I\ncould\nhave done myself, so my prompt was quite precise and I knew I had to give the LLM\nsomething\nto ensure it generated valid code.\nBtw, I’ve been using Claude Sonnet 4 and it works quite well for R. But I also like Gemini because of its very large context window.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nEconometrics and Free Software\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "meta_description": "The more I use LLMs for programming, the more it seems to me that they can only be used successfully if you ask them to do things that you could do yourself. This seems to be the case because: you know exactly what you want/need and thus ...",
    "meta_keywords": null,
    "og_description": "The more I use LLMs for programming, the more it seems to me that they can only be used successfully if you ask them to do things that you could do yourself. This seems to be the case because: you know exactly what you want/need and thus ...",
    "og_image": "https://b-rodrigues.github.io/assets/img/llm_nope_lmao.png",
    "og_title": "You can outsource the grunt work to an LLM, not expertise | R-bloggers",
    "raw_jsonld_article": null,
    "reading_time_min": 2.8,
    "sitemap_lastmod": null,
    "twitter_description": "The more I use LLMs for programming, the more it seems to me that they can only be used successfully if you ask them to do things that you could do yourself. This seems to be the case because: you know exactly what you want/need and thus ...",
    "twitter_title": "You can outsource the grunt work to an LLM, not expertise | R-bloggers",
    "url": "https://www.r-bloggers.com/2025/07/you-can-outsource-the-grunt-work-to-an-llm-not-expertise/",
    "word_count": 567
  }
}