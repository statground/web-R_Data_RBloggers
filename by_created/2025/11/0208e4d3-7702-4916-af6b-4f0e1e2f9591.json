{
  "uuid": "0208e4d3-7702-4916-af6b-4f0e1e2f9591",
  "created_at": "2025-11-17 20:39:56",
  "raw_json": {
    "article_author": null,
    "article_headline": null,
    "article_modified": null,
    "article_published": null,
    "article_section": null,
    "article_tags": null,
    "canonical_url": "https://www.r-bloggers.com/2009/11/r-examine-objects-tutorial/",
    "crawled_at": "2025-11-17T10:16:04.710918",
    "external_links": [
      {
        "href": "http://www.win-vector.com/blog/2009/11/r-examine-objects-tutorial/?utm_source=rss&utm_medium=rss&utm_campaign=r-examine-objects-tutorial",
        "text": "Win-Vector Blog » R"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "http://www.win-vector.com/blog/2009/09/survive-r/",
        "text": "Survive R"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "The R Project for Statistical Computing"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://en.wikipedia.org/wiki/Linear_regression",
        "text": "linear regression"
      },
      {
        "href": "http://www.win-vector.com/blog/2009/09/survive-r/",
        "text": "Survive R"
      },
      {
        "href": "http://www.win-vector.com/blog/2009/09/survive-r/",
        "text": "Survive R"
      },
      {
        "href": "http://www.win-vector.com/blog/2011/02/the-cranky-guide-to-trying-r-packages/",
        "text": "The cranky guide to trying R packages"
      },
      {
        "href": "http://www.win-vector.com/blog/2010/03/r-annoyances/",
        "text": "R annoyances"
      },
      {
        "href": "http://www.win-vector.com/blog/2009/11/r-examine-objects-tutorial/?utm_source=rss&utm_medium=rss&utm_campaign=r-examine-objects-tutorial",
        "text": "Win-Vector Blog » R"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "h1_title": "R-bloggers",
    "html_title": "R examine objects tutorial | R-bloggers",
    "images": [
      {
        "alt": "dat1.png",
        "base64": null,
        "src": "https://i2.wp.com/www.win-vector.com/blog/wp-content/uploads/2009/11/dat1.png?w=450"
      },
      {
        "alt": "dat1.png",
        "base64": null,
        "src": "https://i2.wp.com/www.win-vector.com/blog/wp-content/uploads/2009/11/dat1.png?w=450"
      },
      {
        "alt": "fit1.png",
        "base64": null,
        "src": "https://i0.wp.com/www.win-vector.com/blog/wp-content/uploads/2009/11/fit1.png?w=450"
      },
      {
        "alt": "fit1.png",
        "base64": null,
        "src": "https://i0.wp.com/www.win-vector.com/blog/wp-content/uploads/2009/11/fit1.png?w=450"
      }
    ],
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/john-mount/",
        "text": "John Mount"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/tag/coding/",
        "text": "Coding"
      },
      {
        "href": "https://www.r-bloggers.com/tag/r/",
        "text": "R"
      },
      {
        "href": "https://www.r-bloggers.com/tag/statistics/",
        "text": "statistics"
      },
      {
        "href": "https://www.r-bloggers.com/tag/tutorial/",
        "text": "tutorial"
      },
      {
        "href": "https://www.r-bloggers.com/tag/tutorials/",
        "text": "Tutorials"
      }
    ],
    "lang": "en-US",
    "main_html": "<article class=\"post-58488 post type-post status-publish format-standard hentry category-r-bloggers tag-coding tag-r tag-statistics tag-tutorial tag-tutorials\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">R examine objects tutorial</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">November 21, 2009</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/john-mount/\">John Mount</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<p class=\"syndicated-attribution\"><!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"http://www.win-vector.com/blog/2009/11/r-examine-objects-tutorial/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=r-examine-objects-tutorial\"> Win-Vector Blog » R</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div></p>\n\n<!-- Share buttons by mashshare.net - Version: 3.8.0--><p>This article is quick concrete example of how to use the techniques from  <a href=\"http://www.win-vector.com/blog/2009/09/survive-r/\" rel=\"nofollow\" target=\"_blank\">Survive R</a> to lower the steepness of <a href=\"https://www.r-project.org/\" rel=\"nofollow\" target=\"_blank\">The R Project for Statistical Computing</a>‘s learning curve (so an apology to all readers who are not interested in R).  What follows is for people who already use R and want to achieve more control of the software.<span id=\"more-1134\"></span><br/>\nI am a fan of the <a href=\"https://www.r-project.org/\" rel=\"nofollow\" target=\"_blank\">R</a>.  The R software does a number of incredible things and is the result of a number of good design choices.  However, you can’t fully benefit from R if you are not already familiar the internal workings of R.  You can quickly become familiar with the internal workings of R if you learn how to inspect the objects of R (as an addition to using the built in help system).  Here I give a concrete example of how to use the R system itself to find answers, with or without the help system.  R documentation has the difficult dual responsibility of attempting to explain both how to use the R software and explain the nature of the underlying statistics; so the documentation is not always the quickest thing to browse.</p>\n<p>First let’s give R the commands to build a fake data set that has a variable y that turns out to be 3 times x (another variable) plus some noise:</p>\n<pre>\n&gt; n &lt;- 100\n&gt; x &lt;- rnorm(n)\n&gt; y &lt;- 3*x + 0.2*rnorm(n)\n&gt; d &lt;- data.frame(x,y)\n</pre>\n<p>This data set (by design) has a nearly a linear relation between x and y.  We can plot<br/>\nthe data as follows:</p>\n<pre>\n&gt; library(ggplot2)\n&gt; ggplot(data=d) + geom_point(aes(x=x,y=y))\n</pre>\n<p><center><br/>\n<img alt=\"dat1.png\" border=\"0\" class=\"jetpack-lazy-image\" data-lazy-src=\"https://i2.wp.com/www.win-vector.com/blog/wp-content/uploads/2009/11/dat1.png?w=450&amp;is-pending-load=1\" data-recalc-dims=\"1\" loading=\"lazy\" src=\"https://i2.wp.com/www.win-vector.com/blog/wp-content/uploads/2009/11/dat1.png?w=450\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"/><noscript><img alt=\"dat1.png\" border=\"0\" data-recalc-dims=\"1\" loading=\"lazy\" src=\"https://i2.wp.com/www.win-vector.com/blog/wp-content/uploads/2009/11/dat1.png?w=450\"/></noscript><br/>\n</center></p>\n<p>With data like this the most obvious statistical analysis is a <a href=\"https://en.wikipedia.org/wiki/Linear_regression\" rel=\"nofollow\" target=\"_blank\">linear regression</a>.  R can very quickly perform the linear regression and report the results.</p>\n<pre>\n&gt; model &lt;- lm(y~x,data=d)\n&gt; summary(model)\n\nCall:\nlm(formula = y ~ x, data = d)\n\nResiduals:\n     Min       1Q   Median       3Q      Max\n-0.41071 -0.12762 -0.00651  0.10240  0.62772 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) -0.02609    0.02102  -1.241    0.217\nx            2.99150    0.02202 135.858   &lt;2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 \n\nResidual standard error: 0.2102 on 98 degrees of freedom\nMultiple R-squared: 0.9947,\tAdjusted R-squared: 0.9947\nF-statistic: 1.846e+04 on 1 and 98 DF,  p-value: &lt; 2.2e-16\n</pre>\n<p>We can read the report and see that the estimated fit formula is: y =  2.99150*x – 0.02609 (which is very close to the true formula y = 3*x) .  At this point the analysis is done (if the goal of the analysis is to just print the results).  However, if we want to use the results in a calculation we need to get at the numbers shown in above printout.  This printout contains a lot of information (such as the estimate fit coefficients, the standard errors, the t-values and the significances) that a statistician would want to see and want to use in further calculations.  But it is unclear how to get at these numbers.  For example: how do you get the “standard errors” (the numbers in the “Std. Error” column) from the returned model?  Are we forced to cut and paste them from the printed report?   What can you do?</p>\n<p>The documentation nearly tells us what we need to know.  <tt>help(lm)</tt> yields:</p>\n<blockquote><p><tt><br/>\nThe functions summary and anova are used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.<br/>\n</tt></p></blockquote>\n<p>To a newer R user this may not be clear (as there are technical issues from both R and statistics quickly being run through).   However, the experienced R user would immediately recognize from this help that what is returned form <tt>summary(model)</tt> is an object (not just a blob of text) and that looking at the class of the returned object (which turns out to be summary.lm) might tell them what they would need to know.</p>\n<p>Typing:</p>\n<pre>\n&gt;class(summary(model))\n[1] \"summary.lm\"\n&gt; help(summary.lm)\n</pre>\n<p>Yields:</p>\n<blockquote><p><tt><br/>\ncoefficients: a p x 4 matrix with columns for the estimated coefficient, its standard error, t-statistic and corresponding (two-sided) p-value. Aliased coefficients are omitted.<br/>\n</tt></p></blockquote>\n<p>But if you are not very familiar with R you might miss that the summary function returns a useful object (instead of blob of text).  Also you might only know to look at <tt>help(summary)</tt> which  does not describe the location of the desired standard errors (but does have a reference to summary.lm, so if you are patient you might find it).  We describe how to find the information you need by using R’s object inspection facilities.  This is a “doing it the hard way” technique for when you do not understand the help system or you are using a package with less complete help documentation.</p>\n<p>First  (using the techniques described in the slides:  <a href=\"http://www.win-vector.com/blog/2009/09/survive-r/\" rel=\"nofollow\" target=\"_blank\">Survive R</a>) examine the model to see if the standard errors are there:</p>\n<pre>\n&gt; names(model)\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"          \"fitted.values\" \"assign\"\n [7] \"qr\"            \"df.residual\"   \"xlevels\"       \"call\"          \"terms\"         \"model\"    \n\n&gt; model$coefficients\n(Intercept)           x\n-0.02609243  2.99150259\n</pre>\n<p>We found the coefficients, but did not find the standard errors.  Now we know the standard errors are reported by <tt>summary(model)</tt>, so they must be somewhere.  Instead of performing a wild goose chase to find the standard errors let’s instead trace how the summary method works to find where it gets them.  If we type print(summary) we don’t get any really useful information.  This is because summary is a generic method and we need to know what type-qualified name the summary of a linear model is called.</p>\n<pre>\n&gt; class(model)\n[1] \"lm\"\n</pre>\n<p>So we see our model is of type lm so the <tt>summary(model)</tt> call would use a summary method called summary.lm (which as we saw is also the returned class of the <tt>summary(model)</tt> object).  As we mentioned the solution is in <tt>help(summary.lm)</tt>, but if the solution had not been there we could still make progress:  we could dump the source of the summary.lm method:</p>\n<pre>\n&gt; print(summary.lm)\nfunction (object, correlation = FALSE, symbolic.cor = FALSE,\n    ...)\n{\n    ....\n    class(ans) &lt;- \"summary.lm\"\n    ans\n}\n</pre>\n<p>We actually deleted the bulk of the print(summary.lm) result because the important thing to notice is that the method is huge and that it returns an object instead of a blob of text.  The fact that the method summary.lm was huge means that it is likely calculating the things it reports (confirming that the standard errors are not part of the model object).  The fact that an object is returned means that what we are looking for may sitting somewhere in the summary waiting for us.  To find what we are looking for we convert the summary into a list (using the unclass() method) and look for something with the name or value we are looking for:</p>\n<pre>\n&gt; unclass(summary(model))\n$call\nlm(formula = y ~ x, data = d)\n...\n$coefficients\n               Estimate Std. Error    t value      Pr(&gt;|t|)\n(Intercept) -0.02609243 0.02102062  -1.241278  2.174662e-01\nx            2.99150259 0.02201930 135.858209 2.095643e-113\n...\n</pre>\n<p>And we have found it.  The named slot <tt>summary(model)</tt>$coefficients is in fact a table that has what we are looking for in the second column.  We can create a new list that will let us look up the standard errors by name (for the variable x and for the intercept):</p>\n<pre>\n&gt; stdErrors &lt;- as.list(summary(model)$coefficients[,2])\n</pre>\n<p>Now that we have the stdErrors in list form we can look up the numbers we wanted by name.</p>\n<pre>\n&gt; stdErrors['x']\n$x\n[1] 0.0220193\n\n&gt; stdErrors['(Intercept)']\n$`(Intercept)`\n[1] 0.02102062\n</pre>\n<p>And we finally have the standard errors.  But why did we want the standard errors?  In this case I wanted the standard errors so I could plot the fit model and show the uncertainty of the model.  As, is often the case, R already has a function that does all of this.  Also (as is often the case) the R function that does this asks the right statistical question (instead of the obvious question) and can draw error bars that display the uncertainty of future predictions.  The uncertainty in future prediction is in fact different than the uncertainty of the estimate (what was most obvious to calculate from the standard errors) and (after some reflection) is what I really wanted.  Having these sort of distinctions already thought out is why we are using a statistics package like R instead of just coding everything up.  These calculations are all trivial to implement- but remembering to perform the calculations that answer the right statistical questions can be difficult.  The built in R solution of plotting the the fit model (black line) and the region of expected prediction uncertainty (blue lines) is as follows:</p>\n<pre>\n&gt; pred &lt;- predict.lm(model,interval='prediction')\n&gt; dfit &lt;- data.frame(x,y,fit=pred[,1],lwr=pred[,2],upr=pred[,3])\n&gt; ggplot(data=dfit) + geom_point(aes(x=x,y=y)) +\n    geom_line(aes(x,fit)) +\n    geom_line(aes(x=x,y=lwr),color='blue') + geom_line(aes(x=x,y=upr),color='blue')\n</pre>\n<p><center><br/>\n<img alt=\"fit1.png\" border=\"0\" class=\"jetpack-lazy-image\" data-lazy-src=\"https://i0.wp.com/www.win-vector.com/blog/wp-content/uploads/2009/11/fit1.png?w=450&amp;is-pending-load=1\" data-recalc-dims=\"1\" loading=\"lazy\" src=\"https://i0.wp.com/www.win-vector.com/blog/wp-content/uploads/2009/11/fit1.png?w=450\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"/><noscript><img alt=\"fit1.png\" border=\"0\" data-recalc-dims=\"1\" loading=\"lazy\" src=\"https://i0.wp.com/www.win-vector.com/blog/wp-content/uploads/2009/11/fit1.png?w=450\"/></noscript><br/>\n</center></p>\n<p>And we are done.</p>\n<p>Related posts:<ol><li><a href=\"http://www.win-vector.com/blog/2009/09/survive-r/\" rel=\"nofollow\" target=\"_blank\" title=\"Permanent Link: Survive R\">Survive R</a></li>\n<li><a href=\"http://www.win-vector.com/blog/2011/02/the-cranky-guide-to-trying-r-packages/\" rel=\"nofollow\" target=\"_blank\" title=\"Permanent Link: The cranky guide to trying R packages\">The cranky guide to trying R packages</a></li>\n<li><a href=\"http://www.win-vector.com/blog/2010/03/r-annoyances/\" rel=\"nofollow\" target=\"_blank\" title=\"Permanent Link: R annoyances\">R annoyances</a></li>\n</ol></p>\n\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 3.8.0-->\n<p class=\"syndicated-attribution\"><div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"http://www.win-vector.com/blog/2009/11/r-examine-objects-tutorial/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=r-examine-objects-tutorial\"> Win-Vector Blog » R</a></strong>.</div>\n<hr>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</hr></div></p> </div>\n<div class=\"post-tags clearfix\"><ul><li class=\"round-corners\"><a href=\"https://www.r-bloggers.com/tag/coding/\" rel=\"tag\">Coding</a></li><li class=\"round-corners\"><a href=\"https://www.r-bloggers.com/tag/r/\" rel=\"tag\">R</a></li><li class=\"round-corners\"><a href=\"https://www.r-bloggers.com/tag/statistics/\" rel=\"tag\">statistics</a></li><li class=\"round-corners\"><a href=\"https://www.r-bloggers.com/tag/tutorial/\" rel=\"tag\">tutorial</a></li><li class=\"round-corners\"><a href=\"https://www.r-bloggers.com/tag/tutorials/\" rel=\"tag\">Tutorials</a></li></ul></div></article>",
    "main_text": "R examine objects tutorial\nPosted on\nNovember 21, 2009\nby\nJohn Mount\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nWin-Vector Blog » R\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nThis article is quick concrete example of how to use the techniques from\nSurvive R\nto lower the steepness of\nThe R Project for Statistical Computing\n‘s learning curve (so an apology to all readers who are not interested in R).  What follows is for people who already use R and want to achieve more control of the software.\nI am a fan of the\nR\n.  The R software does a number of incredible things and is the result of a number of good design choices.  However, you can’t fully benefit from R if you are not already familiar the internal workings of R.  You can quickly become familiar with the internal workings of R if you learn how to inspect the objects of R (as an addition to using the built in help system).  Here I give a concrete example of how to use the R system itself to find answers, with or without the help system.  R documentation has the difficult dual responsibility of attempting to explain both how to use the R software and explain the nature of the underlying statistics; so the documentation is not always the quickest thing to browse.\nFirst let’s give R the commands to build a fake data set that has a variable y that turns out to be 3 times x (another variable) plus some noise:\n> n <- 100\n> x <- rnorm(n)\n> y <- 3*x + 0.2*rnorm(n)\n> d <- data.frame(x,y)\nThis data set (by design) has a nearly a linear relation between x and y.  We can plot\nthe data as follows:\n> library(ggplot2)\n> ggplot(data=d) + geom_point(aes(x=x,y=y))\nWith data like this the most obvious statistical analysis is a\nlinear regression\n.  R can very quickly perform the linear regression and report the results.\n> model <- lm(y~x,data=d)\n> summary(model)\n\nCall:\nlm(formula = y ~ x, data = d)\n\nResiduals:\n     Min       1Q   Median       3Q      Max\n-0.41071 -0.12762 -0.00651  0.10240  0.62772 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept) -0.02609    0.02102  -1.241    0.217\nx            2.99150    0.02202 135.858   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 \n\nResidual standard error: 0.2102 on 98 degrees of freedom\nMultiple R-squared: 0.9947,\tAdjusted R-squared: 0.9947\nF-statistic: 1.846e+04 on 1 and 98 DF,  p-value: < 2.2e-16\nWe can read the report and see that the estimated fit formula is: y =  2.99150*x – 0.02609 (which is very close to the true formula y = 3*x) .  At this point the analysis is done (if the goal of the analysis is to just print the results).  However, if we want to use the results in a calculation we need to get at the numbers shown in above printout.  This printout contains a lot of information (such as the estimate fit coefficients, the standard errors, the t-values and the significances) that a statistician would want to see and want to use in further calculations.  But it is unclear how to get at these numbers.  For example: how do you get the “standard errors” (the numbers in the “Std. Error” column) from the returned model?  Are we forced to cut and paste them from the printed report?   What can you do?\nThe documentation nearly tells us what we need to know.\nhelp(lm)\nyields:\nThe functions summary and anova are used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\nTo a newer R user this may not be clear (as there are technical issues from both R and statistics quickly being run through).   However, the experienced R user would immediately recognize from this help that what is returned form\nsummary(model)\nis an object (not just a blob of text) and that looking at the class of the returned object (which turns out to be summary.lm) might tell them what they would need to know.\nTyping:\n>class(summary(model))\n[1] \"summary.lm\"\n> help(summary.lm)\nYields:\ncoefficients: a p x 4 matrix with columns for the estimated coefficient, its standard error, t-statistic and corresponding (two-sided) p-value. Aliased coefficients are omitted.\nBut if you are not very familiar with R you might miss that the summary function returns a useful object (instead of blob of text).  Also you might only know to look at\nhelp(summary)\nwhich  does not describe the location of the desired standard errors (but does have a reference to summary.lm, so if you are patient you might find it).  We describe how to find the information you need by using R’s object inspection facilities.  This is a “doing it the hard way” technique for when you do not understand the help system or you are using a package with less complete help documentation.\nFirst  (using the techniques described in the slides:\nSurvive R\n) examine the model to see if the standard errors are there:\n> names(model)\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"          \"fitted.values\" \"assign\"\n [7] \"qr\"            \"df.residual\"   \"xlevels\"       \"call\"          \"terms\"         \"model\"    \n\n> model$coefficients\n(Intercept)           x\n-0.02609243  2.99150259\nWe found the coefficients, but did not find the standard errors.  Now we know the standard errors are reported by\nsummary(model)\n, so they must be somewhere.  Instead of performing a wild goose chase to find the standard errors let’s instead trace how the summary method works to find where it gets them.  If we type print(summary) we don’t get any really useful information.  This is because summary is a generic method and we need to know what type-qualified name the summary of a linear model is called.\n> class(model)\n[1] \"lm\"\nSo we see our model is of type lm so the\nsummary(model)\ncall would use a summary method called summary.lm (which as we saw is also the returned class of the\nsummary(model)\nobject).  As we mentioned the solution is in\nhelp(summary.lm)\n, but if the solution had not been there we could still make progress:  we could dump the source of the summary.lm method:\n> print(summary.lm)\nfunction (object, correlation = FALSE, symbolic.cor = FALSE,\n    ...)\n{\n    ....\n    class(ans) <- \"summary.lm\"\n    ans\n}\nWe actually deleted the bulk of the print(summary.lm) result because the important thing to notice is that the method is huge and that it returns an object instead of a blob of text.  The fact that the method summary.lm was huge means that it is likely calculating the things it reports (confirming that the standard errors are not part of the model object).  The fact that an object is returned means that what we are looking for may sitting somewhere in the summary waiting for us.  To find what we are looking for we convert the summary into a list (using the unclass() method) and look for something with the name or value we are looking for:\n> unclass(summary(model))\n$call\nlm(formula = y ~ x, data = d)\n...\n$coefficients\n               Estimate Std. Error    t value      Pr(>|t|)\n(Intercept) -0.02609243 0.02102062  -1.241278  2.174662e-01\nx            2.99150259 0.02201930 135.858209 2.095643e-113\n...\nAnd we have found it.  The named slot\nsummary(model)\n$coefficients is in fact a table that has what we are looking for in the second column.  We can create a new list that will let us look up the standard errors by name (for the variable x and for the intercept):\n> stdErrors <- as.list(summary(model)$coefficients[,2])\nNow that we have the stdErrors in list form we can look up the numbers we wanted by name.\n> stdErrors['x']\n$x\n[1] 0.0220193\n\n> stdErrors['(Intercept)']\n$`(Intercept)`\n[1] 0.02102062\nAnd we finally have the standard errors.  But why did we want the standard errors?  In this case I wanted the standard errors so I could plot the fit model and show the uncertainty of the model.  As, is often the case, R already has a function that does all of this.  Also (as is often the case) the R function that does this asks the right statistical question (instead of the obvious question) and can draw error bars that display the uncertainty of future predictions.  The uncertainty in future prediction is in fact different than the uncertainty of the estimate (what was most obvious to calculate from the standard errors) and (after some reflection) is what I really wanted.  Having these sort of distinctions already thought out is why we are using a statistics package like R instead of just coding everything up.  These calculations are all trivial to implement- but remembering to perform the calculations that answer the right statistical questions can be difficult.  The built in R solution of plotting the the fit model (black line) and the region of expected prediction uncertainty (blue lines) is as follows:\n> pred <- predict.lm(model,interval='prediction')\n> dfit <- data.frame(x,y,fit=pred[,1],lwr=pred[,2],upr=pred[,3])\n> ggplot(data=dfit) + geom_point(aes(x=x,y=y)) +\n    geom_line(aes(x,fit)) +\n    geom_line(aes(x=x,y=lwr),color='blue') + geom_line(aes(x=x,y=upr),color='blue')\nAnd we are done.\nRelated posts:\nSurvive R\nThe cranky guide to trying R packages\nR annoyances\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nWin-Vector Blog » R\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nCoding\nR\nstatistics\ntutorial\nTutorials",
    "meta_description": "This article is quick concrete example of how to use the techniques from Survive R to lower the steepness of The R Project for Statistical Computing‘s learning curve (so an apology to all readers who are not interested in R). What follows is for people who already use R and want to achieve more control [...] Related posts:Survive R The cranky guide to trying R packages R annoyances",
    "meta_keywords": "coding,r,statistics,tutorial,tutorials",
    "og_description": "This article is quick concrete example of how to use the techniques from Survive R to lower the steepness of The R Project for Statistical Computing‘s learning curve (so an apology to all readers who are not interested in R). What follows is for people who already use R and want to achieve more control [...] Related posts:Survive R The cranky guide to trying R packages R annoyances",
    "og_image": "https://www.win-vector.com/blog/wp-content/uploads/2009/11/dat1.png",
    "og_title": "R examine objects tutorial | R-bloggers",
    "raw_jsonld_article": null,
    "reading_time_min": 8.6,
    "sitemap_lastmod": "2009-11-21T15:39:21+00:00",
    "twitter_description": "This article is quick concrete example of how to use the techniques from Survive R to lower the steepness of The R Project for Statistical Computing‘s learning curve (so an apology to all readers who are not interested in R). What follows is for people who already use R and want to achieve more control [...] Related posts:Survive R The cranky guide to trying R packages R annoyances",
    "twitter_title": "R examine objects tutorial | R-bloggers",
    "url": "https://www.r-bloggers.com/2009/11/r-examine-objects-tutorial/",
    "word_count": 1715
  }
}