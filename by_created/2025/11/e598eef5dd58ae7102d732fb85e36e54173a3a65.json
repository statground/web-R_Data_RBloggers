{
  "id": "e598eef5dd58ae7102d732fb85e36e54173a3a65",
  "url": "https://www.r-bloggers.com/2025/01/us-presidential-elections-a-bayesian-perspective/",
  "created_at_utc": "2025-11-22T19:59:32Z",
  "data": null,
  "raw_original": {
    "uuid": "f350a398-4b14-4d49-9ab5-928b54a8ad87",
    "created_at": "2025-11-22 19:59:32",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2025/01/us-presidential-elections-a-bayesian-perspective/",
      "crawled_at": "2025-11-22T10:56:13.372071",
      "external_links": [
        {
          "href": "https://tomerzipori.github.io/blog/posts/elections2024/",
          "text": "Tomer's stats blog"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://en.wikipedia.org/wiki/2020_United_States_presidential_election_in_Nevada",
          "text": "Wikipedia"
        },
        {
          "href": "https://tomerzipori.github.io/blog/posts/bayes101/",
          "text": "post"
        },
        {
          "href": "https://tomerzipori.github.io/blog/posts/elections2024/",
          "text": "Tomer's stats blog"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "US Presidential Elections – A Bayesian Perspective | R-bloggers",
      "images": [
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAMBAMAAABCcoqQAAAALVBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAOrOgAAAADnRSTlMARHZmiTLNIrtUme8Qq9MyhvYAAAAJcEhZcwAADsQAAA7EAZUrDhsAAABHSURBVAgdY2AQMhFgYGBNYEhnYOCYwKDFwMAXwCDNwBBXwBB3gEEOSIIRkFEXwDDvAAOfAMNsoEoDBl0GBsYGkC6GSVMEGACgDQxqAEhSYQAAAABJRU5ErkJggg==",
          "src": "https://latex.codecogs.com/png.latex?0"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAAcAAAAMBAMAAABcu7ojAAAAHlBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACGjDitAAAACXRSTlMARM0yInYQiat4/XZtAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAHElEQVQIHWNgEDJgYHC1BBIMnMQSAgwM6Z3qBgBsXAQZn03r+gAAAABJRU5ErkJggg==",
          "src": "https://latex.codecogs.com/png.latex?1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAQBAMAAAA2ZkhwAAAAJFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADHJj5lAAAAC3RSTlMAIu8QVESZq2bdiaoDY/wAAAAJcEhZcwAADsQAAA7EAZUrDhsAAABESURBVAgdY2BgYBACYgYGEzCJRIQkADmsAiVAkoNhCkiCeTOIZJkAItkSQCSnA4i0NgCRkSCCoQqIjQSVgSR7mwADAwABUwZabWIS0gAAAABJRU5ErkJggg==",
          "src": "https://latex.codecogs.com/png.latex?j"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAANBAMAAABSlfMXAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAid2ZVHa7MmYQq+9EIs18fhEmAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAYklEQVQIHWNgYBD67MDgr8rAwMCWwMDgCqQZ+AMYWApAjPoChk4QzRDPMANMMyxj3w5hbD2zGczg/XxBHszg+MBwvwHE4nrAwPYAxOAWYGD5DmLcP8DAAFLNmL+GgfG/AQMAOMAVCT0x4n0AAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?K"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAALMAAAAxBAMAAABjQoUTAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAid2ZuzKrVCJmEO9Eds0xWRQzAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAEJUlEQVRYCa1WXWgcVRT+ZjO/d3fNpn2IqQX3waBFkKUPij7UFbZERHT8wTx2BWMVUliMJS64umqVYsVOLbomtDg2RUGbZgX7EgoOljb+9GFKwGAxdF/tU0VKV9HWM3d2Y2bmZjOb7Fnm3nu+831nZs/M3DlAl/bODi5gEZkdQboF0jmukKth4aNhoGtfLnFJMiKsR5Bugf4qu7TwkLLLwtLl9OCx9JSdrny1OJV55vduM0X4h2D0m4NYhupcLJ2p7JWc8dSPSXss7Uao3QKfAM9iDLtxeNI9mFey0G9UCHlcNoHL3SYL8veBrrhOvwnAcI0ctBxwHPPR4gd1MbxhYCz10k8N6zkoqqPl2PkizHEjc9rAKJ1ko6bV3Nl/gTx7GQ+YUs2SgaFJDJWxo4K+/TDzG00M7MNFoZhlOaxkhNE4oJHF7UJeyq9E2hFG44CJkeNi8cnHuJzqs1Gbq3ZUqrWO4Y7BuY7RDsFZHnM7MBIm9ncIC0Jb/txaMIEiD80ICG1IHyzb7XW8WS5Ca4Lf3kPQrHiieKx+C+wv3OaRvwQa8UTxWHtMKDdQbpEH44nisT4D+ubR/khciCeKx3oB+NmkrQxYyAHJeKJ4rG+nlrcBWSBV3Qv0e6L7XyR7Pp68A0v/xwvqDdp+cTddte25vTHjmpdHadDA/gYSNi3+t1sbNkqrNrxELEuDRkMva53IUFLw29jXvo09qvXhEk99lcYELQ9wTzCwnRb7xhYE1oSkJ+mxIFuiY84GpjxHaFthVIWB9cD3iPA9Hf6uLmKPMEsEr4/JNkBPsl5ck9p8KhTSd/rnImXQWNDVc18fnKdX3g7CyZuFQuGJ725loZzdEgwBiz7Q3iNWwnJ1ZckXC+pRQj4OgtD+8AD2ynUY93h3OWAjvlcPgOSEH2CdE6ph2sMORxahWkYjFGxidvuETY1kumJfKju/TlOLOfvgEa/XjGMJqhKZhKSJM0GBXod1XSpRIzmeWkiO/lLaTi2mNa+ay9CzQarQ029ymLErln5fNUAxilDyqimb1FHqB/A0vBZTycvO7phflDczgXxtp1yB6iLtJqmyfkd5FH6LmbTrUHJtXqdZ5TtjmKG6KYe+8Kp54YPThuJ1lJT3FG8xj7CGlZ4+FlaI/HttAfoRpPevuJDxhUWNJHWUeUi1ErWYiZpLvab6+qhAFIH25CMQcFf5NwFK0AkOJyriaAiV8iGAXNaMYj5yjk8z0mtrEVbjH/rOSdef2as0s2urGavWrGCv8tZbtt5j1fGJ2hvePAzN9P1NjKrji1feXv4v3pqc3kTOlnSIz7p9ItXaX1oF2nxm73UgUzHxw9LnAwMD29Cz1P4HjT2CXQ4/B3qWml31Ep66s4nh1hbas9Ryqw/JsuzEu35B3m5dfc8mJTPjP9ipOz6Nl/Q/jQgrLwDcWrUAAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?%0AP(j)=%5Cfrac%7Be%5E%7BIntercept_j%7D%7D%7B%5Csum_%7Bk=1%7D%5EK%20e%5E%7BIntercept_k%7D%7D%0A"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-16-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-17-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-22-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/tomerzipori.github.io/blog/posts/elections2024/2020_results_nv.png?w=578&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAaEAAAAxBAMAAACBlwsGAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMARHZmiTLNIrtUme8Qq91+bSRLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAHcElEQVRoBdVYfWwU1Rb/zcxOZ6c7ux2fH+gT48iipOiToVtfX3mAS4qaxa/5gzxF1G6eRmPiH0OCYlDpPj8eJTFx3BW1+LWKGolfi0rMS3hxBKJIjC08+4wmJhtJ1UQSQcQGxei5d7vb3Z0ZpaV/TE+7c+/5nY85Z+6dO/ceINy0dj+PT/NE6XqQaQKIRR5o1G6Od30zMF34qMMjjXniLXmQaQK02drsM16VXzLRfoGYmS+mXDH/0dxU+rqbpkkCnjDvhtRmZTALcf0kZ1v+s4i+Vzg55g6LBuS35C89+uEHFgHXYhgPom/AWJOTy1CO5gn5V9SClkW5loBY64W9sw80PiX62wRIhlSEWgQ6sJ1eLCEt58Ievk98I8Cw8OnMrHkD5LiuFrVTh2DtldLvS4hknjaEZDrSUYx0vLoAOx/xMQ8ZpHYbO74Hctr/sMWKdJtRoGcAPQXsz6N1I1rcuL5bKc7IGjOyc9biuq6Qhe8Tzj6c5IMCWpnDCSSwXHpcdUD/l9zjhH+MpDIu881IKHL4QuvvVuSUc1sB+t/szjd8lcMEJjZ06L7x7H7IFw4/OGiHP8aJRTg4MfWp19aME/DpZ5uwsPEEXB6/adLx143TInTVTwFCf5NxdM94t9ZTMgW3xkyk86dO9v4pN3esh5BcAnC+Y1bQJJbay9D87nQOeYnm6MLIV+N3cNXkZlNykbO4lRwp3/3Xxj/QYnO+1WkdCvCeuEZH1PARZglrqwp8NUghCAezniKiA8hccqU4dNkAscj50yFbAf77CG/zEfKn3FsV+Gkwh0E4MgG3mwRM9ziTzHhGRyCUOF85Cvt6e4zQlT4SfsqcVxX4aTBZEI6zqpYn3vba6HUpo2SnLo9CPsb5o6mmZyaluqAmLwF2fbUEp9zSIyV3Lrp+YBgQ26+BsGnVApefMvuB/MLUMNMA7cqEJavnA4UBG4U88nNSRYb7k/eQ6q93HOjZlJFNr7KBEYEyGmX8mp9Akw947QuiT5iTAnrwPO6m3v38t2qlqd6GJxj7f6yQ70/oCab2JpRT36rAoF2Zui59JeJmPB03hJlPHcZmbs0UPdTGkPH7eeQTACgdSoLRyzRGwijj7zgM2lTV06WWK2X5W7CN4FE4i5nGXyDl8AkM+ZiEOwlXjkDlMGlQe9lTZ7ozcB5UdzEiq4QSriQce/Zrr5ikXKUC78TcKn/CbZ+FZyvezmcBHWP8B4eo0+B53c9OzMQgHRwP0lGrBLyAuIH7QOBWmnpDoHWSjmQkbE3T6JAG25W5ywg8TL9vCucwpc8JR6TIl6IG90DCbQB+nTQdRJuOJ8lZwsE8UCIlzh9tzgirD/bZuJiyKVNMlMBWxCxtFH22TFm0OMDH5CSeBWI6DQRpDNoE3EbjRo+GFGnhdvAfZkktm7lNNIXvUdSkyUNB2XiZ7iQOcf4+iGUCa/OaQi71Av+sDEeL+aFyEH2QsnovxJyu97kiWEixNAhWszppsF2ZRtnIlPFH9EObK5QJR5vN5l4midkFnao70hC6TTIljfH7MWbSJOToC3uvK7naOzidEuP8jWjR6z3GIRgJi27O5hoSliFl8Te0GmYM76dT5cVuF1pcyoaM/krzziSNBO3K1CyAryHZI1CtXrfFIhwrU50lRK3ZamyFQdUd84Ccvgi4izR9SXvd1N52fUVBYP5RHSttdCyzobbTLojx8vPPNagLZxSgZFKExSyQmi2a9E0U6H/Lxs0fZFZlLIgOdj38GZCEnHFJg+3KRIMsVg8s5L+53XOYJRax5eRGPKdQEmtyULLyL+ST+fanZfRE/CVTgwZu8ZWhP7hB9eXZx8Z5AQ5QRYeqO4iYWF4CHgq03qCZgbIpEMx8OtBJcEwVE7Y6MNpGsxaPKgecvTSHdSR23oAh/M7zGF1esatdA4v7Wk1lAp1DLwYqrw2UcAFbIRjt+F6bZ6B1YB9ytO7Rat+182QLrS6TjVPsx/7+/n+/+2sZ8tarxmHeE4u8idpNOLxIs4YPnwqeAYLjoz8OnfbDeN/bo7WhgVSurT1zBNLX9GFpIFr+GXnXey/SYDdxxp64Sc3CY/uGzmVzETelbE2Nd5qK+0gupCr/js2drNwfYkps58FF2OLKNl511FTcjztLqMpvbo9bs6CU6/RC1lV+5AFp2jxT+apxBBuL+/QhYFV+ORfVHwSyIUujPpxn0/VctU9HFNo21hf36UNQqfLH3BLkYlUxhG38kF9QrHA80lDcp3Te41X+Ti1rigvn+1mFBPvW9QbCjijNxf1It0NV/gQN3hYr/sgKr1FokN6cN5TAwjHf+tOOM++1CQ8SyXljGWxcI+oU/sz7eyKP12Fh67JDMdFugzfQnqA2cFep9bsVtTBf11eCo60fJ/UxatgRpcJOw2s1k9rWho3ZpAvHYXgAPTwIxf1YGNvzjc3CMMQ2qRjUIjeLY9OM9l1Lly69ghebJuUqJEZ38Ti0B/DS2Hs03TPSbmcZvXf1KEY2jD3jaT7romP1urJW3nRHZdatG8tsujdyeo/BcxAu7zq+XH4Dp7AgssMe4T8AAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?%0A0.5006=softmax(Intercept_%7BHarris%7D)=%5Cfrac%7Be%5E%7BIntercept_%7BHarris%7D%7D%7D%7B%5Csum_%7Bk=1%7D%5EK%20e%5E%7BIntercept_k%7D%7D%0A"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAaEAAAAxBAMAAACBlwsGAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMARHZmiTLNIrtUme8Qq91+bSRLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAHdElEQVRoBdVYa4wUVRb+qqqL7p6uqi5WDUF8FANqhixaMrMZZ8Jg46Cb9oH1A3WFdadVlGxiYhFd8RHtVkRnEhLbHhRnFrUiiJnEx6Dyj8TiEVeJYQYRNyRr7ETRTfwzPpC4S4Ln3ppX10OhmZCaM9NV537nUefcV906QLzp0a94fEogSjeATBNAdHigKdsf77N+YLq0U2UeaSYQ72AAmSZA1lbmz35T3m6i6Y9i/kqx2RUrnyxozq28e5okEAjzMUhZK49GqPrM8s7KkYR+UDgn4x4WDRy6tJIL6Mcf6AD+gsPYgGKfsa4kV5H8pULIkylLtvthxj+BQISfgsZnkP76AcmQHKQdYBF2ZaAgDzegH3/gKHBY+PcFBfMOyKqedpTzhmEdlHIfSsAaJBY5e53ZSkul7RKlvRL//NJtxp4fgJJyCANWos1MAZ196OzFVxU0vAAauFkFY53zRvIOwelNrpC8bTHOo/QpZoaGp1Q5LJeQLkPUN2JuwvqPO1e1Q7VjBEpV/Dk0HMHh8IUb0ADITUfgNGArDrWFKscJ1HoW6aHxfLQxDC6FgfHChk5rFkn3xSv6sGiGwsCziSnGGTwtzFazQBvaWaB5EZukCijL/xch/L249ocoJPO9bgj8+9AfWrz1J+dwzfMzz4PUeJnHhJtKTVUoYU+aS/qp0pjRJ2OM7x6Bp02f3hk05QK9exlpDr48efJHDOAtjwl3qt2mI2WEyAqEZccFT4VoMCgKL0To1wHTB8gCbtbhIAcYQgm3cCbCV5HwrBUU8l7uGhccC2pwJArPR+jXAVN0c5iZvNKBjgQ0Nv6MiaAXCV8VIuNfmVeMCeTBMa72HoXjwlq9M2l12ehyyYHU4NC1FdneljJn6DJBUnMr0vOuBfZ9sxTn3tspzdvb8de+w4DYdBuE/rXtLv/K7AZp7e2whOtWm+it4NxZnTrSbZvpZ6QbH2jn+ITXSVzwI3WS8PTYiykjm0xMlpGSQ9FBD2cIe+sLos+Yv1504jU8Rtx6/lu7ykz/HS+x5ue4XV6v6RpTexdgkhJSJlRD0Dd/nRjGIXwGOqJ9PGQ2mISHU5bBE88LVzo1lNKhpCBbLKMGC10mlnCmxvw6y5UKfP3sJPw4yktAx66FkEoUriGfkPAQ4UlaJSQRh5G1yUvikd27BFssYAs7oulzkBgmfPVV6y8nXR9lXB9Qf7No4VXyJoFlRD1V1Fmbd9kkp0/8v5wxMWRBGQGEQWAbjQFtXATuoKk3DNxK2hIJPQktzf/2zlUSzKdJ+yg7oi2E6syBoKfMkEWquWQ6QSfrphFkdfyTPLUvW77aYly2zDJiUA09OFK0cTVlUwV1NSiPjKUcR9GWKYsZZeAAqasFuuxgA3QTSOgJii4wZFOjB5nyTdR1GTtNLR9N4Tqimb2Qe085wHZ6SRqgSUEM0fi8ppAHu4C7vOGYYX6cHEERUkHvgljS9aIrgoWUydHMG8GLAu5WtlCmGHIBslOGiMcJXER4ma1GquqgA5fsWdr/wCaFKjtkyjTGn8cadRO9f9bgcZdScQDaq+Qq7uTMZI8qBEOzpGEaBoPmkGVIBVyFBsPM4MNcc3WJ24oZLp+xkArYJuGoiKNIW2yr12y0anREk0/gHoaTIaiqI2nuGvOYWNIkquwAD5NmKClvm8r7bqgoCqxs0rHKhnzD+zatAWDlAp0thhoSZvcimW8mLGPRBt1kiybVLQT6H3hh67/ya/MWxDL2PXeEut/Eii2obMaDfYup6EGDRscz9hO3VmyG076HdSXQVjIol1T9AKvsAMx3OF0PyQ6XTA3K50+YqyQN4G/S+MZNxRDJAObLJdHQ3H5W2QE2Rtr2KGakbAoEF7wc6SQ6Js+E9gtObLdUdSCfaFKtAzhoUmUHv9Efx1f4HhlZ3Fd8iqfU/P71SLVHIyWegHYITh3vuaCqDlaeM5DCCjRaVNlBg+sJx66Zn7u7u5/54GQV8o7lY+DoXXQ4kxrtoQlpEJmQRXLNZqRIKEeKmEC4PxcuV6qE/8knS//EAOWVY5C+1XyOU147uN8HEZ/X023ap2vg6QsO3QO27+hcugCqKRU4O37xFfcxbzFV+fdsbWHl/lhQeGVHo92CKME21521cfqK+2p5KVX5zV2q1YhktVY1Tq3kzzwaRbnCTH5TO4K1xX38jd6DfYZcSukbgEKccvDF8mrOB/AmfZWw99mk4j7a4VX5M+4gZIdrxfOifh8WFysc0/tsUnGf0tnNq/wtSsEUF18ZZhUT7Ds3GIhEXyX+4n6irUxVfo0Gb8BSn789aBQbpKsUDCWycMyP/nSGpFdbfClRCsbGv0qCMCHnc3R/gs6NsSX2UUz0kcFvUF6ie+SpUul2PbU4X5/1gmNHQEZp/mVytgrH3jOn9jqWyfjRho1Z3YXjqY2tPm+d3CzpHhBGz3yjs7A+bzGwSjs8CBX9s5r2LVu27EZebIpBYHWH8DC3VJ7G9tF1NN0zUu5jGe2++TiO9oz2yjSfdanRel1Vqfb/w5t1T4xmNt1vcm6/wXMQbmg9tVx+BSd7FRu6xOZNAAAAAElFTkSuQmCC",
          "src": "https://latex.codecogs.com/png.latex?%0A0.4767=softmax(Intercept_%7BTrump%7D)=%5Cfrac%7Be%5E%7BIntercept_%7BTrump%7D%7D%7D%7B%5Csum_%7Bk=1%7D%5EK%20e%5E%7BIntercept_k%7D%7D%0A"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAMBAMAAABCcoqQAAAALVBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAOrOgAAAADnRSTlMARHZmiTLNIrtUme8Qq9MyhvYAAAAJcEhZcwAADsQAAA7EAZUrDhsAAABHSURBVAgdY2AQMhFgYGBNYEhnYOCYwKDFwMAXwCDNwBBXwBB3gEEOSIIRkFEXwDDvAAOfAMNsoEoDBl0GBsYGkC6GSVMEGACgDQxqAEhSYQAAAABJRU5ErkJggg==",
          "src": "https://latex.codecogs.com/png.latex?0"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAMEAAAAtBAMAAADl6hJWAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMARHZmiTLNIrtUme8Qq91+bSRLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAADQUlEQVRYCe1WS2gTURQ9aTIkaSbJVBDxA4aqSIufqURKSytRI1KrdRYKWtFEULpxkY0fFG0WVtNd2vprBTugFApWK7S7gqm4kC5aqBZXYkCqCzf+2i7jfW/Sz3SaaWpmZ2/gvXPPvffczHtvHgMUbLaLBUuYCzi3TZknWBBd7ZDPIq6u0v+ySj/zedACcsRj04fMy9cEJZ4ghHCgrWQt7KXbNWBeln9UiKKJZ/tUfM5kfqMXfRrIX8M805VEOc+oVRECArY4TnJgXraCqF/BRpYuNKqQ4IBPJocByywSQyRFavZilcZK+DuCSQ5osMY2U4cYScmsgxhCs4pWDojr+0T2odA+JE9NICisQ7GCiIx9HBQqPFffrKA7RYsE1sEPNEvMJ6CzzD/bD/glPCax6nDDBYUhf5J1YJRV5pKxk2u5VKAHcAWwiwMil9oH8YUsDqR4RZ4Dnf8m3KQS1iFBG5LGeQ5y1R+BnZ2MFVj7PQlnYhDqB2J4RnWN5RI4yKHRKso5IlbRMyesUsqhI7xqWBS5/oUT4iKaXioDY0J4phOJxJ3XmTTs33xJfWKRyn2XYXeMjL5Q57n/MFd8MgWvbI8yPG90dzLzzDNZZGQMKQuIlxJ3yuFRMLiAJ+iPiVvXPxd6ZJTtKKqrwJYaAm+eBhmzAvMN8WSHuFt2fo3pCm/A7lfqUAqvVJIcbPcm9xOQh7xKKZxpXaap45zm4aU2rxY4hQm0oLkzcDWOc3TzdAaEuEtqAaKmovpgd0jva567KoBx0P/vp18XXW8BVEMDnlQ/BFVLy2v0LvlFMY4STAITto+bovJZCF6J5Ic5CIpRuaimIi9xLel7yphsT+Pwm19AXHyPXsVRJbsAR1WSgI8erlfxtp02FuVkInFjyNe6RztjhtAoZ3zthoAJ4Ygbg2P6U7UgYQPHI46HC7jl4BUt4V1Am8VHNI9p2DiKiZSRXI65qyXQXnJzP6DJp+C+5lowzirPXQXsmZx1HSkLtDWJg3xypkZtezUiu2qWNXCrXMqLrnVlb8Ph8FFY3eEabyDeRs/s8bS4g3iJdRg+PoNJ+l7jZnEHV/Z7KS2muy5rq3Qr28nqSQiNBLimrb4yP+2/TqD6EYazuG8AAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?%0A0.4767=%5Cfrac%7B1%7D%7B%5Csum_%7Bk=1%7D%5EK%20e%5E%7BIntercept_k%7D%7D%0A"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAQwAAAA2BAMAAADANLrfAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAEJndZu+JIrtUMkSrzXZ3NiH7AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAE2klEQVRYCe1WXWwUVRT+Znd2Zjrd7m6KxRiTMv5EQH7cB17gxSmQ1oZalgQlEpOuWjENiU4kxKjY7ptAolkRNUisIwaDxtjRKAlstC/EJkhgn9oHH1wrVklM/SsqYBzPvTOz3e4u7Q676e4Dp917v3vuued+e8+d+RYga12HtscYqK9JGrrqy4DvrqRvaQAWiL6QbAQax0/GG4HGJmN9I9A4gwcbgcZOhMz682ifwZ6J6ml82QBfBRgcaQgaiN6kUXClbp5GwWFUdzf6Lj/ErM+2bctN+uw6DoTCPa7jKQypqihb/3FSyT12yk0a0ThQDHec70o9+SkCVdFQbN3N1fq3C5Q0ByF3ONuVembnqqQh9Hm745CbNGoIU6fuUNfouPR9ZGALLnYQaL+7k3nmsahX1Hlirj81+qc3J8UctBdi1BzANMJWJr1zOJzeTUDfFjanvchy/dIL42Y5f4U+ydaKInuAEziLgxg6knsuhffBgJpSrIOQ40WxlQ2nVvA6f9VpoXntGKRLmYz59NHMaXm892W81P+zQWm+u1KU6zzoJBL0R1USc9gIB4RiCSBbFFvRUDKEGQpUs5jAOwgaYXos9Qu2PSPf/6iBPZfHWJY2m5EpsA3A2eaxT7P6x1DDFnG4nYNOIaurWkFcxTBo4i4Kpqs/iUcQ0CQggiSQk9Pkft7J02TP/Yrt/wEp4QxWmlK3rgBSd5pAsDtHnkjHFmeRrzak4xlaQE/0F/I1iIlmEAkLEgpp4L6/ZpM20W5lbQn3ho9+WHZ2QecrFDFiYOTWqxB/p1qzAnRBvki3ZXDzbr48mH9/AueRKZ/yMyd0mHWBc8yS3DNPs5pFfc0D5KvUjRIN4wokekMspaGQhJDDBrSDikYm29tYx0yM4ykHFbXC/hjztEpvFU1UNmzRKY5OY9ToQYBO414aBkxqsIKhFEPY+i/vqAke6LU8XElPV768FS3uZ+MhE+/GxP7NvwH0jyiP+ZHaSILDcP6RXWZwR60bUWcZ6TX7BnWRLJrYvoSDafyK9YgwVkBLknfULPPAvL3vu3EKIiVUdPyC02ixEMjScA1tbFBRJryinMtvSpfl7fygZkBdlTmEfbHmFG05zl6HSopy76erGBN2oANtvAZ0Sp7JA4djHq5dH7LtP3DcwPCbFj6Z1ulOJin5PfTpfdyAOLWcEPB6FTszmWCmJsFEAuL0Tw7gXj+NusNP9NxYlckEs6AGJhJYidUOmBtXwWiv830qiCwNUZhMMOvRuEhQ+T/ioDR0IY/zy5OipIUiS+eZTDCvekzjIhHUacDUwrcpSW8JXWG/Ri/GEXazxIBGbReihzvTHFDjz9jblFvrNQ9V3nOZoHCd0RCSGNJwgIPKUziR7tMqvPiAnfC71pUJqonJaJBIjOjY5KmFr2yjs5qQ9LWQB3OZoJqA0SCRGLJINly18JVt8s68sSL7NFcmNu56gn4Pk0hE04wGU45FNS4TbEdF4yKh5PADB4vKAlwm9tExMhokEmoc33KwuDS4TJBaqE8+bHCRODZpOWqxyDxqtJ3wqpvotlSNMt5Ymm/cZUeyN7a+RqsSbh65rjSE+OcmJ1JfGk2rBl/bRRarL40APecNcBrBE+lGoLGkafl7TlHi7rHUpftAWOvse3K7URcCfNP/AbRXa97BzGBmAAAAAElFTkSuQmCC",
          "src": "https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bk=1%7D%5EK%20e%5E%7BIntercept_k%7D=%5Cfrac%7B1%7D%7B0.4767%7D=2.097755%0A"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAALEAAAApBAMAAACIMtXYAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMARHZmiTLNIrtUme8Qq91+bSRLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAADu0lEQVRIDdVVXWgUVxg987c/k8nubGtIRKFDErGJtV13BfEnsLqUsn3pUESKpc1ChbwOhTZoW10VjYIPm9UoKuJo2zSFtCyUUgoVhlhUqGBMG0IfSpeGPPSp2hBCUmH73bv+kN1RZmaf/HZmuOfs+c7cvXPnLOC9DsxyrdbQ4TQwPgnR5g0Rq75vqJ7wiyNF3tHS0FduYHwScUvrXj2ujCbR84qY2ySmHbF0uzed2fuBT6MG+SeQ4mYOnWjVE8XvS7/L+l3hxRZnWjSgfKf81aD3TvQB72Aax3DovDFYUCoIL5WIORwxoeVReWwkPh55HUyB5lumzwVAMiQbURtI4SdaeCGjFLzauOjmgGlhZm0++R6UVj1qa22TMO9KmRsS5NwlQ+jKyClbTo1vw/Vhl/anUNGtxsS/QEH7FV+b8tZkBMieR/Y0ZktQRxByWvVbYbs9b7Tn1x/A3i1PsXGhp5BwYQGtwukYYtgtnYsWQcfrnxa9z1mq4A1XZ8Hm9KvmdlNetU4F6Pjc2WS4it3I2MmU7sbj1ilX2jt5x/Ku9ae840/uQx0zMeJD7kMazp12fMhr0hc2s2cT3pcagtC1E+A41dn8wip5DDDnf65Z2IOQxbFaVCd9T7G+gUK3lzkX6XISos1xBxSzXugbx02seeS8AKHMce1vybfXyoZ+C/0Ozblrs64sQnnA8VI6t1IVBL1EzvS0NANzAjkvMjy4DFoU4Js/qH4L4sp6yJbMWI3RnIVFhj+aBwVFs3XIxGWHm2wILyD6gOGb92mwwrjqu+4hruMimcSKeA1kWOZ4qd55xW08gkgSG0kasjCGoxAnOT4CsUJkc+ssFOhN+cyRHO0HdNANOH4fId3jzJ4hK53R8a6F1JsWoj30djOsXL3yjI7n7avuMbbReWwJV2cg9yQS5q7hRBtPtI+zL9c2cIBfJVvaPLXx2DqLmNVKuzH5Z7U6zxPt4H8zATxrLTET39KIx9aPUG0ZEJEBDJ5o+wP7Ai1JvEXtLLbC9yGVBZCvDrmWlc04k+txOikC+m8uQKIXVWIru4UnGj5M094KXBQBYEnTby1BXgR+JqhleKJhArRagSuUpFYWW1YfVJrzlwRV7jfGRgW6BKws6+MxJmXT9wA6EOdeG+gqlvkwyEVKsq6HMSbmKcIIUqTxRPsbIrtRsFoNiRp5bLWxcFHzBEcfJtpAE6uhXElcoPzisbUP2+geBXI+QVuEJdoO/GIRDFQt1eoyyy8WW2930sqoGfL5gk6WaFL3V09c/wfYySHpDG3DAgAAAABJRU5ErkJggg==",
          "src": "https://latex.codecogs.com/png.latex?%0A0.5006=%5Cfrac%7Be%5E%7BIntercept_%7BHarris%7D%7D%7D%7B2.097755%7D%0A"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAVsAAAARBAMAAACBVRJgAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAVGZ2q0TdiSK7EDKZ781MTLoWAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAEWElEQVRIDc1VXYgbVRT+kslkJpnZZLqxKFRxmlhXpaWzm9JWu62pbbG4D50qwdb6E+uLsA8mWxeqLThSkaLVzSpC1ZfBPtQKtfMgiri6U13RVqmhKBR9MAjSgi+7FWHZVeO5J5PJ7kbE9cU9Se49P9/58s2Zmwkg7Nh+3pK8zl3cucGS8SWfpSSchYqOL0wsiThhsIyuDjG1jsxSSKSd5Ibd57ULJnrvkCqrpKwrZd7pz5bHfloK6jo0vIRo2qsgj5hdNH7IbFXsHfK9Xe6AZEG7qD3Wgf+fEzcBH2IAb2JkmXW0qpWgTmUo81rCQ7KOUqhOCr2Wc1+PTa56OXccct8wwHEu7wR16fCo8Lj04DoHB5YX9ym9xaL38tDtDncFwOb2sNdCtxnlX4Bobhst+Y0BmII8avS6nrJW1EfEB3L4ng6zXNaqAepvNq2OK5RWn/jWwSdIORzrhl4IsAdxxiRXlCJ1PI5djcbVWKPRMJ//Y2ezKwDydmSc5Qp0yKhumgWGkLZwFhMBeBAYkHc+UDffgxazI35yXwHejmj53SiUyjWW3FdWcr6SO78aby2fyw/6jfZTQjVoGYXkc7wXGn8t5Qahl4JSl4GvUQYsBZDwLGW5i/a2pblPEIWMAMl9Cl0FuYqPmsgTvwLV5F046ykrzQRdzDIMdWN/BvoKpNyYfUr199StPfWNxzB2S5ucPOJ/iDYmn4Vc47j5EGfcRSiT5IjSiI01sKFABqn+J7kCHTKyXNBNipvMGFlp8b5wSZY4E0ccH0Svixig96EXjPnTHXcw7pLcvh5bm4Y2w/FUttImS9QBLo14WEtQcblRB0eyw9zVBgqPp8vokDGQuwXp7h6DINtQnN8TRLLPznpvjafcv0kH6P2pu4qvbWI72d1Uf4TkOkDSwqBMcqdFfPR3cUZaRirBpbSBZxwky1Q4CZxA3BNdFOmCbLvIN+UyOmRsyl3tY8Sn44ZoCQcFssNOvdGR6kyQVlIo7BwNRZ4W8YtXBSlUIQUQT24uRQv4xoVO6vEVfaBXaTknvLa1pkuKW4zBdG91x03cDMRHc3Ybv1iPZnejy02b1VlEZkT89m/kkMbvRF4xaeESerJraX4iOSkWqUbLZuG1jeU20VQLnFlRT9Tp7NNXnXHa6MV7aRs3UFfcwJ0glTWOp1hukyzLmyiRswWMFv6jkCa5qwkLVpbLRCEjT3cA+gwdJiF3Hv5fBhPitImzmzCxjraUQ7f1FUgFjl+FVKKkMNmASZsoyR5+Bi5QpNdBT2u9yl2dZ5fRIaOQq04hNpmwsJ4G42EFUfxHo4fhFTznRt3kJewl1Ry/j5Qd8I0Vd/vqPVxKlenvB69TIVEFbsNph7vmfTHdnAAdMoKGjadx2tJK4nLVSrc7r2VxQeZaGx87yB12EOkdBkSsffZ5i+THRsPXLnFJy/dR9gv66GX6hW/4kv43qWuundx12QvQIWPyyT8PQTqwFRjrt/EX/GVVumMAzfkAAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?%0Ae%5E%7BIntercept_%7BHarris%7D%7D=0.5006%20%5Ccdot%202.097755=1.050136%0A"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAV0AAAATBAMAAADBg8MsAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAEIndmVS7djLvImarzUSxOJwNAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAE30lEQVRIDc1VXWgcVRT+Jvs3O/s3lkiVIlltY9SGugGR0oLOg1ZEidtCjLAPpg9VqA8uMSHaNGawLVpREgRRquBQof4gZpomrrrVbkFJHoquEUEQZS1ardqQ2AZDYsXv3rmbbmI2WaUPHmb3fOfMd85898ydGeBy29oaGmZr4FSjaOsvpKudqz1fd0uZWyiDFXz9CudWPRXsUBTNXJ5bLb+I/ZWKQiXgnC2CeO8mGBO53RIg/jUQyY3xr2cPAq4gLJhg0jynJxFoagR+2Ot4nSTI9TjY0SkHm8iqwmAZqLjsquXL56WfVlEMeGPAFsHziDnG7a86Hnh8FtgIXutO3AsUFdtzgqkKAJ+FSYTSgSK2yE4S+NP+QryEbsH3uhMkbBH+06rlK5nxlIoy9F7BLoQsI81QAIB6r0e4EO/AMwDnV2EeQfGOWzgJzQqncYfsJMEZ6HbUhNxH/eXKg2WwxFfLV9LqLBXtpvf0ziI+KPUKIPUCDa7PFcTfFNtzHoErIk/fb+EUN8xQCR/IThJsJTFagBgGHgLaj+bHcfrbjQiMZuObDn8MZNocZNrRvidvifyqFnO9JqAyT68+B33a6B0uSaD09iGRGU4D4cqGiuC5iN/CwG2nMWTjhCk6STCTb4R+fjIpyl6C8fMruB94BBjDZOD1ZDOibjQZzca/3z6Pe0S+fqt2txyMuo5cKOA/JUx0STiqSUoENv/i1DunZbFZAk/viIUhi/cdCRIWihXBcy71Gq8VkUjjZkd0EuDtCwim8dZFVsGYRSCSwl5gDvQ3bT9r/oI+BMxjqHuXN6iZedRZ6BLkqnZWNTGKpEi9HBcVANsU4P4F3jMHXBzjfE0RKVME6XSbeut/Ou9ECrhPzleAq+YpTWvt38KKyBSXmuRkqc23K1cyNzA5z9+tmScRKuAT5sXqOOUVrFk10Rf0ijmIl8YTCki9wSK344MmfJV6FUG6CKh3J65JYTh/wls5gfEXewVN7Uv2i/IK4RKHWFdAg8ME36QGL6SJ4VDni8zzdospN/aiM1PiwTWPujx9yb5RTbQUc3K+4DUGfWn0SyD3wzj807y91Lto/yqCdCPXrZ94tgCIlfaVO/VhhnrfYchlhpPAEALFUsy9soEsjVR9CriCPxLiKeZxMD88iKDdGQgf6A4fyLotevJ9nl7Ygph702ty6XnjDQkVYg62SSD0GjOITvFl/hgvuqhYMJnwXNAyOoCOuI3vpF4JHkYodYTjI4s3CB9xR7g+O+uz8QDfz+CrOuJsRsAeMGM28ziOSAf2odU4Ah4wivqfNmkLpk25XhN8wVyiBOMkziDmREztkATg9HAtrs7qKaGDPSpMMFUBNVkYh56NJSOW7CTBPsRKURtPA2se/RTohd5oBrodozFjhrLsdLjtqPx1jfLj2e1wd0ezGEELchBHnYunBisuyE9XyWsiPkFrPp+w9UOs41c2t8GRQGu+eANCTbzW/q4SkF9ULJjlAv3GF5xQUzf0nl7VSQD9rlagsye9qGyZoPyQvQyOfofRkv4M4OFb9xwKy9CZ4i6rwXbWwPkvFPHM0db+ofVn4W8bQwe3Fvfth+t+tZlfxoLmMsmlKaOwNHN5YvHc/UszrBoK/LUsqoY+Synnfl+aWT3+cXUKxLvl/2JGDUKcGjjLU/4G6BCc/IGzhgcAAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?%0AIntercept_%7BHarris%7D=ln(1.050136)=0.04891968%0A"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAQBAMAAAA2ZkhwAAAAJFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADHJj5lAAAAC3RSTlMAIu8QVESZq2bdiaoDY/wAAAAJcEhZcwAADsQAAA7EAZUrDhsAAABESURBVAgdY2BgYBACYgYGEzCJRIQkADmsAiVAkoNhCkiCeTOIZJkAItkSQCSnA4i0NgCRkSCCoQqIjQSVgSR7mwADAwABUwZabWIS0gAAAABJRU5ErkJggg==",
          "src": "https://latex.codecogs.com/png.latex?j"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAIBAMAAAA2IaO4AAAAKlBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmU0mKAAAADXRSTlMARIkiZlTdqxDvmc12Bf+SEwAAAAlwSFlzAAAOxAAADsQBlSsOGwAAACpJREFUCB1jYFQ0cmRgNVNQZ4iQbBBmaNBiAIKtQMxxA0iwbgASPAcYGAByEwXc4G6iEwAAAABJRU5ErkJggg==",
          "src": "https://latex.codecogs.com/png.latex?r"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAK8AAAAsBAMAAADhmPUwAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAEIndmVS7djLvImarzUSxOJwNAAAACXBIWXMAAA7EAAAOxAGVKw4bAAADxklEQVRIDbVWXYgTVxT+JtnJJJNkMtpKH4QmYFfEbmUVKr41LlVo9WHSH1N2WUwf1KILBkF8sGyDb30oG58sLZRBV0G7urOobOm2NgjSwlZIC4LUh4Yuhe5SJAstlFWw59yZJJOZRBCuH8y5937n3G9u7tx7cgBpUMospUnTAyJvjOz9CEgJSSUvUXkCOGhjkhT1KsYkCj8Csg7qpKhYSMsTjv8HTFmq4ypGLGnKySbwlhmzXUGjJk04VYLxORKkZ7xHpipNOHFs/oSJKOmtpGgfaP2SMNtgoav0OFESPssjKfhBqHzGNmsC26WIsshdofQC23fpqYqhDLNDiPDHw5v0yBF+iW7bv0I4TbuA12lYAsrMKJv+sbh9JmzKe+E1YPNjMV8jq6wCSQd4UXhjJS8I61qdQBvm095atEY7VK/ROR4GYibg3sJMueU80uoE2jCfodkMf2L4kBJcDphhvs5mqsKWQXe+J8L8khfnT2XTyheX6X272TXI5hM2jHjVbYO2B/+KF3PUF2tYi2/TFleY+pvNYdqT0xu/qxiv/epgrIg/Vl5tQL05Sk9ZPfX1DcFzoA8PUJxb+ClwtGwO0EWUOHvngGufOmoJMQepstEY3RGpYRG38SMebsg6Aw7xLvb/TLjN/TX9ry9xABj2PMEmQ4ROO2hdh1ZDxsZ1RC6+fNawtToKyWFsbSwjUiMesa6pRlUl78fQ6110Z5AwaVOaNB6htWIZ2Dk2qUTyQMYBoofmGzQ5lSc+APpJAzn6RfE6hT4JgeaadETIia94uUNQ1qjPZ3SWHFmbBoeQsIao7UbaQaKBNSjD3Xx7xHucyNF2NDFu4IFSaBLBGWqKblGWw1axRLyV3MKD9h5nrlRmodYbffMCC3M2TdYxksQuDbugVsaJjNr4NlrBB/FV3Gd+7h0iO8gm8T1thoNfOlxX7xKw/vgdqjIcnCmgOIrz78/hFIXog2MmP9q+os28uadrXuQWTiM+aOKkj/YXLAs+vme3fdJ+6+l272+PgoWu99PBJ02g6rWBhjMOMNEuWGjAt1yvkXkq6CMKxEteJ9DoeSY6BQsNOC8NiPexqw+M33OuRyv3ifiT+HDB8k2f6BCtpe0Q5xI6NXzFuguWftEhkZj/64e8qVbBYmw7fyuQmELBz0K0Cxb1Qo5uKa1fEviKiYKlsGyuPJeCxRT5f7uk9foLlnusWZUm3C5Y+N9fonCnYFHrpKuXWF0GOgWLuEZcsEhFKz+46UOmtJfRZmRqCq1pV3G3dGHDYslkRbowbJbkrMT4H87d6tK74AzLAAAAAElFTkSuQmCC",
          "src": "https://latex.codecogs.com/png.latex?%0AIntercept_j=ln(%5Cfrac%7BP(j)%7D%7BP(r)%7D)%0A"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAACMAAAATBAMAAADojanHAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAid2ZuzKrVCJmEO9Eds0xWRQzAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA8klEQVQYGUWPPUvDYBSFH5O2iakfpQ5Cp2yu/REOxcX8A1MQXLt261BEcGhBHDI14OAgUgenTtKhHVzcnITOnQQHtTj03NdaD7znnvO84SaBP9278OK8+rF3mEDqyo3zQkrwxfaTyiVB39hun+ibHYu3MLN5klD8pG1R2jcbgD+iYVGamJ3Cc8KD0rQOZUOP2VsNYtjqnGmzSPhjPJzBJgd6Kld4N1QUIlqAl0PJClEsC2S2y6vIcOv91fpey6G53FPswsaxXiO96gxzyKz86lxjrHO06hqFHJr6mPQfhfW7i5F+TTdrTUtXHbhed4XQFdElZlstmJuUCwcAAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?P(j)"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAACMAAAATBAMAAADojanHAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAid2ZuzKrVCJmEO9Eds0xWRQzAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA40lEQVQYGU2Mq24CURBAz/Lo3i7PtIK0iv4BH4EgGPYPuoIEW0kNQTTYYipQ3aQWAgKFAgMkGFwVyeqqJhWUpII7wxJ6xZwz5yYD5zdS2eq8+bmt+hDo8qEzFeD+kpvr4vYFhT7egbwWiISPPuk9z3EqCd8hOaMWp6WwCRufCSzWd3MykqaD3T2Uof3gBBRsMX/STYQ7nGW7ZEK4/paUjvCcipWETVeRFbwy5J+syK1E0Q7k/Di0lPQqf/AFHeELOI2WGJ+wEw5knF4vZv0cIBWqm+CSTEU9GV4SK/W3fwWjSxeOCasrvOgftR8AAAAASUVORK5CYII=",
          "src": "https://latex.codecogs.com/png.latex?P(r)"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAQBAMAAAA2ZkhwAAAAJFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADHJj5lAAAAC3RSTlMAIu8QVESZq2bdiaoDY/wAAAAJcEhZcwAADsQAAA7EAZUrDhsAAABESURBVAgdY2BgYBACYgYGEzCJRIQkADmsAiVAkoNhCkiCeTOIZJkAItkSQCSnA4i0NgCRkSCCoQqIjQSVgSR7mwADAwABUwZabWIS0gAAAABJRU5ErkJggg==",
          "src": "https://latex.codecogs.com/png.latex?j"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAIBAMAAAA2IaO4AAAAKlBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmU0mKAAAADXRSTlMARIkiZlTdqxDvmc12Bf+SEwAAAAlwSFlzAAAOxAAADsQBlSsOGwAAACpJREFUCB1jYFQ0cmRgNVNQZ4iQbBBmaNBiAIKtQMxxA0iwbgASPAcYGAByEwXc4G6iEwAAAABJRU5ErkJggg==",
          "src": "https://latex.codecogs.com/png.latex?r"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": "data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAFQAAAAQBAMAAAB6jEWIAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAdomZu1QiEGbdMu/NRKugN9EaAAAACXBIWXMAAA7EAAAOxAGVKw4bAAABU0lEQVQoFZWRvUvDUBTFT/oR42tjsUVwEhEEl2IFF4eCDoKDQ9RR0MyC6OTgFO3i2NExqyC0Y0cn5wh1Emk2/4DSWgpS77mW0C14h3d/59yTxyUPKG97cJer0Hq7j/4EYbbuFn1k/LkRnlH0OTAveFWhMBPNetkY8yF2sA+rxkHOQ0WFwky0CxOiEGATY7htDkohPlQoALZcYHGTx+lnh2YI803R8tG6pSBci3EGlDkYPKyz2WNXpkNiTxKXFARfDKdmrUqz+9wNKAaSk7SUjHsXFASfTqPC04zgNKVvyL3I6wJXIc5vKAhcAAtMwP7RgBMAQm1apQinKhToNHRVDDT6DgcHsGIOcgFWVCiIMd0Ve7CaMPXPE3TlCewvwN2VJ6BQkKj8gTVpeEIxQmEy6SO/VIXpiHV0HKlQkB1jIBOJb7bqciaVTygV/hH1Ui9LAmnRXztdaMlf3PkiAAAAAElFTkSuQmCC",
          "src": "https://latex.codecogs.com/png.latex?20,000%20%5Ctimes%206"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-33-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-35-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-36-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/tomerzipori.github.io/blog/posts/elections2024/one_big_plot2.png?w=578&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-49-1.png?w=450&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-52-1.png?w=450&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/tomer-zipori/",
          "text": "Tomer Zipori"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-389817 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">US Presidential Elections – A Bayesian Perspective</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">January 12, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/tomer-zipori/\">Tomer Zipori</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://tomerzipori.github.io/blog/posts/elections2024/\"> Tomer's stats blog</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<section class=\"level1\" id=\"setup\">\n<h1>Setup</h1>\n<div class=\"cell\">\n<pre>library(tidyverse) # As always\nlibrary(brms)      # For Bayesian modeling\nlibrary(tidybayes) # For visualization\nlibrary(patchwork)</pre>\n</div>\n</section>\n<section class=\"level1\" id=\"introduction\">\n<h1>Introduction</h1>\n<p>Ever since I’ve finished my grad studies (Few months ago), I wanted to experiment with some “real life” applications of statistics. Things that interest real people. With the 2024 American presidential elections being the hot issue around the world, and Bayesian statistics being the hot issue of my personal projects, I thought how can these two mix.</p>\n<p>Two features of Bayesian statistics pop to mind when thinking about election polling:</p>\n<section class=\"level2\" id=\"prior-distributions\">\n<h2 class=\"anchored\" data-anchor-id=\"prior-distributions\">Prior Distributions</h2>\n<p>The need to explicitly define a prior distribution for any Bayesian model is a point of contention. Some (rightfully) argue that this definition can’t be objective, and it is practically impossible to represent the existing body of knowledge in a single probability distribution. Others (rightfully) argue that every statistical model have prior assumptions which are rarely checked, and can influence the model as much as a prior distribution.<sup>1</sup></p>\n<p>One reason the incorporation of past studies into the prior distribution is hard, is that it depends on the specific parameters of the model.</p>\n<p>While prior elicitation can be hard in many cases, election polling is one area where it should be relatively easy! every poll is essentially the same statistical model (how many votes for red, and how many votes for blue), but every time with different data. This is the ideal scenario for a Bayesian statistician as the posterior distribution (the result) of any poll can be used as the prior distribution for the next poll!</p>\n<section class=\"level3\" id=\"graphic\">\n<h3 class=\"anchored\" data-anchor-id=\"graphic\">Graphic</h3>\n</section>\n</section>\n<section class=\"level2\" id=\"posterior-predictive-distributions\">\n<h2 class=\"anchored\" data-anchor-id=\"posterior-predictive-distributions\">Posterior Predictive Distributions</h2>\n<p>One tool of Bayesian statistical inference is the Posterior Predictive Distributions – PPD. This is the prediction of the model. For example, one possible PPD from a Bayesian election poll could be the expected electoral college result for each candidate, or the expected number of seats in the parliament.</p>\n</section>\n</section>\n<section class=\"level1\" id=\"data\">\n<h1>Data</h1>\n<p>The following dataset is a summary of many polls conducted from the start of 2023, up to two days before the election.</p>\n<div class=\"cell\">\n<pre>data &lt;- read_csv(\"../elections2024/president_polls.csv\", show_col_types = F)</pre>\n</div>\n<div class=\"cell\">\n<pre>glimpse(data)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Rows: 18,095\nColumns: 52\n$ poll_id                   &lt;dbl&gt; 89372, 89372, 89372, 89372, 89372, 89372, 89…\n$ pollster_id               &lt;dbl&gt; 1528, 1528, 1528, 1528, 1528, 1528, 1528, 15…\n$ pollster                  &lt;chr&gt; \"AtlasIntel\", \"AtlasIntel\", \"AtlasIntel\", \"A…\n$ sponsor_ids               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ sponsors                  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ display_name              &lt;chr&gt; \"AtlasIntel\", \"AtlasIntel\", \"AtlasIntel\", \"A…\n$ pollster_rating_id        &lt;dbl&gt; 546, 546, 546, 546, 546, 546, 546, 546, 546,…\n$ pollster_rating_name      &lt;chr&gt; \"AtlasIntel\", \"AtlasIntel\", \"AtlasIntel\", \"A…\n$ numeric_grade             &lt;dbl&gt; 2.7, 2.7, 2.7, 2.7, 2.7, 2.7, 2.7, 2.7, 2.7,…\n$ pollscore                 &lt;dbl&gt; -0.8, -0.8, -0.8, -0.8, -0.8, -0.8, -0.8, -0…\n$ methodology               &lt;chr&gt; \"Online Ad\", \"Online Ad\", \"Online Ad\", \"Onli…\n$ transparency_score        &lt;dbl&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,…\n$ state                     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, \"Arizona\", \"Ariz…\n$ start_date                &lt;chr&gt; \"11/3/24\", \"11/3/24\", \"11/3/24\", \"11/3/24\", …\n$ end_date                  &lt;chr&gt; \"11/4/24\", \"11/4/24\", \"11/4/24\", \"11/4/24\", …\n$ sponsor_candidate_id      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ sponsor_candidate         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ sponsor_candidate_party   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ endorsed_candidate_id     &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ endorsed_candidate_name   &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ endorsed_candidate_party  &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ question_id               &lt;dbl&gt; 216453, 216453, 216453, 216453, 216453, 2164…\n$ sample_size               &lt;dbl&gt; 2703, 2703, 2703, 2703, 2703, 2703, 2703, 87…\n$ population                &lt;chr&gt; \"lv\", \"lv\", \"lv\", \"lv\", \"lv\", \"lv\", \"lv\", \"l…\n$ subpopulation             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ population_full           &lt;chr&gt; \"lv\", \"lv\", \"lv\", \"lv\", \"lv\", \"lv\", \"lv\", \"l…\n$ tracking                  &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ created_at                &lt;chr&gt; \"11/4/24 19:06\", \"11/4/24 19:06\", \"11/4/24 1…\n$ notes                     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ url                       &lt;chr&gt; \"https://atlasintel.org/poll/usa-national-20…\n$ url_article               &lt;chr&gt; \"https://atlasintel.org/poll/usa-national-20…\n$ url_topline               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ url_crosstab              &lt;chr&gt; \"https://cdn.atlasintel.org/f1cec70d-8eae-44…\n$ source                    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ internal                  &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ partisan                  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ race_id                   &lt;dbl&gt; 8914, 8914, 8914, 8914, 8914, 8914, 8914, 87…\n$ cycle                     &lt;dbl&gt; 2024, 2024, 2024, 2024, 2024, 2024, 2024, 20…\n$ office_type               &lt;chr&gt; \"U.S. President\", \"U.S. President\", \"U.S. Pr…\n$ seat_number               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ seat_name                 &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ election_date             &lt;chr&gt; \"11/5/24\", \"11/5/24\", \"11/5/24\", \"11/5/24\", …\n$ stage                     &lt;chr&gt; \"general\", \"general\", \"general\", \"general\", …\n$ nationwide_batch          &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA…\n$ ranked_choice_reallocated &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA…\n$ ranked_choice_round       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ hypothetical              &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA…\n$ party                     &lt;chr&gt; \"DEM\", \"REP\", \"GRE\", \"IND\", \"LIB\", \"DEM\", \"R…\n$ answer                    &lt;chr&gt; \"Harris\", \"Trump\", \"Stein\", \"West\", \"Oliver\"…\n$ candidate_id              &lt;dbl&gt; 16661, 16651, 31116, 31097, 31790, 16661, 16…\n$ candidate_name            &lt;chr&gt; \"Kamala Harris\", \"Donald Trump\", \"Jill Stein…\n$ pct                       &lt;dbl&gt; 48.1, 49.2, 1.1, 0.3, 0.1, 48.8, 50.0, 45.9,…</pre>\n</div>\n</div>\n</section>\n<section class=\"level1\" id=\"preprocessing\">\n<h1>Preprocessing</h1>\n<p>Some preprocessing and cleaning is needed here, mainly I want to include only recent polls to avoid dealing with a large number of candidates, and transforming the percentage of votes to a probability:</p>\n<div class=\"cell\">\n<pre>data_clean &lt;- data |&gt;\n  select(poll_id, state, poll_date = start_date, question_id, candidate_name, sample_size, pct) |&gt; # selecting relevant cols only\n  mutate(pct = pct / 100,               # transforming to probabilities\n         poll_date = mdy(poll_date)) |&gt; # transforming to 'date' types\n  filter(year(poll_date) &gt;= 2024 &amp; month(poll_date) &gt;= 10) |&gt; # only recent polls to control for speculative candidates\n  mutate(candidate_name = relevel(factor(candidate_name), ref = \"Donald Trump\")) |&gt; # Defining 'Trump' to be the reference level\n  group_by(poll_id) |&gt;                  # some polls have several q's, this keeps only the main 'who would you vote for' question\n  filter(question_id == min(question_id)) |&gt;\n  ungroup()</pre>\n</div>\n</section>\n<section class=\"level1\" id=\"modeling\">\n<h1>Modeling</h1>\n<p>From a statistical point of view, an election poll is a multiclass classification problem: It estimates the real proportion of votes for each candidate in the population, from the sampled proportions. The dependent variable is categorical and does not have any ordering. Since we don’t have any predictors other than the observed proportions, the model is what is called an <em>empty</em> model - and it’s formulation in <code>R</code> is usually represented as: <code>DV ~ 1</code>. Due to the structure of the current data, each observation (row) need to be weighted by the observed percentage. In order to include weighting by the poll’s sample size, I multiplied this percentage by the sample size.</p>\n<p>This multiclass classification problem can be represented with a series of logistic models, each models one category (candidate) against the others as a binary outcome. In order to do that, I will use the <code>categorical()</code> family implemented in <code>brms</code>.</p>\n<p>Let’s start with a simple case, and model results only for Nevada:</p>\n<div class=\"cell\">\n<pre>data_clean_nv &lt;- data_clean |&gt;\n  filter(state == \"Nevada\")</pre>\n</div>\n<div class=\"cell\">\n<pre>bayesian_model_nv &lt;- brm(formula = candidate_name|weights(sample_size*pct) ~ 1,\n                         family = categorical(link = \"logit\"),\n                         data = data_clean_nv,\n                         chains = 10,\n                         cores = 10,\n                         iter = 4000,\n                         refresh = 0,\n                         seed = 14,\n                         backend = \"cmdstanr\")</pre>\n</div>\n<div class=\"cell\">\n<pre>summary(bayesian_model_nv)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre> Family: categorical \n  Links: muChaseOliver = logit; muCornelWest = logit; muJillStein = logit; muJoelSkousen = logit; muKamalaHarris = logit \nFormula: candidate_name | weights(sample_size * pct) ~ 1 \n   Data: data_clean_nv (Number of observations: 85) \n  Draws: 10 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 20000\n\nRegression Coefficients:\n                         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nmuChaseOliver_Intercept     -4.92      0.11    -5.14    -4.71 1.00     8712\nmuCornelWest_Intercept     -15.07     10.71   -36.77    -8.70 1.00     2989\nmuJillStein_Intercept       -6.10      0.20    -6.51    -5.73 1.00     8233\nmuJoelSkousen_Intercept    -15.53     12.01   -39.09    -8.70 1.00     2538\nmuKamalaHarris_Intercept     0.00      0.01    -0.02     0.03 1.00     9124\n                         Tail_ESS\nmuChaseOliver_Intercept      9672\nmuCornelWest_Intercept       1751\nmuJillStein_Intercept        7736\nmuJoelSkousen_Intercept      1491\nmuKamalaHarris_Intercept     9396\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).</pre>\n</div>\n</div>\n<p>few things to notice: first, Trump doesn’t have a parameter. That is because <code>brms</code> estimates each parameter in comparison to the factor’s reference level, which is set to <img data-lazy-src=\"https://latex.codecogs.com/png.latex?0\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?0\"/></noscript>, or <img data-lazy-src=\"https://latex.codecogs.com/png.latex?1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?1\"/></noscript> on the exponential scale. Second, parameter estimates are logits, as this is essentially an output of multiple logistic regressions. In order to transform these estimates into predicted vote shares for every candidate <img data-lazy-src=\"https://latex.codecogs.com/png.latex?j\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?j\"/></noscript> out of the <img data-lazy-src=\"https://latex.codecogs.com/png.latex?K\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?K\"/></noscript> total candidates, a softmax transformation need to be applied:</p>\n<p><img data-lazy-src=\"https://latex.codecogs.com/png.latex?%0AP(j)=%5Cfrac%7Be%5E%7BIntercept_j%7D%7D%7B%5Csum_%7Bk=1%7D%5EK%20e%5E%7BIntercept_k%7D%7D%0A\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?%0AP(j)=%5Cfrac%7Be%5E%7BIntercept_j%7D%7D%7B%5Csum_%7Bk=1%7D%5EK%20e%5E%7BIntercept_k%7D%7D%0A\"/></noscript></p>\n<p>Extracting more precise point-estimates:</p>\n<div class=\"cell\">\n<pre>draws_nv &lt;- spread_draws(bayesian_model_nv, b_muChaseOliver_Intercept, b_muCornelWest_Intercept, b_muJillStein_Intercept, b_muJoelSkousen_Intercept, b_muKamalaHarris_Intercept)\n\n(c(median(draws_nv$b_muChaseOliver_Intercept), median(draws_nv$b_muCornelWest_Intercept), median(draws_nv$b_muJillStein_Intercept), median(draws_nv$b_muJoelSkousen_Intercept), median(draws_nv$b_muKamalaHarris_Intercept)))</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1]  -4.913210000 -12.452300000  -6.088395000 -12.626300000   0.002381675</pre>\n</div>\n</div>\n<p>For example, applying the softmax transformation in order to get the predicted vote share of Jill Stein:</p>\n<div class=\"cell\">\n<pre>100 * exp(-6.088395) / (exp(-4.91321) + exp(-12.4523) + exp(-6.088395) + exp(-12.6263) + exp(0.002381675) + exp(0))</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 0.1127752</pre>\n</div>\n</div>\n<p>About 0.1%.</p>\n<p>The predicted vote share of Kamala Harris is:</p>\n<div class=\"cell\">\n<pre>100 * exp(0.002381675) / (exp(-4.91321) + exp(-12.4523) + exp(-6.088395) + exp(-12.6263) + exp(0.002381675) + exp(0))</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 49.82007</pre>\n</div>\n</div>\n<p>And of Donald Trump:</p>\n<div class=\"cell\">\n<pre>100 * exp(0) / (exp(-4.91321) + exp(-12.4523) + exp(-6.088395) + exp(-12.6263) + exp(0.002381675) + exp(0))</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 49.70155</pre>\n</div>\n</div>\n<p>But, this is a Bayesian model so let’s not stay stuck with point estimates and look at the whole posterior distribution:</p>\n<p>Extracting draws:</p>\n<div class=\"cell\">\n<pre>probs_nv &lt;- draws_nv |&gt;\n  select(-.chain, -.iteration) |&gt;\n  mutate(b_muChaseOliver_Intercept = exp(b_muChaseOliver_Intercept),\n         b_muKamalaHarris_Intercept = exp(b_muKamalaHarris_Intercept),\n         b_muJillStein_Intercept = exp(b_muJillStein_Intercept),\n         b_muCornelWest_Intercept = exp(b_muCornelWest_Intercept),\n         b_muJoelSkousen_Intercept = exp(b_muJoelSkousen_Intercept)) |&gt;\n  mutate(row_sum = b_muChaseOliver_Intercept + b_muKamalaHarris_Intercept + b_muJillStein_Intercept + b_muCornelWest_Intercept + b_muJoelSkousen_Intercept + 1) |&gt;\n  mutate(Trump = 1 / row_sum,\n         Harris = b_muKamalaHarris_Intercept / row_sum) |&gt;\n  select(.draw, Trump, Harris)</pre>\n</div>\n<div class=\"cell\">\n<pre>probs_nv |&gt;\n  pivot_longer(cols = c(Trump, Harris),\n               names_to = \"Candidate\",\n               values_to = \"prob\") |&gt;\n  ggplot(aes(x = prob * 100, fill = Candidate)) +\n  stat_slab(color = \"gray24\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"#2166AC\", \"#B2182B\")) +\n  scale_x_continuous(breaks = seq(48, 52, 0.2), labels = seq(48, 52, 0.2)) +\n  labs(x = \"Predicted vote share in %\") +\n  theme_classic() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i0.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-16-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-16-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<p>Very close!</p>\n<p>And what is the predicted difference between the two main candidates?</p>\n<div class=\"cell\">\n<pre>probs_nv |&gt;\n  mutate(diff = Trump - Harris) |&gt;\n  ggplot(aes(x = diff * 100, fill = after_stat(x &gt; 0))) +\n  stat_slab(color = \"gray24\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  scale_fill_manual(values = c(\"#2166AC\", \"#B2182B\"), labels = c(\"Harris win\", \"Trump win\")) +\n  scale_x_continuous(breaks = seq(-3, 4, 0.5), labels = seq(-3, 4, 0.5)) +\n  labs(x = \"Predicted vote share difference in %\", fill = \" \") +\n  theme_classic() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i0.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-17-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-17-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<p>Again, very close (with a slight advantage to Harris).</p>\n<p>Another useful measure from Bayesian statistics is the probability of direction (pd). Due to the winner-takes-all electoral system in 48 of the 50 states, the difference doesn’t really matter. So what is the probability that each candidate will win?</p>\n<p>The probability that Trump will win is seen in the red area in the plot above, that is the probability that the difference in vote share is positive:</p>\n<div class=\"cell\">\n<pre>diff &lt;- probs_nv$Trump - probs_nv$Harris</pre>\n</div>\n<div class=\"cell\">\n<pre>length(diff[diff &gt; 0]) / length(diff)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 0.42815</pre>\n</div>\n</div>\n<p>Trump has a 42.82% chance of winning Nevada.</p>\n<div class=\"cell\">\n<pre>length(diff[diff &lt; 0]) / length(diff)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 0.57185</pre>\n</div>\n</div>\n<p>And Harris has 57.19% chance.</p>\n<p>Let’s make the plot a little more informative:</p>\n<div class=\"cell\">\n<pre>diff_plot &lt;- probs_nv |&gt;\n  mutate(diff = Trump - Harris) |&gt;\n  mutate(diff = diff * 100) |&gt;\n  ggplot(aes(x = diff, fill = after_stat(cut(x, breaks = c(-Inf, -2, -1, 0, 1, 2, Inf), labels = c(\"Harris by more than 2%\", \"Harris by 1%-2%\", \"Harris by less than 1%\", \"Trump by less than 1%\", \"Trump by 1%-2%\", \"Trump by more than 2%\"))))) +\n  stat_slab(color = \"gray24\") +\n  scale_fill_manual(values = rev(RColorBrewer::brewer.pal(6, \"RdBu\"))) +\n  scale_x_continuous(limits = c(-3, 3), breaks = seq(-3, 3, 0.5), labels = seq(-3, 3, 0.5)) +\n  labs(fill = \" \", x = \"Predicted Difference in %\", title = \"Predicted difference in votes - Nevada\") +\n  theme_classic() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        plot.title = element_text(family = \"serif\", size = 22, hjust = 0.5))</pre>\n</div>\n<div class=\"cell\">\n<pre>diff_plot</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i2.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-22-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-22-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<section class=\"level2\" id=\"eliciting-a-custom-prior\">\n<h2 class=\"anchored\" data-anchor-id=\"eliciting-a-custom-prior\">Eliciting a custom prior</h2>\n<p>For the last model we used brms’ default prior. In order to elicit our own, For simplicity, I’ll start with the 2020 vote share between Biden and Trump:</p>\n<div class=\"quarto-figure quarto-figure-center\">\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i0.wp.com/tomerzipori.github.io/blog/posts/elections2024/2020_results_nv.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/tomerzipori.github.io/blog/posts/elections2024/2020_results_nv.png?w=578&amp;ssl=1\"/></noscript></p>\n<figcaption>2020 Results - Nevada (from <a href=\"https://en.wikipedia.org/wiki/2020_United_States_presidential_election_in_Nevada\" rel=\"nofollow\" target=\"_blank\">Wikipedia</a>)</figcaption>\n</figure>\n</div>\n<div class=\"callout callout-style-default callout-note callout-titled\">\n<div class=\"callout-header d-flex align-content-center\">\n<div class=\"callout-icon-container\">\n<i class=\"callout-icon\"></i>\n</div>\n<div class=\"callout-title-container flex-fill\">\nNote\n</div>\n</div>\n<div class=\"callout-body-container callout-body\">\n<p>This part contain some math. Don’t skip it, you can understand it! But if you want to skip it, go to the ‘Modeling with a custom prior’ section.</p>\n</div>\n</div>\n<div class=\"cell\">\n<pre>prior_trump &lt;- 0.4767\nprior_harris &lt;- 0.5006</pre>\n</div>\n<p>These percentages need to be transformed to the logistic model’s scale, now using the inverse-softmax transformation:</p>\n<p><img data-lazy-src=\"https://latex.codecogs.com/png.latex?%0A0.5006=softmax(Intercept_%7BHarris%7D)=%5Cfrac%7Be%5E%7BIntercept_%7BHarris%7D%7D%7D%7B%5Csum_%7Bk=1%7D%5EK%20e%5E%7BIntercept_k%7D%7D%0A\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?%0A0.5006=softmax(Intercept_%7BHarris%7D)=%5Cfrac%7Be%5E%7BIntercept_%7BHarris%7D%7D%7D%7B%5Csum_%7Bk=1%7D%5EK%20e%5E%7BIntercept_k%7D%7D%0A\"/></noscript></p>\n<p>And:</p>\n<p><img data-lazy-src=\"https://latex.codecogs.com/png.latex?%0A0.4767=softmax(Intercept_%7BTrump%7D)=%5Cfrac%7Be%5E%7BIntercept_%7BTrump%7D%7D%7D%7B%5Csum_%7Bk=1%7D%5EK%20e%5E%7BIntercept_k%7D%7D%0A\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?%0A0.4767=softmax(Intercept_%7BTrump%7D)=%5Cfrac%7Be%5E%7BIntercept_%7BTrump%7D%7D%7D%7B%5Csum_%7Bk=1%7D%5EK%20e%5E%7BIntercept_k%7D%7D%0A\"/></noscript></p>\n<p>But with Trump’s intercept fixed to <img data-lazy-src=\"https://latex.codecogs.com/png.latex?0\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?0\"/></noscript> as the factor’s reference level, it’s possible to calculate the sum in the denominator:</p>\n<p><img data-lazy-src=\"https://latex.codecogs.com/png.latex?%0A0.4767=%5Cfrac%7B1%7D%7B%5Csum_%7Bk=1%7D%5EK%20e%5E%7BIntercept_k%7D%7D%0A\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?%0A0.4767=%5Cfrac%7B1%7D%7B%5Csum_%7Bk=1%7D%5EK%20e%5E%7BIntercept_k%7D%7D%0A\"/></noscript></p>\n<p>Quick algebra gives:</p>\n<p><img data-lazy-src=\"https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bk=1%7D%5EK%20e%5E%7BIntercept_k%7D=%5Cfrac%7B1%7D%7B0.4767%7D=2.097755%0A\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bk=1%7D%5EK%20e%5E%7BIntercept_k%7D=%5Cfrac%7B1%7D%7B0.4767%7D=2.097755%0A\"/></noscript></p>\n<p>Now it’s possible to calculate Harris’ intercept:</p>\n<p><img data-lazy-src=\"https://latex.codecogs.com/png.latex?%0A0.5006=%5Cfrac%7Be%5E%7BIntercept_%7BHarris%7D%7D%7D%7B2.097755%7D%0A\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?%0A0.5006=%5Cfrac%7Be%5E%7BIntercept_%7BHarris%7D%7D%7D%7B2.097755%7D%0A\"/></noscript></p>\n<p><img data-lazy-src=\"https://latex.codecogs.com/png.latex?%0Ae%5E%7BIntercept_%7BHarris%7D%7D=0.5006%20%5Ccdot%202.097755=1.050136%0A\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?%0Ae%5E%7BIntercept_%7BHarris%7D%7D=0.5006%20%5Ccdot%202.097755=1.050136%0A\"/></noscript></p>\n<p><img data-lazy-src=\"https://latex.codecogs.com/png.latex?%0AIntercept_%7BHarris%7D=ln(1.050136)=0.04891968%0A\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?%0AIntercept_%7BHarris%7D=ln(1.050136)=0.04891968%0A\"/></noscript></p>\n<p>A quicker way to derive these intercepts is to notice that for every candidate <img data-lazy-src=\"https://latex.codecogs.com/png.latex?j\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?j\"/></noscript> other than the ‘reference’ candidate <img data-lazy-src=\"https://latex.codecogs.com/png.latex?r\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?r\"/></noscript>, the intercept is:</p>\n<p><img data-lazy-src=\"https://latex.codecogs.com/png.latex?%0AIntercept_j=ln(%5Cfrac%7BP(j)%7D%7BP(r)%7D)%0A\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?%0AIntercept_j=ln(%5Cfrac%7BP(j)%7D%7BP(r)%7D)%0A\"/></noscript></p>\n<p>Where <img data-lazy-src=\"https://latex.codecogs.com/png.latex?P(j)\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?P(j)\"/></noscript> and <img data-lazy-src=\"https://latex.codecogs.com/png.latex?P(r)\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?P(r)\"/></noscript> are the assumed vote shares of candidate <img data-lazy-src=\"https://latex.codecogs.com/png.latex?j\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?j\"/></noscript> and <img data-lazy-src=\"https://latex.codecogs.com/png.latex?r\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?r\"/></noscript> respectively.</p>\n</section>\n</section>\n<section class=\"level1\" id=\"modeling-with-a-custom-prior\">\n<h1>Modeling with a custom prior</h1>\n<p>Setting the prior for Harris’ intercept, giving it relatively large standard deviation reflecting the many factors differentiating the 2024 and 2020 elections.</p>\n<div class=\"cell\">\n<pre>prior_nv &lt;- set_prior(\"normal(0.04891968, 0.1)\", class = \"Intercept\", dpar = \"muKamalaHarris\")</pre>\n</div>\n<div class=\"cell\">\n<pre>bayesian_model_nv_wprior &lt;- brm(formula = candidate_name|weights(sample_size*pct) ~ 1,\n                                family = categorical(link = \"logit\"),\n                                data = data_clean_nv,\n                                prior = prior_nv,\n                                chains = 10,\n                                cores = 10,\n                                iter = 4000,\n                                refresh = 0,\n                                seed = 14,\n                                backend = \"cmdstanr\")</pre>\n</div>\n<div class=\"cell\">\n<pre>summary(bayesian_model_nv_wprior)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre> Family: categorical \n  Links: muChaseOliver = logit; muCornelWest = logit; muJillStein = logit; muJoelSkousen = logit; muKamalaHarris = logit \nFormula: candidate_name | weights(sample_size * pct) ~ 1 \n   Data: data_clean_nv (Number of observations: 85) \n  Draws: 10 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 20000\n\nRegression Coefficients:\n                         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nmuChaseOliver_Intercept     -4.92      0.11    -5.14    -4.71 1.00    10322\nmuCornelWest_Intercept     -14.79      7.81   -36.48    -8.68 1.01     2915\nmuJillStein_Intercept       -6.09      0.20    -6.50    -5.72 1.00     9801\nmuJoelSkousen_Intercept    -15.41     11.07   -37.29    -8.72 1.00     2797\nmuKamalaHarris_Intercept     0.00      0.01    -0.02     0.03 1.00    10356\n                         Tail_ESS\nmuChaseOliver_Intercept     10191\nmuCornelWest_Intercept       1659\nmuJillStein_Intercept        9246\nmuJoelSkousen_Intercept      1551\nmuKamalaHarris_Intercept    10037\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).</pre>\n</div>\n</div>\n<p>I’ll inspect the model again, this time using the <code>brms::posterior_epred()</code> function, generating predictions on the probability scale:</p>\n<div class=\"cell\">\n<pre>new_data &lt;- expand.grid(x = NA)\n\npred_probs_nv &lt;- posterior_epred(bayesian_model_nv_wprior, newdata = new_data)</pre>\n</div>\n<p>This essentially creates a <img data-lazy-src=\"https://latex.codecogs.com/png.latex?20,000%20%5Ctimes%206\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img src=\"https://latex.codecogs.com/png.latex?20,000%20%5Ctimes%206\"/></noscript> array of 20,000 “simulated elections” based on the model, and the vote share of each of the 6 candidates. For example, here are the first 5 simulated elections and the vote share in each:</p>\n<div class=\"cell\">\n<pre>pred_probs_nv[1:5,,]</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>     Donald Trump Chase Oliver  Cornel West  Jill Stein Joel Skousen\n[1,]    0.4953947  0.003684427 5.757740e-05 0.001019819 1.934454e-05\n[2,]    0.4994877  0.004458325 1.934866e-06 0.001474521 1.406709e-05\n[3,]    0.5026360  0.003951306 1.079202e-06 0.001657708 8.114247e-06\n[4,]    0.5044252  0.003509907 9.118997e-07 0.001623817 1.605403e-06\n[5,]    0.4987907  0.003857605 2.889669e-06 0.001544016 5.206677e-06\n     Kamala Harris\n[1,]     0.4998241\n[2,]     0.4945634\n[3,]     0.4917458\n[4,]     0.4904386\n[5,]     0.4957995</pre>\n</div>\n</div>\n<p>Turning it into the same plots as before gives:</p>\n<div class=\"cell\">\n<pre>pred_probs_nv_df &lt;- data.frame(pred_probs_nv[,1,]) |&gt;\n  mutate(poll_id = factor(c(1:n()))) |&gt;\n  pivot_longer(cols = !poll_id,\n               names_to = \"Candidate\",\n               values_to = \"Proportion\") |&gt;\n  mutate(Candidate = str_replace_all(Candidate, \"\\\\.\", \" \")) |&gt;\n  mutate(Candidate = str_replace(Candidate, \"^\\\\S* \", \"\"))</pre>\n</div>\n<div class=\"cell\">\n<pre>prob_plot &lt;- pred_probs_nv_df |&gt;\n  filter(Candidate %in% c(\"Trump\", \"Harris\")) |&gt;\n  ggplot(aes(x = 100 * Proportion, fill = Candidate)) +\n  ggdist::stat_slab(color = \"gray24\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"#2166AC\", \"#B2182B\")) +\n  scale_x_continuous(breaks = seq(48, 52, 0.2), labels = seq(48, 52, 0.2)) +\n  labs(x = \"Predicted vote share in %\") +\n  theme_classic() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())</pre>\n</div>\n<div class=\"cell\">\n<pre>prob_plot</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i0.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-33-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-33-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<div class=\"cell\">\n<pre>diff_plot_wprior &lt;- pred_probs_nv_df |&gt;\n  filter(Candidate %in% c(\"Trump\", \"Harris\")) |&gt;\n  pivot_wider(id_cols = poll_id,\n              names_from = Candidate,\n              values_from = Proportion) |&gt;\n  mutate(diff = Trump - Harris) |&gt;\n  mutate(diff = diff * 100) |&gt;\n  ggplot(aes(x = diff, fill = after_stat(cut(x, breaks = c(-Inf, -2, -1, 0, 1, 2, Inf), labels = c(\"Harris by more than 2%\", \"Harris by 1%-2%\", \"Harris by less than 1%\", \"Trump by less than 1%\", \"Trump by 1%-2%\", \"Trump by more than 2%\"))))) +\n  ggdist::stat_slab(color = \"gray24\") +\n  scale_fill_manual(values = rev(RColorBrewer::brewer.pal(6, \"RdBu\"))) +\n  scale_x_continuous(limits = c(-3, 3), labels = seq(-3, 3, 0.5), breaks = seq(-3, 3, 0.5)) +\n  labs(fill = \" \", x = \"Predicted Difference in %\", title = \"Predicted difference in votes - Nevada\", subtitle = \"Custom Prior\") +\n  theme_classic() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        plot.title = element_text(family = \"serif\", size = 22, hjust = 0.5),\n        plot.subtitle = element_text(family = \"serif\", size = 16, hjust = 0.5))</pre>\n</div>\n<div class=\"cell\">\n<pre>diff_plot_wprior</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i1.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-35-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-35-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<p>How much the custom prior has changed the result?</p>\n<div class=\"cell\">\n<pre>diff_plot / diff_plot_wprior +\n  plot_layout(guides = \"collect\")</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i2.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-36-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-36-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<p>Visually, not by much…</p>\n<p>And what about the predicted chance of each candidate of winning the state?</p>\n<div class=\"cell\">\n<pre>probs_nv &lt;- pred_probs_nv_df |&gt;\n  filter(Candidate %in% c(\"Trump\", \"Harris\")) |&gt;\n  pivot_wider(id_cols = poll_id,\n              names_from = Candidate,\n              values_from = Proportion)\n\ndiff &lt;- probs_nv$Trump - probs_nv$Harris</pre>\n</div>\n<div class=\"cell\">\n<pre>length(diff[diff &gt; 0]) / length(diff)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 0.40885</pre>\n</div>\n</div>\n<p>Trump now has a 40.89% chance of winning Nevada, compared with the 42.82% he had before setting the prior.</p>\n<div class=\"cell\">\n<pre>length(diff[diff &lt; 0]) / length(diff)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 0.59115</pre>\n</div>\n</div>\n<p>And Harris has 59.12% chance, a slight increase from the 57.19% she had before.</p>\n<p>Although visually there hasn’t been much of a change, the prior shifted the chances of winning by ~2% in favor of Harris.</p>\n</section>\n<section class=\"level1\" id=\"running-models-for-all-states\">\n<h1>Running models for all states</h1>\n<p>In this section I run the same Bayesian model for each state. The better way of doing it will be to run one big model with <code>state</code> as a categorical predictor.<sup>2</sup> This one-big-model method didn’t converge on the current data, so I resort to run a separate model for each state.</p>\n<p>Here I define some functions to run on the list of states:</p>\n<div class=\"cell\">\n<pre>run_b_model &lt;- function(state) {\n  \n  data_clean_state &lt;- data_clean[data_clean$state == state,]\n  \n  bayesian_model &lt;- brm(formula = candidate_name|weights(sample_size*pct) ~ 1,\n                        family = categorical(link = \"logit\"),\n                        data = data_clean_state,\n                        chains = 10,\n                        cores = 10,\n                        iter = 4000,\n                        refresh = 0,\n                        seed = 14,\n                        backend = \"cmdstanr\")\n  \n  return(bayesian_model)\n}\n\nplots &lt;- function(state) {\n  \n  b_model &lt;- run_b_model(state = state)\n  \n  new_data &lt;- expand.grid(x = NA)\n\n  pred_prob &lt;- posterior_epred(b_model, newdata = new_data)\n\n  pred_prob_df &lt;- data.frame(pred_prob[,1,]) |&gt;\n    mutate(poll_id = factor(c(1:n()))) |&gt;\n    pivot_longer(cols = !poll_id,\n                 names_to = \"Candidate\",\n                 values_to = \"Proportion\") |&gt;\n    mutate(Candidate = str_squish(str_replace_all(Candidate, \"\\\\.\", \" \")))\n  \n  prob_plot &lt;- pred_prob_df |&gt;\n  filter(Candidate %in% c(\"Donald Trump\", \"Kamala Harris\")) |&gt;\n  ggplot(aes(x = Proportion, fill = Candidate)) +\n  ggdist::stat_slab(alpha = 0.8) +\n  theme_classic() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\n  \n  \n  diff_df &lt;- pred_prob_df |&gt;\n   filter(Candidate %in% c(\"Donald Trump\", \"Kamala Harris\")) |&gt;\n   pivot_wider(id_cols = poll_id,\n                names_from = Candidate,\n                values_from = Proportion) |&gt;\n   mutate(diff = 100*(`Donald Trump` - `Kamala Harris`),\n          state = state) |&gt;\n   mutate(diff_label = cut(diff, breaks = c(-Inf, -10, -5, -1, 0, 1, 5, 10, Inf), labels = c(\"Harris by more than 10%\", \"Harris by 10%-5%\", \"Harris by 5%-1%\", \"Harris by less than 1%\", \"Trump by less than 1%\", \"Trump by 5%-1%\", \"Trump by 10%-5%\", \"Trump by more than 10%\"))) |&gt;\n   mutate(diff_label = factor(diff_label, levels = c(\"Harris by more than 10%\", \"Harris by 10%-5%\", \"Harris by 5%-1%\", \"Harris by less than 1%\", \"Trump by less than 1%\", \"Trump by 5%-1%\", \"Trump by 10%-5%\", \"Trump by more than 10%\"), ordered = TRUE))\n  \n  diff_plot &lt;- diff_df |&gt;\n    ggplot(aes(x = diff, fill = after_stat(cut(x, breaks = c(-Inf, -10, -5, -1, 0, 1, 5, 10, Inf), labels = c(\"Harris by more than 10%\", \"Harris by 10%-5%\", \"Harris by 5%-1%\", \"Harris by less than 1%\", \"Trump by less than 1%\", \"Trump by 5%-1%\", \"Trump by 10%-5%\", \"Trump by more than 10%\"))))) +\n    ggdist::stat_slab(color = \"gray30\") +\n    scale_fill_manual(values = rev(RColorBrewer::brewer.pal(8, \"RdBu\"))[sort(as.numeric(unique(diff_df$diff_label)))]) +\n    labs(fill = \"Difference in %\", x = \"Predicted Difference in %\", title = glue::glue(\"{state}\")) +\n    theme_classic() +\n    theme(axis.title.y = element_blank(),\n          axis.text.y = element_blank(),\n          axis.ticks.y = element_blank(),\n          plot.title = element_text(family = \"serif\", size = 22, hjust = 0.5))\n\n  return(list(model = b_model, prob = prob_plot, diff = diff_plot))\n\n}</pre>\n</div>\n<p>Running it on every state:</p>\n<div class=\"cell\">\n<pre>states &lt;- lapply(X = unique(data_clean$state)[!(is.na(unique(data_clean$state)))],\n                 FUN = plots)</pre>\n</div>\n<p>Extracting the predicted difference between Harris and Trump in each state:</p>\n<div class=\"cell\">\n<pre>diff_plots &lt;- lapply(X = 1:43,\n                     FUN = function(x) {states[[x]]$diff})\n\none_big_plot &lt;- patchwork::wrap_plots(diff_plots, ncol = 5, nrow = 9) +\n  plot_layout(guides = \"collect\") +\n  plot_annotation(theme = theme(legend.position = \"none\",\n                                plot.title = element_text(family = \"serif\", size = 14, hjust = 0.5)))</pre>\n</div>\n<div class=\"cell\">\n<pre>one_big_plot</pre>\n</div>\n<p><img data-lazy-src=\"https://i0.wp.com/tomerzipori.github.io/blog/posts/elections2024/one_big_plot2.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\" style=\"width:155.0%;height:155.0%\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i0.wp.com/tomerzipori.github.io/blog/posts/elections2024/one_big_plot2.png?w=578&amp;ssl=1\" style=\"width:155.0%;height:155.0%\"/></noscript></p>\n</section>\n<section class=\"level1\" id=\"expected-electoral-college-results\">\n<h1>Expected Electoral College Results</h1>\n<p>Using the Bayesian model it is possible to calculate the expected electoral college results. For each ‘simulated’ election, I will calculate the electoral votes each candidate won.</p>\n<div class=\"cell\">\n<pre>electors_df &lt;- read_csv(\"../elections2024/2024_Electoral_College.csv\", show_col_types = FALSE) # Data frame containing elector count for each state</pre>\n</div>\n<p>For simulated election, the winner in each state is determined based on the predicted difference in votes (positive = Trump win, Negative = Harris win):</p>\n<div class=\"cell\">\n<pre>states_df_list &lt;- lapply(X = 1:43,\n                    FUN = function(x) {states[[x]]$diff$data})\n\nstates_df &lt;- do.call(\"rbind\", states_df_list) |&gt;\n  mutate(diff_binary = case_when(diff &gt; 0 ~ \"Trump\",\n                                 diff &lt; 0 ~ \"Harris\")) |&gt;\n  select(poll_id, diff_binary, state) |&gt;\n  left_join(select(electors_df, State, Total), by = join_by(state == State)) |&gt;\n  mutate(Total = case_when(state %in% c(\"Nebraska\", \"Maine\") ~ 2,\n                           .default = Total)) |&gt;\n  replace_na(list(Total = 1))\n\nglimpse(states_df)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Rows: 860,000\nColumns: 4\n$ poll_id     &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ diff_binary &lt;chr&gt; \"Trump\", \"Trump\", \"Trump\", \"Trump\", \"Trump\", \"Trump\", \"Tru…\n$ state       &lt;chr&gt; \"Arizona\", \"Arizona\", \"Arizona\", \"Arizona\", \"Arizona\", \"Ar…\n$ Total       &lt;dbl&gt; 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11…</pre>\n</div>\n</div>\n<p>Summing all electors for each candidate in each simulated election (and completing the picture with states that were not polled):</p>\n<div class=\"cell\">\n<pre>expected_electors &lt;- states_df |&gt;\n  group_by(poll_id, diff_binary) |&gt;\n  reframe(tot = sum(Total)) |&gt;\n  mutate(tot = case_when(diff_binary == \"Trump\" ~ tot + 9 + 6 + 4 + 6 + 8 + 8 + 6 + 3 + 4,\n                         diff_binary == \"Harris\" ~ tot + 7 + 3 + 3 + 4))\n\nhead(expected_electors)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre># A tibble: 6 × 3\n  poll_id diff_binary   tot\n  &lt;fct&gt;   &lt;chr&gt;       &lt;dbl&gt;\n1 1       Harris        276\n2 1       Trump         262\n3 2       Harris        276\n4 2       Trump         262\n5 3       Harris        270\n6 3       Trump         268</pre>\n</div>\n</div>\n<p>Visualizing each electoral result for both candidate, and their predicted probability:</p>\n<div class=\"cell\">\n<pre>expected_electors |&gt;\n  drop_na(diff_binary) |&gt;\n  group_by(diff_binary, tot) |&gt;\n  reframe(count = n()) |&gt;\n  mutate(percent = count/sum(count)) |&gt;\n  ggplot(aes(x = tot, y = percent, fill = diff_binary)) +\n  geom_bar(stat = \"identity\") +\n  scale_x_continuous(limits = c(225, 315), breaks = seq(225, 315, 5), labels = seq(225, 315, 5)) +\n  scale_fill_manual(values = c(\"#2166AC\", \"#B2182B\")) +\n  labs(y = \"Predicted Probability\", x = \"Electors Won\", fill = \"Candidate\") +\n  theme_classic()</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i2.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-49-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-49-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n<p>The most probable results are a narrow electoral win for Harris, with over representation for Trump in the high end, and for Harris on the low end. This could be understood as higher probability for a Trump landslide, rather than a Harris landslide.</p>\n<p>Calculating the most probable results:</p>\n<div class=\"cell\">\n<pre>probable_outcomes &lt;- expected_electors |&gt;\n  drop_na(diff_binary) |&gt;\n  pivot_wider(names_from = diff_binary,\n              values_from = tot,\n              id_cols = poll_id) |&gt;\n  count(Harris, Trump) |&gt;\n  rename(count = n) |&gt;\n  mutate(count = count / sum(count)) |&gt;\n  unite(outcome, Harris:Trump, remove = FALSE, sep = \":\")</pre>\n</div>\n<p>Top 20 most probable results:</p>\n<div class=\"cell\">\n<pre>top20_probable_outcomes &lt;- probable_outcomes |&gt;\n  arrange(desc(count)) |&gt;\n  head(20) |&gt;\n  mutate(Winner = case_when(Trump &gt; Harris ~ \"Trump\",\n                            .default = \"Harris\"))</pre>\n</div>\n<div class=\"cell\">\n<pre>ggplot(top20_probable_outcomes, aes(x = reorder(outcome, count), y = count, fill = Winner)) +\n  geom_bar(stat = \"identity\", color = \"gray44\") +\n  scale_fill_manual(values = c(\"Harris\" = \"#2166AC\", \"Trump\" = \"#B2182B\")) +\n  labs(\n    title = \"Top 20 Most Probable Electoral Results\",\n    x = \"Electoral Result\",\n    y = \"Probability\",\n    fill = \"Winner\"\n  ) +\n  theme_classic() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(hjust = 0.5, size = 16)\n  )</pre>\n<div class=\"cell-output-display\">\n<div>\n<figure class=\"figure\">\n<p><img class=\"img-fluid figure-img\" data-lazy-src=\"https://i1.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-52-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid figure-img\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/tomerzipori.github.io/blog/posts/elections2024/index_files/figure-html/unnamed-chunk-52-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</figure>\n</div>\n</div>\n</div>\n</section>\n<section class=\"level1\" id=\"conclusion\">\n<h1>Conclusion</h1>\n<p>Of course there are a lot more interesting calculations and visualizations that can be derived from the current Bayesian model, and from other models. This is a first attempt at implementing Bayesian statistical methods in the election polling field, I had fun.</p>\n</section>\n<div class=\"default\" id=\"quarto-appendix\"><section class=\"footnotes footnotes-end-of-document\" id=\"footnotes\"><h2 class=\"anchored quarto-appendix-heading\">Footnotes</h2>\n<ol>\n<li id=\"fn1\"><p>For a more deep discussion on prior distributions, see this <a href=\"https://tomerzipori.github.io/blog/posts/bayes101/\" rel=\"nofollow\" target=\"_blank\">post</a>.↩︎</p></li>\n<li id=\"fn2\"><p>Or as a factor with random levels, but I don’t think it’s theoretically correct in the US presidential elections.↩︎</p></li>\n</ol>\n</section></div>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://tomerzipori.github.io/blog/posts/elections2024/\"> Tomer's stats blog</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
      "main_text": "US Presidential Elections – A Bayesian Perspective\nPosted on\nJanuary 12, 2025\nby\nTomer Zipori\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nTomer's stats blog\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nSetup\nlibrary(tidyverse) # As always\nlibrary(brms)      # For Bayesian modeling\nlibrary(tidybayes) # For visualization\nlibrary(patchwork)\nIntroduction\nEver since I’ve finished my grad studies (Few months ago), I wanted to experiment with some “real life” applications of statistics. Things that interest real people. With the 2024 American presidential elections being the hot issue around the world, and Bayesian statistics being the hot issue of my personal projects, I thought how can these two mix.\nTwo features of Bayesian statistics pop to mind when thinking about election polling:\nPrior Distributions\nThe need to explicitly define a prior distribution for any Bayesian model is a point of contention. Some (rightfully) argue that this definition can’t be objective, and it is practically impossible to represent the existing body of knowledge in a single probability distribution. Others (rightfully) argue that every statistical model have prior assumptions which are rarely checked, and can influence the model as much as a prior distribution.\n1\nOne reason the incorporation of past studies into the prior distribution is hard, is that it depends on the specific parameters of the model.\nWhile prior elicitation can be hard in many cases, election polling is one area where it should be relatively easy! every poll is essentially the same statistical model (how many votes for red, and how many votes for blue), but every time with different data. This is the ideal scenario for a Bayesian statistician as the posterior distribution (the result) of any poll can be used as the prior distribution for the next poll!\nGraphic\nPosterior Predictive Distributions\nOne tool of Bayesian statistical inference is the Posterior Predictive Distributions – PPD. This is the prediction of the model. For example, one possible PPD from a Bayesian election poll could be the expected electoral college result for each candidate, or the expected number of seats in the parliament.\nData\nThe following dataset is a summary of many polls conducted from the start of 2023, up to two days before the election.\ndata <- read_csv(\"../elections2024/president_polls.csv\", show_col_types = F)\nglimpse(data)\nRows: 18,095\nColumns: 52\n$ poll_id                   <dbl> 89372, 89372, 89372, 89372, 89372, 89372, 89…\n$ pollster_id               <dbl> 1528, 1528, 1528, 1528, 1528, 1528, 1528, 15…\n$ pollster                  <chr> \"AtlasIntel\", \"AtlasIntel\", \"AtlasIntel\", \"A…\n$ sponsor_ids               <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ sponsors                  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ display_name              <chr> \"AtlasIntel\", \"AtlasIntel\", \"AtlasIntel\", \"A…\n$ pollster_rating_id        <dbl> 546, 546, 546, 546, 546, 546, 546, 546, 546,…\n$ pollster_rating_name      <chr> \"AtlasIntel\", \"AtlasIntel\", \"AtlasIntel\", \"A…\n$ numeric_grade             <dbl> 2.7, 2.7, 2.7, 2.7, 2.7, 2.7, 2.7, 2.7, 2.7,…\n$ pollscore                 <dbl> -0.8, -0.8, -0.8, -0.8, -0.8, -0.8, -0.8, -0…\n$ methodology               <chr> \"Online Ad\", \"Online Ad\", \"Online Ad\", \"Onli…\n$ transparency_score        <dbl> 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,…\n$ state                     <chr> NA, NA, NA, NA, NA, NA, NA, \"Arizona\", \"Ariz…\n$ start_date                <chr> \"11/3/24\", \"11/3/24\", \"11/3/24\", \"11/3/24\", …\n$ end_date                  <chr> \"11/4/24\", \"11/4/24\", \"11/4/24\", \"11/4/24\", …\n$ sponsor_candidate_id      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ sponsor_candidate         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ sponsor_candidate_party   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ endorsed_candidate_id     <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ endorsed_candidate_name   <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ endorsed_candidate_party  <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ question_id               <dbl> 216453, 216453, 216453, 216453, 216453, 2164…\n$ sample_size               <dbl> 2703, 2703, 2703, 2703, 2703, 2703, 2703, 87…\n$ population                <chr> \"lv\", \"lv\", \"lv\", \"lv\", \"lv\", \"lv\", \"lv\", \"l…\n$ subpopulation             <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ population_full           <chr> \"lv\", \"lv\", \"lv\", \"lv\", \"lv\", \"lv\", \"lv\", \"l…\n$ tracking                  <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ created_at                <chr> \"11/4/24 19:06\", \"11/4/24 19:06\", \"11/4/24 1…\n$ notes                     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ url                       <chr> \"https://atlasintel.org/poll/usa-national-20…\n$ url_article               <chr> \"https://atlasintel.org/poll/usa-national-20…\n$ url_topline               <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ url_crosstab              <chr> \"https://cdn.atlasintel.org/f1cec70d-8eae-44…\n$ source                    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ internal                  <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ partisan                  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ race_id                   <dbl> 8914, 8914, 8914, 8914, 8914, 8914, 8914, 87…\n$ cycle                     <dbl> 2024, 2024, 2024, 2024, 2024, 2024, 2024, 20…\n$ office_type               <chr> \"U.S. President\", \"U.S. President\", \"U.S. Pr…\n$ seat_number               <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ seat_name                 <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ election_date             <chr> \"11/5/24\", \"11/5/24\", \"11/5/24\", \"11/5/24\", …\n$ stage                     <chr> \"general\", \"general\", \"general\", \"general\", …\n$ nationwide_batch          <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA…\n$ ranked_choice_reallocated <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA…\n$ ranked_choice_round       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ hypothetical              <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA…\n$ party                     <chr> \"DEM\", \"REP\", \"GRE\", \"IND\", \"LIB\", \"DEM\", \"R…\n$ answer                    <chr> \"Harris\", \"Trump\", \"Stein\", \"West\", \"Oliver\"…\n$ candidate_id              <dbl> 16661, 16651, 31116, 31097, 31790, 16661, 16…\n$ candidate_name            <chr> \"Kamala Harris\", \"Donald Trump\", \"Jill Stein…\n$ pct                       <dbl> 48.1, 49.2, 1.1, 0.3, 0.1, 48.8, 50.0, 45.9,…\nPreprocessing\nSome preprocessing and cleaning is needed here, mainly I want to include only recent polls to avoid dealing with a large number of candidates, and transforming the percentage of votes to a probability:\ndata_clean <- data |>\n  select(poll_id, state, poll_date = start_date, question_id, candidate_name, sample_size, pct) |> # selecting relevant cols only\n  mutate(pct = pct / 100,               # transforming to probabilities\n         poll_date = mdy(poll_date)) |> # transforming to 'date' types\n  filter(year(poll_date) >= 2024 & month(poll_date) >= 10) |> # only recent polls to control for speculative candidates\n  mutate(candidate_name = relevel(factor(candidate_name), ref = \"Donald Trump\")) |> # Defining 'Trump' to be the reference level\n  group_by(poll_id) |>                  # some polls have several q's, this keeps only the main 'who would you vote for' question\n  filter(question_id == min(question_id)) |>\n  ungroup()\nModeling\nFrom a statistical point of view, an election poll is a multiclass classification problem: It estimates the real proportion of votes for each candidate in the population, from the sampled proportions. The dependent variable is categorical and does not have any ordering. Since we don’t have any predictors other than the observed proportions, the model is what is called an\nempty\nmodel - and it’s formulation in\nR\nis usually represented as:\nDV ~ 1\n. Due to the structure of the current data, each observation (row) need to be weighted by the observed percentage. In order to include weighting by the poll’s sample size, I multiplied this percentage by the sample size.\nThis multiclass classification problem can be represented with a series of logistic models, each models one category (candidate) against the others as a binary outcome. In order to do that, I will use the\ncategorical()\nfamily implemented in\nbrms\n.\nLet’s start with a simple case, and model results only for Nevada:\ndata_clean_nv <- data_clean |>\n  filter(state == \"Nevada\")\nbayesian_model_nv <- brm(formula = candidate_name|weights(sample_size*pct) ~ 1,\n                         family = categorical(link = \"logit\"),\n                         data = data_clean_nv,\n                         chains = 10,\n                         cores = 10,\n                         iter = 4000,\n                         refresh = 0,\n                         seed = 14,\n                         backend = \"cmdstanr\")\nsummary(bayesian_model_nv)\nFamily: categorical \n  Links: muChaseOliver = logit; muCornelWest = logit; muJillStein = logit; muJoelSkousen = logit; muKamalaHarris = logit \nFormula: candidate_name | weights(sample_size * pct) ~ 1 \n   Data: data_clean_nv (Number of observations: 85) \n  Draws: 10 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 20000\n\nRegression Coefficients:\n                         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nmuChaseOliver_Intercept     -4.92      0.11    -5.14    -4.71 1.00     8712\nmuCornelWest_Intercept     -15.07     10.71   -36.77    -8.70 1.00     2989\nmuJillStein_Intercept       -6.10      0.20    -6.51    -5.73 1.00     8233\nmuJoelSkousen_Intercept    -15.53     12.01   -39.09    -8.70 1.00     2538\nmuKamalaHarris_Intercept     0.00      0.01    -0.02     0.03 1.00     9124\n                         Tail_ESS\nmuChaseOliver_Intercept      9672\nmuCornelWest_Intercept       1751\nmuJillStein_Intercept        7736\nmuJoelSkousen_Intercept      1491\nmuKamalaHarris_Intercept     9396\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\nfew things to notice: first, Trump doesn’t have a parameter. That is because\nbrms\nestimates each parameter in comparison to the factor’s reference level, which is set to\n, or\non the exponential scale. Second, parameter estimates are logits, as this is essentially an output of multiple logistic regressions. In order to transform these estimates into predicted vote shares for every candidate\nout of the\ntotal candidates, a softmax transformation need to be applied:\nExtracting more precise point-estimates:\ndraws_nv <- spread_draws(bayesian_model_nv, b_muChaseOliver_Intercept, b_muCornelWest_Intercept, b_muJillStein_Intercept, b_muJoelSkousen_Intercept, b_muKamalaHarris_Intercept)\n\n(c(median(draws_nv$b_muChaseOliver_Intercept), median(draws_nv$b_muCornelWest_Intercept), median(draws_nv$b_muJillStein_Intercept), median(draws_nv$b_muJoelSkousen_Intercept), median(draws_nv$b_muKamalaHarris_Intercept)))\n[1]  -4.913210000 -12.452300000  -6.088395000 -12.626300000   0.002381675\nFor example, applying the softmax transformation in order to get the predicted vote share of Jill Stein:\n100 * exp(-6.088395) / (exp(-4.91321) + exp(-12.4523) + exp(-6.088395) + exp(-12.6263) + exp(0.002381675) + exp(0))\n[1] 0.1127752\nAbout 0.1%.\nThe predicted vote share of Kamala Harris is:\n100 * exp(0.002381675) / (exp(-4.91321) + exp(-12.4523) + exp(-6.088395) + exp(-12.6263) + exp(0.002381675) + exp(0))\n[1] 49.82007\nAnd of Donald Trump:\n100 * exp(0) / (exp(-4.91321) + exp(-12.4523) + exp(-6.088395) + exp(-12.6263) + exp(0.002381675) + exp(0))\n[1] 49.70155\nBut, this is a Bayesian model so let’s not stay stuck with point estimates and look at the whole posterior distribution:\nExtracting draws:\nprobs_nv <- draws_nv |>\n  select(-.chain, -.iteration) |>\n  mutate(b_muChaseOliver_Intercept = exp(b_muChaseOliver_Intercept),\n         b_muKamalaHarris_Intercept = exp(b_muKamalaHarris_Intercept),\n         b_muJillStein_Intercept = exp(b_muJillStein_Intercept),\n         b_muCornelWest_Intercept = exp(b_muCornelWest_Intercept),\n         b_muJoelSkousen_Intercept = exp(b_muJoelSkousen_Intercept)) |>\n  mutate(row_sum = b_muChaseOliver_Intercept + b_muKamalaHarris_Intercept + b_muJillStein_Intercept + b_muCornelWest_Intercept + b_muJoelSkousen_Intercept + 1) |>\n  mutate(Trump = 1 / row_sum,\n         Harris = b_muKamalaHarris_Intercept / row_sum) |>\n  select(.draw, Trump, Harris)\nprobs_nv |>\n  pivot_longer(cols = c(Trump, Harris),\n               names_to = \"Candidate\",\n               values_to = \"prob\") |>\n  ggplot(aes(x = prob * 100, fill = Candidate)) +\n  stat_slab(color = \"gray24\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"#2166AC\", \"#B2182B\")) +\n  scale_x_continuous(breaks = seq(48, 52, 0.2), labels = seq(48, 52, 0.2)) +\n  labs(x = \"Predicted vote share in %\") +\n  theme_classic() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\nVery close!\nAnd what is the predicted difference between the two main candidates?\nprobs_nv |>\n  mutate(diff = Trump - Harris) |>\n  ggplot(aes(x = diff * 100, fill = after_stat(x > 0))) +\n  stat_slab(color = \"gray24\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  scale_fill_manual(values = c(\"#2166AC\", \"#B2182B\"), labels = c(\"Harris win\", \"Trump win\")) +\n  scale_x_continuous(breaks = seq(-3, 4, 0.5), labels = seq(-3, 4, 0.5)) +\n  labs(x = \"Predicted vote share difference in %\", fill = \" \") +\n  theme_classic() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\nAgain, very close (with a slight advantage to Harris).\nAnother useful measure from Bayesian statistics is the probability of direction (pd). Due to the winner-takes-all electoral system in 48 of the 50 states, the difference doesn’t really matter. So what is the probability that each candidate will win?\nThe probability that Trump will win is seen in the red area in the plot above, that is the probability that the difference in vote share is positive:\ndiff <- probs_nv$Trump - probs_nv$Harris\nlength(diff[diff > 0]) / length(diff)\n[1] 0.42815\nTrump has a 42.82% chance of winning Nevada.\nlength(diff[diff < 0]) / length(diff)\n[1] 0.57185\nAnd Harris has 57.19% chance.\nLet’s make the plot a little more informative:\ndiff_plot <- probs_nv |>\n  mutate(diff = Trump - Harris) |>\n  mutate(diff = diff * 100) |>\n  ggplot(aes(x = diff, fill = after_stat(cut(x, breaks = c(-Inf, -2, -1, 0, 1, 2, Inf), labels = c(\"Harris by more than 2%\", \"Harris by 1%-2%\", \"Harris by less than 1%\", \"Trump by less than 1%\", \"Trump by 1%-2%\", \"Trump by more than 2%\"))))) +\n  stat_slab(color = \"gray24\") +\n  scale_fill_manual(values = rev(RColorBrewer::brewer.pal(6, \"RdBu\"))) +\n  scale_x_continuous(limits = c(-3, 3), breaks = seq(-3, 3, 0.5), labels = seq(-3, 3, 0.5)) +\n  labs(fill = \" \", x = \"Predicted Difference in %\", title = \"Predicted difference in votes - Nevada\") +\n  theme_classic() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        plot.title = element_text(family = \"serif\", size = 22, hjust = 0.5))\ndiff_plot\nEliciting a custom prior\nFor the last model we used brms’ default prior. In order to elicit our own, For simplicity, I’ll start with the 2020 vote share between Biden and Trump:\n2020 Results - Nevada (from\nWikipedia\n)\nNote\nThis part contain some math. Don’t skip it, you can understand it! But if you want to skip it, go to the ‘Modeling with a custom prior’ section.\nprior_trump <- 0.4767\nprior_harris <- 0.5006\nThese percentages need to be transformed to the logistic model’s scale, now using the inverse-softmax transformation:\nAnd:\nBut with Trump’s intercept fixed to\nas the factor’s reference level, it’s possible to calculate the sum in the denominator:\nQuick algebra gives:\nNow it’s possible to calculate Harris’ intercept:\nA quicker way to derive these intercepts is to notice that for every candidate\nother than the ‘reference’ candidate\n, the intercept is:\nWhere\nand\nare the assumed vote shares of candidate\nand\nrespectively.\nModeling with a custom prior\nSetting the prior for Harris’ intercept, giving it relatively large standard deviation reflecting the many factors differentiating the 2024 and 2020 elections.\nprior_nv <- set_prior(\"normal(0.04891968, 0.1)\", class = \"Intercept\", dpar = \"muKamalaHarris\")\nbayesian_model_nv_wprior <- brm(formula = candidate_name|weights(sample_size*pct) ~ 1,\n                                family = categorical(link = \"logit\"),\n                                data = data_clean_nv,\n                                prior = prior_nv,\n                                chains = 10,\n                                cores = 10,\n                                iter = 4000,\n                                refresh = 0,\n                                seed = 14,\n                                backend = \"cmdstanr\")\nsummary(bayesian_model_nv_wprior)\nFamily: categorical \n  Links: muChaseOliver = logit; muCornelWest = logit; muJillStein = logit; muJoelSkousen = logit; muKamalaHarris = logit \nFormula: candidate_name | weights(sample_size * pct) ~ 1 \n   Data: data_clean_nv (Number of observations: 85) \n  Draws: 10 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 20000\n\nRegression Coefficients:\n                         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nmuChaseOliver_Intercept     -4.92      0.11    -5.14    -4.71 1.00    10322\nmuCornelWest_Intercept     -14.79      7.81   -36.48    -8.68 1.01     2915\nmuJillStein_Intercept       -6.09      0.20    -6.50    -5.72 1.00     9801\nmuJoelSkousen_Intercept    -15.41     11.07   -37.29    -8.72 1.00     2797\nmuKamalaHarris_Intercept     0.00      0.01    -0.02     0.03 1.00    10356\n                         Tail_ESS\nmuChaseOliver_Intercept     10191\nmuCornelWest_Intercept       1659\nmuJillStein_Intercept        9246\nmuJoelSkousen_Intercept      1551\nmuKamalaHarris_Intercept    10037\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\nI’ll inspect the model again, this time using the\nbrms::posterior_epred()\nfunction, generating predictions on the probability scale:\nnew_data <- expand.grid(x = NA)\n\npred_probs_nv <- posterior_epred(bayesian_model_nv_wprior, newdata = new_data)\nThis essentially creates a\narray of 20,000 “simulated elections” based on the model, and the vote share of each of the 6 candidates. For example, here are the first 5 simulated elections and the vote share in each:\npred_probs_nv[1:5,,]\nDonald Trump Chase Oliver  Cornel West  Jill Stein Joel Skousen\n[1,]    0.4953947  0.003684427 5.757740e-05 0.001019819 1.934454e-05\n[2,]    0.4994877  0.004458325 1.934866e-06 0.001474521 1.406709e-05\n[3,]    0.5026360  0.003951306 1.079202e-06 0.001657708 8.114247e-06\n[4,]    0.5044252  0.003509907 9.118997e-07 0.001623817 1.605403e-06\n[5,]    0.4987907  0.003857605 2.889669e-06 0.001544016 5.206677e-06\n     Kamala Harris\n[1,]     0.4998241\n[2,]     0.4945634\n[3,]     0.4917458\n[4,]     0.4904386\n[5,]     0.4957995\nTurning it into the same plots as before gives:\npred_probs_nv_df <- data.frame(pred_probs_nv[,1,]) |>\n  mutate(poll_id = factor(c(1:n()))) |>\n  pivot_longer(cols = !poll_id,\n               names_to = \"Candidate\",\n               values_to = \"Proportion\") |>\n  mutate(Candidate = str_replace_all(Candidate, \"\\\\.\", \" \")) |>\n  mutate(Candidate = str_replace(Candidate, \"^\\\\S* \", \"\"))\nprob_plot <- pred_probs_nv_df |>\n  filter(Candidate %in% c(\"Trump\", \"Harris\")) |>\n  ggplot(aes(x = 100 * Proportion, fill = Candidate)) +\n  ggdist::stat_slab(color = \"gray24\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"#2166AC\", \"#B2182B\")) +\n  scale_x_continuous(breaks = seq(48, 52, 0.2), labels = seq(48, 52, 0.2)) +\n  labs(x = \"Predicted vote share in %\") +\n  theme_classic() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\nprob_plot\ndiff_plot_wprior <- pred_probs_nv_df |>\n  filter(Candidate %in% c(\"Trump\", \"Harris\")) |>\n  pivot_wider(id_cols = poll_id,\n              names_from = Candidate,\n              values_from = Proportion) |>\n  mutate(diff = Trump - Harris) |>\n  mutate(diff = diff * 100) |>\n  ggplot(aes(x = diff, fill = after_stat(cut(x, breaks = c(-Inf, -2, -1, 0, 1, 2, Inf), labels = c(\"Harris by more than 2%\", \"Harris by 1%-2%\", \"Harris by less than 1%\", \"Trump by less than 1%\", \"Trump by 1%-2%\", \"Trump by more than 2%\"))))) +\n  ggdist::stat_slab(color = \"gray24\") +\n  scale_fill_manual(values = rev(RColorBrewer::brewer.pal(6, \"RdBu\"))) +\n  scale_x_continuous(limits = c(-3, 3), labels = seq(-3, 3, 0.5), breaks = seq(-3, 3, 0.5)) +\n  labs(fill = \" \", x = \"Predicted Difference in %\", title = \"Predicted difference in votes - Nevada\", subtitle = \"Custom Prior\") +\n  theme_classic() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        plot.title = element_text(family = \"serif\", size = 22, hjust = 0.5),\n        plot.subtitle = element_text(family = \"serif\", size = 16, hjust = 0.5))\ndiff_plot_wprior\nHow much the custom prior has changed the result?\ndiff_plot / diff_plot_wprior +\n  plot_layout(guides = \"collect\")\nVisually, not by much…\nAnd what about the predicted chance of each candidate of winning the state?\nprobs_nv <- pred_probs_nv_df |>\n  filter(Candidate %in% c(\"Trump\", \"Harris\")) |>\n  pivot_wider(id_cols = poll_id,\n              names_from = Candidate,\n              values_from = Proportion)\n\ndiff <- probs_nv$Trump - probs_nv$Harris\nlength(diff[diff > 0]) / length(diff)\n[1] 0.40885\nTrump now has a 40.89% chance of winning Nevada, compared with the 42.82% he had before setting the prior.\nlength(diff[diff < 0]) / length(diff)\n[1] 0.59115\nAnd Harris has 59.12% chance, a slight increase from the 57.19% she had before.\nAlthough visually there hasn’t been much of a change, the prior shifted the chances of winning by ~2% in favor of Harris.\nRunning models for all states\nIn this section I run the same Bayesian model for each state. The better way of doing it will be to run one big model with\nstate\nas a categorical predictor.\n2\nThis one-big-model method didn’t converge on the current data, so I resort to run a separate model for each state.\nHere I define some functions to run on the list of states:\nrun_b_model <- function(state) {\n  \n  data_clean_state <- data_clean[data_clean$state == state,]\n  \n  bayesian_model <- brm(formula = candidate_name|weights(sample_size*pct) ~ 1,\n                        family = categorical(link = \"logit\"),\n                        data = data_clean_state,\n                        chains = 10,\n                        cores = 10,\n                        iter = 4000,\n                        refresh = 0,\n                        seed = 14,\n                        backend = \"cmdstanr\")\n  \n  return(bayesian_model)\n}\n\nplots <- function(state) {\n  \n  b_model <- run_b_model(state = state)\n  \n  new_data <- expand.grid(x = NA)\n\n  pred_prob <- posterior_epred(b_model, newdata = new_data)\n\n  pred_prob_df <- data.frame(pred_prob[,1,]) |>\n    mutate(poll_id = factor(c(1:n()))) |>\n    pivot_longer(cols = !poll_id,\n                 names_to = \"Candidate\",\n                 values_to = \"Proportion\") |>\n    mutate(Candidate = str_squish(str_replace_all(Candidate, \"\\\\.\", \" \")))\n  \n  prob_plot <- pred_prob_df |>\n  filter(Candidate %in% c(\"Donald Trump\", \"Kamala Harris\")) |>\n  ggplot(aes(x = Proportion, fill = Candidate)) +\n  ggdist::stat_slab(alpha = 0.8) +\n  theme_classic() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\n  \n  \n  diff_df <- pred_prob_df |>\n   filter(Candidate %in% c(\"Donald Trump\", \"Kamala Harris\")) |>\n   pivot_wider(id_cols = poll_id,\n                names_from = Candidate,\n                values_from = Proportion) |>\n   mutate(diff = 100*(`Donald Trump` - `Kamala Harris`),\n          state = state) |>\n   mutate(diff_label = cut(diff, breaks = c(-Inf, -10, -5, -1, 0, 1, 5, 10, Inf), labels = c(\"Harris by more than 10%\", \"Harris by 10%-5%\", \"Harris by 5%-1%\", \"Harris by less than 1%\", \"Trump by less than 1%\", \"Trump by 5%-1%\", \"Trump by 10%-5%\", \"Trump by more than 10%\"))) |>\n   mutate(diff_label = factor(diff_label, levels = c(\"Harris by more than 10%\", \"Harris by 10%-5%\", \"Harris by 5%-1%\", \"Harris by less than 1%\", \"Trump by less than 1%\", \"Trump by 5%-1%\", \"Trump by 10%-5%\", \"Trump by more than 10%\"), ordered = TRUE))\n  \n  diff_plot <- diff_df |>\n    ggplot(aes(x = diff, fill = after_stat(cut(x, breaks = c(-Inf, -10, -5, -1, 0, 1, 5, 10, Inf), labels = c(\"Harris by more than 10%\", \"Harris by 10%-5%\", \"Harris by 5%-1%\", \"Harris by less than 1%\", \"Trump by less than 1%\", \"Trump by 5%-1%\", \"Trump by 10%-5%\", \"Trump by more than 10%\"))))) +\n    ggdist::stat_slab(color = \"gray30\") +\n    scale_fill_manual(values = rev(RColorBrewer::brewer.pal(8, \"RdBu\"))[sort(as.numeric(unique(diff_df$diff_label)))]) +\n    labs(fill = \"Difference in %\", x = \"Predicted Difference in %\", title = glue::glue(\"{state}\")) +\n    theme_classic() +\n    theme(axis.title.y = element_blank(),\n          axis.text.y = element_blank(),\n          axis.ticks.y = element_blank(),\n          plot.title = element_text(family = \"serif\", size = 22, hjust = 0.5))\n\n  return(list(model = b_model, prob = prob_plot, diff = diff_plot))\n\n}\nRunning it on every state:\nstates <- lapply(X = unique(data_clean$state)[!(is.na(unique(data_clean$state)))],\n                 FUN = plots)\nExtracting the predicted difference between Harris and Trump in each state:\ndiff_plots <- lapply(X = 1:43,\n                     FUN = function(x) {states[[x]]$diff})\n\none_big_plot <- patchwork::wrap_plots(diff_plots, ncol = 5, nrow = 9) +\n  plot_layout(guides = \"collect\") +\n  plot_annotation(theme = theme(legend.position = \"none\",\n                                plot.title = element_text(family = \"serif\", size = 14, hjust = 0.5)))\none_big_plot\nExpected Electoral College Results\nUsing the Bayesian model it is possible to calculate the expected electoral college results. For each ‘simulated’ election, I will calculate the electoral votes each candidate won.\nelectors_df <- read_csv(\"../elections2024/2024_Electoral_College.csv\", show_col_types = FALSE) # Data frame containing elector count for each state\nFor simulated election, the winner in each state is determined based on the predicted difference in votes (positive = Trump win, Negative = Harris win):\nstates_df_list <- lapply(X = 1:43,\n                    FUN = function(x) {states[[x]]$diff$data})\n\nstates_df <- do.call(\"rbind\", states_df_list) |>\n  mutate(diff_binary = case_when(diff > 0 ~ \"Trump\",\n                                 diff < 0 ~ \"Harris\")) |>\n  select(poll_id, diff_binary, state) |>\n  left_join(select(electors_df, State, Total), by = join_by(state == State)) |>\n  mutate(Total = case_when(state %in% c(\"Nebraska\", \"Maine\") ~ 2,\n                           .default = Total)) |>\n  replace_na(list(Total = 1))\n\nglimpse(states_df)\nRows: 860,000\nColumns: 4\n$ poll_id     <fct> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ diff_binary <chr> \"Trump\", \"Trump\", \"Trump\", \"Trump\", \"Trump\", \"Trump\", \"Tru…\n$ state       <chr> \"Arizona\", \"Arizona\", \"Arizona\", \"Arizona\", \"Arizona\", \"Ar…\n$ Total       <dbl> 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11…\nSumming all electors for each candidate in each simulated election (and completing the picture with states that were not polled):\nexpected_electors <- states_df |>\n  group_by(poll_id, diff_binary) |>\n  reframe(tot = sum(Total)) |>\n  mutate(tot = case_when(diff_binary == \"Trump\" ~ tot + 9 + 6 + 4 + 6 + 8 + 8 + 6 + 3 + 4,\n                         diff_binary == \"Harris\" ~ tot + 7 + 3 + 3 + 4))\n\nhead(expected_electors)\n# A tibble: 6 × 3\n  poll_id diff_binary   tot\n  <fct>   <chr>       <dbl>\n1 1       Harris        276\n2 1       Trump         262\n3 2       Harris        276\n4 2       Trump         262\n5 3       Harris        270\n6 3       Trump         268\nVisualizing each electoral result for both candidate, and their predicted probability:\nexpected_electors |>\n  drop_na(diff_binary) |>\n  group_by(diff_binary, tot) |>\n  reframe(count = n()) |>\n  mutate(percent = count/sum(count)) |>\n  ggplot(aes(x = tot, y = percent, fill = diff_binary)) +\n  geom_bar(stat = \"identity\") +\n  scale_x_continuous(limits = c(225, 315), breaks = seq(225, 315, 5), labels = seq(225, 315, 5)) +\n  scale_fill_manual(values = c(\"#2166AC\", \"#B2182B\")) +\n  labs(y = \"Predicted Probability\", x = \"Electors Won\", fill = \"Candidate\") +\n  theme_classic()\nThe most probable results are a narrow electoral win for Harris, with over representation for Trump in the high end, and for Harris on the low end. This could be understood as higher probability for a Trump landslide, rather than a Harris landslide.\nCalculating the most probable results:\nprobable_outcomes <- expected_electors |>\n  drop_na(diff_binary) |>\n  pivot_wider(names_from = diff_binary,\n              values_from = tot,\n              id_cols = poll_id) |>\n  count(Harris, Trump) |>\n  rename(count = n) |>\n  mutate(count = count / sum(count)) |>\n  unite(outcome, Harris:Trump, remove = FALSE, sep = \":\")\nTop 20 most probable results:\ntop20_probable_outcomes <- probable_outcomes |>\n  arrange(desc(count)) |>\n  head(20) |>\n  mutate(Winner = case_when(Trump > Harris ~ \"Trump\",\n                            .default = \"Harris\"))\nggplot(top20_probable_outcomes, aes(x = reorder(outcome, count), y = count, fill = Winner)) +\n  geom_bar(stat = \"identity\", color = \"gray44\") +\n  scale_fill_manual(values = c(\"Harris\" = \"#2166AC\", \"Trump\" = \"#B2182B\")) +\n  labs(\n    title = \"Top 20 Most Probable Electoral Results\",\n    x = \"Electoral Result\",\n    y = \"Probability\",\n    fill = \"Winner\"\n  ) +\n  theme_classic() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(hjust = 0.5, size = 16)\n  )\nConclusion\nOf course there are a lot more interesting calculations and visualizations that can be derived from the current Bayesian model, and from other models. This is a first attempt at implementing Bayesian statistical methods in the election polling field, I had fun.\nFootnotes\nFor a more deep discussion on prior distributions, see this\npost\n.↩︎\nOr as a factor with random levels, but I don’t think it’s theoretically correct in the US presidential elections.↩︎\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nTomer's stats blog\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "Setup library(tidyverse) # As always library(brms) # For Bayesian modeling library(tidybayes) # For visualization library(patchwork) Introduction Ever since I’ve finished my grad studies (Few months ago), I wanted to experiment with so...",
      "meta_keywords": null,
      "og_description": "Setup library(tidyverse) # As always library(brms) # For Bayesian modeling library(tidybayes) # For visualization library(patchwork) Introduction Ever since I’ve finished my grad studies (Few months ago), I wanted to experiment with so...",
      "og_image": "https://latex.codecogs.com/png.latex?0",
      "og_title": "US Presidential Elections – A Bayesian Perspective | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 21.1,
      "sitemap_lastmod": null,
      "twitter_description": "Setup library(tidyverse) # As always library(brms) # For Bayesian modeling library(tidybayes) # For visualization library(patchwork) Introduction Ever since I’ve finished my grad studies (Few months ago), I wanted to experiment with so...",
      "twitter_title": "US Presidential Elections – A Bayesian Perspective | R-bloggers",
      "url": "https://www.r-bloggers.com/2025/01/us-presidential-elections-a-bayesian-perspective/",
      "word_count": 4217
    }
  }
}