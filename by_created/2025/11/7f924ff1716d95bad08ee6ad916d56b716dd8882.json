{
  "id": "7f924ff1716d95bad08ee6ad916d56b716dd8882",
  "url": "https://www.r-bloggers.com/2025/03/bayesian-proportional-hazards-model-for-a-stepped-wedge-design/",
  "created_at_utc": "2025-11-22T19:58:56Z",
  "data": null,
  "raw_original": {
    "uuid": "1ec9aac1-9efa-4fd7-a316-893690f32506",
    "created_at": "2025-11-22 19:58:56",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2025/03/bayesian-proportional-hazards-model-for-a-stepped-wedge-design/",
      "crawled_at": "2025-11-22T10:51:19.113263",
      "external_links": [
        {
          "href": "https://www.rdatagen.net/post/2025-04-01-bayesian-proportional-hazards-model-for-a-stepped-wedge-design/",
          "text": "ouR data generation"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://www.rdatagen.net/post/2025-02-11-estimating-a-bayesian-proportional-hazards-model/",
          "text": "beginning"
        },
        {
          "href": "https://www.rdatagen.net/post/2025-04-01-bayesian-proportional-hazards-model-for-a-stepped-wedge-design/",
          "text": "ouR data generation"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Bayesian proportional hazards model for a stepped-wedge design | R-bloggers",
      "images": [
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/www.rdatagen.net/post/2025-04-01-bayesian-proportional-hazards-model-for-a-stepped-wedge-design/index.en_files/figure-html/swplot-1.png?w=450&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/keith-goldfeld/",
          "text": "Keith Goldfeld"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-391582 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Bayesian proportional hazards model for a stepped-wedge design</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">March 31, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/keith-goldfeld/\">Keith Goldfeld</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://www.rdatagen.net/post/2025-04-01-bayesian-proportional-hazards-model-for-a-stepped-wedge-design/\"> ouR data generation</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<p>We’ve finally reached the end of the road. This is the fifth and last post in a series building up to a Bayesian proportional hazards model for analyzing a stepped-wedge cluster-randomized trial. If you are just joining in, you may want to start at the <a href=\"https://www.rdatagen.net/post/2025-02-11-estimating-a-bayesian-proportional-hazards-model/\" rel=\"nofollow\" target=\"_blank\">beginning</a>.</p>\n<p>The model presented here integrates non-linear time trends and cluster-specific random effects—elements we’ve previously explored in isolation. There’s nothing fundamentally new in this post; it brings everything together. Given that the groundwork has already been laid, I’ll keep the commentary brief and focus on providing the code.</p>\n<div class=\"section level3\" id=\"simulating-data-from-a-stepped-wedge-crt\">\n<h3>Simulating data from a stepped-wedge CRT</h3>\n<p>I’ll generate a single data set for 25 sites, each site enrolling study participants over a 30-month period. Sites will transition from control to intervention sequentially, with one new site starting each month. Each site will enroll 25 patients each month.</p>\n<p>The outcome (<span class=\"math inline\">\\(Y\\)</span>) is the number of days to an event. The treatment (<span class=\"math inline\">\\(A\\)</span>) reduces the time to event. Survival times also depend on the enrollment month—an effect I’ve exaggerated for illustration. Additionally, each site <span class=\"math inline\">\\(i\\)</span> has a site-specific effect <span class=\"math inline\">\\(b_i \\sim N(\\mu=0, \\sigma = 0.5)\\)</span>, which influences the time to event among its participants.</p>\n<p>Here are the libraries needed for the code shown here:</p>\n<pre>library(simstudy)\nlibrary(data.table)\nlibrary(splines)\nlibrary(splines2)\nlibrary(survival)\nlibrary(survminer)\nlibrary(coxme)\nlibrary(cmdstanr)</pre>\n<div class=\"section level4\" id=\"definitions\">\n<h4>Definitions</h4>\n<pre>def &lt;- defData(varname = \"b\", formula = 0, variance = 0.5^2)\n\ndefS &lt;-\n  defSurv(\n    varname = \"eventTime\",\n    formula = \n      \"..int + ..delta_f * A + ..beta_1 * k + ..beta_2 * k^2 + ..beta_3 * k^3 + b\",\n    shape = 0.30)  |&gt;\n  defSurv(varname = \"censorTime\", formula = -11.3, shape = 0.36)</pre>\n</div>\n<div class=\"section level4\" id=\"parameters\">\n<h4>Parameters</h4>\n<pre>int &lt;- -11.6\ndelta_f &lt;-  0.80\n\nbeta_1 &lt;-  0.05\nbeta_2 &lt;-  -0.025\nbeta_3 &lt;- 0.001</pre>\n</div>\n<div class=\"section level4\" id=\"data-generation\">\n<h4>Data generation</h4>\n<pre>set.seed(28271)\n\n### Site level data\n\nds &lt;- genData(25, def, id = \"site\")                 \nds &lt;- addPeriods(ds, 30, \"site\", perName = \"k\") \n\n# Each site has a unique starting point, site 1 starts period 3, site 2 period 4, etc.\n\nds &lt;- trtStepWedge(ds, \"site\", nWaves = 25,     \n                   lenWaves = 1, startPer = 3, \n                   grpName = \"A\", perName = \"k\")\n\n### Individual level data\n\ndd &lt;- genCluster(ds, \"timeID\", numIndsVar = 25, level1ID = \"id\") \ndd &lt;- genSurv(dd, defS, timeName = \"Y\", censorName = \"censorTime\", digits = 0,\n              eventName = \"event\", typeName = \"eventType\")\n\n### Final observed data set\n\ndd &lt;- dd[, .(id, site, k, A, Y, event)]</pre>\n<p>Here is a set of Kaplan-Meier plots for each site and enrollment period. When a site is in the intervention condition, the K-M curve is red. For simplicity, censoring is not shown, though about 20% of cases in this dataset are censored.</p>\n<p><img data-lazy-src=\"https://i1.wp.com/www.rdatagen.net/post/2025-04-01-bayesian-proportional-hazards-model-for-a-stepped-wedge-design/index.en_files/figure-html/swplot-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.rdatagen.net/post/2025-04-01-bayesian-proportional-hazards-model-for-a-stepped-wedge-design/index.en_files/figure-html/swplot-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</div>\n</div>\n<div class=\"section level3\" id=\"model-estimation\">\n<h3>Model estimation</h3>\n<p>This model has quite a few components relative to the earlier models, but nothing is really new. There is a penalized spline for the effect of time and a random effect for each site. The primary parameter of interest is still <span class=\"math inline\">\\(\\beta\\)</span>.</p>\n<p>For completeness, here is the model specification:</p>\n<p><span class=\"math display\">\\[\n\\log L(\\beta) = \\sum_{j=1}^{J} \\left[ \\sum_{i \\in D_j}  \\left(\\beta A_i + \\sum_{m=1} ^ M \\gamma_m X_{m_i} + b_{s[i]} \\right) - \\sum_{r=0}^{d_j-1} \\log \\left( \\sum_{k \\in R_j}  \\left(\\beta A_k + \\sum_{m=1} ^ M \\gamma_m X_{m_i} + b_{s[k]} \\right) - r \\cdot \\bar{w}_j \\right) \\right] - \\lambda \\sum_{m=1}^{M} \\left( Q^{(2)} \\gamma \\right)_m^2\n\\\\\n\\]</span></p>\n<p>where</p>\n<ul>\n<li><span class=\"math inline\">\\(J\\)</span>: number of unique event times</li>\n<li><span class=\"math inline\">\\(M\\)</span>: number of spline basis functions</li>\n<li><span class=\"math inline\">\\(D_j\\)</span> is the set of individuals who experience an event at time <span class=\"math inline\">\\(t_j\\)</span>.</li>\n<li><span class=\"math inline\">\\(R_j\\)</span> is the risk set at time <span class=\"math inline\">\\(t_j\\)</span>, including all individuals who are still at risk at that time.</li>\n<li><span class=\"math inline\">\\(d_j\\)</span> is the number of events occurring at time <span class=\"math inline\">\\(t_j\\)</span>.</li>\n<li><span class=\"math inline\">\\(r\\)</span> ranges from 0 to <span class=\"math inline\">\\(d_j - 1\\)</span>, iterating over the tied events.</li>\n<li><span class=\"math inline\">\\(\\bar{w}_j\\)</span> represents the average risk weight of individuals experiencing an event at <span class=\"math inline\">\\(t_j\\)</span>:</li>\n</ul>\n<p><span class=\"math display\">\\[\\bar{w}_j = \\frac{1}{d_j} \\sum_{i \\in D_j}  \\left(\\beta A_i + b_{s[i]} \\right)\\]</span></p>\n<ul>\n<li><span class=\"math inline\">\\(A_i\\)</span>: binary indicator for treatment</li>\n<li><span class=\"math inline\">\\(X_{m_i}\\)</span>: value of the <span class=\"math inline\">\\(m^{\\text{th}}\\)</span> spline basis function for the <span class=\"math inline\">\\(i^{\\text{th}}\\)</span> observation</li>\n<li><span class=\"math inline\">\\(Q^{(2)}\\)</span>: the second-difference matrix of the spline function</li>\n</ul>\n<p>The parameters of the model are</p>\n<ul>\n<li><span class=\"math inline\">\\(\\beta\\)</span>: treatment coefficient</li>\n<li><span class=\"math inline\">\\(\\gamma_m\\)</span>: spline coefficient for the <span class=\"math inline\">\\(m^\\text{th}\\)</span> spline basis function</li>\n<li><span class=\"math inline\">\\(b_{s[i]}\\)</span>: cluster-specific random effect, where <span class=\"math inline\">\\(s[i]\\)</span> is the cluster of patient <span class=\"math inline\">\\(i\\)</span></li>\n<li><span class=\"math inline\">\\(\\lambda\\)</span>: the penalization term; this will not be estimated but provided by the user</li>\n</ul>\n<p>The assumed prior distributions for <span class=\"math inline\">\\(\\beta\\)</span> and the random effects are:</p>\n<p><span class=\"math display\">\\[\n\\begin{aligned}\n\\beta &amp;\\sim N(0,4) \\\\\nb_i &amp;\\sim N(0,\\sigma_b) \\\\\n\\sigma_b &amp;\\sim t_{\\text{student}}(df = 3, \\mu=0, \\sigma = 2) \\\\\n\\gamma_m &amp;\\sim N(0,2)\n\\end{aligned}\n\\]</span></p>\n<p>And here is the implementation of the model in Stan:</p>\n<pre>stan_code &lt;- \n\"\ndata {\n  \n  int&lt;lower=1&gt; S;          // Number of clusters\n  int&lt;lower=1&gt; K;          // Number of covariates\n  \n  int&lt;lower=1&gt; N_o;        // Number of uncensored observations\n  array[N_o] int i_o;      // Event times (sorted in decreasing order)\n\n  int&lt;lower=1&gt; N;          // Number of total observations\n  matrix[N, K] x;          // Covariates for all observations\n  array[N] int&lt;lower=1,upper=S&gt; s;          // Cluster\n  \n  // Spline-related data\n  \n  int&lt;lower=1&gt; Q;          // Number of basis functions\n  matrix[N, Q] B;          // Spline basis matrix\n  matrix[N, Q] Q2_spline;  // 2nd derivative for penalization\n  real&lt;lower=0&gt; lambda;    // penalization term\n  \n  array[N] int index;\n\n  int&lt;lower=0&gt; T;            // Number of records as ties\n  int&lt;lower=1&gt; J;            // Number of groups of ties\n  array[T] int t_grp;        // Indicating tie group\n  array[T] int t_index;      // Index in data set\n  vector[T] t_adj;           // Adjustment for ties (efron)\n  \n}\n\nparameters {\n  \n  vector[K] beta;          // Fixed effects for covariates\n  \n  vector[S] b;             // Random effects\n  real&lt;lower=0&gt; sigma_b;   // SD of random effect\n  \n  vector[Q] gamma;         // Spline coefficients\n  \n}\n\nmodel {\n  \n  // Priors\n  \n  beta ~ normal(0, 1);\n  \n  // Random effects\n  \n  b ~ normal(0, sigma_b);\n  sigma_b ~ normal(0, 0.5);\n\n  \n  // Spline coefficients prior\n  \n  gamma ~ normal(0, 2);\n  \n  // Penalization term for spline second derivative\n  \n  target += -lambda * sum(square(Q2_spline * gamma));\n  \n  // Compute cumulative sum of exp(theta) in log space (more efficient)\n  \n  vector[N] theta;\n  vector[N] log_sum_exp_theta;\n  vector[J] exp_theta_grp = rep_vector(0, J);\n  \n  int first_in_grp;\n  \n  // Calculate theta for each observation\n  \n  for (i in 1:N) {\n    theta[i] = dot_product(x[i], beta) + dot_product(B[i], gamma) + b[s[i]];\n  }\n  \n  // Compute cumulative sum of log(exp(theta)) from last to first observation\n  \n  log_sum_exp_theta = rep_vector(0.0, N);\n  log_sum_exp_theta[N] = theta[N];\n  \n  for (i in tail(sort_indices_desc(index), N-1)) {\n    log_sum_exp_theta[i] = log_sum_exp(theta[i], log_sum_exp_theta[i + 1]);\n  }\n\n   // Efron algorithm - adjusting cumulative sum for ties\n  \n  for (i in 1:T) {\n    exp_theta_grp[t_grp[i]] += exp(theta[t_index[i]]);\n  }\n\n  for (i in 1:T) {\n  \n    if (t_adj[i] == 0) {\n      first_in_grp = t_index[i];\n    }\n\n    log_sum_exp_theta[t_index[i]] =\n      log( exp(log_sum_exp_theta[first_in_grp]) - t_adj[i] * exp_theta_grp[t_grp[i]]);\n  }\n  \n  // Likelihood for uncensored observations\n\n  for (n_o in 1:N_o) {\n    target += theta[i_o[n_o]] - log_sum_exp_theta[i_o[n_o]];\n  }\n}\n\"</pre>\n<p>Compiling the model:</p>\n<pre>stan_model &lt;- cmdstan_model(write_stan_file(stan_code))</pre>\n<p>Getting the data from <code>R</code> to <code>Stan</code>:</p>\n<pre>dx &lt;- copy(dd)\nsetorder(dx, Y)\ndx[, index := .I]\n\ndx.obs &lt;- dx[event == 1]\nN_obs &lt;- dx.obs[, .N]\ni_obs &lt;- dx.obs[, index]\n\nN_all &lt;- dx[, .N]\nx_all &lt;- data.frame(dx[, .(A)])\ns_all &lt;- dx[, site]\n\nK &lt;- ncol(x_all)                 # num covariates - in this case just A\nS &lt;- dx[, length(unique(site))]\n\n# Spline-related info\n\nn_knots &lt;- 5\nspline_degree &lt;- 3\nknot_dist &lt;- 1/(n_knots + 1)\nprobs &lt;- seq(knot_dist, 1 - knot_dist, by = knot_dist)\nknots &lt;- quantile(dx$k, probs = probs)\nspline_basis &lt;- bs(dx$k, knots = knots, degree = spline_degree, intercept = TRUE)\nB &lt;- as.matrix(spline_basis)\n\nQ2 &lt;- dbs(dx$k, knots = knots, degree = spline_degree, derivs = 2, intercept = TRUE)\nQ2_spline &lt;- as.matrix(Q2)\n\nties &lt;- dx[, .N, keyby = Y][N&gt;1, .(grp = .I, Y)]\nties &lt;- merge(ties, dx, by = \"Y\")\nties &lt;- ties[, order := 1:.N, keyby = grp][, .(grp, index)]\nties[, adj := 0:(.N-1)/.N, keyby = grp]\n\nstan_data &lt;- list(\n  S = S,\n  K = K,\n  N_o = N_obs,\n  i_o = i_obs,\n  N = N_all,\n  x = x_all,\n  s = s_all,\n  Q = ncol(B),\n  B = B,\n  Q2_spline = Q2_spline,\n  lambda = 0.15,\n  index = dx$index,\n  T = nrow(ties),\n  J = max(ties$grp),\n  t_grp = ties$grp,\n  t_index = ties$index,\n  t_adj = ties$adj\n)</pre>\n<p>Now we sample from the posterior - you can see that it takes quite a while to run, at least on my 2020 MacBook Pro M1 with 8GB RAM:</p>\n<pre>fit_mcmc &lt;- stan_model$sample(\n  data = stan_data,\n  seed = 1234,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 0\n)\n## Running MCMC with 4 parallel chains...\n## Chain 4 finished in 1847.8 seconds.\n## Chain 1 finished in 2202.8 seconds.\n## Chain 3 finished in 2311.8 seconds.\n## Chain 2 finished in 2414.9 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 2194.3 seconds.\n## Total execution time: 2415.3 seconds.\nfit_mcmc$summary(variables = c(\"beta\", \"sigma_b\"))\n## # A tibble: 2 × 10\n##   variable  mean median     sd    mad    q5   q95  rhat ess_bulk ess_tail\n##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n## 1 beta[1]  0.815  0.815 0.0298 0.0298 0.767 0.865  1.00    3513.    5077.\n## 2 sigma_b  0.543  0.535 0.0775 0.0739 0.432 0.683  1.00    3146.    5110.</pre>\n</div>\n<div class=\"section level3\" id=\"estimating-a-frequentist-random-effects-model\">\n<h3>Estimating a “frequentist” random-effects model</h3>\n<p>After all that, it turns out you can just fit a frailty model with random effects for site and a spline for time period <span class=\"math inline\">\\(k\\)</span> using the <code>coxmme</code> package. This is obviously much simpler then everything I have presented here.</p>\n<pre>frailty_model &lt;- coxme(Surv(Y, event) ~ A + ns(k, df = 3) + (1 | site), data = dd)\nsummary(frailty_model)\n## Mixed effects coxme model\n##  Formula: Surv(Y, event) ~ A + ns(k, df = 3) + (1 | site) \n##     Data: dd \n## \n##   events, n = 14989, 18750\n## \n## Random effects:\n##   group  variable        sd  variance\n## 1  site Intercept 0.5306841 0.2816256\n##                   Chisq    df p   AIC   BIC\n## Integrated loglik 18038  5.00 0 18028 17990\n##  Penalized loglik 18185 27.85 0 18129 17917\n## \n## Fixed effects:\n##                    coef exp(coef) se(coef)      z      p\n## A               0.80966   2.24714  0.02959  27.36 &lt;2e-16\n## ns(k, df = 3)1 -2.71392   0.06628  0.04428 -61.29 &lt;2e-16\n## ns(k, df = 3)2  1.04004   2.82933  0.07851  13.25 &lt;2e-16\n## ns(k, df = 3)3  4.48430  88.61492  0.04729  94.83 &lt;2e-16</pre>\n<p>However, the advantage of the Bayesian model is its flexibility. For example, if you wanted to include site-specific spline curves—analogous to site-specific time effects—you could extend the Bayesian approach to do so. The current Bayesian model implements a study-wide time spline, but incorporating site-specific splines would be a natural extension. I initially hoped to implement site-specific splines using the <code>mgcv</code> package, but the models did not converge. I am quite confident that a Bayesian extension would, though it would likely require substantial computing resources. If someone wants me to try that, I certainly could, but for now, I’ll stop here.</p>\n</div>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://www.rdatagen.net/post/2025-04-01-bayesian-proportional-hazards-model-for-a-stepped-wedge-design/\"> ouR data generation</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
      "main_text": "Bayesian proportional hazards model for a stepped-wedge design\nPosted on\nMarch 31, 2025\nby\nKeith Goldfeld\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nouR data generation\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nWe’ve finally reached the end of the road. This is the fifth and last post in a series building up to a Bayesian proportional hazards model for analyzing a stepped-wedge cluster-randomized trial. If you are just joining in, you may want to start at the\nbeginning\n.\nThe model presented here integrates non-linear time trends and cluster-specific random effects—elements we’ve previously explored in isolation. There’s nothing fundamentally new in this post; it brings everything together. Given that the groundwork has already been laid, I’ll keep the commentary brief and focus on providing the code.\nSimulating data from a stepped-wedge CRT\nI’ll generate a single data set for 25 sites, each site enrolling study participants over a 30-month period. Sites will transition from control to intervention sequentially, with one new site starting each month. Each site will enroll 25 patients each month.\nThe outcome (\n\\(Y\\)\n) is the number of days to an event. The treatment (\n\\(A\\)\n) reduces the time to event. Survival times also depend on the enrollment month—an effect I’ve exaggerated for illustration. Additionally, each site\n\\(i\\)\nhas a site-specific effect\n\\(b_i \\sim N(\\mu=0, \\sigma = 0.5)\\)\n, which influences the time to event among its participants.\nHere are the libraries needed for the code shown here:\nlibrary(simstudy)\nlibrary(data.table)\nlibrary(splines)\nlibrary(splines2)\nlibrary(survival)\nlibrary(survminer)\nlibrary(coxme)\nlibrary(cmdstanr)\nDefinitions\ndef <- defData(varname = \"b\", formula = 0, variance = 0.5^2)\n\ndefS <-\n  defSurv(\n    varname = \"eventTime\",\n    formula = \n      \"..int + ..delta_f * A + ..beta_1 * k + ..beta_2 * k^2 + ..beta_3 * k^3 + b\",\n    shape = 0.30)  |>\n  defSurv(varname = \"censorTime\", formula = -11.3, shape = 0.36)\nParameters\nint <- -11.6\ndelta_f <-  0.80\n\nbeta_1 <-  0.05\nbeta_2 <-  -0.025\nbeta_3 <- 0.001\nData generation\nset.seed(28271)\n\n### Site level data\n\nds <- genData(25, def, id = \"site\")                 \nds <- addPeriods(ds, 30, \"site\", perName = \"k\") \n\n# Each site has a unique starting point, site 1 starts period 3, site 2 period 4, etc.\n\nds <- trtStepWedge(ds, \"site\", nWaves = 25,     \n                   lenWaves = 1, startPer = 3, \n                   grpName = \"A\", perName = \"k\")\n\n### Individual level data\n\ndd <- genCluster(ds, \"timeID\", numIndsVar = 25, level1ID = \"id\") \ndd <- genSurv(dd, defS, timeName = \"Y\", censorName = \"censorTime\", digits = 0,\n              eventName = \"event\", typeName = \"eventType\")\n\n### Final observed data set\n\ndd <- dd[, .(id, site, k, A, Y, event)]\nHere is a set of Kaplan-Meier plots for each site and enrollment period. When a site is in the intervention condition, the K-M curve is red. For simplicity, censoring is not shown, though about 20% of cases in this dataset are censored.\nModel estimation\nThis model has quite a few components relative to the earlier models, but nothing is really new. There is a penalized spline for the effect of time and a random effect for each site. The primary parameter of interest is still\n\\(\\beta\\)\n.\nFor completeness, here is the model specification:\n\\[\n\\log L(\\beta) = \\sum_{j=1}^{J} \\left[ \\sum_{i \\in D_j}  \\left(\\beta A_i + \\sum_{m=1} ^ M \\gamma_m X_{m_i} + b_{s[i]} \\right) - \\sum_{r=0}^{d_j-1} \\log \\left( \\sum_{k \\in R_j}  \\left(\\beta A_k + \\sum_{m=1} ^ M \\gamma_m X_{m_i} + b_{s[k]} \\right) - r \\cdot \\bar{w}_j \\right) \\right] - \\lambda \\sum_{m=1}^{M} \\left( Q^{(2)} \\gamma \\right)_m^2\n\\\\\n\\]\nwhere\n\\(J\\)\n: number of unique event times\n\\(M\\)\n: number of spline basis functions\n\\(D_j\\)\nis the set of individuals who experience an event at time\n\\(t_j\\)\n.\n\\(R_j\\)\nis the risk set at time\n\\(t_j\\)\n, including all individuals who are still at risk at that time.\n\\(d_j\\)\nis the number of events occurring at time\n\\(t_j\\)\n.\n\\(r\\)\nranges from 0 to\n\\(d_j - 1\\)\n, iterating over the tied events.\n\\(\\bar{w}_j\\)\nrepresents the average risk weight of individuals experiencing an event at\n\\(t_j\\)\n:\n\\[\\bar{w}_j = \\frac{1}{d_j} \\sum_{i \\in D_j}  \\left(\\beta A_i + b_{s[i]} \\right)\\]\n\\(A_i\\)\n: binary indicator for treatment\n\\(X_{m_i}\\)\n: value of the\n\\(m^{\\text{th}}\\)\nspline basis function for the\n\\(i^{\\text{th}}\\)\nobservation\n\\(Q^{(2)}\\)\n: the second-difference matrix of the spline function\nThe parameters of the model are\n\\(\\beta\\)\n: treatment coefficient\n\\(\\gamma_m\\)\n: spline coefficient for the\n\\(m^\\text{th}\\)\nspline basis function\n\\(b_{s[i]}\\)\n: cluster-specific random effect, where\n\\(s[i]\\)\nis the cluster of patient\n\\(i\\)\n\\(\\lambda\\)\n: the penalization term; this will not be estimated but provided by the user\nThe assumed prior distributions for\n\\(\\beta\\)\nand the random effects are:\n\\[\n\\begin{aligned}\n\\beta &\\sim N(0,4) \\\\\nb_i &\\sim N(0,\\sigma_b) \\\\\n\\sigma_b &\\sim t_{\\text{student}}(df = 3, \\mu=0, \\sigma = 2) \\\\\n\\gamma_m &\\sim N(0,2)\n\\end{aligned}\n\\]\nAnd here is the implementation of the model in Stan:\nstan_code <- \n\"\ndata {\n  \n  int<lower=1> S;          // Number of clusters\n  int<lower=1> K;          // Number of covariates\n  \n  int<lower=1> N_o;        // Number of uncensored observations\n  array[N_o] int i_o;      // Event times (sorted in decreasing order)\n\n  int<lower=1> N;          // Number of total observations\n  matrix[N, K] x;          // Covariates for all observations\n  array[N] int<lower=1,upper=S> s;          // Cluster\n  \n  // Spline-related data\n  \n  int<lower=1> Q;          // Number of basis functions\n  matrix[N, Q] B;          // Spline basis matrix\n  matrix[N, Q] Q2_spline;  // 2nd derivative for penalization\n  real<lower=0> lambda;    // penalization term\n  \n  array[N] int index;\n\n  int<lower=0> T;            // Number of records as ties\n  int<lower=1> J;            // Number of groups of ties\n  array[T] int t_grp;        // Indicating tie group\n  array[T] int t_index;      // Index in data set\n  vector[T] t_adj;           // Adjustment for ties (efron)\n  \n}\n\nparameters {\n  \n  vector[K] beta;          // Fixed effects for covariates\n  \n  vector[S] b;             // Random effects\n  real<lower=0> sigma_b;   // SD of random effect\n  \n  vector[Q] gamma;         // Spline coefficients\n  \n}\n\nmodel {\n  \n  // Priors\n  \n  beta ~ normal(0, 1);\n  \n  // Random effects\n  \n  b ~ normal(0, sigma_b);\n  sigma_b ~ normal(0, 0.5);\n\n  \n  // Spline coefficients prior\n  \n  gamma ~ normal(0, 2);\n  \n  // Penalization term for spline second derivative\n  \n  target += -lambda * sum(square(Q2_spline * gamma));\n  \n  // Compute cumulative sum of exp(theta) in log space (more efficient)\n  \n  vector[N] theta;\n  vector[N] log_sum_exp_theta;\n  vector[J] exp_theta_grp = rep_vector(0, J);\n  \n  int first_in_grp;\n  \n  // Calculate theta for each observation\n  \n  for (i in 1:N) {\n    theta[i] = dot_product(x[i], beta) + dot_product(B[i], gamma) + b[s[i]];\n  }\n  \n  // Compute cumulative sum of log(exp(theta)) from last to first observation\n  \n  log_sum_exp_theta = rep_vector(0.0, N);\n  log_sum_exp_theta[N] = theta[N];\n  \n  for (i in tail(sort_indices_desc(index), N-1)) {\n    log_sum_exp_theta[i] = log_sum_exp(theta[i], log_sum_exp_theta[i + 1]);\n  }\n\n   // Efron algorithm - adjusting cumulative sum for ties\n  \n  for (i in 1:T) {\n    exp_theta_grp[t_grp[i]] += exp(theta[t_index[i]]);\n  }\n\n  for (i in 1:T) {\n  \n    if (t_adj[i] == 0) {\n      first_in_grp = t_index[i];\n    }\n\n    log_sum_exp_theta[t_index[i]] =\n      log( exp(log_sum_exp_theta[first_in_grp]) - t_adj[i] * exp_theta_grp[t_grp[i]]);\n  }\n  \n  // Likelihood for uncensored observations\n\n  for (n_o in 1:N_o) {\n    target += theta[i_o[n_o]] - log_sum_exp_theta[i_o[n_o]];\n  }\n}\n\"\nCompiling the model:\nstan_model <- cmdstan_model(write_stan_file(stan_code))\nGetting the data from\nR\nto\nStan\n:\ndx <- copy(dd)\nsetorder(dx, Y)\ndx[, index := .I]\n\ndx.obs <- dx[event == 1]\nN_obs <- dx.obs[, .N]\ni_obs <- dx.obs[, index]\n\nN_all <- dx[, .N]\nx_all <- data.frame(dx[, .(A)])\ns_all <- dx[, site]\n\nK <- ncol(x_all)                 # num covariates - in this case just A\nS <- dx[, length(unique(site))]\n\n# Spline-related info\n\nn_knots <- 5\nspline_degree <- 3\nknot_dist <- 1/(n_knots + 1)\nprobs <- seq(knot_dist, 1 - knot_dist, by = knot_dist)\nknots <- quantile(dx$k, probs = probs)\nspline_basis <- bs(dx$k, knots = knots, degree = spline_degree, intercept = TRUE)\nB <- as.matrix(spline_basis)\n\nQ2 <- dbs(dx$k, knots = knots, degree = spline_degree, derivs = 2, intercept = TRUE)\nQ2_spline <- as.matrix(Q2)\n\nties <- dx[, .N, keyby = Y][N>1, .(grp = .I, Y)]\nties <- merge(ties, dx, by = \"Y\")\nties <- ties[, order := 1:.N, keyby = grp][, .(grp, index)]\nties[, adj := 0:(.N-1)/.N, keyby = grp]\n\nstan_data <- list(\n  S = S,\n  K = K,\n  N_o = N_obs,\n  i_o = i_obs,\n  N = N_all,\n  x = x_all,\n  s = s_all,\n  Q = ncol(B),\n  B = B,\n  Q2_spline = Q2_spline,\n  lambda = 0.15,\n  index = dx$index,\n  T = nrow(ties),\n  J = max(ties$grp),\n  t_grp = ties$grp,\n  t_index = ties$index,\n  t_adj = ties$adj\n)\nNow we sample from the posterior - you can see that it takes quite a while to run, at least on my 2020 MacBook Pro M1 with 8GB RAM:\nfit_mcmc <- stan_model$sample(\n  data = stan_data,\n  seed = 1234,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 0\n)\n## Running MCMC with 4 parallel chains...\n## Chain 4 finished in 1847.8 seconds.\n## Chain 1 finished in 2202.8 seconds.\n## Chain 3 finished in 2311.8 seconds.\n## Chain 2 finished in 2414.9 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 2194.3 seconds.\n## Total execution time: 2415.3 seconds.\nfit_mcmc$summary(variables = c(\"beta\", \"sigma_b\"))\n## # A tibble: 2 × 10\n##   variable  mean median     sd    mad    q5   q95  rhat ess_bulk ess_tail\n##   <chr>    <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n## 1 beta[1]  0.815  0.815 0.0298 0.0298 0.767 0.865  1.00    3513.    5077.\n## 2 sigma_b  0.543  0.535 0.0775 0.0739 0.432 0.683  1.00    3146.    5110.\nEstimating a “frequentist” random-effects model\nAfter all that, it turns out you can just fit a frailty model with random effects for site and a spline for time period\n\\(k\\)\nusing the\ncoxmme\npackage. This is obviously much simpler then everything I have presented here.\nfrailty_model <- coxme(Surv(Y, event) ~ A + ns(k, df = 3) + (1 | site), data = dd)\nsummary(frailty_model)\n## Mixed effects coxme model\n##  Formula: Surv(Y, event) ~ A + ns(k, df = 3) + (1 | site) \n##     Data: dd \n## \n##   events, n = 14989, 18750\n## \n## Random effects:\n##   group  variable        sd  variance\n## 1  site Intercept 0.5306841 0.2816256\n##                   Chisq    df p   AIC   BIC\n## Integrated loglik 18038  5.00 0 18028 17990\n##  Penalized loglik 18185 27.85 0 18129 17917\n## \n## Fixed effects:\n##                    coef exp(coef) se(coef)      z      p\n## A               0.80966   2.24714  0.02959  27.36 <2e-16\n## ns(k, df = 3)1 -2.71392   0.06628  0.04428 -61.29 <2e-16\n## ns(k, df = 3)2  1.04004   2.82933  0.07851  13.25 <2e-16\n## ns(k, df = 3)3  4.48430  88.61492  0.04729  94.83 <2e-16\nHowever, the advantage of the Bayesian model is its flexibility. For example, if you wanted to include site-specific spline curves—analogous to site-specific time effects—you could extend the Bayesian approach to do so. The current Bayesian model implements a study-wide time spline, but incorporating site-specific splines would be a natural extension. I initially hoped to implement site-specific splines using the\nmgcv\npackage, but the models did not converge. I am quite confident that a Bayesian extension would, though it would likely require substantial computing resources. If someone wants me to try that, I certainly could, but for now, I’ll stop here.\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nouR data generation\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "We’ve finally reached the end of the road. This is the fifth and last post in a series building up to a Bayesian proportional hazards model for analyzing a stepped-wedge cluster-randomized trial. If you are just joining in, you may want to start at ...",
      "meta_keywords": null,
      "og_description": "We’ve finally reached the end of the road. This is the fifth and last post in a series building up to a Bayesian proportional hazards model for analyzing a stepped-wedge cluster-randomized trial. If you are just joining in, you may want to start at ...",
      "og_image": "https://www.rdatagen.net/post/2025-04-01-bayesian-proportional-hazards-model-for-a-stepped-wedge-design/index.en_files/figure-html/swplot-1.png",
      "og_title": "Bayesian proportional hazards model for a stepped-wedge design | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 9.6,
      "sitemap_lastmod": null,
      "twitter_description": "We’ve finally reached the end of the road. This is the fifth and last post in a series building up to a Bayesian proportional hazards model for analyzing a stepped-wedge cluster-randomized trial. If you are just joining in, you may want to start at ...",
      "twitter_title": "Bayesian proportional hazards model for a stepped-wedge design | R-bloggers",
      "url": "https://www.r-bloggers.com/2025/03/bayesian-proportional-hazards-model-for-a-stepped-wedge-design/",
      "word_count": 1915
    }
  }
}