{
  "id": "7e9ee42a606b20f78141656e1a480128f3eb8493",
  "url": "https://www.r-bloggers.com/2023/10/plotting-a-logistic-regression-in-base-r/",
  "created_at_utc": "2025-11-17T20:39:29Z",
  "data": null,
  "raw_original": {
    "uuid": "32a2396e-175d-48bf-824d-3ab8a09c434b",
    "created_at": "2025-11-17 20:39:29",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2023/10/plotting-a-logistic-regression-in-base-r/",
      "crawled_at": "2025-11-17T10:04:25.352241",
      "external_links": [
        {
          "href": "https://www.spsanderson.com/steveondata/posts/2023-10-26/index.html",
          "text": "Steve's Data Tips and Tricks"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://www.spsanderson.com/steveondata/posts/2023-10-26/index.html",
          "text": "Steve's Data Tips and Tricks"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Plotting a Logistic Regression In Base R | R-bloggers",
      "images": [
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i0.wp.com/www.spsanderson.com/steveondata/posts/2023-10-26/index_files/figure-html/unnamed-chunk-4-1.png?w=450&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/steven-p-sanderson-ii-mph/",
          "text": "Steven P. Sanderson II, MPH"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-379436 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Plotting a Logistic Regression In Base R</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">October 25, 2023</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/steven-p-sanderson-ii-mph/\">Steven P. Sanderson II, MPH</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \r\n<div style=\"min-height: 30px;\">\r\n[social4i size=\"small\" align=\"align-left\"]\r\n</div>\r\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\r\n[This article was first published on  <strong><a href=\"https://www.spsanderson.com/steveondata/posts/2023-10-26/index.html\"> Steve's Data Tips and Tricks</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<section class=\"level1\" id=\"introduction\">\n<h1>Introduction</h1>\n<p>Logistic regression is a statistical method used for predicting the probability of a binary outcome. It’s a fundamental tool in machine learning and statistics, often employed in various fields such as healthcare, finance, and marketing. We use logistic regression when we want to understand the relationship between one or more independent variables and a binary outcome, which can be “yes/no,” “1/0,” or any two-class distinction.</p>\n</section>\n<section class=\"level1\" id=\"getting-started\">\n<h1>Getting Started</h1>\n<p>Before we dive into plotting the logistic regression curve, let’s start with the basics. First, you’ll need some data. For this blog post, I’ll assume you have your dataset ready. If you don’t, you can easily find sample datasets online to practice with.</p>\n</section>\n<section class=\"level1\" id=\"load-the-data\">\n<h1>Load the Data</h1>\n<p>In R, we use the <code>read.csv</code> function to load a CSV file into a data frame. For example, if you have a dataset called “mydata.csv,” you can load it like this:</p>\n<pre># Load the data into a data frame\ndata &lt;- read.csv(\"mydata.csv\")</pre>\n<p>We will instead use the following data set:</p>\n<div class=\"cell\">\n<pre>library(dplyr)\n\nset.seed(123)\ndf &lt;- tibble(\n    x = runif(100, 0, 10),\n    y = rbinom(100, 1, 1 / (1 + exp(-1 * (0.5 * x - 2.5))))\n)\n\nhead(df)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre># A tibble: 6 × 2\n      x     y\n  &lt;dbl&gt; &lt;int&gt;\n1 2.88      0\n2 7.88      1\n3 4.09      0\n4 8.83      0\n5 9.40      1\n6 0.456     0</pre>\n</div>\n</div>\n</section>\n<section class=\"level1\" id=\"fit-a-logistic-regression-model\">\n<h1>Fit a Logistic Regression Model</h1>\n<p>Next, we need to fit a logistic regression model to our data. We’ll use the <code>glm</code> (Generalized Linear Model) function to do this. Suppose we want to predict the probability of a “success” (1) based on a single predictor variable “x.”</p>\n<div class=\"cell\">\n<pre># Fit a logistic regression model\nmodel &lt;- glm(y ~ x, data = df, family = binomial)\n\nbroom::glance(model)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre># A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1          138.      99  -51.5  107.  112.     103.          98   100</pre>\n</div>\n<pre>broom::tidy(model)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre># A tibble: 2 × 5\n  term        estimate std.error statistic     p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1 (Intercept)   -2.63      0.571     -4.60 0.00000422 \n2 x              0.505     0.102      4.96 0.000000699</pre>\n</div>\n<pre>head(broom::augment(model), 1) |&gt; \n  dplyr::glimpse()</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>Rows: 1\nColumns: 8\n$ y          &lt;int&gt; 0\n$ x          &lt;dbl&gt; 2.875775\n$ .fitted    &lt;dbl&gt; -1.175925\n$ .resid     &lt;dbl&gt; -0.7333581\n$ .hat       &lt;dbl&gt; 0.01969748\n$ .sigma     &lt;dbl&gt; 1.028093\n$ .cooksd    &lt;dbl&gt; 0.003162007\n$ .std.resid &lt;dbl&gt; -0.7406892</pre>\n</div>\n</div>\n</section>\n<section class=\"level1\" id=\"predict-probabilities\">\n<h1>Predict Probabilities</h1>\n<p>Now that we have our model, we can use it to predict probabilities. We’ll create a sequence of values for our predictor variable, and for each value, we’ll predict the probability of success, in this case <code>y</code>.</p>\n<div class=\"cell\">\n<pre># Create a sequence of predictor values\nx_seq &lt;- seq(0, 10, 0.01)\n\n# Predict probabilities\nprobabilities &lt;- predict(\n  model, \n  newdata = data.frame(x = x_seq), \n  type = \"response\"\n  )\n\nhead(x_seq)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>[1] 0.00 0.01 0.02 0.03 0.04 0.05</pre>\n</div>\n<pre>head(probabilities)</pre>\n<div class=\"cell-output cell-output-stdout\">\n<pre>         1          2          3          4          5          6 \n0.06732923 0.06764710 0.06796636 0.06828702 0.06860908 0.06893255 </pre>\n</div>\n</div>\n<p>The <code>predict</code> function here calculates the probabilities using our logistic regression model.</p>\n</section>\n<section class=\"level1\" id=\"plot-the-logistic-regression-curve\">\n<h1>Plot the Logistic Regression Curve</h1>\n<p>Finally, let’s plot the logistic regression curve. We’ll use the <code>plot</code> function to create a scatter plot of the data points, and then we’ll overlay the logistic curve using the <code>lines</code> function.</p>\n<div class=\"cell\">\n<pre># Plot the data points\nplot(\n  df$x, df$y, \n  pch = 16, \n  col = \"blue\", \n  xlab = \"Predictor Variable\", \n  ylab = \"Probability of Success\"\n  )\n\n# Add the logistic regression curve\nlines(x_seq, probabilities, col = \"red\", lwd = 2)</pre>\n<div class=\"cell-output-display\">\n<p><img class=\"img-fluid\" data-lazy-src=\"https://i0.wp.com/www.spsanderson.com/steveondata/posts/2023-10-26/index_files/figure-html/unnamed-chunk-4-1.png?w=450&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img class=\"img-fluid\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/www.spsanderson.com/steveondata/posts/2023-10-26/index_files/figure-html/unnamed-chunk-4-1.png?w=450&amp;ssl=1\"/></noscript></p>\n</div>\n</div>\n<p>And there you have it! You’ve successfully plotted a logistic regression curve in base R. The blue dots represent your data points, and the red curve is the logistic regression curve, showing how the probability of success changes with the predictor variable.</p>\n</section>\n<section class=\"level1\" id=\"conclusion\">\n<h1>Conclusion</h1>\n<p>I encourage you to try this out with your own dataset. Logistic regression is a powerful tool for modeling binary outcomes, and visualizing the curve helps you understand the relationship between your predictor variable and the probability of success. Experiment with different datasets and predictor variables to gain a deeper understanding of this essential statistical technique.</p>\n<p>Remember, practice makes perfect, and the more you work with logistic regression in R, the more proficient you’ll become. Happy coding!</p>\n</section>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 3.8.9-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://www.spsanderson.com/steveondata/posts/2023-10-26/index.html\"> Steve's Data Tips and Tricks</a></strong>.</div>\n<hr>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\r\n\r\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\r\n</hr></div> </div>\n</article>",
      "main_text": "Plotting a Logistic Regression In Base R\nPosted on\nOctober 25, 2023\nby\nSteven P. Sanderson II, MPH\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nSteve's Data Tips and Tricks\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nIntroduction\nLogistic regression is a statistical method used for predicting the probability of a binary outcome. It’s a fundamental tool in machine learning and statistics, often employed in various fields such as healthcare, finance, and marketing. We use logistic regression when we want to understand the relationship between one or more independent variables and a binary outcome, which can be “yes/no,” “1/0,” or any two-class distinction.\nGetting Started\nBefore we dive into plotting the logistic regression curve, let’s start with the basics. First, you’ll need some data. For this blog post, I’ll assume you have your dataset ready. If you don’t, you can easily find sample datasets online to practice with.\nLoad the Data\nIn R, we use the\nread.csv\nfunction to load a CSV file into a data frame. For example, if you have a dataset called “mydata.csv,” you can load it like this:\n# Load the data into a data frame\ndata <- read.csv(\"mydata.csv\")\nWe will instead use the following data set:\nlibrary(dplyr)\n\nset.seed(123)\ndf <- tibble(\n    x = runif(100, 0, 10),\n    y = rbinom(100, 1, 1 / (1 + exp(-1 * (0.5 * x - 2.5))))\n)\n\nhead(df)\n# A tibble: 6 × 2\n      x     y\n  <dbl> <int>\n1 2.88      0\n2 7.88      1\n3 4.09      0\n4 8.83      0\n5 9.40      1\n6 0.456     0\nFit a Logistic Regression Model\nNext, we need to fit a logistic regression model to our data. We’ll use the\nglm\n(Generalized Linear Model) function to do this. Suppose we want to predict the probability of a “success” (1) based on a single predictor variable “x.”\n# Fit a logistic regression model\nmodel <- glm(y ~ x, data = df, family = binomial)\n\nbroom::glance(model)\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n1          138.      99  -51.5  107.  112.     103.          98   100\nbroom::tidy(model)\n# A tibble: 2 × 5\n  term        estimate std.error statistic     p.value\n  <chr>          <dbl>     <dbl>     <dbl>       <dbl>\n1 (Intercept)   -2.63      0.571     -4.60 0.00000422 \n2 x              0.505     0.102      4.96 0.000000699\nhead(broom::augment(model), 1) |> \n  dplyr::glimpse()\nRows: 1\nColumns: 8\n$ y          <int> 0\n$ x          <dbl> 2.875775\n$ .fitted    <dbl> -1.175925\n$ .resid     <dbl> -0.7333581\n$ .hat       <dbl> 0.01969748\n$ .sigma     <dbl> 1.028093\n$ .cooksd    <dbl> 0.003162007\n$ .std.resid <dbl> -0.7406892\nPredict Probabilities\nNow that we have our model, we can use it to predict probabilities. We’ll create a sequence of values for our predictor variable, and for each value, we’ll predict the probability of success, in this case\ny\n.\n# Create a sequence of predictor values\nx_seq <- seq(0, 10, 0.01)\n\n# Predict probabilities\nprobabilities <- predict(\n  model, \n  newdata = data.frame(x = x_seq), \n  type = \"response\"\n  )\n\nhead(x_seq)\n[1] 0.00 0.01 0.02 0.03 0.04 0.05\nhead(probabilities)\n1          2          3          4          5          6 \n0.06732923 0.06764710 0.06796636 0.06828702 0.06860908 0.06893255\nThe\npredict\nfunction here calculates the probabilities using our logistic regression model.\nPlot the Logistic Regression Curve\nFinally, let’s plot the logistic regression curve. We’ll use the\nplot\nfunction to create a scatter plot of the data points, and then we’ll overlay the logistic curve using the\nlines\nfunction.\n# Plot the data points\nplot(\n  df$x, df$y, \n  pch = 16, \n  col = \"blue\", \n  xlab = \"Predictor Variable\", \n  ylab = \"Probability of Success\"\n  )\n\n# Add the logistic regression curve\nlines(x_seq, probabilities, col = \"red\", lwd = 2)\nAnd there you have it! You’ve successfully plotted a logistic regression curve in base R. The blue dots represent your data points, and the red curve is the logistic regression curve, showing how the probability of success changes with the predictor variable.\nConclusion\nI encourage you to try this out with your own dataset. Logistic regression is a powerful tool for modeling binary outcomes, and visualizing the curve helps you understand the relationship between your predictor variable and the probability of success. Experiment with different datasets and predictor variables to gain a deeper understanding of this essential statistical technique.\nRemember, practice makes perfect, and the more you work with logistic regression in R, the more proficient you’ll become. Happy coding!\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nSteve's Data Tips and Tricks\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "Introduction Logistic regression is a statistical method used for predicting the probability of a binary outcome. It’s a fundamental tool in machine learning and statistics, often employed in various fields such as healthcare, finance, and marke...",
      "meta_keywords": null,
      "og_description": "Introduction Logistic regression is a statistical method used for predicting the probability of a binary outcome. It’s a fundamental tool in machine learning and statistics, often employed in various fields such as healthcare, finance, and marke...",
      "og_image": "https://www.spsanderson.com/steveondata/posts/2023-10-26/index_files/figure-html/unnamed-chunk-4-1.png",
      "og_title": "Plotting a Logistic Regression In Base R | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 4.3,
      "sitemap_lastmod": "2023-10-26T04:00:00+00:00",
      "twitter_description": "Introduction Logistic regression is a statistical method used for predicting the probability of a binary outcome. It’s a fundamental tool in machine learning and statistics, often employed in various fields such as healthcare, finance, and marke...",
      "twitter_title": "Plotting a Logistic Regression In Base R | R-bloggers",
      "url": "https://www.r-bloggers.com/2023/10/plotting-a-logistic-regression-in-base-r/",
      "word_count": 870
    }
  }
}