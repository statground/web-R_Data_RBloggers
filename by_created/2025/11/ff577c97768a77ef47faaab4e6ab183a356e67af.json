{
  "id": "ff577c97768a77ef47faaab4e6ab183a356e67af",
  "url": "https://www.r-bloggers.com/2025/05/simulating-a-simple-response-adaptive-randomization-i-have-to-see-it-to-believe-it/",
  "created_at_utc": "2025-11-22T19:58:41Z",
  "data": null,
  "raw_original": {
    "uuid": "d5f9dc3b-ecbb-4a3b-914a-5bb72ee85152",
    "created_at": "2025-11-22 19:58:41",
    "raw_json": {
      "article_author": null,
      "article_headline": null,
      "article_modified": null,
      "article_published": null,
      "article_section": null,
      "article_tags": null,
      "canonical_url": "https://www.r-bloggers.com/2025/05/simulating-a-simple-response-adaptive-randomization-i-have-to-see-it-to-believe-it/",
      "crawled_at": "2025-11-22T10:49:30.173727",
      "external_links": [
        {
          "href": "https://www.kenkoonwong.com/blog/rar/",
          "text": "r on Everyday Is A School Day"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#objectives",
          "text": null
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#what",
          "text": "What Is Response Adaptive Randomization?"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#formulae",
          "text": "Adaptive Formula for Response Adaptive Randomization"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#plan",
          "text": "Simulation Plan"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#adapt",
          "text": "Adaptive vs 50-50 Allocation"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#code",
          "text": "Code"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#interpretation",
          "text": "Interpretation"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#limit",
          "text": "Limitations"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#opportunity",
          "text": "Opportunity for Improvement"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#lessons",
          "text": "Lessons Learnt"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#what",
          "text": null
        },
        {
          "href": "https://www.remapcap.org/",
          "text": "REMAP-CAP"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#formulae",
          "text": null
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#thall-and-wathen-approach",
          "text": null
        },
        {
          "href": "https://pmc.ncbi.nlm.nih.gov/articles/PMC2030491/",
          "text": "Dive deeper"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#plan",
          "text": null
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#adaptive",
          "text": null
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#questions-i-have-for-myself",
          "text": null
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#code",
          "text": null
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#interpretation",
          "text": null
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#visualization",
          "text": null
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#will-rar-need-less-patients-to-show-a-positive-treatment-effect",
          "text": null
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#will-rar-have-the-same-accuracy-at-identifying-treatment-effect",
          "text": null
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#if-there-is-no-effect-will-rar-be-able-to-tease-that-out-and-what-would-that-look-like",
          "text": null
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#limit",
          "text": null
        },
        {
          "href": "https://academic.oup.com/cid/article/71/11/3002/5813456",
          "text": "Resist the Temptation of Response-Adaptive Randomization"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#what-about-multiplicity-adjustment-and-type-1-error",
          "text": null
        },
        {
          "href": "https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-020-01042-7",
          "text": "Do we need to adjust for interim analyses in a Bayesian adaptive trial design?"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#opportunity",
          "text": null
        },
        {
          "href": "https://statmodeling.stat.columbia.edu/2015/11/01/cauchy-priors-for-logistic-regression-coefficients/",
          "text": "read more"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/#lessons",
          "text": null
        },
        {
          "href": "https://statmodeling.stat.columbia.edu/2015/11/01/cauchy-priors-for-logistic-regression-coefficients/",
          "text": "read more"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/",
          "text": "comment or visit my other blogs"
        },
        {
          "href": "https://bsky.app/profile/kenkoonwong.bsky.social",
          "text": "BlueSky"
        },
        {
          "href": "https://twitter.com/kenkoonwong/",
          "text": "twitter"
        },
        {
          "href": "https://github.com/kenkoonwong/",
          "text": "GitHub"
        },
        {
          "href": "https://med-mastodon.com/@kenkoonwong",
          "text": "Mastodon"
        },
        {
          "href": "https://www.kenkoonwong.com/contact/",
          "text": "contact me"
        },
        {
          "href": "https://www.kenkoonwong.com/blog/rar/",
          "text": "r on Everyday Is A School Day"
        },
        {
          "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
          "text": "daily e-mail updates"
        },
        {
          "href": "https://www.r-project.org/",
          "text": "R"
        },
        {
          "href": "https://www.r-users.com/",
          "text": "Click here if you're looking to post or find an R/data-science job"
        },
        {
          "href": "http://r-posts.com/",
          "text": "here"
        }
      ],
      "h1_title": "R-bloggers",
      "html_title": "Simulating A Simple Response Adaptive Randomization – I Have To See It To Believe It | R-bloggers",
      "images": [
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i1.wp.com/www.kenkoonwong.com/blog/rar/dice.jpg?w=578&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/www.kenkoonwong.com/blog/rar/simulation_plot.png?w=578&ssl=1"
        },
        {
          "alt": null,
          "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
          "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
        },
        {
          "alt": null,
          "base64": null,
          "src": "https://i2.wp.com/www.kenkoonwong.com/blog/rar/simulation_null.png?w=578&ssl=1"
        }
      ],
      "internal_links": [
        {
          "href": "https://www.r-bloggers.com/author/r-on-everyday-is-a-school-day/",
          "text": "r on Everyday Is A School Day"
        },
        {
          "href": "https://www.r-bloggers.com/category/r-bloggers/",
          "text": "R bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers"
        },
        {
          "href": "https://www.r-bloggers.com/contact-us/",
          "text": "here"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        },
        {
          "href": "https://www.r-bloggers.com/",
          "text": "R-bloggers.com"
        },
        {
          "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
          "text": "learning R"
        },
        {
          "href": "https://www.r-bloggers.com/add-your-blog/",
          "text": "click here"
        }
      ],
      "lang": "en-US",
      "main_html": "<article class=\"post-392263 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Simulating A Simple Response Adaptive Randomization – I Have To See It To Believe It</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">May 3, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/r-on-everyday-is-a-school-day/\">r on Everyday Is A School Day</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://www.kenkoonwong.com/blog/rar/\"> r on Everyday Is A School Day</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47--><blockquote>\n<p>In my simulations of Response Adaptive Randomization, I discovered it performs comparably to fixed 50-50 allocation in identifying treatment effects. The adaptive approach does appear to work! However, with only 10 trials, I’ve merely scratched the surface. Important limitations exist – temporal bias risks, statistical inefficiency, and complex multiplicity adjustments in Bayesian frameworks.</p>\n</blockquote>\n<p><img alt=\"\" data-lazy-src=\"https://i1.wp.com/www.kenkoonwong.com/blog/rar/dice.jpg?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"\" data-recalc-dims=\"1\" src=\"https://i1.wp.com/www.kenkoonwong.com/blog/rar/dice.jpg?w=578&amp;ssl=1\"/></noscript></p>\n<h2 id=\"objectives\">Objectives\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#objectives\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h2>\n<ul>\n<li>\n<a href=\"https://www.kenkoonwong.com/blog/rar/#what\" rel=\"nofollow\" target=\"_blank\">What Is Response Adaptive Randomization?</a>\n<ul>\n<li>\n<a href=\"https://www.kenkoonwong.com/blog/rar/#formulae\" rel=\"nofollow\" target=\"_blank\">Adaptive Formula for Response Adaptive Randomization</a></li>\n</ul>\n</li>\n<li>\n<a href=\"https://www.kenkoonwong.com/blog/rar/#plan\" rel=\"nofollow\" target=\"_blank\">Simulation Plan</a>\n<ul>\n<li>\n<a href=\"https://www.kenkoonwong.com/blog/rar/#adapt\" rel=\"nofollow\" target=\"_blank\">Adaptive vs 50-50 Allocation</a></li>\n</ul>\n</li>\n<li>\n<a href=\"https://www.kenkoonwong.com/blog/rar/#code\" rel=\"nofollow\" target=\"_blank\">Code</a></li>\n<li>\n<a href=\"https://www.kenkoonwong.com/blog/rar/#interpretation\" rel=\"nofollow\" target=\"_blank\">Interpretation</a></li>\n<li>\n<a href=\"https://www.kenkoonwong.com/blog/rar/#limit\" rel=\"nofollow\" target=\"_blank\">Limitations</a></li>\n<li>\n<a href=\"https://www.kenkoonwong.com/blog/rar/#opportunity\" rel=\"nofollow\" target=\"_blank\">Opportunity for Improvement</a></li>\n<li>\n<a href=\"https://www.kenkoonwong.com/blog/rar/#lessons\" rel=\"nofollow\" target=\"_blank\">Lessons Learnt</a></li>\n</ul>\n<h2 id=\"what\">What Is Response Adaptive Randomization?\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#what\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h2>\n<p>Response-Adaptive Randomization (RAR) is a technique used in clinical trials where the allocation of patients to different treatment arms changes based on interim results collected during the trial. Unlike traditional fixed randomization where treatment allocation ratios remain constant throughout the study, RAR adjusts the probability of assignment to treatment groups as data accumulates, typically to assign more patients to treatments that appear to be performing better. This approach is designed to achieve two main goals: to maximize the information gained about superior treatments while minimizing the number of patients exposed to inferior treatments during the trial itself.</p>\n<p>The primary motivation for using RAR is ethical – it aims to treat more trial participants effectively while still gathering sufficient data for scientific conclusions. It’s particularly considered in trials involving serious conditions with high mortality rates or in multi-arm trials where several experimental treatments are being compared. RAR has received considerable theoretical attention since the 1930s but remains controversial in practice, with proponents citing its potential ethical advantages while critics point to concerns about statistical validity, potential bias from temporal trends, and increased complexity in trial design and analysis.</p>\n<p>\n<a href=\"https://www.remapcap.org/\" rel=\"nofollow\" target=\"_blank\">REMAP-CAP</a> was the first study that I came across that introduced me to this design and I found the theory quite intriguing and interesting! It does appear too good to be true but for me, I cannot get the intuition behind how the adaptive randomization be able to identify it. Fortunately, there is another way we can convince ourselves that this works, and that is to simulate it for ourselves, Bayesian style!</p>\n<h3 id=\"formulae\">Adaptive Formula for Response Adaptive Randomization\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#formulae\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h3>\n<h4 id=\"thall-and-wathen-approach\">Thall and Wathen approach\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#thall-and-wathen-approach\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>This is a commonly used formula that adjusts randomization probabilities based on posterior probabilities. For a two-arm trial, the probability of assigning a patient to treatment 1 is:</p>\n<p><code>\\begin{gather} π₁,ᵢ = \\frac{[P(p₁ &gt; p₀|data)]^c}{[P(p₁ &gt; p₀|data)]^c + [1-P(p₁ &gt; p₀|data)]^c} \\end{gather}</code></p>\n<p>Where P(p₁ &gt; p₀|data) is the posterior probability that treatment 1 is better than treatment 0, and c is a tuning parameter that controls adaptation speed. When c=0, this reduces to equal randomization; when c=1, it becomes Thompson Sampling.</p>\n<p>There may be other approaches to RAR, but this is the one that makes sense and easy to implement. \n<a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC2030491/\" rel=\"nofollow\" target=\"_blank\">Dive deeper</a></p>\n<h2 id=\"plan\">Simulation Plan\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#plan\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h2>\n<p>Hopefully simulating this multiple times might give me a better idea of how it will work in practice. How do we do that?</p>\n<h4>Adaptive vs 50-50 Allocation\n<a href=\"https://www.kenkoonwong.com/blog/rar/#adaptive\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a></h4>\n<ol>\n<li>Set up a world where we have the entire population and we know how they respond with and without treatment.</li>\n<li>We’re going to set treatment effect as <code>-1.09</code>, which means the treatment is better at reducing some proportion of event than the control. The formula would be <code>log odds = b0 + b1 * treatment</code>, where <code>b0</code> is 0, and <code>b1</code> is our treatment effect.</li>\n<li>We will then write a code to simulate both <code>Response Adaptive Randomization</code> and <code>50-50 allocation</code>, with a 50 sets. Each set will then have 4 sequential analyses and sampling. The first analysis will have 50 patients with random allocation with 50%. For subsequent interim analyses, response adaptive randomization group will depend on the response, whereas 50-50 allocation group will remain as 50%. For adatpive randomization, we will use Thall and Wathen approach with <code>c</code> between <code>0</code> and <code>0.5</code>. We will use Thall and Warten’s formula for updating the <code>c</code> with <code>n / (2*N)</code>, where <code>n</code> is the number of patients sampled thus far plus the ones will be sampled this in interim trial, and <code>N</code> is the maximum number of patients in the trial. As you can see, when total of 200 patients sampled, c will be <code>0.5</code> at the last interim analysis.</li>\n<li>Each trial for both groups is set with the same seed to ensure reproducibility.</li>\n<li>After each trial, we extract the coefficient of interest (in our case beta1), and also assess what is the probability of beta1 being less than 0, which means the treatment is helpful at reducing whatever outcome we want to reduce.</li>\n</ol>\n<h4 id=\"questions-i-have-for-myself\">Questions I Have For Myself\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#questions-i-have-for-myself\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<ol>\n<li>What is the difference between <code>Response Adaptive Randomization</code> and <code>50-50 allocation</code> in terms of treatment effect estimates? Will RAR have the same accuracy at identifying treatment effect? Will RAR reach identify treatment effect faster than 50-50 allocation?</li>\n<li>If there is no effect, will RAR be able to tease that out to? And what would that look like?</li>\n</ol>\n<h2 id=\"code\">Code\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#code\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h2>\n<pre>library(tidyverse)\nlibrary(cmdstanr)\nlibrary(glue)\n\n## comparing 50-50 allocation vs Adaptive Randomization\nmethod_list &lt;- c(\"50_50\",\"adaptive\")\nseeds &lt;- sample(1:100000, size = 10, replace = F)\n\n\n## set up empty dataframe\nresult &lt;- tibble(\n  b0 = numeric(),\n  b0_lower = numeric(),\n  b0_upper = numeric(),\n  b1 = numeric(),\n  b1_lower = numeric(),\n  b1_upper = numeric(),\n  prob = numeric(),\n  treatment_num = numeric(),\n  num_sample = numeric(),\n  treatment_num_cum = numeric(),\n  num = numeric(),\n  method = character(),\n  seed = numeric()\n)\n\nfor (seed in seeds) {\nfor (method in method_list){\ntreatment_effect &lt;- -1.09\n\n### Set Up Entire Population, knowing both effects of placebo and treatment of each patient\nset.seed(seed)\nN &lt;- 100000\nx0 &lt;- replicate(N, 0)\ny0 &lt;- rbinom(N, 1, plogis(treatment_effect*x0))\nx1 &lt;- replicate(N,1)\ny1 &lt;- rbinom(N, 1, plogis(treatment_effect*x1))\ndf &lt;- tibble(y0,y1) |&gt;\n  mutate(id = row_number())\n\n\n### Max sample\nmax_n &lt;- 200\n\n### How many sampling trials\nn &lt;- 50\nsample_number &lt;- max_n / n\nb0 = b0_lower = b0_upper = b1 = b1_lower = b1_upper = prob_vec = treatment_num = num_vec = vector(mode = \"numeric\", length = sample_number)\nx_vec &lt;- c()\n\n### Changing c parameter\nn_sum &lt;- 0\nc_param &lt;- function(x) {\n  value &lt;- x / (2*max_n)\n  return(value)\n}\n\nfor (i in 0:sample_number) {\n  ## Set initial parameters and don't log it\n  if (i == 0) {\n    b0mu &lt;- 0\n    b0sd &lt;- 10\n    b1mu &lt;- 0\n    b1sd &lt;- 2.5\n    diff &lt;- 0.5\n    x &lt;- rbinom(n, 1, 0.5)\n    num_vec[i+1] &lt;- n\n    n_sum &lt;- n\n  } else {\n  ## Update prior\nb0mu &lt;- fit$summary(\"beta0\")[['median']]\nb0sd &lt;- fit$summary(\"beta0\")[['sd']]\nb1mu &lt;- fit$summary(\"beta1\")[['median']]\nb1sd &lt;- fit$summary(\"beta1\")[['sd']]\nb0[i] &lt;- b0mu\nb0_lower[i] &lt;- fit$summary(\"beta0\")[[\"q5\"]]\nb0_upper[i] &lt;- fit$summary(\"beta0\")[[\"q95\"]]\nb1[i] &lt;- b1mu\nb1_lower[i] &lt;- b1_lower_i\nb1_upper[i] &lt;- b1_upper_i\nn_sum &lt;- n_sum + n\n\n\n## Assigment of sampling proportion; 50% allocation at all times vs Adaptive\nif (method == \"50_50\") {\n  diff &lt;- 0.5\n  } else {\n    \n    prob &lt;- beta1 |&gt;\n      mutate(treatment_benefit = ifelse(beta1 &lt; 0, 1, 0)) |&gt;\n      summarize(prop = mean(treatment_benefit)) |&gt;\n      pull()\n    \n    c &lt;- c_param(n_sum)\n    # diff &lt;- min(max(prob, 0.1), 0.9)\n    diff &lt;- prob^c / (prob^c + (1-prob)^c)\n  }\n\nprob_vec[i] &lt;- diff\ntreatment_num[i] = sum(x)\n\n## Each Sampling is 50 patients\nnum_vec[i+1] &lt;- n\nx &lt;- rbinom(n, 1, diff)\n}\n  \n\n## Sampling from population\ndf_list &lt;- df |&gt;\n  slice_sample(n = n) |&gt;\n  bind_cols(x=x) |&gt;\n  mutate(y = case_when(\n    x == 1 ~ y1,\n    x == 0 ~ y0\n  ))\n\n## Bayesian Model\n\n## main model\nstan_model &lt;- glue(\"\ndata {{\n  int&lt;lower=0&gt; N;  \n  array[N] int x;  \n  array[N] int y;  \n}}\nparameters {{\n  real beta0;  \n  real beta1;  \n}}\nmodel {{\n  beta0 ~ normal({b0mu},{b0sd});\n  beta1 ~ normal({b1mu},{b1sd});\n  y ~ bernoulli_logit(beta0 + beta1*to_vector(x));\n}}\n\")\n  \n## compile model\nmod &lt;- write_stan_file(stan_model)\nmodel &lt;- cmdstan_model(mod)\nfit &lt;- model$sample(\n  data = list(N=nrow(df_list), x=df_list$x, y=df_list$y),\n  chains = 4, \n  iter_sampling = 2000,\n  iter_warmup = 1000,\n  seed = 1,\n  parallel_chains = 4\n)\n\n## Remove patients who are already sampled from the population\nsample &lt;- df_list |&gt; pull(id)\ndf &lt;- df |&gt; filter(!id %in% sample)\nx_vec &lt;- c(x_vec,x)\nprint(i)\n\n## Extract MCMC\nmcmc &lt;- as.data.frame(fit$draws(inc_warmup = F))\n\n## Assess probability that treatment effect is &lt; 0 \nbeta1 &lt;- mcmc |&gt;\n  select(contains(\"beta1\")) |&gt;\n  pivot_longer(cols = everything(), names_to = \"column\", values_to = \"beta1\") \n\nb1_lower_i &lt;- beta1 |&gt;\n  summarize(lower = quantile(beta1, 0.025)) |&gt;\n  pull(lower)\n\nb1_upper_i &lt;- beta1 |&gt;\n  summarize(upper = quantile(beta1, 0.975)) |&gt;\n  pull(upper)\n\n\n}\n\n\n## log results\nresult &lt;- result |&gt;\n  bind_rows(tibble(b0=b0,b0_lower=b0_lower,b0_upper=b0_upper,b1=b1,b1_lower=b1_lower,b1_upper=b1_upper,prob=prob_vec,treatment_num=treatment_num, num_sample=num_vec[1:(length(num_vec)-1)]) |&gt; \n  mutate(treatment_num_cum = cumsum(treatment_num),\n         num = cumsum(num_sample),\n         method = method,\n         seed = seed) |&gt;\n  slice_head(n=30))\n\n\n}\n}\n</pre>\n<h2 id=\"interpretation\">Interpretation\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#interpretation\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h2>\n<h4 id=\"visualization\">Visualization\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#visualization\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<pre>## Visualize the result\nresult |&gt;\n  ggplot(aes(x=num,y=b1)) +\n  geom_point() +\n  geom_line() +\n  geom_ribbon(aes(ymin=b1_lower,ymax=b1_upper), alpha=0.5) +\n  geom_hline(yintercept = 0) +\n  geom_hline(yintercept = treatment_effect, color = \"blue\") +\n  geom_label(aes(x=num,y=b1,label=treatment_num_cum), size=3) +\n  ggtitle(\"Reponse Adaptive Randomization vs 50-50 Fixed Randomization\", subtitle = \"Blue line = True value, Black line = No different between treatment &amp; placebo, Numbers labeled = Number of treatment\") +\n  xlab(\"Patients\") +\n  theme_bw() +\n  xlim(40,210) +\n  facet_grid(method~seed)\n</pre><p><img alt=\"\" data-lazy-src=\"https://i2.wp.com/www.kenkoonwong.com/blog/rar/simulation_plot.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.kenkoonwong.com/blog/rar/simulation_plot.png?w=578&amp;ssl=1\"/></noscript>\nThe above plot shows the beta1 coefficient parameter from the posterior distribution. The 10 columns are the seeds for each set of trial. The row represents the method of allocation, either 50-50 or adaptive randomization. The blue line is the true treatment effect, which is -1.09. The grey line is when there is no effect (0), and the shaded area is the 95% credible interval. Simple heuristic is that if the grey area goes below the black line, it then means there is 95% probability that there is a treatment effect. Now let’s see if we can answer the questions we had.</p>\n<h4 id=\"will-rar-need-less-patients-to-show-a-positive-treatment-effect\">Will RAR need less patients to show a positive treatment effect?\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#will-rar-need-less-patients-to-show-a-positive-treatment-effect\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>Does not seem like it like, both 50-50 and RAR seem to have similar number of patients to show a positive treatment effect.</p>\n<h4 id=\"will-rar-have-the-same-accuracy-at-identifying-treatment-effect\">Will RAR have the same accuracy at identifying treatment effect?\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#will-rar-have-the-same-accuracy-at-identifying-treatment-effect\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p>Yes. The patterns on both methods appear to be quite similar.</p>\n<h4 id=\"if-there-is-no-effect-will-rar-be-able-to-tease-that-out-and-what-would-that-look-like\">If there is no effect, will RAR be able to tease that out? And what would that look like?\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#if-there-is-no-effect-will-rar-be-able-to-tease-that-out-and-what-would-that-look-like\" rel=\"nofollow\" target=\"_blank\"></a>\n</h4>\n<p><img alt=\"\" data-lazy-src=\"https://i2.wp.com/www.kenkoonwong.com/blog/rar/simulation_null.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"\" data-recalc-dims=\"1\" src=\"https://i2.wp.com/www.kenkoonwong.com/blog/rar/simulation_null.png?w=578&amp;ssl=1\"/></noscript>\nMaybe? both 50-50 and adpative randomization seem to be able to identify that there is no treatment effect. However, the 50-50 allocation seems to be more stable than the adaptive randomization. This is only from 10 trials, hard to say. We also didn’t set criteria for stopping for futility.</p>\n<p>On a side note, notice how with seed <code>26561</code> and <code>87907</code>, we will falsely conclude that there is a treatment effect when there is none.</p>\n<h2 id=\"limit\">Limitations\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#limit\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h2>\n<p>According to \n<a href=\"https://academic.oup.com/cid/article/71/11/3002/5813456\" rel=\"nofollow\" target=\"_blank\">Resist the Temptation of Response-Adaptive Randomization</a>, Response-Adaptive Randomization (RAR) causes many problems, including:</p>\n<ol>\n<li>Bias from temporal trends in clinical trials when patients enrolled at different times face systematically different conditions.</li>\n<li>Inefficiency in treatment effect estimation that often requires larger sample sizes to maintain statistical power.</li>\n<li>Volatility in sample-size distributions that can paradoxically assign more patients to inferior treatments due to random variation.</li>\n<li>Difficulty of validly analyzing results when sample sizes themselves contain information about treatment efficacy.</li>\n<li>The potential for selection bias when researchers become unintentionally unblinded to interim results as allocation probabilities shift.</li>\n</ol>\n<h5 id=\"what-about-multiplicity-adjustment-and-type-1-error\">What About Multiplicity Adjustment and Type 1 Error?\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#what-about-multiplicity-adjustment-and-type-1-error\" rel=\"nofollow\" target=\"_blank\"></a>\n</h5>\n<p>Bayesian adaptive designs face a practical dilemma regarding multiplicity adjustment. While Bayesian inference theoretically doesn’t require corrections for multiple looks at data, regulatory requirements typically demand Type I error control for confirmation trials regardless of statistical approach. Case studies show that unadjusted interim analyses with early efficacy stopping inflate Type I error rates, while futility-only stopping decreases Type I error but reduces power. For researchers implementing Bayesian adaptive designs with early efficacy stopping, adjustments to boundaries become necessary as analyses increase, creating tension between Bayesian philosophy and regulatory demands, especially in trials aiming to change clinical practice.</p>\n<p>Read more: \n<a href=\"https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-020-01042-7\" rel=\"nofollow\" target=\"_blank\">Do we need to adjust for interim analyses in a Bayesian adaptive trial design?</a></p>\n<h2 id=\"opportunity\">Opportunity for Improvement\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#opportunity\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h2>\n<ul>\n<li>We only did 10 trials total, which is not enough to draw concrete conclusions.</li>\n<li>Cauchy distribution for logistic regression coefficient prior \n<a href=\"https://statmodeling.stat.columbia.edu/2015/11/01/cauchy-priors-for-logistic-regression-coefficients/\" rel=\"nofollow\" target=\"_blank\">read more</a></li>\n<li>Set ROPE (Region of Practical Equivalence) for the treatment effect, and see if we can get a better idea of how many patients we need to sample before we can conclude that there is no treatment effect.</li>\n</ul>\n<p>I had sent my friend Alec Wong the script earlier on to proof-read. Here are the comments for me to improve in for future reference.</p>\n<ul>\n<li>Extract functionality into dedicated functions, ideally small, concise, and highly descriptive of what it does. Write them to avoid global variables as much as possible, and instead be explicit about what variables the function depends on, and pass them in.</li>\n<li>A lot of lines that are independent of the “methods” loop, but nevertheless show up inside the loop. Anything that does not depend on the loop should not belong in the loop. You modify the df of simulated data during the loop, yes, but that needs not be the case, you could modify to a new variable instead of overwriting df.</li>\n<li>The “method” loop is actually quite small and doesn’t do very much. There appears little reason to write the script so that everything is run twice.</li>\n<li>You re-use n many times in this script, making it difficult to reason about what the value of n is at any given time.  If you follow the advice in (1), you can re-use n inside functions without ambiguity because they are scoped to the function.</li>\n</ul>\n<p>Thanks Alec! I’ll work on these!</p>\n<h2 id=\"lessons\">Lessons Learnt\n  <a href=\"https://www.kenkoonwong.com/blog/rar/#lessons\" rel=\"nofollow\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"anchor-symbol\" height=\"26\" viewbox=\"0 0 22 22\" width=\"26\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M0 0h24v24H0z\" fill=\"currentColor\"></path>\n<path d=\"M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z\"></path>\n</svg></a>\n</h2>\n<ul>\n<li>Refreshed on our bayesian statistics and Stan code</li>\n<li>Learnt about RAR, and what it looks like compared to 50-50 allocation</li>\n<li>Literature search on the question on multiplicity and bayesian statistics</li>\n<li>Cauchy distribution for logistic regression coefficient prior \n<a href=\"https://statmodeling.stat.columbia.edu/2015/11/01/cauchy-priors-for-logistic-regression-coefficients/\" rel=\"nofollow\" target=\"_blank\">read more</a></li>\n</ul>\n<p>If you like this article:</p>\n<ul>\n<li>please feel free to send me a \n<a href=\"https://www.kenkoonwong.com/blog/\" rel=\"nofollow\" target=\"_blank\">comment or visit my other blogs</a></li>\n<li>please feel free to follow me on \n<a href=\"https://bsky.app/profile/kenkoonwong.bsky.social\" rel=\"nofollow\" target=\"_blank\">BlueSky</a>, \n<a href=\"https://twitter.com/kenkoonwong/\" rel=\"nofollow\" target=\"_blank\">twitter</a>, \n<a href=\"https://github.com/kenkoonwong/\" rel=\"nofollow\" target=\"_blank\">GitHub</a> or \n<a href=\"https://med-mastodon.com/@kenkoonwong\" rel=\"nofollow\" target=\"_blank\">Mastodon</a></li>\n<li>if you would like collaborate please feel free to \n<a href=\"https://www.kenkoonwong.com/contact/\" rel=\"nofollow\" target=\"_blank\">contact me</a></li>\n</ul>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://www.kenkoonwong.com/blog/rar/\"> r on Everyday Is A School Day</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
      "main_text": "Simulating A Simple Response Adaptive Randomization – I Have To See It To Believe It\nPosted on\nMay 3, 2025\nby\nr on Everyday Is A School Day\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nr on Everyday Is A School Day\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nIn my simulations of Response Adaptive Randomization, I discovered it performs comparably to fixed 50-50 allocation in identifying treatment effects. The adaptive approach does appear to work! However, with only 10 trials, I’ve merely scratched the surface. Important limitations exist – temporal bias risks, statistical inefficiency, and complex multiplicity adjustments in Bayesian frameworks.\nObjectives\nWhat Is Response Adaptive Randomization?\nAdaptive Formula for Response Adaptive Randomization\nSimulation Plan\nAdaptive vs 50-50 Allocation\nCode\nInterpretation\nLimitations\nOpportunity for Improvement\nLessons Learnt\nWhat Is Response Adaptive Randomization?\nResponse-Adaptive Randomization (RAR) is a technique used in clinical trials where the allocation of patients to different treatment arms changes based on interim results collected during the trial. Unlike traditional fixed randomization where treatment allocation ratios remain constant throughout the study, RAR adjusts the probability of assignment to treatment groups as data accumulates, typically to assign more patients to treatments that appear to be performing better. This approach is designed to achieve two main goals: to maximize the information gained about superior treatments while minimizing the number of patients exposed to inferior treatments during the trial itself.\nThe primary motivation for using RAR is ethical – it aims to treat more trial participants effectively while still gathering sufficient data for scientific conclusions. It’s particularly considered in trials involving serious conditions with high mortality rates or in multi-arm trials where several experimental treatments are being compared. RAR has received considerable theoretical attention since the 1930s but remains controversial in practice, with proponents citing its potential ethical advantages while critics point to concerns about statistical validity, potential bias from temporal trends, and increased complexity in trial design and analysis.\nREMAP-CAP\nwas the first study that I came across that introduced me to this design and I found the theory quite intriguing and interesting! It does appear too good to be true but for me, I cannot get the intuition behind how the adaptive randomization be able to identify it. Fortunately, there is another way we can convince ourselves that this works, and that is to simulate it for ourselves, Bayesian style!\nAdaptive Formula for Response Adaptive Randomization\nThall and Wathen approach\nThis is a commonly used formula that adjusts randomization probabilities based on posterior probabilities. For a two-arm trial, the probability of assigning a patient to treatment 1 is:\n\\begin{gather} π₁,ᵢ = \\frac{[P(p₁ > p₀|data)]^c}{[P(p₁ > p₀|data)]^c + [1-P(p₁ > p₀|data)]^c} \\end{gather}\nWhere P(p₁ > p₀|data) is the posterior probability that treatment 1 is better than treatment 0, and c is a tuning parameter that controls adaptation speed. When c=0, this reduces to equal randomization; when c=1, it becomes Thompson Sampling.\nThere may be other approaches to RAR, but this is the one that makes sense and easy to implement.\nDive deeper\nSimulation Plan\nHopefully simulating this multiple times might give me a better idea of how it will work in practice. How do we do that?\nAdaptive vs 50-50 Allocation\nSet up a world where we have the entire population and we know how they respond with and without treatment.\nWe’re going to set treatment effect as\n-1.09\n, which means the treatment is better at reducing some proportion of event than the control. The formula would be\nlog odds = b0 + b1 * treatment\n, where\nb0\nis 0, and\nb1\nis our treatment effect.\nWe will then write a code to simulate both\nResponse Adaptive Randomization\nand\n50-50 allocation\n, with a 50 sets. Each set will then have 4 sequential analyses and sampling. The first analysis will have 50 patients with random allocation with 50%. For subsequent interim analyses, response adaptive randomization group will depend on the response, whereas 50-50 allocation group will remain as 50%. For adatpive randomization, we will use Thall and Wathen approach with\nc\nbetween\n0\nand\n0.5\n. We will use Thall and Warten’s formula for updating the\nc\nwith\nn / (2*N)\n, where\nn\nis the number of patients sampled thus far plus the ones will be sampled this in interim trial, and\nN\nis the maximum number of patients in the trial. As you can see, when total of 200 patients sampled, c will be\n0.5\nat the last interim analysis.\nEach trial for both groups is set with the same seed to ensure reproducibility.\nAfter each trial, we extract the coefficient of interest (in our case beta1), and also assess what is the probability of beta1 being less than 0, which means the treatment is helpful at reducing whatever outcome we want to reduce.\nQuestions I Have For Myself\nWhat is the difference between\nResponse Adaptive Randomization\nand\n50-50 allocation\nin terms of treatment effect estimates? Will RAR have the same accuracy at identifying treatment effect? Will RAR reach identify treatment effect faster than 50-50 allocation?\nIf there is no effect, will RAR be able to tease that out to? And what would that look like?\nCode\nlibrary(tidyverse)\nlibrary(cmdstanr)\nlibrary(glue)\n\n## comparing 50-50 allocation vs Adaptive Randomization\nmethod_list <- c(\"50_50\",\"adaptive\")\nseeds <- sample(1:100000, size = 10, replace = F)\n\n## set up empty dataframe\nresult <- tibble(\n  b0 = numeric(),\n  b0_lower = numeric(),\n  b0_upper = numeric(),\n  b1 = numeric(),\n  b1_lower = numeric(),\n  b1_upper = numeric(),\n  prob = numeric(),\n  treatment_num = numeric(),\n  num_sample = numeric(),\n  treatment_num_cum = numeric(),\n  num = numeric(),\n  method = character(),\n  seed = numeric()\n)\n\nfor (seed in seeds) {\nfor (method in method_list){\ntreatment_effect <- -1.09\n\n### Set Up Entire Population, knowing both effects of placebo and treatment of each patient\nset.seed(seed)\nN <- 100000\nx0 <- replicate(N, 0)\ny0 <- rbinom(N, 1, plogis(treatment_effect*x0))\nx1 <- replicate(N,1)\ny1 <- rbinom(N, 1, plogis(treatment_effect*x1))\ndf <- tibble(y0,y1) |>\n  mutate(id = row_number())\n\n### Max sample\nmax_n <- 200\n\n### How many sampling trials\nn <- 50\nsample_number <- max_n / n\nb0 = b0_lower = b0_upper = b1 = b1_lower = b1_upper = prob_vec = treatment_num = num_vec = vector(mode = \"numeric\", length = sample_number)\nx_vec <- c()\n\n### Changing c parameter\nn_sum <- 0\nc_param <- function(x) {\n  value <- x / (2*max_n)\n  return(value)\n}\n\nfor (i in 0:sample_number) {\n  ## Set initial parameters and don't log it\n  if (i == 0) {\n    b0mu <- 0\n    b0sd <- 10\n    b1mu <- 0\n    b1sd <- 2.5\n    diff <- 0.5\n    x <- rbinom(n, 1, 0.5)\n    num_vec[i+1] <- n\n    n_sum <- n\n  } else {\n  ## Update prior\nb0mu <- fit$summary(\"beta0\")[['median']]\nb0sd <- fit$summary(\"beta0\")[['sd']]\nb1mu <- fit$summary(\"beta1\")[['median']]\nb1sd <- fit$summary(\"beta1\")[['sd']]\nb0[i] <- b0mu\nb0_lower[i] <- fit$summary(\"beta0\")[[\"q5\"]]\nb0_upper[i] <- fit$summary(\"beta0\")[[\"q95\"]]\nb1[i] <- b1mu\nb1_lower[i] <- b1_lower_i\nb1_upper[i] <- b1_upper_i\nn_sum <- n_sum + n\n\n## Assigment of sampling proportion; 50% allocation at all times vs Adaptive\nif (method == \"50_50\") {\n  diff <- 0.5\n  } else {\n    \n    prob <- beta1 |>\n      mutate(treatment_benefit = ifelse(beta1 < 0, 1, 0)) |>\n      summarize(prop = mean(treatment_benefit)) |>\n      pull()\n    \n    c <- c_param(n_sum)\n    # diff <- min(max(prob, 0.1), 0.9)\n    diff <- prob^c / (prob^c + (1-prob)^c)\n  }\n\nprob_vec[i] <- diff\ntreatment_num[i] = sum(x)\n\n## Each Sampling is 50 patients\nnum_vec[i+1] <- n\nx <- rbinom(n, 1, diff)\n}\n  \n\n## Sampling from population\ndf_list <- df |>\n  slice_sample(n = n) |>\n  bind_cols(x=x) |>\n  mutate(y = case_when(\n    x == 1 ~ y1,\n    x == 0 ~ y0\n  ))\n\n## Bayesian Model\n\n## main model\nstan_model <- glue(\"\ndata {{\n  int<lower=0> N;  \n  array[N] int x;  \n  array[N] int y;  \n}}\nparameters {{\n  real beta0;  \n  real beta1;  \n}}\nmodel {{\n  beta0 ~ normal({b0mu},{b0sd});\n  beta1 ~ normal({b1mu},{b1sd});\n  y ~ bernoulli_logit(beta0 + beta1*to_vector(x));\n}}\n\")\n  \n## compile model\nmod <- write_stan_file(stan_model)\nmodel <- cmdstan_model(mod)\nfit <- model$sample(\n  data = list(N=nrow(df_list), x=df_list$x, y=df_list$y),\n  chains = 4, \n  iter_sampling = 2000,\n  iter_warmup = 1000,\n  seed = 1,\n  parallel_chains = 4\n)\n\n## Remove patients who are already sampled from the population\nsample <- df_list |> pull(id)\ndf <- df |> filter(!id %in% sample)\nx_vec <- c(x_vec,x)\nprint(i)\n\n## Extract MCMC\nmcmc <- as.data.frame(fit$draws(inc_warmup = F))\n\n## Assess probability that treatment effect is < 0 \nbeta1 <- mcmc |>\n  select(contains(\"beta1\")) |>\n  pivot_longer(cols = everything(), names_to = \"column\", values_to = \"beta1\") \n\nb1_lower_i <- beta1 |>\n  summarize(lower = quantile(beta1, 0.025)) |>\n  pull(lower)\n\nb1_upper_i <- beta1 |>\n  summarize(upper = quantile(beta1, 0.975)) |>\n  pull(upper)\n\n}\n\n## log results\nresult <- result |>\n  bind_rows(tibble(b0=b0,b0_lower=b0_lower,b0_upper=b0_upper,b1=b1,b1_lower=b1_lower,b1_upper=b1_upper,prob=prob_vec,treatment_num=treatment_num, num_sample=num_vec[1:(length(num_vec)-1)]) |> \n  mutate(treatment_num_cum = cumsum(treatment_num),\n         num = cumsum(num_sample),\n         method = method,\n         seed = seed) |>\n  slice_head(n=30))\n\n}\n}\nInterpretation\nVisualization\n## Visualize the result\nresult |>\n  ggplot(aes(x=num,y=b1)) +\n  geom_point() +\n  geom_line() +\n  geom_ribbon(aes(ymin=b1_lower,ymax=b1_upper), alpha=0.5) +\n  geom_hline(yintercept = 0) +\n  geom_hline(yintercept = treatment_effect, color = \"blue\") +\n  geom_label(aes(x=num,y=b1,label=treatment_num_cum), size=3) +\n  ggtitle(\"Reponse Adaptive Randomization vs 50-50 Fixed Randomization\", subtitle = \"Blue line = True value, Black line = No different between treatment & placebo, Numbers labeled = Number of treatment\") +\n  xlab(\"Patients\") +\n  theme_bw() +\n  xlim(40,210) +\n  facet_grid(method~seed)\nThe above plot shows the beta1 coefficient parameter from the posterior distribution. The 10 columns are the seeds for each set of trial. The row represents the method of allocation, either 50-50 or adaptive randomization. The blue line is the true treatment effect, which is -1.09. The grey line is when there is no effect (0), and the shaded area is the 95% credible interval. Simple heuristic is that if the grey area goes below the black line, it then means there is 95% probability that there is a treatment effect. Now let’s see if we can answer the questions we had.\nWill RAR need less patients to show a positive treatment effect?\nDoes not seem like it like, both 50-50 and RAR seem to have similar number of patients to show a positive treatment effect.\nWill RAR have the same accuracy at identifying treatment effect?\nYes. The patterns on both methods appear to be quite similar.\nIf there is no effect, will RAR be able to tease that out? And what would that look like?\nMaybe? both 50-50 and adpative randomization seem to be able to identify that there is no treatment effect. However, the 50-50 allocation seems to be more stable than the adaptive randomization. This is only from 10 trials, hard to say. We also didn’t set criteria for stopping for futility.\nOn a side note, notice how with seed\n26561\nand\n87907\n, we will falsely conclude that there is a treatment effect when there is none.\nLimitations\nAccording to\nResist the Temptation of Response-Adaptive Randomization\n, Response-Adaptive Randomization (RAR) causes many problems, including:\nBias from temporal trends in clinical trials when patients enrolled at different times face systematically different conditions.\nInefficiency in treatment effect estimation that often requires larger sample sizes to maintain statistical power.\nVolatility in sample-size distributions that can paradoxically assign more patients to inferior treatments due to random variation.\nDifficulty of validly analyzing results when sample sizes themselves contain information about treatment efficacy.\nThe potential for selection bias when researchers become unintentionally unblinded to interim results as allocation probabilities shift.\nWhat About Multiplicity Adjustment and Type 1 Error?\nBayesian adaptive designs face a practical dilemma regarding multiplicity adjustment. While Bayesian inference theoretically doesn’t require corrections for multiple looks at data, regulatory requirements typically demand Type I error control for confirmation trials regardless of statistical approach. Case studies show that unadjusted interim analyses with early efficacy stopping inflate Type I error rates, while futility-only stopping decreases Type I error but reduces power. For researchers implementing Bayesian adaptive designs with early efficacy stopping, adjustments to boundaries become necessary as analyses increase, creating tension between Bayesian philosophy and regulatory demands, especially in trials aiming to change clinical practice.\nRead more:\nDo we need to adjust for interim analyses in a Bayesian adaptive trial design?\nOpportunity for Improvement\nWe only did 10 trials total, which is not enough to draw concrete conclusions.\nCauchy distribution for logistic regression coefficient prior\nread more\nSet ROPE (Region of Practical Equivalence) for the treatment effect, and see if we can get a better idea of how many patients we need to sample before we can conclude that there is no treatment effect.\nI had sent my friend Alec Wong the script earlier on to proof-read. Here are the comments for me to improve in for future reference.\nExtract functionality into dedicated functions, ideally small, concise, and highly descriptive of what it does. Write them to avoid global variables as much as possible, and instead be explicit about what variables the function depends on, and pass them in.\nA lot of lines that are independent of the “methods” loop, but nevertheless show up inside the loop. Anything that does not depend on the loop should not belong in the loop. You modify the df of simulated data during the loop, yes, but that needs not be the case, you could modify to a new variable instead of overwriting df.\nThe “method” loop is actually quite small and doesn’t do very much. There appears little reason to write the script so that everything is run twice.\nYou re-use n many times in this script, making it difficult to reason about what the value of n is at any given time.  If you follow the advice in (1), you can re-use n inside functions without ambiguity because they are scoped to the function.\nThanks Alec! I’ll work on these!\nLessons Learnt\nRefreshed on our bayesian statistics and Stan code\nLearnt about RAR, and what it looks like compared to 50-50 allocation\nLiterature search on the question on multiplicity and bayesian statistics\nCauchy distribution for logistic regression coefficient prior\nread more\nIf you like this article:\nplease feel free to send me a\ncomment or visit my other blogs\nplease feel free to follow me on\nBlueSky\n,\ntwitter\n,\nGitHub\nor\nMastodon\nif you would like collaborate please feel free to\ncontact me\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nr on Everyday Is A School Day\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
      "meta_description": "In my simulations of Response Adaptive Randomization, I discovered it performs comparably to fixed 50-50 allocation in identifying treatment effects. The adaptive approach does appear to work! However, with only 10 trials, I’ve merely scratched the surface. Important limitations exist - temporal bias risks, statistical inefficiency, and complex multiplicity adjustments in Bayesian frameworks. Objectives What Is Response Adaptive Randomization? Adaptive Formula for Response Adaptive Randomization Simulation Plan Adaptive vs 50-50 Allocation Code Interpretation Limitations Opportunity for Improvement Lessons Learnt What Is Response Adaptive Randomization? Response-Adaptive Randomization (RAR) is a technique used in clinical trials where the allocation of patients to different treatment arms changes based on interim results collected during the trial. Unlike traditional fixed randomization where treatment allocation ratios remain constant throughout the study, RAR adjusts the probability of assignment to treatment groups as data accumulates, typically to assign more patients to treatments that appear to be performing better. This approach is designed to achieve two main goals: to maximize the information gained about superior treatments while minimizing the number of patients exposed to inferior treatments during the trial itself. The primary motivation for using RAR is ethical - it aims to treat more trial participants effectively while still gathering sufficient data for scientific conclusions. It’s particularly considered in trials involving serious conditions with high mortality rates or in multi-arm trials where several experimental treatments are being compared. RAR has received considerable theoretical attention since the 1930s but remains controversial in practice, with proponents citing its potential ethical advantages while critics point to concerns about statistical validity, potential bias from temporal trends, and increased complexity in trial design and analysis. REMAP-CAP was the first study that I came across that introduced me to this design and I found the theory quite intriguing and interesting! It does appear too good to be true but for me, I cannot get the intuition behind how the adaptive randomization be able to identify it. Fortunately, there is another way we can convince ourselves that this works, and that is to simulate it for ourselves, Bayesian style! Adaptive Formula for Response Adaptive Randomization Thall and Wathen approach This is a commonly used formula that adjusts randomization probabilities based on posterior probabilities. For a two-arm trial, the probability of assigning a patient to treatment 1 is: \\begin{gather} π₁,ᵢ = \\frac{[P(p₁ > p₀|data)]^c}{[P(p₁ > p₀|data)]^c + [1-P(p₁ > p₀|data)]^c} \\end{gather} Where P(p₁ > p₀|data) is the posterior probability that treatment 1 is better than treatment 0, and c is a tuning parameter that controls adaptation speed. When c=0, this reduces to equal randomization; when c=1, it becomes Thompson Sampling. There may be other approaches to RAR, but this is the one that makes sense and easy to implement. Dive deeper Simulation Plan Hopefully simulating this multiple times might give me a better idea of how it will work in practice. How do we do that? Adaptive vs 50-50 Allocation Set up a world where we have the entire population and we know how they respond with and without treatment. We’re going to set treatment effect as -1.09, which means the treatment is better at reducing some proportion of event than the control. The formula would be log odds = b0 + b1 * treatment, where b0 is 0, and b1 is our treatment effect. We will then write a code to simulate both Response Adaptive Randomization and 50-50 allocation, with a 50 sets. Each set will then have 4 sequential analyses and sampling. The first analysis will have 50 patients with random allocation with 50%. For subsequent interim analyses, response adaptive randomization group will depend on the response, whereas 50-50 allocation group will remain as 50%. For adatpive randomization, we will use Thall and Wathen approach with c between 0 and 0.5. We will use Thall and Warten’s formula for updating the c with n / (2*N), where n is the number of patients sampled thus far plus the ones will be sampled this in interim trial, and N is the maximum number of patients in the trial. As you can see, when total of 200 patients sampled, c will be 0.5 at the last interim analysis. Each trial for both groups is set with the same seed to ensure reproducibility. After each trial, we extract the coefficient of interest (in our case beta1), and also assess what is the probability of beta1 being less than 0, which means the treatment is helpful at reducing whatever outcome we want to reduce. Questions I Have For Myself What is the difference between Response Adaptive Randomization and 50-50 allocation in terms of treatment effect estimates? Will RAR have the same accuracy at identifying treatment effect? Will RAR reach identify treatment effect faster than 50-50 allocation? If there is no effect, will RAR be able to tease that out to? And what would that look like? Code library(tidyverse) library(cmdstanr) library(glue) ## comparing 50-50 allocation vs Adaptive Randomization method_list",
      "meta_keywords": null,
      "og_description": "In my simulations of Response Adaptive Randomization, I discovered it performs comparably to fixed 50-50 allocation in identifying treatment effects. The adaptive approach does appear to work! However, with only 10 trials, I’ve merely scratched the surface. Important limitations exist - temporal bias risks, statistical inefficiency, and complex multiplicity adjustments in Bayesian frameworks. Objectives What Is Response Adaptive Randomization? Adaptive Formula for Response Adaptive Randomization Simulation Plan Adaptive vs 50-50 Allocation Code Interpretation Limitations Opportunity for Improvement Lessons Learnt What Is Response Adaptive Randomization? Response-Adaptive Randomization (RAR) is a technique used in clinical trials where the allocation of patients to different treatment arms changes based on interim results collected during the trial. Unlike traditional fixed randomization where treatment allocation ratios remain constant throughout the study, RAR adjusts the probability of assignment to treatment groups as data accumulates, typically to assign more patients to treatments that appear to be performing better. This approach is designed to achieve two main goals: to maximize the information gained about superior treatments while minimizing the number of patients exposed to inferior treatments during the trial itself. The primary motivation for using RAR is ethical - it aims to treat more trial participants effectively while still gathering sufficient data for scientific conclusions. It’s particularly considered in trials involving serious conditions with high mortality rates or in multi-arm trials where several experimental treatments are being compared. RAR has received considerable theoretical attention since the 1930s but remains controversial in practice, with proponents citing its potential ethical advantages while critics point to concerns about statistical validity, potential bias from temporal trends, and increased complexity in trial design and analysis. REMAP-CAP was the first study that I came across that introduced me to this design and I found the theory quite intriguing and interesting! It does appear too good to be true but for me, I cannot get the intuition behind how the adaptive randomization be able to identify it. Fortunately, there is another way we can convince ourselves that this works, and that is to simulate it for ourselves, Bayesian style! Adaptive Formula for Response Adaptive Randomization Thall and Wathen approach This is a commonly used formula that adjusts randomization probabilities based on posterior probabilities. For a two-arm trial, the probability of assigning a patient to treatment 1 is: \\begin{gather} π₁,ᵢ = \\frac{[P(p₁ > p₀|data)]^c}{[P(p₁ > p₀|data)]^c + [1-P(p₁ > p₀|data)]^c} \\end{gather} Where P(p₁ > p₀|data) is the posterior probability that treatment 1 is better than treatment 0, and c is a tuning parameter that controls adaptation speed. When c=0, this reduces to equal randomization; when c=1, it becomes Thompson Sampling. There may be other approaches to RAR, but this is the one that makes sense and easy to implement. Dive deeper Simulation Plan Hopefully simulating this multiple times might give me a better idea of how it will work in practice. How do we do that? Adaptive vs 50-50 Allocation Set up a world where we have the entire population and we know how they respond with and without treatment. We’re going to set treatment effect as -1.09, which means the treatment is better at reducing some proportion of event than the control. The formula would be log odds = b0 + b1 * treatment, where b0 is 0, and b1 is our treatment effect. We will then write a code to simulate both Response Adaptive Randomization and 50-50 allocation, with a 50 sets. Each set will then have 4 sequential analyses and sampling. The first analysis will have 50 patients with random allocation with 50%. For subsequent interim analyses, response adaptive randomization group will depend on the response, whereas 50-50 allocation group will remain as 50%. For adatpive randomization, we will use Thall and Wathen approach with c between 0 and 0.5. We will use Thall and Warten’s formula for updating the c with n / (2*N), where n is the number of patients sampled thus far plus the ones will be sampled this in interim trial, and N is the maximum number of patients in the trial. As you can see, when total of 200 patients sampled, c will be 0.5 at the last interim analysis. Each trial for both groups is set with the same seed to ensure reproducibility. After each trial, we extract the coefficient of interest (in our case beta1), and also assess what is the probability of beta1 being less than 0, which means the treatment is helpful at reducing whatever outcome we want to reduce. Questions I Have For Myself What is the difference between Response Adaptive Randomization and 50-50 allocation in terms of treatment effect estimates? Will RAR have the same accuracy at identifying treatment effect? Will RAR reach identify treatment effect faster than 50-50 allocation? If there is no effect, will RAR be able to tease that out to? And what would that look like? Code library(tidyverse) library(cmdstanr) library(glue) ## comparing 50-50 allocation vs Adaptive Randomization method_list",
      "og_image": "https://www.kenkoonwong.com/blog/rar/dice.jpg",
      "og_title": "Simulating A Simple Response Adaptive Randomization – I Have To See It To Believe It | R-bloggers",
      "raw_jsonld_article": null,
      "reading_time_min": 12.2,
      "sitemap_lastmod": null,
      "twitter_description": "In my simulations of Response Adaptive Randomization, I discovered it performs comparably to fixed 50-50 allocation in identifying treatment effects. The adaptive approach does appear to work! However, with only 10 trials, I’ve merely scratched the surface. Important limitations exist - temporal bias risks, statistical inefficiency, and complex multiplicity adjustments in Bayesian frameworks. Objectives What Is Response Adaptive Randomization? Adaptive Formula for Response Adaptive Randomization Simulation Plan Adaptive vs 50-50 Allocation Code Interpretation Limitations Opportunity for Improvement Lessons Learnt What Is Response Adaptive Randomization? Response-Adaptive Randomization (RAR) is a technique used in clinical trials where the allocation of patients to different treatment arms changes based on interim results collected during the trial. Unlike traditional fixed randomization where treatment allocation ratios remain constant throughout the study, RAR adjusts the probability of assignment to treatment groups as data accumulates, typically to assign more patients to treatments that appear to be performing better. This approach is designed to achieve two main goals: to maximize the information gained about superior treatments while minimizing the number of patients exposed to inferior treatments during the trial itself. The primary motivation for using RAR is ethical - it aims to treat more trial participants effectively while still gathering sufficient data for scientific conclusions. It’s particularly considered in trials involving serious conditions with high mortality rates or in multi-arm trials where several experimental treatments are being compared. RAR has received considerable theoretical attention since the 1930s but remains controversial in practice, with proponents citing its potential ethical advantages while critics point to concerns about statistical validity, potential bias from temporal trends, and increased complexity in trial design and analysis. REMAP-CAP was the first study that I came across that introduced me to this design and I found the theory quite intriguing and interesting! It does appear too good to be true but for me, I cannot get the intuition behind how the adaptive randomization be able to identify it. Fortunately, there is another way we can convince ourselves that this works, and that is to simulate it for ourselves, Bayesian style! Adaptive Formula for Response Adaptive Randomization Thall and Wathen approach This is a commonly used formula that adjusts randomization probabilities based on posterior probabilities. For a two-arm trial, the probability of assigning a patient to treatment 1 is: \\begin{gather} π₁,ᵢ = \\frac{[P(p₁ > p₀|data)]^c}{[P(p₁ > p₀|data)]^c + [1-P(p₁ > p₀|data)]^c} \\end{gather} Where P(p₁ > p₀|data) is the posterior probability that treatment 1 is better than treatment 0, and c is a tuning parameter that controls adaptation speed. When c=0, this reduces to equal randomization; when c=1, it becomes Thompson Sampling. There may be other approaches to RAR, but this is the one that makes sense and easy to implement. Dive deeper Simulation Plan Hopefully simulating this multiple times might give me a better idea of how it will work in practice. How do we do that? Adaptive vs 50-50 Allocation Set up a world where we have the entire population and we know how they respond with and without treatment. We’re going to set treatment effect as -1.09, which means the treatment is better at reducing some proportion of event than the control. The formula would be log odds = b0 + b1 * treatment, where b0 is 0, and b1 is our treatment effect. We will then write a code to simulate both Response Adaptive Randomization and 50-50 allocation, with a 50 sets. Each set will then have 4 sequential analyses and sampling. The first analysis will have 50 patients with random allocation with 50%. For subsequent interim analyses, response adaptive randomization group will depend on the response, whereas 50-50 allocation group will remain as 50%. For adatpive randomization, we will use Thall and Wathen approach with c between 0 and 0.5. We will use Thall and Warten’s formula for updating the c with n / (2*N), where n is the number of patients sampled thus far plus the ones will be sampled this in interim trial, and N is the maximum number of patients in the trial. As you can see, when total of 200 patients sampled, c will be 0.5 at the last interim analysis. Each trial for both groups is set with the same seed to ensure reproducibility. After each trial, we extract the coefficient of interest (in our case beta1), and also assess what is the probability of beta1 being less than 0, which means the treatment is helpful at reducing whatever outcome we want to reduce. Questions I Have For Myself What is the difference between Response Adaptive Randomization and 50-50 allocation in terms of treatment effect estimates? Will RAR have the same accuracy at identifying treatment effect? Will RAR reach identify treatment effect faster than 50-50 allocation? If there is no effect, will RAR be able to tease that out to? And what would that look like? Code library(tidyverse) library(cmdstanr) library(glue) ## comparing 50-50 allocation vs Adaptive Randomization method_list",
      "twitter_title": "Simulating A Simple Response Adaptive Randomization – I Have To See It To Believe It | R-bloggers",
      "url": "https://www.r-bloggers.com/2025/05/simulating-a-simple-response-adaptive-randomization-i-have-to-see-it-to-believe-it/",
      "word_count": 2435
    }
  }
}