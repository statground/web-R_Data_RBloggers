{
  "uuid": "1708214c-a54c-4dda-8397-f6a6da184fe6",
  "created_at": "2025-11-22 19:58:27",
  "raw_json": {
    "article_author": null,
    "article_headline": null,
    "article_modified": null,
    "article_published": null,
    "article_section": null,
    "article_tags": null,
    "canonical_url": "https://www.r-bloggers.com/2025/06/beyond-arma-garch-leveraging-model-agnostic-machine-learning-and-conformal-prediction-for-nonparametric-probabilistic-stock-forecasting-ml-arch/",
    "crawled_at": "2025-11-22T10:47:57.036983",
    "external_links": [
      {
        "href": "https://thierrymoudiki.github.io//blog/2025/06/02/r/beyond-garch",
        "text": "T. Moudiki's Webpage - R"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      },
      {
        "href": "https://thierrymoudiki.github.io/blog/2024/12/29/r/stock-forecasting",
        "text": "not point forecasting"
      },
      {
        "href": "https://en.wikipedia.org/wiki/Autoregressive_conditional_heteroskedasticity",
        "text": "ARMA for the mean and GARCH for volatility"
      },
      {
        "href": "https://thierrymoudiki.github.io//blog/2025/06/02/r/beyond-garch",
        "text": "T. Moudiki's Webpage - R"
      },
      {
        "href": "https://feedburner.google.com/fb/a/mailverify?uri=RBloggers",
        "text": "daily e-mail updates"
      },
      {
        "href": "https://www.r-project.org/",
        "text": "R"
      },
      {
        "href": "https://www.r-users.com/",
        "text": "Click here if you're looking to post or find an R/data-science job"
      },
      {
        "href": "http://r-posts.com/",
        "text": "here"
      }
    ],
    "h1_title": "R-bloggers",
    "html_title": "Beyond ARMA-GARCH: leveraging model-agnostic Machine Learning and conformal prediction for nonparametric probabilistic stock forecasting (ML-ARCH) | R-bloggers",
    "images": [
      {
        "alt": "image-title-here",
        "base64": "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7",
        "src": "https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif"
      },
      {
        "alt": "image-title-here",
        "base64": null,
        "src": "https://i0.wp.com/thierrymoudiki.github.io/images/2025-06-02/2025-06-02-image1.png?w=578&ssl=1"
      }
    ],
    "internal_links": [
      {
        "href": "https://www.r-bloggers.com/author/t-moudiki/",
        "text": "T. Moudiki"
      },
      {
        "href": "https://www.r-bloggers.com/category/r-bloggers/",
        "text": "R bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers"
      },
      {
        "href": "https://www.r-bloggers.com/contact-us/",
        "text": "here"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      },
      {
        "href": "https://www.r-bloggers.com/",
        "text": "R-bloggers.com"
      },
      {
        "href": "https://www.r-bloggers.com/how-to-learn-r-2/",
        "text": "learning R"
      },
      {
        "href": "https://www.r-bloggers.com/add-your-blog/",
        "text": "click here"
      }
    ],
    "lang": "en-US",
    "main_html": "<article class=\"post-392821 post type-post status-publish format-standard hentry category-r-bloggers\">\n<header class=\"post-header\">\n<h1 class=\"entry-title\">Beyond ARMA-GARCH: leveraging model-agnostic Machine Learning and conformal prediction for nonparametric probabilistic stock forecasting (ML-ARCH)</h1>\n<p class=\"meta post-meta\">Posted on <span class=\"updated\">June 1, 2025</span>  by <span class=\"vcard author\"><a class=\"fn\" href=\"https://www.r-bloggers.com/author/t-moudiki/\">T. Moudiki</a></span>  in <a href=\"https://www.r-bloggers.com/category/r-bloggers/\" rel=\"category tag\">R bloggers</a> | 0 Comments</p>\n</header>\n<div class=\"entry clearfix\">\n<!-- \n<div style=\"min-height: 30px;\">\n[social4i size=\"small\" align=\"align-left\"]\n</div>\n-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 12px;\">\n[This article was first published on  <strong><a href=\"https://thierrymoudiki.github.io//blog/2025/06/02/r/beyond-garch\"> T. Moudiki's Webpage - R</a></strong>, and kindly contributed to <a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers</a>].  (You can report issue about the content on this page <a href=\"https://www.r-bloggers.com/contact-us/\">here</a>)\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div>\n\n<!-- Share buttons by mashshare.net - Version: 4.0.47--><h1 id=\"introduction\">Introduction</h1>\n<p>Probabilistic (<a href=\"https://thierrymoudiki.github.io/blog/2024/12/29/r/stock-forecasting\" rel=\"nofollow\" target=\"_blank\">not point forecasting</a>) stock forecasting is notably useful for <strong>testing trading strategies</strong> or <strong>risk capital valuation</strong>. Because stock prices exhibit a latent stochastic volatility, this type of forecasting methods relies on classical  parametric models like <a href=\"https://en.wikipedia.org/wiki/Autoregressive_conditional_heteroskedasticity\" rel=\"nofollow\" target=\"_blank\">ARMA for the mean and GARCH for volatility</a>.</p>\n<p><strong>This post offers a flexible hybrid alternative to ARMA-GARCH, combining conformal prediction and machine learning approaches with AutoRegressive Conditional Heteroskedastic (ARCH) effects.</strong></p>\n<p>The model decomposes the time series into two components:</p>\n<ol>\n<li>Mean component: \\(y_t = \\mu_t + \\sigma_t \\varepsilon_t\\)</li>\n<li>Volatility component: \\(\\sigma_t^2 = f(\\varepsilon_{t-1}^2, \\varepsilon_{t-2}^2, …)\\)</li>\n</ol>\n<p>where:</p>\n<ul>\n<li>\\(\\mu_t\\) is the conditional mean (modeled using <strong>any forecasting method</strong>)</li>\n<li>\\(\\sigma_t\\) is the conditional volatility (modeled using <strong>machine learning</strong>)</li>\n<li>\\(\\varepsilon_t\\) are standardized residuals</li>\n</ul>\n<p>The <strong>key innovation</strong> is using any time series model for mean forecast, and machine learning methods + conformal prediction to model the volatility component, allowing for more flexible and potentially more accurate volatility forecasts than traditional GARCH models. The function supports various machine learning methods through parameters <code>fit_func</code> and <code>predict_func</code> as in other <code>ahead</code> models, and through the <code>caret</code> package.</p>\n<p>The forecasting process involves:</p>\n<ul>\n<li>Fitting a mean model (default: <code>auto.arima</code>)</li>\n<li>Modeling the squared residuals using machine learning. For this to work, the residuals from the mean model need to be centered, so that</li>\n</ul>\n\n\\[\\mathbb{E}[\\epsilon_t^2|F_{t-1}]\\]\n\n<p>(basically a supervised regression of squared residuals on their lags) is a good approximation of the latent conditional volatility</p>\n<ul>\n<li>Conformalizing the standardized residuals for prediction intervals</li>\n</ul>\n<p>This new approach combines the interpretability of traditional time series models with the flexibility of machine learning, while maintaining proper uncertainty quantification through conformal prediction.</p>\n<h1 id=\"basic-usage\">Basic Usage</h1>\n<p>Install package:</p>\n<pre>options(repos = c(\n                    techtonique = \"https://r-packages.techtonique.net\",\n                    CRAN = \"https://cloud.r-project.org\"\n                ))\n\ninstall.packages(\"ahead\")            \n</pre>\n<p>Let’s start with a simple example using the Google stock price data from the <code>fpp2</code> package:</p>\n<pre>library(forecast)\nlibrary(ahead)\nlibrary(randomForest)\nlibrary(e1071)\nlibrary(glmnet)\n\ny &lt;- fpp2::goog200\n\n# Default model for volatility (Ridge regression for volatility)\n(obj_ridge &lt;- ahead::mlarchf(y, h=20L, B=500L))\n</pre>\n<h1 id=\"different-machine-learning-methods\">Different Machine Learning Methods</h1>\n<p>The package supports various machine learning methods for volatility modeling. Here are some examples:</p>\n<pre># Random Forest\n(obj_rf &lt;- ahead::mlarchf(y, fit_func = randomForest::randomForest, \n                     predict_func = predict, h=20L, B=500L))\n\n# Support Vector Machine\n(obj_svm &lt;- ahead::mlarchf(y, fit_func = e1071::svm, \n                     predict_func = predict, h=20L, B=500L))\n\n# Elastic Net\n(obj_glmnet &lt;- ahead::mlarchf(y, fit_func = glmnet::cv.glmnet, \n                     predict_func = predict, h=20L, B=500L))\n</pre>\n<p>Let’s visualize the forecasts:</p>\n<pre>par(mfrow=c(1, 2))\nplot(obj_ridge, main=\"Ridge Regression\")\nplot(obj_rf, main=\"Random Forest\")\n\npar(mfrow=c(1, 2))\nplot(obj_svm, main=\"Support Vector Machine\")\nplot(obj_glmnet, main=\"Elastic Net\")\n</pre>\n<p><img alt=\"image-title-here\" class=\"img-responsive\" data-lazy-src=\"https://i0.wp.com/thierrymoudiki.github.io/images/2025-06-02/2025-06-02-image1.png?w=578&amp;ssl=1\" data-recalc-dims=\"1\" src=\"https://www.r-bloggers.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif\"/><noscript><img alt=\"image-title-here\" class=\"img-responsive\" data-recalc-dims=\"1\" src=\"https://i0.wp.com/thierrymoudiki.github.io/images/2025-06-02/2025-06-02-image1.png?w=578&amp;ssl=1\"/></noscript></p>\n<h1 id=\"using-caret-models\">Using caret Models</h1>\n<p>The package also supports models from the <code>caret</code> package, which provides access to hundreds of machine learning methods. Here’s how to use them:</p>\n<pre>y &lt;- window(fpp2::goog200, start=100)\n\n# Random Forest via caret\n(obj_rf &lt;- ahead::mlarchf(y, ml_method=\"ranger\", h=20L))\n\n# Gradient Boosting via caret\n(obj_glmboost &lt;- ahead::mlarchf(y, ml_method=\"glmboost\", h=20L))\n</pre>\n<p>Visualizing the forecasts:</p>\n<pre>par(mfrow=c(1, 2))\nplot(obj_rf, main=\"Random Forest (caret)\")\nplot(obj_glmboost, main=\"Gradient Boosting (caret)\")\n</pre>\n<p>Looking at the simulation paths:</p>\n<pre>par(mfrow=c(1, 2))\nmatplot(obj_rf$sims, type='l', main=\"RF Simulation Paths\")\nmatplot(obj_glmboost$sims, type='l', main=\"GBM Simulation Paths\")\n</pre>\n<h1 id=\"customizing-mean-and-residual-models\">Customizing Mean and Residual Models</h1>\n<p>You can also customize both the mean forecasting model and the model for forecasting standardized residuals:</p>\n<pre># Using Theta method for both mean and residuals\n(obj_svm &lt;- ahead::mlarchf(y, fit_func = e1071::svm, \n                     predict_func = predict, h=20L, \n                     mean_model=forecast::rwf,\n                     model_residuals=forecast::thetaf))\n\n(obj_glmnet &lt;- ahead::mlarchf(y, fit_func = glmnet::cv.glmnet, \n                     predict_func = predict, h=20L, \n                     mean_model=forecast::thetaf,\n                     model_residuals=forecast::thetaf))\n\npar(mfrow=c(1, 2))\nplot(obj_svm, main=\"SVM with Theta\")\nplot(obj_glmnet, main=\"Elastic Net with Theta\")\n</pre>\n<p>When using non-ARIMA models for the mean forecast, it’s important to check if the residuals are centered and stationary:</p>\n<pre># Diagnostic tests for residuals\nprint(obj_svm$resids_t_test)\n## \n##  One Sample t-test\n## \n## data:  resids\n## t = 1.0148, df = 99, p-value = 0.3127\n## alternative hypothesis: true mean is not equal to 0\n## 95 percent confidence interval:\n##  -0.7180739  2.2214961\n## sample estimates:\n## mean of x \n## 0.7517111\nprint(obj_svm$resids_kpss_test)\n## \n##  KPSS Test for Level Stationarity\n## \n## data:  resids\n## KPSS Level = 7.5912e-76, Truncation lag parameter = 4, p-value = 0.1\nprint(obj_glmnet$resids_t_test)\n## \n##  One Sample t-test\n## \n## data:  resids\n## t = 1.0992, df = 100, p-value = 0.2743\n## alternative hypothesis: true mean is not equal to 0\n## 95 percent confidence interval:\n##  -0.6460748  2.2513707\n## sample estimates:\n## mean of x \n## 0.8026479\nprint(obj_glmnet$resids_kpss_test)\n## \n##  KPSS Test for Level Stationarity\n## \n## data:  resids\n## KPSS Level = 0.26089, Truncation lag parameter = 4, p-value = 0.1\n</pre>\n<div class=\"jp-relatedposts\" id=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n<!-- Share buttons by mashshare.net - Version: 4.0.47-->\n<div style=\"border: 1px solid; background: none repeat scroll 0 0 #EDEDED; margin: 1px; font-size: 13px;\">\n<div style=\"text-align: center;\">To <strong>leave a comment</strong> for the author, please follow the link and comment on their blog: <strong><a href=\"https://thierrymoudiki.github.io//blog/2025/06/02/r/beyond-garch\"> T. Moudiki's Webpage - R</a></strong>.</div>\n<hr/>\n<a href=\"https://www.r-bloggers.com/\" rel=\"nofollow\">R-bloggers.com</a> offers <strong><a href=\"https://feedburner.google.com/fb/a/mailverify?uri=RBloggers\" rel=\"nofollow\">daily e-mail updates</a></strong> about <a href=\"https://www.r-project.org/\" rel=\"nofollow\" title=\"The R Project for Statistical Computing\">R</a> news and tutorials about <a href=\"https://www.r-bloggers.com/how-to-learn-r-2/\" rel=\"nofollow\" title=\"R tutorials\">learning R</a> and many other topics. <a href=\"https://www.r-users.com/\" rel=\"nofollow\" title=\"Data science jobs\">Click here if you're looking to post or find an R/data-science job</a>.\n\n<hr/>Want to share your content on R-bloggers?<a href=\"https://www.r-bloggers.com/add-your-blog/\" rel=\"nofollow\"> click here</a> if you have a blog, or <a href=\"http://r-posts.com/\" rel=\"nofollow\"> here</a> if you don't.\n</div> </div>\n</article>",
    "main_text": "Beyond ARMA-GARCH: leveraging model-agnostic Machine Learning and conformal prediction for nonparametric probabilistic stock forecasting (ML-ARCH)\nPosted on\nJune 1, 2025\nby\nT. Moudiki\nin\nR bloggers\n| 0 Comments\n[This article was first published on\nT. Moudiki's Webpage - R\n, and kindly contributed to\nR-bloggers\n].  (You can report issue about the content on this page\nhere\n)\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.\nIntroduction\nProbabilistic (\nnot point forecasting\n) stock forecasting is notably useful for\ntesting trading strategies\nor\nrisk capital valuation\n. Because stock prices exhibit a latent stochastic volatility, this type of forecasting methods relies on classical  parametric models like\nARMA for the mean and GARCH for volatility\n.\nThis post offers a flexible hybrid alternative to ARMA-GARCH, combining conformal prediction and machine learning approaches with AutoRegressive Conditional Heteroskedastic (ARCH) effects.\nThe model decomposes the time series into two components:\nMean component: \\(y_t = \\mu_t + \\sigma_t \\varepsilon_t\\)\nVolatility component: \\(\\sigma_t^2 = f(\\varepsilon_{t-1}^2, \\varepsilon_{t-2}^2, …)\\)\nwhere:\n\\(\\mu_t\\) is the conditional mean (modeled using\nany forecasting method\n)\n\\(\\sigma_t\\) is the conditional volatility (modeled using\nmachine learning\n)\n\\(\\varepsilon_t\\) are standardized residuals\nThe\nkey innovation\nis using any time series model for mean forecast, and machine learning methods + conformal prediction to model the volatility component, allowing for more flexible and potentially more accurate volatility forecasts than traditional GARCH models. The function supports various machine learning methods through parameters\nfit_func\nand\npredict_func\nas in other\nahead\nmodels, and through the\ncaret\npackage.\nThe forecasting process involves:\nFitting a mean model (default:\nauto.arima\n)\nModeling the squared residuals using machine learning. For this to work, the residuals from the mean model need to be centered, so that\n\\[\\mathbb{E}[\\epsilon_t^2|F_{t-1}]\\]\n(basically a supervised regression of squared residuals on their lags) is a good approximation of the latent conditional volatility\nConformalizing the standardized residuals for prediction intervals\nThis new approach combines the interpretability of traditional time series models with the flexibility of machine learning, while maintaining proper uncertainty quantification through conformal prediction.\nBasic Usage\nInstall package:\noptions(repos = c(\n                    techtonique = \"https://r-packages.techtonique.net\",\n                    CRAN = \"https://cloud.r-project.org\"\n                ))\n\ninstall.packages(\"ahead\")\nLet’s start with a simple example using the Google stock price data from the\nfpp2\npackage:\nlibrary(forecast)\nlibrary(ahead)\nlibrary(randomForest)\nlibrary(e1071)\nlibrary(glmnet)\n\ny <- fpp2::goog200\n\n# Default model for volatility (Ridge regression for volatility)\n(obj_ridge <- ahead::mlarchf(y, h=20L, B=500L))\nDifferent Machine Learning Methods\nThe package supports various machine learning methods for volatility modeling. Here are some examples:\n# Random Forest\n(obj_rf <- ahead::mlarchf(y, fit_func = randomForest::randomForest, \n                     predict_func = predict, h=20L, B=500L))\n\n# Support Vector Machine\n(obj_svm <- ahead::mlarchf(y, fit_func = e1071::svm, \n                     predict_func = predict, h=20L, B=500L))\n\n# Elastic Net\n(obj_glmnet <- ahead::mlarchf(y, fit_func = glmnet::cv.glmnet, \n                     predict_func = predict, h=20L, B=500L))\nLet’s visualize the forecasts:\npar(mfrow=c(1, 2))\nplot(obj_ridge, main=\"Ridge Regression\")\nplot(obj_rf, main=\"Random Forest\")\n\npar(mfrow=c(1, 2))\nplot(obj_svm, main=\"Support Vector Machine\")\nplot(obj_glmnet, main=\"Elastic Net\")\nUsing caret Models\nThe package also supports models from the\ncaret\npackage, which provides access to hundreds of machine learning methods. Here’s how to use them:\ny <- window(fpp2::goog200, start=100)\n\n# Random Forest via caret\n(obj_rf <- ahead::mlarchf(y, ml_method=\"ranger\", h=20L))\n\n# Gradient Boosting via caret\n(obj_glmboost <- ahead::mlarchf(y, ml_method=\"glmboost\", h=20L))\nVisualizing the forecasts:\npar(mfrow=c(1, 2))\nplot(obj_rf, main=\"Random Forest (caret)\")\nplot(obj_glmboost, main=\"Gradient Boosting (caret)\")\nLooking at the simulation paths:\npar(mfrow=c(1, 2))\nmatplot(obj_rf$sims, type='l', main=\"RF Simulation Paths\")\nmatplot(obj_glmboost$sims, type='l', main=\"GBM Simulation Paths\")\nCustomizing Mean and Residual Models\nYou can also customize both the mean forecasting model and the model for forecasting standardized residuals:\n# Using Theta method for both mean and residuals\n(obj_svm <- ahead::mlarchf(y, fit_func = e1071::svm, \n                     predict_func = predict, h=20L, \n                     mean_model=forecast::rwf,\n                     model_residuals=forecast::thetaf))\n\n(obj_glmnet <- ahead::mlarchf(y, fit_func = glmnet::cv.glmnet, \n                     predict_func = predict, h=20L, \n                     mean_model=forecast::thetaf,\n                     model_residuals=forecast::thetaf))\n\npar(mfrow=c(1, 2))\nplot(obj_svm, main=\"SVM with Theta\")\nplot(obj_glmnet, main=\"Elastic Net with Theta\")\nWhen using non-ARIMA models for the mean forecast, it’s important to check if the residuals are centered and stationary:\n# Diagnostic tests for residuals\nprint(obj_svm$resids_t_test)\n## \n##  One Sample t-test\n## \n## data:  resids\n## t = 1.0148, df = 99, p-value = 0.3127\n## alternative hypothesis: true mean is not equal to 0\n## 95 percent confidence interval:\n##  -0.7180739  2.2214961\n## sample estimates:\n## mean of x \n## 0.7517111\nprint(obj_svm$resids_kpss_test)\n## \n##  KPSS Test for Level Stationarity\n## \n## data:  resids\n## KPSS Level = 7.5912e-76, Truncation lag parameter = 4, p-value = 0.1\nprint(obj_glmnet$resids_t_test)\n## \n##  One Sample t-test\n## \n## data:  resids\n## t = 1.0992, df = 100, p-value = 0.2743\n## alternative hypothesis: true mean is not equal to 0\n## 95 percent confidence interval:\n##  -0.6460748  2.2513707\n## sample estimates:\n## mean of x \n## 0.8026479\nprint(obj_glmnet$resids_kpss_test)\n## \n##  KPSS Test for Level Stationarity\n## \n## data:  resids\n## KPSS Level = 0.26089, Truncation lag parameter = 4, p-value = 0.1\nRelated\nTo\nleave a comment\nfor the author, please follow the link and comment on their blog:\nT. Moudiki's Webpage - R\n.\nR-bloggers.com\noffers\ndaily e-mail updates\nabout\nR\nnews and tutorials about\nlearning R\nand many other topics.\nClick here if you're looking to post or find an R/data-science job\n.\nWant to share your content on R-bloggers?\nclick here\nif you have a blog, or\nhere\nif you don't.",
    "meta_description": "A flexible hybrid approach to probabilistic stock forecasting that combines machine learning with ARCH effects, offering an alternative to traditional ARMA-GARCH models",
    "meta_keywords": null,
    "og_description": "A flexible hybrid approach to probabilistic stock forecasting that combines machine learning with ARCH effects, offering an alternative to traditional ARMA-GARCH models",
    "og_image": "https://thierrymoudiki.github.io/images/2025-06-02/2025-06-02-image1.png",
    "og_title": "Beyond ARMA-GARCH: leveraging model-agnostic Machine Learning and conformal prediction for nonparametric probabilistic stock forecasting (ML-ARCH) | R-bloggers",
    "raw_jsonld_article": null,
    "reading_time_min": 4.7,
    "sitemap_lastmod": null,
    "twitter_description": "A flexible hybrid approach to probabilistic stock forecasting that combines machine learning with ARCH effects, offering an alternative to traditional ARMA-GARCH models",
    "twitter_title": "Beyond ARMA-GARCH: leveraging model-agnostic Machine Learning and conformal prediction for nonparametric probabilistic stock forecasting (ML-ARCH) | R-bloggers",
    "url": "https://www.r-bloggers.com/2025/06/beyond-arma-garch-leveraging-model-agnostic-machine-learning-and-conformal-prediction-for-nonparametric-probabilistic-stock-forecasting-ml-arch/",
    "word_count": 939
  }
}