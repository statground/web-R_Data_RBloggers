#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Generate / update repo-level crawl statistics for web-R_Data_RBloggers.

Design goals
- Fast even as by_created grows (incremental update using RBLOGGERS_COUNTS.json)
- Safe for GitHub Actions (no external deps)
- Does NOT affect DB sync: only writes *.md / *.json metadata at repo root
"""

from __future__ import annotations

import argparse
import json
import os
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Tuple


COUNTS_JSON = os.getenv("COUNTS_JSON", "RBLOGGERS_COUNTS.json")
STATS_MD = os.getenv("STATS_MD", "RBLOGGERS_REPO_STATS.md")
BASE_DIR = os.getenv("BASE_DIR", "by_created")
MAX_MONTH_ROWS = int(os.getenv("MAX_MONTH_ROWS", "48"))  # show recent N months


def utc_now() -> datetime:
    return datetime.now(timezone.utc).replace(microsecond=0)


def load_json(path: Path, default):
    if not path.exists():
        return default
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except Exception:
        return default


def save_json(path: Path, obj) -> None:
    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")


def human_bytes(n: int) -> str:
    # simple binary units
    units = ["B", "KiB", "MiB", "GiB", "TiB"]
    v = float(n)
    for u in units:
        if v < 1024.0 or u == units[-1]:
            if u == "B":
                return f"{int(v)} {u}"
            return f"{v:.2f} {u}"
        v /= 1024.0
    return f"{n} B"


def parse_year_month(relpath: str) -> Tuple[str, str]:
    # expected: by_created/YYYY/MM/<id>.json
    parts = Path(relpath).parts
    # tolerate leading repo root
    try:
        idx = parts.index(BASE_DIR)
        y = parts[idx + 1]
        m = parts[idx + 2]
        return y, m
    except Exception:
        return "unknown", "unknown"


def read_action_result(repo_root: Path, action_result_path: str) -> Dict:
    p = repo_root / action_result_path
    return load_json(p, default={})


def add_file_counts(by_month: Dict, ym: str, bytes_n: int) -> None:
    if ym not in by_month:
        by_month[ym] = {"files": 0, "bytes": 0}
    by_month[ym]["files"] = int(by_month[ym].get("files", 0)) + 1
    by_month[ym]["bytes"] = int(by_month[ym].get("bytes", 0)) + int(bytes_n)


def render_md(*, updated_at: str, totals: Dict, by_month: Dict, last_run: Dict) -> str:
    total_files = int(totals.get("total_files", 0))
    total_bytes = int(totals.get("total_bytes", 0))
    months_sorted = sorted(by_month.items(), key=lambda x: x[0], reverse=True)
    months_sorted = months_sorted[:MAX_MONTH_ROWS]

    # Compose markdown
    out = []
    out.append("# R-Bloggers Repo Stats")
    out.append(f"Updated: {updated_at}")
    out.append("")
    out.append("## Summary")
    out.append(f"- Total JSON files: {total_files:,}")
    out.append(f"- Total size: {human_bytes(total_bytes)}")
    if last_run:
        out.append(f"- Last run new files: {int(last_run.get('new_files', 0)):,}")
        if last_run.get("finished_at_utc"):
            out.append(f"- Last run finished: {last_run.get('finished_at_utc')}")
    out.append("")
    out.append("## Recent months (by_created/YYYY/MM)")
    out.append("Year-Month | Files | Size")
    out.append("---|---:|---:")
    for ym, v in months_sorted:
        out.append(f"{ym} | {int(v.get('files', 0)):,} | {human_bytes(int(v.get('bytes', 0)))}")
    out.append("")
    out.append("### Notes")
    out.append(f"- This report is generated by `scripts/update_repo_stats.py`.")
    out.append(f"- Counts are maintained incrementally in `{COUNTS_JSON}` using `.action_result.json` from the crawler.")
    out.append(f"- Only metadata files are written (`{STATS_MD}`, `{COUNTS_JSON}`); DB sync remains driven by JSON files under `{BASE_DIR}/`.")
    out.append("")
    return "\n".join(out)


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--repo-root", default=None, help="repo root (auto-detect by default)")
    ap.add_argument("--action-result", default=".action_result.json", help="path to action result json")
    args = ap.parse_args()

    repo_root = Path(args.repo_root).resolve() if args.repo_root else Path(__file__).resolve().parents[1]
    base_dir = repo_root / BASE_DIR
    counts_path = repo_root / COUNTS_JSON
    md_path = repo_root / STATS_MD

    now = utc_now()
    updated_at = now.isoformat().replace("+00:00", "Z")

    counts = load_json(counts_path, default={
        "updated_at_utc": None,
        "totals": {"total_files": 0, "total_bytes": 0},
        "by_month": {},
        "last_run": {},
    })

    totals = counts.get("totals") or {"total_files": 0, "total_bytes": 0}
    by_month = counts.get("by_month") or {}
    last_run = {}

    action = read_action_result(repo_root, args.action_result)
    new_files: List[str] = action.get("files") or []
    new_files = [f for f in new_files if isinstance(f, str) and f.endswith(".json") and (f.startswith(BASE_DIR + "/") or f.startswith(BASE_DIR + "\\"))]

    # Incremental update: add only newly created files this run
    newly_added = 0
    newly_bytes = 0
    for rel in new_files:
        p = repo_root / rel
        if not p.exists() or not p.is_file():
            continue
        size_n = p.stat().st_size
        y, m = parse_year_month(rel)
        ym = f"{y}-{m}"
        add_file_counts(by_month, ym, size_n)
        newly_added += 1
        newly_bytes += size_n

    # If counts file missing OR base_dir empty, keep as-is.
    totals["total_files"] = int(totals.get("total_files", 0)) + newly_added
    totals["total_bytes"] = int(totals.get("total_bytes", 0)) + newly_bytes

    last_run = {
        "new_files": newly_added,
        "new_bytes": newly_bytes,
        "finished_at_utc": updated_at,
    }

    counts["updated_at_utc"] = updated_at
    counts["totals"] = totals
    counts["by_month"] = by_month
    counts["last_run"] = last_run

    save_json(counts_path, counts)

    md = render_md(updated_at=updated_at, totals=totals, by_month=by_month, last_run=last_run)
    md_path.write_text(md, encoding="utf-8")

    print(f"[stats] wrote {md_path.name} and {counts_path.name}")
    print(f"[stats] +files={newly_added}, +bytes={newly_bytes}")


if __name__ == "__main__":
    main()
