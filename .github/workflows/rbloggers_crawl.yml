name: Crawl R-Bloggers (hourly)

on:
  schedule:
    - cron: "0 * * * *"
  workflow_dispatch:
    inputs:
      resync:
        description: "Force resync by_created files even if no new files"
        required: false
        default: "false"
      resync_month:
        description: "Optional: YYYY/MM (e.g. 2026/01). If empty, resync all by_created"
        required: false
        default: ""

concurrency:
  group: rbloggers-crawl-main
  cancel-in-progress: true

permissions:
  contents: write

jobs:
  crawl-and-sync:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f scripts/requirements.txt ]; then
            pip install -r scripts/requirements.txt
          else
            pip install requests beautifulsoup4 lxml
          fi

      - name: Crawl R-Bloggers
        run: |
          python scripts/crawl_rbloggers.py

      - name: Update Repository Stats
        run: |
          python scripts/update_repo_stats.py

      # Commit & Push, then compute changed by_created json files between BEFORE and AFTER
      - name: Commit and Push changes
        id: commit_push
        env:
          BEFORE_SHA: ${{ github.sha }}
        run: |
          set -e

          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          git add by_created/
          git add RBLOGGERS_COUNTS.json RBLOGGERS_REPO_STATS.md
          git add .action_result.json || true

          COMMITTED="0"
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "Auto Update: R-Bloggers Data & Stats ($(date +'%Y-%m-%d %H:%M'))"
            git push
            COMMITTED="1"
          fi

          AFTER_SHA="$(git rev-parse HEAD)"
          echo "committed=${COMMITTED}" >> "$GITHUB_OUTPUT"
          echo "sha=${AFTER_SHA}" >> "$GITHUB_OUTPUT"
          echo "ref=${GITHUB_REF_NAME}" >> "$GITHUB_OUTPUT"
          echo "repo=${GITHUB_REPOSITORY}" >> "$GITHUB_OUTPUT"

          # by_created 하위 json 변경 목록 추출(이번 실행에서 커밋이 없으면 빈 목록)
          if [ "${COMMITTED}" = "1" ]; then
            git diff --name-only "${BEFORE_SHA}" "${AFTER_SHA}" -- 'by_created/**/*.json' > /tmp/changed_files.txt || true
          else
            : > /tmp/changed_files.txt
          fi

          python - <<'PY'
          import json
          files=[]
          with open('/tmp/changed_files.txt','r',encoding='utf-8') as f:
            for line in f:
              p=line.strip()
              if p:
                files.append(p)
          print("changed by_created json files:", len(files))
          with open('/tmp/changed_files.json','w',encoding='utf-8') as f:
            json.dump(files, f, ensure_ascii=False)
          PY

          # Multiline-safe output
          echo "files_json<<EOF" >> "$GITHUB_OUTPUT"
          cat /tmp/changed_files.json >> "$GITHUB_OUTPUT"
          echo "" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"

      # Build file list for webhook: default=diff files; resync=true => glob by_created
      - name: Build file list for webhook
        id: build_files
        env:
          RESYNC: ${{ github.event.inputs.resync }}
          RESYNC_MONTH: ${{ github.event.inputs.resync_month }}
          DIFF_FILES_JSON: ${{ steps.commit_push.outputs.files_json }}
        run: |
          python - <<'PY'
          import os, json, glob

          resync = (os.environ.get("RESYNC","false") or "").lower() == "true"
          month  = (os.environ.get("RESYNC_MONTH","") or "").strip()
          diff_files = []
          try:
            diff_files = json.loads(os.environ.get("DIFF_FILES_JSON","[]"))
          except Exception:
            diff_files = []

          if not resync:
            files = diff_files
          else:
            if month:
              pattern = f"by_created/{month}/**/*.json"
            else:
              pattern = "by_created/**/*.json"
            files = [p.replace("\\","/") for p in glob.glob(pattern, recursive=True)]

          with open("files.json","w",encoding="utf-8") as f:
            json.dump(files, f, ensure_ascii=False)
          print("files_count:", len(files))
          PY

          echo "files_json<<EOF" >> "$GITHUB_OUTPUT"
          cat files.json >> "$GITHUB_OUTPUT"
          echo "" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"

      # Trigger Web-R Sync:
      # - Token header must be X-WEBR-SYNC-TOKEN
      # - Batched to avoid 504 Gateway Time-out
      - name: Trigger Web-R Sync (batched)
        if: always()
        env:
          WEBR_SYNC_URL: ${{ secrets.WEBR_SYNC_URL }}
          WEBR_SYNC_TOKEN: ${{ secrets.WEBR_SYNC_TOKEN }}
          GH_SHA: ${{ steps.commit_push.outputs.sha }}
          GH_REF_NAME: ${{ steps.commit_push.outputs.ref }}
          GH_REPO: ${{ steps.commit_push.outputs.repo }}
          FILES_JSON: ${{ steps.build_files.outputs.files_json }}
        run: |
          if [ -z "${WEBR_SYNC_URL:-}" ] || [ -z "${WEBR_SYNC_TOKEN:-}" ]; then
            echo "WEBR_SYNC_URL or WEBR_SYNC_TOKEN not set. Skipping sync."
            exit 0
          fi

          python - <<'PY'
          import os, json, math, subprocess, tempfile

          files = json.loads(os.environ.get("FILES_JSON","[]") or "[]")
          print("total_files:", len(files))
          if not files:
            print("No files. Skip webhook.")
            raise SystemExit(0)

          # Adjust batch size if needed (smaller => safer against timeouts)
          BATCH = int(os.environ.get("WEBR_SYNC_BATCH","200"))

          repo = os.environ.get("GH_REPO","")
          sha  = os.environ.get("GH_SHA","")
          ref  = os.environ.get("GH_REF_NAME","")
          url  = os.environ.get("WEBR_SYNC_URL","")
          token= os.environ.get("WEBR_SYNC_TOKEN","")

          total_batches = math.ceil(len(files)/BATCH) if BATCH > 0 else 1
          for idx, i in enumerate(range(0, len(files), BATCH), start=1):
            part = files[i:i+BATCH]
            payload = {"repo": repo, "sha": sha, "ref": ref, "files": part}
            with tempfile.NamedTemporaryFile("w", delete=False, encoding="utf-8", suffix=".json") as f:
              json.dump(payload, f, ensure_ascii=False)
              path = f.name
            print(f"batch {idx}/{total_batches} size={len(part)}")
            subprocess.check_call([
              "curl", "--fail-with-body", "-sS", "-X", "POST",
              "-H", "Content-Type: application/json",
              "-H", f"X-WEBR-SYNC-TOKEN: {token}",
              "-d", f"@{path}",
              url
            ])
          PY
