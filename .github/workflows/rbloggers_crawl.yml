name: Crawl R-Bloggers (hourly)

on:
  schedule:
    - cron: "0 * * * *"
  workflow_dispatch:

concurrency:
  group: rbloggers-crawl-main
  cancel-in-progress: true

permissions:
  contents: write

jobs:
  crawl-and-sync:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          clean: true

      - name: Sync to origin/main (before generating files)
        shell: bash
        run: |
          set -euo pipefail
          git fetch origin main
          git checkout main
          git reset --hard origin/main
          git clean -fd

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi

      - name: Crawl R-Bloggers -> by_created
        shell: bash
        run: |
          set -euo pipefail
          python scripts/crawl_rbloggers.py

      - name: Update repo stats (RBLOGGERS_REPO_STATS.md)
        shell: bash
        run: |
          set -euo pipefail
          python scripts/update_repo_stats.py

      - name: Commit & push (json + stats) + compute changed files
        id: commit_push
        shell: bash
        run: |
          set -euo pipefail

          BEFORE_SHA="${GITHUB_SHA}"

          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          git add -A

          COMMITTED="0"
          if git diff --cached --quiet; then
            echo "Nothing to commit."
          else
            git commit -m "chore: update rbloggers crawl + stats"
            git push origin main
            COMMITTED="1"
          fi

          AFTER_SHA="$(git rev-parse HEAD)"

          echo "committed=${COMMITTED}" >> "$GITHUB_OUTPUT"
          echo "before_sha=${BEFORE_SHA}" >> "$GITHUB_OUTPUT"
          echo "after_sha=${AFTER_SHA}" >> "$GITHUB_OUTPUT"
          echo "ref_name=${GITHUB_REF_NAME}" >> "$GITHUB_OUTPUT"
          echo "repo=${GITHUB_REPOSITORY}" >> "$GITHUB_OUTPUT"

          # 1) prefer .action_result.json (if your crawler writes file list here)
          FILES_JSON="[]"
          if [ -f ".action_result.json" ]; then
            FILES_JSON="$(python -c 'import json; obj=json.load(open(".action_result.json","r",encoding="utf-8")); files=obj.get("files",[]) or obj.get("new_files_relpaths",[]) or []; files=[f for f in files if isinstance(f,str) and f.startswith("by_created/") and f.endswith(".json")]; import json as _j; print(_j.dumps(files, ensure_ascii=False))' || echo '[]')"
          fi

          # 2) fallback to git diff (only if committed AND action_result empty)
          if [ "$COMMITTED" = "1" ]; then
            if [ "$FILES_JSON" = "[]" ]; then
              FILES_JSON="$(git diff --name-only "$BEFORE_SHA" "$AFTER_SHA" -- 'by_created/**/*.json' | python -c 'import sys,json; files=[l.strip() for l in sys.stdin if l.strip()]; print(json.dumps(files, ensure_ascii=False))')"
            fi
          fi

          # output files_json (multiline-safe)
          echo "files_json<<EOF" >> "$GITHUB_OUTPUT"
          echo "$FILES_JSON" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"

          echo "changed_files_count=$(python -c 'import json; import sys; print(len(json.loads(sys.argv[1])))' "$FILES_JSON")"

      - name: Sync JSON files to Web-R DB (skip if none)
        shell: bash
        env:
          WEBR_SYNC_URL: ${{ secrets.WEBR_SYNC_URL }}
          WEBR_SYNC_TOKEN: ${{ secrets.WEBR_SYNC_TOKEN }}

          GH_SHA: ${{ steps.commit_push.outputs.after_sha }}
          GH_REF_NAME: ${{ steps.commit_push.outputs.ref_name }}
          GH_REPO: ${{ steps.commit_push.outputs.repo }}

          FILES_JSON: ${{ steps.commit_push.outputs.files_json }}

          # 504 회피용: 배치 크기 (필요시 5로 낮추기)
          WEBR_SYNC_BATCH: "10"
        run: |
          set -euo pipefail

          if [ -z "${WEBR_SYNC_URL:-}" ] || [ -z "${WEBR_SYNC_TOKEN:-}" ]; then
            echo "WEBR_SYNC_URL or WEBR_SYNC_TOKEN not set. Skip DB sync."
            exit 0
          fi

          FILES_COUNT="$(python -c 'import os,json; print(len(json.loads(os.environ.get("FILES_JSON","[]"))))')"
          echo "files_count=${FILES_COUNT}"

          if [ "${FILES_COUNT}" = "0" ]; then
            echo "No files to sync. Skip webhook."
            exit 0
          fi

          python - <<'PY'
          import os, json, math, subprocess, tempfile, time

          def post_with_retry(cmd, retries=3):
            for attempt in range(1, retries+1):
              try:
                subprocess.check_call(cmd)
                return
              except subprocess.CalledProcessError:
                if attempt == retries:
                  raise
                wait = 10 * attempt
                print(f"curl failed (attempt {attempt}/{retries}). retry in {wait}s")
                time.sleep(wait)

          files = json.loads(os.environ["FILES_JSON"])
          batch = int(os.environ.get("WEBR_SYNC_BATCH","10") or "10")
          if batch <= 0:
            batch = 10

          payload_base = {
            "repo": os.environ.get("GH_REPO",""),
            "sha": os.environ.get("GH_SHA",""),
            "ref": os.environ.get("GH_REF_NAME",""),
          }

          url = os.environ["WEBR_SYNC_URL"]
          token = os.environ["WEBR_SYNC_TOKEN"]

          total = math.ceil(len(files)/batch)
          for idx, i in enumerate(range(0, len(files), batch), start=1):
            part = files[i:i+batch]
            payload = dict(payload_base)
            payload["files"] = part

            with tempfile.NamedTemporaryFile("w", delete=False, encoding="utf-8", suffix=".json") as f:
              json.dump(payload, f, ensure_ascii=False)
              path = f.name

            print(f"batch {idx}/{total} size={len(part)}")
            cmd = [
              "curl","--fail-with-body","-sS","-L","-X","POST", url,
              "-H","Content-Type: application/json",
              "-H",f"X-WEBR-SYNC-TOKEN: {token}",
              "--data-binary",f"@{path}",
            ]
            post_with_retry(cmd, retries=3)
            time.sleep(1)
          PY
